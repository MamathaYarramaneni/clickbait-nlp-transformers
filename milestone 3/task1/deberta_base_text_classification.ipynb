{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t3IxC6FH3HC4"
      },
      "source": [
        "#DeBERTa base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZQaWfFsFaNT",
        "outputId": "a3f6aefd-3dc0-4fcc-b003-baaaf1dc7a0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, evaluate\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.3 transformers-4.28.1 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "#install transformers datasets evaluate\n",
        "!pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "852d8f7b7e314e38b19729752dd9809a",
            "7ef2bc4eafd14d5fbda17f8d7afe122d",
            "a99191ae496e499f8612fac657d384c2",
            "35b0aa0387a14fe4b00dfc59447af139",
            "a3f35a23095140a0a8b473e3190e1ca3",
            "e6693bd77d694161962a0343ebdc0f40",
            "8ea4256e75a54222a279174294893f6d",
            "cdeee073d5ca40db8a3eb72b322d5a23",
            "0868f02c2ec3436aa196a09623b08655",
            "78c297ac70f84334b2e8ad022ac90552",
            "4d6c1d93b1404e5bb0227d12ca9d4cc0"
          ]
        },
        "id": "oqb9X5cE3HC5",
        "outputId": "476d1ce8-9e6b-4474-f030-93b3a36314fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-a39e475095145fe4/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "852d8f7b7e314e38b19729752dd9809a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#import the dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('csv', data_files={'train': 'df_train.csv',\n",
        "                                          'val': 'df_valid.csv',\n",
        "                                              'test': 'df_test.csv'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "67f3937162144adaad6399dc26d06faa",
            "d9c26949a5a4449cafd39259f52b8af9",
            "0d95ffcc94ee460f9e69a9e267aa58bb",
            "51d954f4a7714a3fbecc4ae72efe83d8",
            "8a4efda2dfa44fe79edceb6e8aa5a8c6",
            "b99a02d8df434bef934944f65bb04ede",
            "f00d60ef72f64221bafc69b1c6a80388",
            "48e000dd84a942d5bfbd33bbcd3e2fc0",
            "854fd95e31934c569e83e972b2e1e185",
            "612fc16828734ff2baeebcd405f0bed0",
            "65cbf682550c4fde8c1ab6471e52b4e6",
            "a4ae0fb455b6438d9c06f908c99868d9",
            "a75ab8a740d9482cb4185392d2965552",
            "df551dac8e0240359042d59e6e270f9d",
            "3a093a3ab742434ea33cb342e46f25d2",
            "20ea7298123746d2a463c6cd39b92221",
            "58836f9d07564a72931002031e866b15",
            "a64bf6f511d4453b9ef67ebe63e7a99b",
            "49903ba365e6467aaeb7b526b93ddd34",
            "60cf24c106d440f49e8f2e1a251804cd",
            "33590fc97a9a4d94acff0f9bee9ec6f8",
            "70fea9fc848142db9a99d63317a5abc6",
            "480f2b8dd0df4e84b9f146a325114c6a",
            "c03ba1131cc948e0ba8b97ec9c7d38d4",
            "0de2c5b1fbe8417a9514f47cd6e5faf9",
            "07641d0df0a143d58ef64ef930d7a334",
            "1846b5265a7d4391a3e99a4d92537515",
            "dc39cabc680e4609b8f06d4cc10283d8",
            "36f9583a1f8a4c3b87d60ba2722fa51f",
            "89595f8314a2425cbb2eddeccff709f0",
            "1ee3b3376d3241feaf43ad31308b6ca9",
            "4a20a2242cb146248577da3f9df479e8",
            "049dbd54824941a58c34c449fcbf0e57",
            "5b2c7928f1124d6d92d07b74bba8eb65",
            "6293968f3be0452693d849bfde3ed681",
            "1af12cd77e1c45bd9878b79f5bd67e32",
            "9f32332c4cb244759135bc09b6388de5",
            "a81f551f983d4ba0bf719c783372de9e",
            "4036bc8deb544a8dbc342d416a077fff",
            "4acb1838fc1947b3bec484df6248a881",
            "36fd0e48a6324827ac12d964bfbfb40d",
            "f24b984c91a54b02a1366a0dd3d63254",
            "6b341a8a4fbb4fe5a5ce7e946755a62a",
            "bb9971d522094fb3b4f02c422d27292f"
          ]
        },
        "id": "q9pdzcjO3HC5",
        "outputId": "a1fc19c3-3519-42bd-c7bc-8c69e371113e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67f3937162144adaad6399dc26d06faa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4ae0fb455b6438d9c06f908c99868d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "480f2b8dd0df4e84b9f146a325114c6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b2c7928f1124d6d92d07b74bba8eb65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#import the transformers and the tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV5ri_4l3HC5"
      },
      "outputs": [],
      "source": [
        "#preprocess the data by tokenizing the text\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length',\n",
        "                                max_length=128,\n",
        "                                truncation=True,\n",
        "                                return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVG-xFpD3HC5"
      },
      "outputs": [],
      "source": [
        "#declare dictionaries to map the labels\n",
        "id2label = {0: \"phrase\", 1: \"passage\", 2: \"multi\"}\n",
        "label2id = {\"phrase\": 0, \"passage\": 1, \"multi\": 2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "58b31aff6e2347c7a1486a4db31e4170",
            "acf878d2b3b6477aa449c876ce28fdf3",
            "ecc456738f5a441c81b763427c41dc1e",
            "28e10fc991bf4924856bf4676861bb24",
            "1e01fd01260d44929e9592891a04d9d9",
            "6434508fc6fb490d85664f7b0854c30a",
            "03c5018ff1704e738587b6b6de1fa882",
            "70d8a0590dc34fde9eddb5f7fb06b0ce",
            "95e48a70cd92469fa268b31600d9a33e",
            "6ec6215fe94f4e6dacd2a3628e2d7b49",
            "7dfc63664f7e46578a65b74ad7f23768"
          ]
        },
        "id": "QGjPLC143HC5",
        "outputId": "eb3d257a-5ea9-40f9-80e6-77be629d4a49"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58b31aff6e2347c7a1486a4db31e4170",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/559M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#import the pretrained model from huggingface\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"microsoft/deberta-base\", num_labels=3, id2label=id2label, label2id=label2id\n",
        ").to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "2423e80c3fe949aa80da764e59589797",
            "4f42dab2b1cd4ba8be5b46f442400ebb",
            "0989c8806a7d4f4ba246c030e3e2837c",
            "f9641d12c5cc435198d0502a5448ac81",
            "6fd2bafda1464539962d17f847a59787",
            "11567ac6d0a7447a98ba85e8bb1ca4c3",
            "2252164ac80347ea92206ec16d6e719c",
            "281f5f4852114d64be6bdfe604b33177",
            "40a68232196e4f2fb0c06f5e0785ba49",
            "16d36e7e4d4d4391841a8859ae08325f",
            "8c4e9a2d637f4b86addb50e9487f3e05",
            "8fd327937a4a4c1e9631e615b26f4817",
            "811f1956f1fd4903a95396586d135f14",
            "18080b31c3ea4aa3b0bb4bc657691bdc",
            "0ba9b3338dbb4bf6bd50325b3132b36f",
            "604ed017db48485390c22abcbeb7c377",
            "21d88b53a6d14de3add79f430be6f661",
            "6ddb5d31a1ae4d139e234523763d9a2e",
            "0ad9911d5c8645dfa3b5ad8183c94d98",
            "cb5d1a66a7ec439abb849fd994391bbd",
            "c3a2d7c0a8c54ee4a0ff9febcddd1838",
            "4d9cf52757b24f06a04997ef6261ec4c",
            "3046c933096b45928649d3448929cc1b",
            "b51c008228614ecc93b461a4e3d09356",
            "e4b7acf28ef5493fb3b4fbbcfb190978",
            "461d618a4a5b46e691e728f1c82e894f",
            "2066eaabe4934baeb5be491c50a7703b",
            "090dde3c1a81426197b38a2ca1c79a66",
            "f888f1e175af4e0abbf582f82e6e7b89",
            "4a85f2fae84b4e7392c95f14727b76dd",
            "a5ce25fb627041a9bc30fc4763b3a6cb",
            "fbbd68c56b0345edbc5b5b158dc71803",
            "1bb263c53e3541d5a460cc52c4fc3eb5"
          ]
        },
        "id": "eYCA2Cp23HC5",
        "outputId": "42aff363-6fa5-449c-eadf-cb7d896077e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2423e80c3fe949aa80da764e59589797",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2560 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fd327937a4a4c1e9631e615b26f4817",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/640 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3046c933096b45928649d3448929cc1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#run the preprocess function on the input text\n",
        "tokenized_data = dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um4PgnHZ3HC5"
      },
      "outputs": [],
      "source": [
        "#import the metrics\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "  accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "\n",
        "  return {\"f1\": f1, \"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHKLu4QN3HC6"
      },
      "outputs": [],
      "source": [
        "#import the data collator of huggingface\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jE6o5Xjq3HC6"
      },
      "source": [
        "###DeBERTa-base training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h2Cq1q_3HC6"
      },
      "outputs": [],
      "source": [
        "# empty the cache\n",
        "import torch \n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "WGwmfXyP3HC6",
        "outputId": "d0d070ce-4995-40ef-d0ff-76515b5e5abd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [800/800 07:15, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.813664</td>\n",
              "      <td>0.608009</td>\n",
              "      <td>0.629687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.757530</td>\n",
              "      <td>0.657405</td>\n",
              "      <td>0.681250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.837368</td>\n",
              "      <td>0.666304</td>\n",
              "      <td>0.696875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.700500</td>\n",
              "      <td>0.942731</td>\n",
              "      <td>0.655298</td>\n",
              "      <td>0.682813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.700500</td>\n",
              "      <td>1.069776</td>\n",
              "      <td>0.650505</td>\n",
              "      <td>0.675000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=800, training_loss=0.5276985740661622, metrics={'train_runtime': 436.1602, 'train_samples_per_second': 29.347, 'train_steps_per_second': 1.834, 'total_flos': 981119877120000.0, 'train_loss': 0.5276985740661622, 'epoch': 5.0})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# declare the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output4\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    # push_to_hub=True,\n",
        ")\n",
        "\n",
        "#declare the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"val\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "#run the trainer\n",
        "trainer.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf4jqYg_3HC6"
      },
      "source": [
        "###DeBERTa-base inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tnH8JRIc3HC6",
        "outputId": "014464f5-9cdf-4cfb-a8b6-c739e3682a0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load the trained model\n",
        "model_path = \"output4/checkpoint-800\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_path, num_labels=3, id2label=id2label, label2id=label2id\n",
        ").to(\"cuda\")\n",
        "\n",
        "# run the trainer and predict the outputs\n",
        "test_trainer = Trainer(model) \n",
        "\n",
        "raw_pred, labels, metrics = test_trainer.predict(tokenized_data[\"test\"]) \n",
        "\n",
        "y_pred = np.argmax(raw_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMrnZk8D3HC6",
        "outputId": "2cbb2d26-8163-4cd3-c410-ed11a171fd56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7056227340408437"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#find the metrics f1\n",
        "test_f1 = f1_metric.compute(predictions=y_pred, references=labels, average=\"macro\")[\"f1\"]\n",
        "test_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5SxXd8F3HC6",
        "outputId": "40f9b106-fc34-442a-c0a8-682f1ab545f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.70875"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#find the metrics accuracy\n",
        "test_accuracy = accuracy_metric.compute(predictions=y_pred, references=labels)[\"accuracy\"]\n",
        "test_accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "31WFbRSU6bhC"
      },
      "source": [
        "References:\n",
        "\n",
        "https://huggingface.co/microsoft/deberta-base\n",
        "\n",
        "https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
        "\n",
        "\n",
        "> @inproceedings{\n",
        "he2021deberta,\\\n",
        "title={DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION},\\\n",
        "author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},\\\n",
        "booktitle={International Conference on Learning Representations},\\\n",
        "year={2021},\\\n",
        "url={https://openreview.net/forum?id=XPZIaotutsD}\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
