{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#BERT base"
      ],
      "metadata": {
        "id": "uMzIRfMOgzwA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEMe5GNdfbpt",
        "outputId": "13be80d5-b4cd-4c48-d8de-b5005a5fdaba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, evaluate\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.3 transformers-4.28.1 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#load the preprocessed dataset\n",
        "dataset = load_dataset('csv', data_files={'train': 'df_train.csv',\n",
        "                                          'val': 'df_valid.csv',\n",
        "                                              'test': 'df_test.csv'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "1ea6bb229d294d4abd68125586149ea2",
            "8243c75b2749453bbe2debc56104d53c",
            "266e336be40c40eda72a120b37ff0cb0",
            "df8057144d0d42e395c1f59c9a8bcaa6",
            "81ead6ced7234544b4463ebc9e960aea",
            "7026437ed37b4d20b16da340c212f1d9",
            "76177a0392f744689cd42173185ffb05",
            "b874857270764bc996137068b3833876",
            "d8fdacd487064979a129f1c6ffcaf49b",
            "032bfb677fb748ed83ed2441fc97bc33",
            "f2fb367f323d4937aae3eaa4be44865c",
            "ec39d50bff724b2eaba4db3c2a6a7b9a",
            "297a418ecd1f4d85b3c5d1399575975c",
            "320798bad8c14a4680d6c198d2c7bfba",
            "830c3a7446e849f3a385e9b8f5a97bcb",
            "e4f7c72872b84754a878594c18c7b5f7",
            "af3a4cbe2e744af1976f975db7550421",
            "017a83d253544a2f9c879abd73ed51f9",
            "d4124ec888d44e7dbfe6bfcc8209d0a5",
            "1de66a7d33de4771879b57f48742175a",
            "7aabece3955e4000b3862a62d3a53122",
            "bebf26eeded244f0af2214592f746876",
            "5c9380aa55b64131a6b4e6e9f347eadc",
            "aac472c83e1f4f2b856578676bfd52fb",
            "f31507361c3f496e9c16b4ab598c545c",
            "871d5386e19242a3900f447c3419376e",
            "0107879c4f0c4c2caf54264231cd7761",
            "92affe1a7ee34bb48a7760659481027d",
            "3c9de12fad3748dcae4a1c674343bf48",
            "b0f44de31b0c4cc0b772fe8787e37693",
            "eac49535281f482da78943c7ef8c2488",
            "090985dded84471caa3db42fa189391e",
            "357ba87f30504d9d9156cf297598a0a9",
            "89340b99722f47cca9ffac98ef502f80",
            "40f9b6e87b384c7ca74efa678d94f90a",
            "57b1c7cd5ba145c49a82f9e981dcaf39",
            "c41b96d0cef341a5a3817ebac5271ce7",
            "f14a79a400b044e385d82d77beae3efc",
            "ced51cc9ecf94623b2a9daa90342d39e",
            "ea3ff83b4353443fa10f0ac6d9719869",
            "aee61435e62e4103bbf717e86c6b99a3",
            "2f233496129c41c8ae7db1ba02176732",
            "4444d7597c8a4bcbbfa4a9070a367186",
            "190934d4af2a451fa7b107178f159e77",
            "ca69ecdc2f8a4aa99b4784611a674439",
            "86c34483e783412291b9aaac6a152bf7",
            "0977faa5416a47c6b3b2c5a448dd379e",
            "534e52755fbc44d4bc1f82ef112bef2c",
            "94f645398f6644bca79c65929972137a",
            "c2c975d8cb884f5fa2b3b2b86c2de94c",
            "e7b047f490e54781806fb60a9d1561ef",
            "1a29ab62354541709a31caeda6153745",
            "ccc1d71cf1774e7da9f28e358a6eb4a8",
            "5901d2c2255946b6b952476db1275297",
            "218a56a59192471a8bbe103b74dee0e9",
            "bdbff8659e6146c7b9f613ac54185a5f",
            "65bff396c4e947489d76de88a0a2b4d1",
            "0c54fb127a974a5f89667c091a460226",
            "5c0a7b954bc8496bb221aec39d157185",
            "24a0cbe99e804dd1a6268a20084f1e08",
            "5ca8ad15f8644b3a8f53d6115c4e68b4",
            "f5e3c95dfcd24f239791155b9f77788d",
            "913d64f09e7a4904b5ec914d42ce2a0a",
            "01f990e7e5ac40b6bfd89b91d751545f",
            "b833f9908193476a974bc93c47ad84aa",
            "c609ebbe08fb431388c793e7b83f4c00"
          ]
        },
        "id": "4ETbAGqrhoi8",
        "outputId": "bcf838d2-8014-4b47-ad8a-f2cc197225b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-2cec45cfe0e5b614/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ea6bb229d294d4abd68125586149ea2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec39d50bff724b2eaba4db3c2a6a7b9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c9380aa55b64131a6b4e6e9f347eadc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating val split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89340b99722f47cca9ffac98ef502f80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca69ecdc2f8a4aa99b4784611a674439"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-2cec45cfe0e5b614/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdbff8659e6146c7b9f613ac54185a5f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the bert base tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "201c39c85aff418ba84652a59f957295",
            "32975539c0d94d568456930cb265f08b",
            "f793e6dbc598477985f684014d5d7558",
            "38632f76543b445283985da5d8b83646",
            "f6290661eabd4782b28acb9f951e4155",
            "d0b7a2c7e2ca44cdbe1618744b09e50b",
            "8768c9d23e2849668440c8187f601f46",
            "ccfe2ffb2a104b4398e0498a6c65e40b",
            "d85749bc9ec34a2daf5675f25676edf9",
            "d6fef198eb704fdc913c4f0ecac9f9a6",
            "f370885bcb3847dbb663c26c975cbbac",
            "c7637a1f24d3401d95a4db5eb2331aac",
            "d6d50e54a42c4bcdba8e76ca9809fb1b",
            "6488e187f75d472da0a310dd6b81e751",
            "aa7fe2b9797948d8bc3b3cf5620f47a8",
            "e2598aa225ce461b8c0dc8a51922bd0f",
            "b952aeebb70644eea039fabc2c8e953d",
            "06c87853f7374364a2b48cbbf5d47a29",
            "c8bde841bc674205aef0379d5c786954",
            "8e1f1dd197784d8bb2341556bcd23c59",
            "5d4cd14cb49a4cc089fafd20b4bc2cca",
            "b76a9bb6809c44909e180ab26668b63f",
            "7c73e7a83a8f4881aec5f093fa364207",
            "bb1749fa04584b3d86c12cc49c4eb13c",
            "2384bf8bd49f4ac0941618d82c04a801",
            "28bc3fa2d002414f87fb54a07a41f1f3",
            "034ee62a38364e8b8530d553d4c7f2a6",
            "323ce731867f4743bfa70ec8d50877f0",
            "ef28668b3d3f4da68b741b41ad8970fb",
            "9797708bdcc34889b2115041db6a49bb",
            "8d0a1d847c5649ceb04ead29574e9cde",
            "49f831b418064641b3a114ac3cf3f98e",
            "8aaf53734d6c473e92bc91a266d97a3b",
            "56ca819b096842c5be0b811e88d05439",
            "63b847dd45e6442785be978765792ebf",
            "5e030d2a85554d4cb4782ea9bb07b816",
            "fd549d8ca6ff4bc2a303162b6fdd7d49",
            "477af17658df4a10adb1239c5fb2fded",
            "a49a2e38aa7242c0946847cb3c808a6b",
            "fbb2bf2448ab4f419e0024eab38c3315",
            "9d5b25b7af8a4ee4adf2d24f69de0b07",
            "827881555f7a45daaac0dbb9d8622f08",
            "ba93534a19d9448380c81a8449a8ea0b",
            "3e79f14e0f8d4a41b4fc88813b8475c2"
          ]
        },
        "id": "FkPpFDo5hwIb",
        "outputId": "f32c8c56-29b7-4047-ffa4-93ebf70245b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "201c39c85aff418ba84652a59f957295"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7637a1f24d3401d95a4db5eb2331aac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c73e7a83a8f4881aec5f093fa364207"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56ca819b096842c5be0b811e88d05439"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess function to tokenize the text\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length',\n",
        "                                max_length=128,\n",
        "                                truncation=True,\n",
        "                                return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "q7DtcYIghzwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dictionaries to map ids to labels and vice versa\n",
        "id2label = {0: \"phrase\", 1: \"passage\", 2: \"multi\"}\n",
        "label2id = {\"phrase\": 0, \"passage\": 1, \"multi\": 2}"
      ],
      "metadata": {
        "id": "NfIJdZ8fh2GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the bert base model and pass it to classification model of huggingface\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\", num_labels=3, id2label=id2label, label2id=label2id\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "96b04f4d4bff48c2a5a43d6b45831e1e",
            "0b35391ff3cf4a2d91f6b2e7f18333a1",
            "f39bfbeb88e24532b020f7f0150380f9",
            "6b4bc5d58fb94dc4bf10795bd02e4dd8",
            "50d1f6a5bfb34fee9dc1095be6194f9b",
            "ab0a5cfd89e14c769514221f72f5c3b7",
            "1fc4b8e814bf4bce8e5dea94367e473e",
            "fb9360b01b594a8c9710439a87a20b58",
            "3297742e5a684c17a06f1cfbb43bc32b",
            "f0616c74c9174e28ad5744fe314dd3b7",
            "fc227e07a05a4851bbf1fecbbf0034ef"
          ]
        },
        "id": "h6V4hUVTh5-V",
        "outputId": "1f371470-3e70-435f-8c74-8c8ae938be35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96b04f4d4bff48c2a5a43d6b45831e1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize the data in train, validation and test sets\n",
        "tokenized_data = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "318919db40e14242aa5a076fb3a474c1",
            "759886a5c5254a8d88dfd048994ca8a8",
            "9cab428f68d347199421a07efdcd1d60",
            "0a6c2428495b401584fea939aa48abaa",
            "df587f8fa5ce404b98bb5ce9383d6f3a",
            "788919e5a3444ab59519190e5bf02620",
            "3175ed9679b941b3b810b9af8c52ca13",
            "eab561cbfb6e4abfbf303fa37a66b208",
            "baae82431edb4541ba533e1446730e68",
            "762598221d0c427d889b5cad05e15371",
            "dff3dc9ddb7c47099f0914b9b5bf5ce0",
            "35cb9e81f81641199cce21c0a2cdc245",
            "afd7e32b26d44848983dc2637c6002ee",
            "d93f0e40af4e4d9cb6ef1d29d84a3410",
            "f1ee632be38c49be8cc601a2e5198006",
            "f75ae9a631944e5cae9785f7da5650e4",
            "f02d21f8f19d4fd585e2546a651ef1aa",
            "f1fae4f0377b4be7a3f339cb09eef307",
            "40b5039f53454002b22ade662f71c5d2",
            "3aa38b84e50c4accbd79af1cf731dbac",
            "a554c1c69c544c2898c92102b4f3a177",
            "ced650097c634fc0b1e47d9e5a7f2e2a",
            "3309664f3c1e49c1b95298bb7cc4b2d1",
            "23f3dc1536574fb7b71ff269e609a179",
            "7b0d35d5659f40a4bbb414275ad55fdb",
            "5a9c9dec54f247eebe5a9889ea2d2bb3",
            "924a6fc38dfb459ba8e1c7f3cc696cef",
            "eebca323044b40f3983ef2c7d2e08fd1",
            "34b61f3a0c614598905d11acc85cde46",
            "9c9149e3d70944b7abfcf84e8d01dcbf",
            "8466f988cb49454e9cafc283deeea61d",
            "85dccb6a2de84d0496c6604ea5bd02bf",
            "ba609bd87c354ebc925ec900a09cbb51"
          ]
        },
        "id": "xxj70qsdh938",
        "outputId": "06398e8f-ea8c-4c52-db2b-59b68b32f17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2560 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "318919db40e14242aa5a076fb3a474c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/640 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35cb9e81f81641199cce21c0a2cdc245"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3309664f3c1e49c1b95298bb7cc4b2d1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the evaluation metrics - accuracy and f1\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "  accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "\n",
        "  return {\"f1\": f1, \"accuracy\": accuracy}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f54cca0d1e714287abdb8d39039aad19",
            "2334252957c94d14ac74dcac99bc6e2e",
            "55a48c7814214f84bdf8cffbec8cf785",
            "d79b185fd5164eda8314741a9684c5af",
            "97f18436a7a24deaa601dfce32d0b049",
            "c7c74c8860ed42f4b38ea22f3fa5ac60",
            "1d29a384c3b14081905516f4ebec1fd0",
            "29662284e9e94f02a9f1f56a587ba2eb",
            "7cc3e85359384aa7b1d49645c97333cf",
            "61bb13e554984cb191098816ac248a83",
            "d6e62e1772f84d268e6fbab3024f14e0",
            "f03a95fae7e840cf90d1f24e4cb85c41",
            "14ee0a7e6571417dadf691a51043201f",
            "a2c4241e7a474e57ab973791675a5442",
            "bdc5e0472a2445729b7308779899f3d9",
            "97a3c6f164b848f29863a20be0a94225",
            "d9e09ed835ef458fb3e96cccd29f87e3",
            "7d47c8318c3042f2ac4f2c8c0d364359",
            "62c7cd79509a43a09748131901b12959",
            "ad66a841d749420d9303adc9939d7353",
            "82887b8e219c4449b1b5239f32917dff",
            "6e21d52fd38c456888c0d60ecaea691d"
          ]
        },
        "id": "shuG9cUyiAXO",
        "outputId": "a462cb21-b6eb-415b-9d13-8c2d08b4a7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f54cca0d1e714287abdb8d39039aad19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f03a95fae7e840cf90d1f24e4cb85c41"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the data collator\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "FAsPW91UiIDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BERT-base training\n",
        "\n"
      ],
      "metadata": {
        "id": "QAkvUFbKm4w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the training arguments for fine-tuning the bert-base model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    # push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"val\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "VDmGJko_iOiN",
        "outputId": "822efbe0-1e21-4465-8f96-1199b5879df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [800/800 05:28, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.858514</td>\n",
              "      <td>0.562646</td>\n",
              "      <td>0.590625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.814094</td>\n",
              "      <td>0.612080</td>\n",
              "      <td>0.643750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.891824</td>\n",
              "      <td>0.613780</td>\n",
              "      <td>0.645312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.736900</td>\n",
              "      <td>0.980457</td>\n",
              "      <td>0.615846</td>\n",
              "      <td>0.645312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.736900</td>\n",
              "      <td>1.023788</td>\n",
              "      <td>0.610417</td>\n",
              "      <td>0.640625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=800, training_loss=0.5718225193023682, metrics={'train_runtime': 329.7012, 'train_samples_per_second': 38.823, 'train_steps_per_second': 2.426, 'total_flos': 841962936729600.0, 'train_loss': 0.5718225193023682, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BERT-base inference\n"
      ],
      "metadata": {
        "id": "lt2NB0dIk66y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model\n",
        "model_path = \"output/checkpoint-800\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_path, num_labels=3, id2label=id2label, label2id=label2id\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Define test trainer\n",
        "test_trainer = Trainer(model) \n",
        "# Make prediction\n",
        "raw_pred, labels, metrics = test_trainer.predict(tokenized_data[\"test\"]) \n",
        "# Preprocess raw predictions\n",
        "y_pred = np.argmax(raw_pred, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "62iRXmZKkZQ1",
        "outputId": "df52f24d-bfad-4d2e-a085-9f148a8fcdbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute f1 score\n",
        "test_f1 = f1_metric.compute(predictions=y_pred, references=labels, average=\"macro\")[\"f1\"]\n",
        "test_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcYdogk-lr3J",
        "outputId": "20805d98-e8fd-4db3-cb57-a89d71d2db7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6618399351725451"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute accuracy score\n",
        "test_accuracy = accuracy_metric.compute(predictions=y_pred, references=labels)[\"accuracy\"]\n",
        "test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6LkukrNltsA",
        "outputId": "03717cbd-fe74-40fb-cace-319a837bac47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.66625"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}