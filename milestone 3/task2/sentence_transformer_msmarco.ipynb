{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89eafe1a0aed49d08408eb01b2f41595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e920630da58044e78ba230e9ded95660",
              "IPY_MODEL_de6fae214f964797bcbbe758bd13d66b",
              "IPY_MODEL_1ac1f04be6484cf984d097d92eb5b994"
            ],
            "layout": "IPY_MODEL_7d764d23d82d4914a8552db49dce69fc"
          }
        },
        "e920630da58044e78ba230e9ded95660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef18f14751634210bdce6a1ce7736865",
            "placeholder": "​",
            "style": "IPY_MODEL_cbac79d2e18247e6bbc53ce598867f48",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "de6fae214f964797bcbbe758bd13d66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_368a103847724bde8198cca521dd047d",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72b0555bc9ee4cea8f982ab39755c67e",
            "value": 482
          }
        },
        "1ac1f04be6484cf984d097d92eb5b994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3020f722fa42628ec46fb540b82b9d",
            "placeholder": "​",
            "style": "IPY_MODEL_3f39e11daf9445918c997de5abdc32a2",
            "value": " 482/482 [00:00&lt;00:00, 12.8kB/s]"
          }
        },
        "7d764d23d82d4914a8552db49dce69fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef18f14751634210bdce6a1ce7736865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbac79d2e18247e6bbc53ce598867f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "368a103847724bde8198cca521dd047d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b0555bc9ee4cea8f982ab39755c67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a3020f722fa42628ec46fb540b82b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f39e11daf9445918c997de5abdc32a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "311e2f0501974eeda430362e446e9d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_029e712d7e66432192a95a6263c230c3",
              "IPY_MODEL_53062eab40484ce29069c32d1b2817ce",
              "IPY_MODEL_5edebec614e1419da88989bf1296f906"
            ],
            "layout": "IPY_MODEL_3fe019993b9c4862932fa5771a46dfbd"
          }
        },
        "029e712d7e66432192a95a6263c230c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b42c2a4647f41839d18ffdc5e4f7e8d",
            "placeholder": "​",
            "style": "IPY_MODEL_3512f1c6b6db4402955dd7c7150c2644",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "53062eab40484ce29069c32d1b2817ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_873ae62fd5974c20aebb8d714b306476",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c850a7eb852c4c1099b3f27fa78bd516",
            "value": 898823
          }
        },
        "5edebec614e1419da88989bf1296f906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d685d46ed4cc41e3860bc73b0c96562a",
            "placeholder": "​",
            "style": "IPY_MODEL_6be0bc77ec0e42fd8f97b3d5d9a72b42",
            "value": " 899k/899k [00:00&lt;00:00, 25.1MB/s]"
          }
        },
        "3fe019993b9c4862932fa5771a46dfbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b42c2a4647f41839d18ffdc5e4f7e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3512f1c6b6db4402955dd7c7150c2644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "873ae62fd5974c20aebb8d714b306476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c850a7eb852c4c1099b3f27fa78bd516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d685d46ed4cc41e3860bc73b0c96562a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be0bc77ec0e42fd8f97b3d5d9a72b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57b30d168e9c4f62ac9bfa73883903e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab7adb8901bd4185ae534b3167c97830",
              "IPY_MODEL_bf6ae60dd7724b099e5c5835c7d27b95",
              "IPY_MODEL_cf03d795aea04050a3e5ba9516b23ae8"
            ],
            "layout": "IPY_MODEL_145b30f0413748d68c234e69f0ec11ac"
          }
        },
        "ab7adb8901bd4185ae534b3167c97830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36d4a2da1a724a3d8e5c14445a7d6e5c",
            "placeholder": "​",
            "style": "IPY_MODEL_5ca07a58a689401c982829e0b44f1ee4",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "bf6ae60dd7724b099e5c5835c7d27b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dc2fa0a0d66490aacab3c9f9ceb64e7",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e68e7e75059049b98bbe06d471bc3f40",
            "value": 456318
          }
        },
        "cf03d795aea04050a3e5ba9516b23ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10be1dab9adf4d55a060924f8c2ec3f5",
            "placeholder": "​",
            "style": "IPY_MODEL_a3ba08cf516248fbbcf1b880278c01a8",
            "value": " 456k/456k [00:00&lt;00:00, 19.1MB/s]"
          }
        },
        "145b30f0413748d68c234e69f0ec11ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d4a2da1a724a3d8e5c14445a7d6e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ca07a58a689401c982829e0b44f1ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dc2fa0a0d66490aacab3c9f9ceb64e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e68e7e75059049b98bbe06d471bc3f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10be1dab9adf4d55a060924f8c2ec3f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ba08cf516248fbbcf1b880278c01a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3974c37f6ccd42fd9be810bec67fc6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80d61df1643946bca0b7f574fd196135",
              "IPY_MODEL_d196a33ce7334c6f91ee71c70af0a8ef",
              "IPY_MODEL_f4df8dff31894278ac92ce51276b23a8"
            ],
            "layout": "IPY_MODEL_03fe43a2c1da44f6853e4a01e73d53f8"
          }
        },
        "80d61df1643946bca0b7f574fd196135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2fe0fe4e9114409b40a3a67007812c0",
            "placeholder": "​",
            "style": "IPY_MODEL_feebaf844370461296ee9ed5aa7d5694",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "d196a33ce7334c6f91ee71c70af0a8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97dd9564aa52478689a70b885e79f405",
            "max": 1425941629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9331e152cfcf49f69b3006c959fa7885",
            "value": 1425941629
          }
        },
        "f4df8dff31894278ac92ce51276b23a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4722439b9b05445bba229227fad75531",
            "placeholder": "​",
            "style": "IPY_MODEL_e72a109f9ae740f0988c55731e954b56",
            "value": " 1.43G/1.43G [00:16&lt;00:00, 63.4MB/s]"
          }
        },
        "03fe43a2c1da44f6853e4a01e73d53f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2fe0fe4e9114409b40a3a67007812c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feebaf844370461296ee9ed5aa7d5694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97dd9564aa52478689a70b885e79f405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9331e152cfcf49f69b3006c959fa7885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4722439b9b05445bba229227fad75531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72a109f9ae740f0988c55731e954b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbccf1f6-9b6c-46fb-af4c-891a248a28f8",
        "id": "fORwaxHzwMHG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Create the tokenizer and model\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
        "# model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-bert-base-dot-v5\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"sentence-transformers/msmarco-bert-base-dot-v5\")\n",
        "\n",
        "# Define the question answering pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, batch_size = 1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ddcde2-c48a-42be-95e1-092e7ed29ffd",
        "id": "R5wHriUXwMHJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at sentence-transformers/msmarco-bert-base-dot-v5 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"multi-train.csv\")"
      ],
      "metadata": {
        "id": "YvYAcgs2wMHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "cIrKR97CwMHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_validation = pd.read_csv(\"multi-valid.csv\")"
      ],
      "metadata": {
        "id": "MfvF8v4fwMHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdaIhcmLz5LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "IQqmiqPHBzhO",
        "outputId": "253b077b-f685-4f84-a219-52897b81b22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0                                  uuid  \\\n",
              "1              1  b1a1f63d-8853-4a11-89e8-6b2952a393ec   \n",
              "2              2  008b7b19-0445-4e16-8f9e-075b73f80ca4   \n",
              "4              4  31b108a3-c828-421a-a4b9-cf651e9ac859   \n",
              "10            10  46aa8d72-fbd4-4796-a85b-0a0363c21812   \n",
              "11            11  917e1106-413c-4be5-818b-ad500314feaa   \n",
              "...          ...                                   ...   \n",
              "3178        3178  edec6cde-bbd3-4f50-ba51-ef98bdf19b63   \n",
              "3179        3179  84277c0f-4ef1-444e-8e04-55c84af593e5   \n",
              "3183        3183  5b61d712-8b03-4ee6-ba04-b39ce2b206f7   \n",
              "3198        3198  9d05984c-3920-47c0-aa97-8df58cca1fec   \n",
              "3199        3199  0d9e3a31-77f7-414a-9d70-5213f2c0cd94   \n",
              "\n",
              "                                               postText  \\\n",
              "1        NASA sets date for full recovery of ozone hole   \n",
              "2     This is what makes employees happy -- and it's...   \n",
              "4     The perfect way to cook rice so that it's perf...   \n",
              "10    Analysis: This may be the most brutal number i...   \n",
              "11    #TeenMom2 star @PBandJenelley_1 reveals the se...   \n",
              "...                                                 ...   \n",
              "3178  He Dug A Huge Hole In His Backyard, And What H...   \n",
              "3179  Best Buy Has An Insane Xbox One Deal For A Lim...   \n",
              "3183  Student forced to carry papers to prove she ca...   \n",
              "3198  You need to see this Twitter account that pred...   \n",
              "3199         GOP congressman comes out for gay marriage   \n",
              "\n",
              "                                       targetParagraphs  \\\n",
              "1     2070 is shaping up to be a great year for Moth...   \n",
              "2     Despite common belief, money isn't the key to ...   \n",
              "4     Boiling rice may seem simple, but there is a v...   \n",
              "10    Plenty has been made of the big Congressional ...   \n",
              "11    \"Teen Mom 2\" star Jenelle Evans took to Twitte...   \n",
              "...                                                 ...   \n",
              "3178  When it comes to home projects, sometimes the ...   \n",
              "3179  Best Buy Has An Insane Xbox One Deal For A Lim...   \n",
              "3183  She's not a tourist visiting a foreign country...   \n",
              "3198  What the HELL?! 1. Unless you’re somewhere wit...   \n",
              "3199  Rep. Charlie Dent (R-Pa.) came out in support ...   \n",
              "\n",
              "                                            targetTitle  \\\n",
              "1     Hole In Ozone Layer Expected To Make Full Reco...   \n",
              "2     Intellectual Stimulation Trumps Money For Empl...   \n",
              "4     Revealed: The perfect way to cook rice so that...   \n",
              "10    This may be the most brutal number in the CBO ...   \n",
              "11    'Teen Mom 2' Star Jenelle Evans Reveals Sex Of...   \n",
              "...                                                 ...   \n",
              "3178  He Dug A Huge Hole In His Backyard, And What H...   \n",
              "3179  Best Buy Has An Insane Xbox One Deal For A Lim...   \n",
              "3183  Melona Clark, Hampton University Student, Carr...   \n",
              "3198  WTF, It Looks Like This Twitter Account \"Predi...   \n",
              "3199  Pennsylvania GOP Rep. Charlie Dent Comes Out F...   \n",
              "\n",
              "                                        spoiler        spoilerPositions  \\\n",
              "1                                          2070      [[[0, 0], [0, 4]]]   \n",
              "2                      intellectual stimulation  [[[1, 186], [1, 210]]]   \n",
              "4                              in a rice cooker    [[[5, 60], [5, 76]]]   \n",
              "10                                  750 percent  [[[2, 109], [2, 120]]]   \n",
              "11                                          boy  [[[0, 103], [0, 106]]]   \n",
              "...                                         ...                     ...   \n",
              "3178                    own underground bunker!  [[[20, 70], [20, 93]]]   \n",
              "3179                                    $50 off  [[[8, 101], [8, 108]]]   \n",
              "3183  student at Hampton University in Virginia     [[[1, 9], [1, 50]]]   \n",
              "3198                             @beyoncefan666    [[[3, 55], [3, 69]]]   \n",
              "3199                  Rep. Charlie Dent (R-Pa.)     [[[0, 0], [0, 25]]]   \n",
              "\n",
              "        tags start_positions end_positions  \n",
              "1     phrase             [0]           [4]  \n",
              "2     phrase           [272]         [296]  \n",
              "4     phrase           [655]         [671]  \n",
              "10    phrase           [583]         [594]  \n",
              "11    phrase           [103]         [106]  \n",
              "...      ...             ...           ...  \n",
              "3178  phrase          [6104]        [6127]  \n",
              "3179  phrase          [1814]        [1821]  \n",
              "3183  phrase           [163]         [204]  \n",
              "3198  phrase           [408]         [422]  \n",
              "3199  phrase             [0]          [25]  \n",
              "\n",
              "[1367 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17b89c7e-e7e0-4c9a-80db-6f868d6e36eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>uuid</th>\n",
              "      <th>postText</th>\n",
              "      <th>targetParagraphs</th>\n",
              "      <th>targetTitle</th>\n",
              "      <th>spoiler</th>\n",
              "      <th>spoilerPositions</th>\n",
              "      <th>tags</th>\n",
              "      <th>start_positions</th>\n",
              "      <th>end_positions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>b1a1f63d-8853-4a11-89e8-6b2952a393ec</td>\n",
              "      <td>NASA sets date for full recovery of ozone hole</td>\n",
              "      <td>2070 is shaping up to be a great year for Moth...</td>\n",
              "      <td>Hole In Ozone Layer Expected To Make Full Reco...</td>\n",
              "      <td>2070</td>\n",
              "      <td>[[[0, 0], [0, 4]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>008b7b19-0445-4e16-8f9e-075b73f80ca4</td>\n",
              "      <td>This is what makes employees happy -- and it's...</td>\n",
              "      <td>Despite common belief, money isn't the key to ...</td>\n",
              "      <td>Intellectual Stimulation Trumps Money For Empl...</td>\n",
              "      <td>intellectual stimulation</td>\n",
              "      <td>[[[1, 186], [1, 210]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[272]</td>\n",
              "      <td>[296]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>31b108a3-c828-421a-a4b9-cf651e9ac859</td>\n",
              "      <td>The perfect way to cook rice so that it's perf...</td>\n",
              "      <td>Boiling rice may seem simple, but there is a v...</td>\n",
              "      <td>Revealed: The perfect way to cook rice so that...</td>\n",
              "      <td>in a rice cooker</td>\n",
              "      <td>[[[5, 60], [5, 76]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[655]</td>\n",
              "      <td>[671]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>46aa8d72-fbd4-4796-a85b-0a0363c21812</td>\n",
              "      <td>Analysis: This may be the most brutal number i...</td>\n",
              "      <td>Plenty has been made of the big Congressional ...</td>\n",
              "      <td>This may be the most brutal number in the CBO ...</td>\n",
              "      <td>750 percent</td>\n",
              "      <td>[[[2, 109], [2, 120]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[583]</td>\n",
              "      <td>[594]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>917e1106-413c-4be5-818b-ad500314feaa</td>\n",
              "      <td>#TeenMom2 star @PBandJenelley_1 reveals the se...</td>\n",
              "      <td>\"Teen Mom 2\" star Jenelle Evans took to Twitte...</td>\n",
              "      <td>'Teen Mom 2' Star Jenelle Evans Reveals Sex Of...</td>\n",
              "      <td>boy</td>\n",
              "      <td>[[[0, 103], [0, 106]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[103]</td>\n",
              "      <td>[106]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3178</th>\n",
              "      <td>3178</td>\n",
              "      <td>edec6cde-bbd3-4f50-ba51-ef98bdf19b63</td>\n",
              "      <td>He Dug A Huge Hole In His Backyard, And What H...</td>\n",
              "      <td>When it comes to home projects, sometimes the ...</td>\n",
              "      <td>He Dug A Huge Hole In His Backyard, And What H...</td>\n",
              "      <td>own underground bunker!</td>\n",
              "      <td>[[[20, 70], [20, 93]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[6104]</td>\n",
              "      <td>[6127]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3179</th>\n",
              "      <td>3179</td>\n",
              "      <td>84277c0f-4ef1-444e-8e04-55c84af593e5</td>\n",
              "      <td>Best Buy Has An Insane Xbox One Deal For A Lim...</td>\n",
              "      <td>Best Buy Has An Insane Xbox One Deal For A Lim...</td>\n",
              "      <td>Best Buy Has An Insane Xbox One Deal For A Lim...</td>\n",
              "      <td>$50 off</td>\n",
              "      <td>[[[8, 101], [8, 108]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[1814]</td>\n",
              "      <td>[1821]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3183</th>\n",
              "      <td>3183</td>\n",
              "      <td>5b61d712-8b03-4ee6-ba04-b39ce2b206f7</td>\n",
              "      <td>Student forced to carry papers to prove she ca...</td>\n",
              "      <td>She's not a tourist visiting a foreign country...</td>\n",
              "      <td>Melona Clark, Hampton University Student, Carr...</td>\n",
              "      <td>student at Hampton University in Virginia</td>\n",
              "      <td>[[[1, 9], [1, 50]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[163]</td>\n",
              "      <td>[204]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3198</th>\n",
              "      <td>3198</td>\n",
              "      <td>9d05984c-3920-47c0-aa97-8df58cca1fec</td>\n",
              "      <td>You need to see this Twitter account that pred...</td>\n",
              "      <td>What the HELL?! 1. Unless you’re somewhere wit...</td>\n",
              "      <td>WTF, It Looks Like This Twitter Account \"Predi...</td>\n",
              "      <td>@beyoncefan666</td>\n",
              "      <td>[[[3, 55], [3, 69]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[408]</td>\n",
              "      <td>[422]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3199</th>\n",
              "      <td>3199</td>\n",
              "      <td>0d9e3a31-77f7-414a-9d70-5213f2c0cd94</td>\n",
              "      <td>GOP congressman comes out for gay marriage</td>\n",
              "      <td>Rep. Charlie Dent (R-Pa.) came out in support ...</td>\n",
              "      <td>Pennsylvania GOP Rep. Charlie Dent Comes Out F...</td>\n",
              "      <td>Rep. Charlie Dent (R-Pa.)</td>\n",
              "      <td>[[[0, 0], [0, 25]]]</td>\n",
              "      <td>phrase</td>\n",
              "      <td>[0]</td>\n",
              "      <td>[25]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1367 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17b89c7e-e7e0-4c9a-80db-6f868d6e36eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17b89c7e-e7e0-4c9a-80db-6f868d6e36eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17b89c7e-e7e0-4c9a-80db-6f868d6e36eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"postText\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"targetParagraphs\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"spoiler\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        start_char = int(examples[\"start_positions\"][i][1])\n",
        "        end_char = start_char + len(examples[\"spoiler\"][i])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "wzok5MBXBzbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "kNxw7kwaBzWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.2)"
      ],
      "metadata": {
        "id": "nZXDrru5BzRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import datasets\n",
        "\n",
        "val_dataset2 = datasets.Dataset.from_pandas(df_test)\n",
        "train_dataset2 = datasets.Dataset.from_pandas(df_train)"
      ],
      "metadata": {
        "id": "78KT2ko7BzMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset2.map(preprocess_function, batched=True,\n",
        "    remove_columns=train_dataset2.column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "977d781e70714fad9ead5eb98cda3a7f",
            "c5195a26fd154bf388e7a1bc2bff2add",
            "65152fb2ebcb4831993ffa57572fd57f",
            "f830254488774f36bee78a1cec38f1dc",
            "4cfe43335168497a91b3fc746ce01e42",
            "6f6ad318239a4c7694be215f41de8d8f",
            "491f0b1cdd0143f7bc94255afa43a6e0",
            "29f2d38e3085485f9ce801f1de87b4ce",
            "b7feb01ee5564c1f8fb72720e48a7a36",
            "209c1c73494f406fb3fbd094d8ab17a7",
            "092938cdc01f495880951eebe5350115"
          ]
        },
        "id": "e8dU1N52BzHb",
        "outputId": "ee58e9c7-7715-47f9-adec-d2c17df3bf39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1093 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "977d781e70714fad9ead5eb98cda3a7f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = val_dataset2.map(preprocess_function, batched=True,\n",
        "    remove_columns=val_dataset2.column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "ff02992ad5694c9a99d4a13ff9931b07",
            "441559a2174447af9711689b48b97608",
            "5ff11c7e18fc4d18922788324c0be885",
            "ac209544b64f4110ad776747b034ef3d",
            "5d4398d9c7b24b568534ca62867ce336",
            "a5605d4b17914dd0a19a46dc4934f21b",
            "c7b608e031a34962a1968ead05bf1492",
            "3019099f5d594886a14c3e0c520583ae",
            "569394b5e56d4b918b94cae9a8d041b7",
            "2d6225c9ca8b45c5b19dd78361eb6ed8",
            "6a7efe7eb79c477cad8bbe1183e43099"
          ]
        },
        "id": "2_jgQutdBzCj",
        "outputId": "85c26b54-2f5c-4d37-e0d8-d533e9760e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/274 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff02992ad5694c9a99d4a13ff9931b07"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2umQ7gnBy9h",
        "outputId": "8b602093-d93a-4a24-e90a-0cea0f1b3c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['start_positions', 'end_positions', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 274\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmlyf_M1By3y",
        "outputId": "778c1256-6172-4f0a-f2f7-f717f3b9f471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['start_positions', 'end_positions', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 1093\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ],
      "metadata": {
        "id": "UDOILb34ByzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "m9T-WDDzByvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFkrAV3VCRCz",
        "outputId": "d05dd7a8-93b3-4d77-c53e-e8652ca1e569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"qa_train_passage\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    #push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "X2MRx9BHCQxF",
        "outputId": "13a5de83-81c5-4e86-ad71-f8fac03d34c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2735' max='2735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2735/2735 09:48, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.959400</td>\n",
              "      <td>1.619157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.429000</td>\n",
              "      <td>1.524606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.121600</td>\n",
              "      <td>1.678660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.869200</td>\n",
              "      <td>2.018714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.604700</td>\n",
              "      <td>2.321848</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2735, training_loss=1.1401159366698326, metrics={'train_runtime': 591.8352, 'train_samples_per_second': 9.234, 'train_steps_per_second': 4.621, 'total_flos': 1070990081671680.0, 'train_loss': 1.1401159366698326, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each row in the dataset and train the model\n",
        "for index, row in df.iterrows():\n",
        "    context = row[\"targetParagraphs\"]\n",
        "    question = row[\"targetTitle\"]\n",
        "    if isinstance(row[\"spoiler\"], str):\n",
        "      answer = row[\"spoiler\"].split('.')\n",
        "    else: \n",
        "      answer = \"\"\n",
        "    #answer = row[\"spoiler\"].split('.')\n",
        "    qa_pipeline(context=context, question=question, answer=answer)\n",
        "\n",
        "# # Use the trained model to generate responses\n",
        "# prompt = \"What is the answer to the following question?\"\n",
        "# question = \"What is the capital of France?\"\n",
        "# context = \"France is a country located in Western Europe. Its capital is Paris.\"\n",
        "\n",
        "# response = qa_pipeline(context=context, question=question)\n",
        "\n",
        "# print(response[\"answer\"])"
      ],
      "metadata": {
        "id": "CVEL1RieGDdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spoilers = []\n",
        "\n",
        "for index, row in df_validation.iterrows():\n",
        "  curr = []\n",
        "  for val in str(row['targetParagraphs']).split('\\n'):\n",
        "    # print(index, val)\n",
        "    if val!=\"\" and not val.isdigit():\n",
        "      context = val\n",
        "      question = row[\"targetTitle\"]\n",
        "      response = qa_pipeline(context=context, question=question)\n",
        "      # adding a threshold limit to the probability score\n",
        "      if response[\"score\"] >= 0.01\n",
        "        curr.append(response[\"answer\"])\n",
        "      print(response)\n",
        "  print(curr)\n",
        "\n",
        "\n",
        "  spoilers.append(curr)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cda023-ad24-41ea-8d8e-ed35edb267dc",
        "id": "JY7x8Wt3wMHK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'score': 0.00029325985815376043, 'start': 16, 'end': 31, 'answer': 'Segall Maricopa'}\n",
            "{'score': 0.00014652364188805223, 'start': 346, 'end': 375, 'answer': 'sheriff of Arizona’s Maricopa'}\n",
            "{'score': 0.000800741312559694, 'start': 164, 'end': 168, 'answer': 'were'}\n",
            "{'score': 0.0050505357794463634, 'start': 27, 'end': 63, 'answer': 'had unusually harsh words for Arpaio'}\n",
            "{'score': 0.0011482243426144123, 'start': 38, 'end': 75, 'answer': 'inequitable application of discipline'}\n",
            "{'score': 0.0004309076757635921, 'start': 105, 'end': 119, 'answer': 'had encouraged'}\n",
            "{'score': 0.0005470547475852072, 'start': 159, 'end': 195, 'answer': 'had violated the order \"out of spite'}\n",
            "{'score': 0.0035541693214327097, 'start': 39, 'end': 73, 'answer': 'had violated the order unknowingly'}\n",
            "{'score': 0.0005591019289568067, 'start': 106, 'end': 166, 'answer': 'contempt on two counts, and retired Chief Brian Sands and Lt'}\n",
            "{'score': 0.00042490652413107455, 'start': 153, 'end': 254, 'answer': 'evidentiary hearing, Sheriff Arpaio and Chief Deputy Sheridan made multiple intentional misstatements'}\n",
            "{'score': 0.0005936860106885433, 'start': 106, 'end': 112, 'answer': 'wither'}\n",
            "{'score': 0.0006531550316140056, 'start': 40, 'end': 119, 'answer': 'investigator to look into comments Snow’s wife purportedly made in a restaurant'}\n",
            "{'score': 0.0008155058603733778, 'start': 133, 'end': 160, 'answer': 'impartial and should recuse'}\n",
            "{'score': 0.000716143986210227, 'start': 123, 'end': 172, 'answer': 'disobeyed orders to gather evidence and continued'}\n",
            "{'score': 0.002231624675914645, 'start': 27, 'end': 90, 'answer': 'thousands of pieces of evidence from the plaintiffs and deleted'}\n",
            "{'score': 0.009947161190211773, 'start': 42, 'end': 63, 'answer': 'the sheriff to resign'}\n",
            "{'score': 0.00046936003491282463, 'start': 110, 'end': 122, 'answer': 'be entrusted'}\n",
            "{'score': 0.0016919182380661368, 'start': 24, 'end': 66, 'answer': 'the original case against Arpaio, demanded'}\n",
            "{'score': 0.0003582575009204447, 'start': 86, 'end': 136, 'answer': 'investigations that root out and punish misconduct'}\n",
            "{'score': 0.0006941855535842478, 'start': 18, 'end': 25, 'answer': 'was one'}\n",
            "['Segall Maricopa', 'sheriff of Arizona’s Maricopa', 'were', 'had unusually harsh words for Arpaio', 'inequitable application of discipline', 'had encouraged', 'had violated the order \"out of spite', 'had violated the order unknowingly', 'contempt on two counts, and retired Chief Brian Sands and Lt', 'evidentiary hearing, Sheriff Arpaio and Chief Deputy Sheridan made multiple intentional misstatements', 'wither', 'investigator to look into comments Snow’s wife purportedly made in a restaurant', 'impartial and should recuse', 'disobeyed orders to gather evidence and continued', 'thousands of pieces of evidence from the plaintiffs and deleted', 'the sheriff to resign', 'be entrusted', 'the original case against Arpaio, demanded', 'investigations that root out and punish misconduct', 'was one']\n",
            "{'score': 0.000249674340011552, 'start': 68, 'end': 96, 'answer': 'less, to one singular staple'}\n",
            "{'score': 6.074666089261882e-05, 'start': 626, 'end': 642, 'answer': 'Iggy Pop, Johnny'}\n",
            "{'score': 0.0002799518988467753, 'start': 118, 'end': 131, 'answer': \"CBGB's legacy\"}\n",
            "{'score': 0.019348202273249626, 'start': 5, 'end': 15, 'answer': 'are you up'}\n",
            "{'score': 0.0009569316753186285, 'start': 27, 'end': 39, 'answer': \"'m just here\"}\n",
            "{'score': 0.0011984219308942556, 'start': 34, 'end': 48, 'answer': 'will start [in'}\n",
            "{'score': 0.003750760806724429, 'start': 35, 'end': 64, 'answer': 'Are you more of a theater guy'}\n",
            "{'score': 0.00011771534627769142, 'start': 356, 'end': 384, 'answer': 'was just, yeah, I’m enjoying'}\n",
            "{'score': 0.001637226203456521, 'start': 0, 'end': 33, 'answer': 'Were you familiar with the legacy'}\n",
            "{'score': 0.00014070475299376994, 'start': 183, 'end': 192, 'answer': 'very much'}\n",
            "{'score': 9.204458183376119e-05, 'start': 462, 'end': 496, 'answer': 'was amazing. They just had so much'}\n",
            "{'score': 0.006347659509629011, 'start': 0, 'end': 47, 'answer': 'Did you grow up listening to the music depicted'}\n",
            "{'score': 9.088208025787026e-05, 'start': 145, 'end': 152, 'answer': 'Blondie'}\n",
            "{'score': 0.00023915382917039096, 'start': 93, 'end': 100, 'answer': 'Blondie'}\n",
            "{'score': 0.006073561031371355, 'start': 0, 'end': 13, 'answer': 'Did you dress'}\n",
            "{'score': 0.002634655451402068, 'start': 47, 'end': 67, 'answer': 'was a new experience'}\n",
            "{'score': 0.003096518572419882, 'start': 47, 'end': 68, 'answer': 'did you come to learn'}\n",
            "{'score': 0.00013173266779631376, 'start': 478, 'end': 481, 'answer': 'lot'}\n",
            "{'score': 0.0001606619480298832, 'start': 0, 'end': 40, 'answer': 'Grint: Yeah, there wasn’t really a whole'}\n",
            "{'score': 0.012691345997154713, 'start': 6, 'end': 26, 'answer': 'was on set the whole'}\n",
            "{'score': 0.0009475144906900823, 'start': 72, 'end': 91, 'answer': 'was such a nice guy'}\n",
            "{'score': 0.013053366914391518, 'start': 0, 'end': 11, 'answer': 'Did he give'}\n",
            "{'score': 0.000492805615067482, 'start': 157, 'end': 196, 'answer': 'lot of that. And he was such a nice guy'}\n",
            "{'score': 0.008253783918917179, 'start': 0, 'end': 8, 'answer': 'Was this'}\n",
            "{'score': 0.0069120582193136215, 'start': 0, 'end': 6, 'answer': 'Grint:'}\n",
            "{'score': 0.0074545410461723804, 'start': 0, 'end': 20, 'answer': 'Were you comfortable'}\n",
            "{'score': 9.345345461042598e-05, 'start': 7, 'end': 59, 'answer': 'Weirdly, yeah. It didn’t really feel that big a deal'}\n",
            "{'score': 0.0013214112259447575, 'start': 81, 'end': 114, 'answer': \"that you'd be intimidated to have\"}\n",
            "{'score': 0.00275790155865252, 'start': 9, 'end': 22, 'answer': 'I think every'}\n",
            "{'score': 0.00020370537822600454, 'start': 231, 'end': 263, 'answer': 'was quite a hard one. It’s quite'}\n",
            "{'score': 0.0010696995304897428, 'start': 131, 'end': 176, 'answer': 'did you think of the band you were portraying'}\n",
            "{'score': 0.00024212285643443465, 'start': 156, 'end': 167, 'answer': 'I’ve always'}\n",
            "{'score': 0.013991734944283962, 'start': 23, 'end': 36, 'answer': 'd ever pursue'}\n",
            "{'score': 0.00122673693113029, 'start': 35, 'end': 57, 'answer': 'I’ve tried to leverage'}\n",
            "{'score': 0.0007102577365003526, 'start': 69, 'end': 123, 'answer': 'were your thoughts going into a character who was much'}\n",
            "{'score': 0.00016033940482884645, 'start': 104, 'end': 112, 'answer': 'some get'}\n",
            "{'score': 0.0025252888444811106, 'start': 23, 'end': 40, 'answer': 'Had you seen each'}\n",
            "{'score': 0.0001514876785222441, 'start': 302, 'end': 307, 'answer': 'great'}\n",
            "{'score': 0.00026572300703264773, 'start': 202, 'end': 257, 'answer': 'I don’t think I ever really saw him outside of that wig'}\n",
            "{'score': 0.005706635769456625, 'start': 33, 'end': 37, 'answer': 'most'}\n",
            "{'score': 0.0003665404801722616, 'start': 184, 'end': 207, 'answer': 'I love her, she’s great'}\n",
            "{'score': 0.002479806775227189, 'start': 28, 'end': 80, 'answer': \"It's October. What's your favorite Halloween costume\"}\n",
            "{'score': 0.00012160737242083997, 'start': 338, 'end': 358, 'answer': 'in it, and you’d get'}\n",
            "{'score': 0.0003495949786156416, 'start': 113, 'end': 131, 'answer': 'had a good costume'}\n",
            "{'score': 0.07318631559610367, 'start': 3, 'end': 9, 'answer': 'course'}\n",
            "{'score': 0.0005332187283784151, 'start': 120, 'end': 154, 'answer': 'a Play-Doh logo. With a yellow hat'}\n",
            "{'score': 0.017966624349355698, 'start': 12, 'end': 32, 'answer': 'a favorite Halloween'}\n",
            "{'score': 0.002254596445709467, 'start': 9, 'end': 21, 'answer': 'I don’t even'}\n",
            "{'score': 0.0002341876970604062, 'start': 148, 'end': 172, 'answer': 'all just kind of elderly'}\n",
            "{'score': 0.008295426145195961, 'start': 14, 'end': 36, 'answer': 'in limited release now'}\n",
            "['less, to one singular staple', 'Iggy Pop, Johnny', \"CBGB's legacy\", 'are you up', \"'m just here\", 'will start [in', 'Are you more of a theater guy', 'was just, yeah, I’m enjoying', 'Were you familiar with the legacy', 'very much', 'was amazing. They just had so much', 'Did you grow up listening to the music depicted', 'Blondie', 'Blondie', 'Did you dress', 'was a new experience', 'did you come to learn', 'lot', 'Grint: Yeah, there wasn’t really a whole', 'was on set the whole', 'was such a nice guy', 'Did he give', 'lot of that. And he was such a nice guy', 'Was this', 'Grint:', 'Were you comfortable', 'Weirdly, yeah. It didn’t really feel that big a deal', \"that you'd be intimidated to have\", 'I think every', 'was quite a hard one. It’s quite', 'did you think of the band you were portraying', 'I’ve always', 'd ever pursue', 'I’ve tried to leverage', 'were your thoughts going into a character who was much', 'some get', 'Had you seen each', 'great', 'I don’t think I ever really saw him outside of that wig', 'most', 'I love her, she’s great', \"It's October. What's your favorite Halloween costume\", 'in it, and you’d get', 'had a good costume', 'course', 'a Play-Doh logo. With a yellow hat', 'a favorite Halloween', 'I don’t even', 'all just kind of elderly', 'in limited release now']\n",
            "{'score': 0.0006408779299817979, 'start': 139, 'end': 161, 'answer': 'in ultra-sexy skivvies'}\n",
            "{'score': 0.0003347607562318444, 'start': 36, 'end': 46, 'answer': 'Rossellini'}\n",
            "{'score': 0.000382891419576481, 'start': 180, 'end': 204, 'answer': 'of like a superhero suit'}\n",
            "{'score': 0.0007108735153451562, 'start': 29, 'end': 79, 'answer': 'Wiedemann hosts an online cooking series for Vogue'}\n",
            "{'score': 0.0007189325988292694, 'start': 78, 'end': 136, 'answer': 'my core. My diet stayed pretty much the same, except I cut'}\n",
            "{'score': 0.00017879084043670446, 'start': 251, 'end': 273, 'answer': 'be \"sexier and curvier'}\n",
            "{'score': 0.0007243676809594035, 'start': 11, 'end': 24, 'answer': \"we don't plan\"}\n",
            "['in ultra-sexy skivvies', 'Rossellini', 'of like a superhero suit', 'Wiedemann hosts an online cooking series for Vogue', 'my core. My diet stayed pretty much the same, except I cut', 'be \"sexier and curvier', \"we don't plan\"]\n",
            "{'score': 0.0005081328563392162, 'start': 100, 'end': 115, 'answer': \"mid-'90s. Clark\"}\n",
            "{'score': 0.000470618688268587, 'start': 19, 'end': 45, 'answer': 'I really missed it,\" Clark'}\n",
            "{'score': 0.00025684156571514904, 'start': 45, 'end': 96, 'answer': 'took up writing. Since leaving the courtroom, Clark'}\n",
            "{'score': 0.00010663364082574844, 'start': 408, 'end': 423, 'answer': \"Wow, you're not\"}\n",
            "{'score': 0.0010563196847215295, 'start': 52, 'end': 73, 'answer': 'did change me,\" Clark'}\n",
            "{'score': 0.00015636208991054446, 'start': 356, 'end': 359, 'answer': '100'}\n",
            "[\"mid-'90s. Clark\", 'I really missed it,\" Clark', 'took up writing. Since leaving the courtroom, Clark', \"Wow, you're not\", 'did change me,\" Clark', '100']\n",
            "{'score': 0.004218541085720062, 'start': 44, 'end': 63, 'answer': 'selling her Beverly'}\n",
            "{'score': 0.0004297349660191685, 'start': 118, 'end': 128, 'answer': 'well worth'}\n",
            "{'score': 0.00016357668209820986, 'start': 256, 'end': 267, 'answer': 'too big for'}\n",
            "['selling her Beverly', 'well worth', 'too big for']\n",
            "{'score': 0.11084438860416412, 'start': 0, 'end': 9, 'answer': 'Instagram'}\n",
            "{'score': 0.012177770026028156, 'start': 38, 'end': 47, 'answer': 'good deal'}\n",
            "{'score': 0.0020519501995295286, 'start': 14, 'end': 46, 'answer': 'straits when you realise we live'}\n",
            "{'score': 0.00034845469053834677, 'start': 218, 'end': 255, 'answer': 'raking in seven-figure salaries every'}\n",
            "{'score': 0.011661252938210964, 'start': 6, 'end': 19, 'answer': 'Hathaway – £3'}\n",
            "{'score': 0.0012751570902764797, 'start': 13, 'end': 42, 'answer': 'fanatic earns a small fortune'}\n",
            "{'score': 0.0037719779647886753, 'start': 17, 'end': 36, 'answer': 'most of her selfies'}\n",
            "{'score': 0.0018697840860113502, 'start': 24, 'end': 48, 'answer': 'Hathaway (@paigehathaway'}\n",
            "{'score': 0.0018705271650105715, 'start': 24, 'end': 48, 'answer': 'Hathaway (@paigehathaway'}\n",
            "{'score': 0.012828857637941837, 'start': 8, 'end': 18, 'answer': 'Zales – £3'}\n",
            "{'score': 0.010152325965464115, 'start': 51, 'end': 64, 'answer': 'hair removal.'}\n",
            "{'score': 0.005914499517530203, 'start': 14, 'end': 50, 'answer': 'TeamNoFuzz with alarming regularity.'}\n",
            "{'score': 0.0017959499964490533, 'start': 26, 'end': 46, 'answer': 'Zales (@chantelzales'}\n",
            "{'score': 0.001805089064873755, 'start': 26, 'end': 46, 'answer': 'Zales (@chantelzales'}\n",
            "{'score': 0.01728573441505432, 'start': 4, 'end': 11, 'answer': 'Cheri –'}\n",
            "{'score': 0.0022496881429105997, 'start': 79, 'end': 83, 'answer': 'hell'}\n",
            "{'score': 0.001931681064888835, 'start': 0, 'end': 12, 'answer': 'We just hope'}\n",
            "{'score': 0.002116801682859659, 'start': 18, 'end': 38, 'answer': 'AnaCherí (@anacheri'}\n",
            "{'score': 0.0020849748980253935, 'start': 30, 'end': 69, 'answer': 'anacheri) on Jul 25, 2016 at 2:42pm PDT'}\n",
            "{'score': 0.014122335240244865, 'start': 8, 'end': 22, 'answer': 'Ratchford – £2'}\n",
            "{'score': 0.0006177743780426681, 'start': 156, 'end': 168, 'answer': 'of it rubbed'}\n",
            "{'score': 0.01309480331838131, 'start': 14, 'end': 30, 'answer': 'could definitely'}\n",
            "{'score': 0.0014939523534849286, 'start': 28, 'end': 31, 'answer': 'i l'}\n",
            "{'score': 0.0015106054488569498, 'start': 28, 'end': 31, 'answer': 'i l'}\n",
            "{'score': 0.017519762739539146, 'start': 8, 'end': 19, 'answer': 'Alende – £2'}\n",
            "{'score': 0.001905894372612238, 'start': 15, 'end': 32, 'answer': 'doppleganger gets'}\n",
            "{'score': 0.0042066448368132114, 'start': 18, 'end': 45, 'answer': 'all back, she’s really just'}\n",
            "{'score': 0.00246664066798985, 'start': 27, 'end': 49, 'answer': 'Alende (@claudiaalende'}\n",
            "{'score': 0.0026424808893352747, 'start': 27, 'end': 49, 'answer': 'Alende (@claudiaalende'}\n",
            "{'score': 0.01806611754000187, 'start': 9, 'end': 20, 'answer': 'Somers – £2'}\n",
            "{'score': 0.0018786852015182376, 'start': 71, 'end': 126, 'answer': 'waist training wraps that look a little like tofu bacon'}\n",
            "{'score': 0.0020047849975526333, 'start': 27, 'end': 49, 'answer': 'Somers (@lacikaysomers'}\n",
            "{'score': 0.002007280010730028, 'start': 27, 'end': 49, 'answer': 'Somers (@lacikaysomers'}\n",
            "{'score': 0.018528543412685394, 'start': 0, 'end': 15, 'answer': 'Amanda Lee – £1'}\n",
            "{'score': 0.0038144844584167004, 'start': 47, 'end': 70, 'answer': 'protein shakes and hang'}\n",
            "{'score': 0.0014066341100260615, 'start': 83, 'end': 87, 'answer': 'have'}\n",
            "{'score': 0.002056300174444914, 'start': 31, 'end': 76, 'answer': 'amandaeliselee) on Aug 29, 2016 at 5:22pm PDT'}\n",
            "{'score': 0.0020481334067881107, 'start': 31, 'end': 76, 'answer': 'amandaeliselee) on Aug 19, 2015 at 1:42pm PDT'}\n",
            "{'score': 0.01668391562998295, 'start': 6, 'end': 18, 'answer': 'Falconi – £1'}\n",
            "{'score': 0.001819620025344193, 'start': 79, 'end': 114, 'answer': 'legitimate nutritionist would avoid'}\n",
            "{'score': 0.010729795321822166, 'start': 0, 'end': 42, 'answer': 'You know, for the health of their clients.'}\n",
            "{'score': 0.0018982174806296825, 'start': 24, 'end': 46, 'answer': 'Falconi (@bellafalconi'}\n",
            "{'score': 0.001910004997625947, 'start': 24, 'end': 46, 'answer': 'Falconi (@bellafalconi'}\n",
            "{'score': 0.0005568308406509459, 'start': 122, 'end': 171, 'answer': 'fillers to liposuction and private gym membership'}\n",
            "{'score': 0.0011070218170061707, 'start': 85, 'end': 104, 'answer': 'fulfilling prophecy'}\n",
            "{'score': 0.11420920491218567, 'start': 0, 'end': 5, 'answer': 'GIPHY'}\n",
            "{'score': 0.001128686242736876, 'start': 138, 'end': 147, 'answer': 'judgement'}\n",
            "{'score': 0.0005756427417509258, 'start': 141, 'end': 190, 'answer': 'curled the bags maybe their arm gains would match'}\n",
            "['Instagram', 'good deal', 'straits when you realise we live', 'raking in seven-figure salaries every', 'Hathaway – £3', 'fanatic earns a small fortune', 'most of her selfies', 'Hathaway (@paigehathaway', 'Hathaway (@paigehathaway', 'Zales – £3', 'hair removal.', 'TeamNoFuzz with alarming regularity.', 'Zales (@chantelzales', 'Zales (@chantelzales', 'Cheri –', 'hell', 'We just hope', 'AnaCherí (@anacheri', 'anacheri) on Jul 25, 2016 at 2:42pm PDT', 'Ratchford – £2', 'of it rubbed', 'could definitely', 'i l', 'i l', 'Alende – £2', 'doppleganger gets', 'all back, she’s really just', 'Alende (@claudiaalende', 'Alende (@claudiaalende', 'Somers – £2', 'waist training wraps that look a little like tofu bacon', 'Somers (@lacikaysomers', 'Somers (@lacikaysomers', 'Amanda Lee – £1', 'protein shakes and hang', 'have', 'amandaeliselee) on Aug 29, 2016 at 5:22pm PDT', 'amandaeliselee) on Aug 19, 2015 at 1:42pm PDT', 'Falconi – £1', 'legitimate nutritionist would avoid', 'You know, for the health of their clients.', 'Falconi (@bellafalconi', 'Falconi (@bellafalconi', 'fillers to liposuction and private gym membership', 'fulfilling prophecy', 'GIPHY', 'judgement', 'curled the bags maybe their arm gains would match']\n",
            "{'score': 0.005496883764863014, 'start': 33, 'end': 37, 'answer': 'most'}\n",
            "{'score': 0.000804780749604106, 'start': 164, 'end': 181, 'answer': 'have in your home'}\n",
            "{'score': 0.0007140836678445339, 'start': 152, 'end': 189, 'answer': 'often the filthiest part of a kitchen'}\n",
            "{'score': 0.023358888924121857, 'start': 10, 'end': 26, 'answer': 'YOUR OWN CLEANER'}\n",
            "{'score': 0.0007001508492976427, 'start': 101, 'end': 110, 'answer': 'Hellewell'}\n",
            "{'score': 0.0015907706692814827, 'start': 93, 'end': 115, 'answer': 'wonders to help remove'}\n",
            "{'score': 0.006536911707371473, 'start': 18, 'end': 23, 'answer': 'react'}\n",
            "{'score': 0.0006795859662815928, 'start': 9, 'end': 56, 'answer': 'paste onto the area you need to treat and leave'}\n",
            "{'score': 0.019608424976468086, 'start': 20, 'end': 22, 'answer': '30'}\n",
            "{'score': 0.004087336361408234, 'start': 6, 'end': 73, 'answer': \"was the last time you removed the shelves from your oven?' asks Rik\"}\n",
            "{'score': 0.0012107574148103595, 'start': 116, 'end': 124, 'answer': 'you keep'}\n",
            "{'score': 0.00042777982889674604, 'start': 165, 'end': 239, 'answer': 'soak. Make sure you read the instructions on the cleaning product and wear'}\n",
            "{'score': 0.0010373643599450588, 'start': 30, 'end': 69, 'answer': 'shelving from the resealable bag. Rinse'}\n",
            "{'score': 0.02093283087015152, 'start': 14, 'end': 24, 'answer': 'TOOTHBRUSH'}\n",
            "{'score': 0.0010781919118016958, 'start': 8, 'end': 34, 'answer': 'toothbrush is an essential'}\n",
            "{'score': 0.0022402945905923843, 'start': 17, 'end': 47, 'answer': 'you use an electric toothbrush'}\n",
            "{'score': 0.020609788596630096, 'start': 0, 'end': 6, 'answer': '4. USE'}\n",
            "{'score': 0.00296241813339293, 'start': 20, 'end': 25, 'answer': 'ideal'}\n",
            "{'score': 0.0012393355136737227, 'start': 42, 'end': 90, 'answer': 'soak in oven cleaner and warm water, then scrape'}\n",
            "{'score': 0.026035398244857788, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.0024064083117991686, 'start': 4, 'end': 41, 'answer': 'may sound strange, but you can remove'}\n",
            "{'score': 0.0008973624790087342, 'start': 1, 'end': 58, 'answer': 'In fact, this technique will make clean-ups in the future'}\n",
            "{'score': 0.0009590145782567561, 'start': 98, 'end': 143, 'answer': 'areas with all-purpose oven cleaner to ensure'}\n",
            "{'score': 0.020193709060549736, 'start': 0, 'end': 1, 'answer': '6'}\n",
            "{'score': 0.004034120123833418, 'start': 7, 'end': 34, 'answer': 'all cooked a wonderful meal'}\n",
            "{'score': 0.0020331568084657192, 'start': 39, 'end': 46, 'answer': 'pungent'}\n",
            "{'score': 0.0009333143243566155, 'start': 14, 'end': 26, 'answer': 'few drops in'}\n",
            "{'score': 0.022816993296146393, 'start': 0, 'end': 6, 'answer': '7. USE'}\n",
            "{'score': 0.0009329801541753113, 'start': 77, 'end': 126, 'answer': 'hob can help remove built-up grease. Simply apply'}\n",
            "{'score': 0.00018527488282416016, 'start': 52, 'end': 71, 'answer': 'hob clean, sprinkle'}\n",
            "{'score': 0.018130222335457802, 'start': 0, 'end': 30, 'answer': '8. POLISH WITH CREAM OF TARTAR'}\n",
            "{'score': 0.0014827220002189279, 'start': 34, 'end': 79, 'answer': 'odd cleaning product to use on your oven, but'}\n",
            "{'score': 0.0034840020816773176, 'start': 0, 'end': 38, 'answer': \"'Simply apply with a thin cloth, leave\"}\n",
            "{'score': 0.010576477274298668, 'start': 0, 'end': 39, 'answer': '9. REMOVE STUCK ON FOOD WITH DISHWASHER'}\n",
            "{'score': 0.0011979085393249989, 'start': 79, 'end': 99, 'answer': 'pans in a dishwasher'}\n",
            "{'score': 0.0007001943304203451, 'start': 0, 'end': 18, 'answer': \"'Take a dishwasher\"}\n",
            "{'score': 0.02340570278465748, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 0.004555367864668369, 'start': 11, 'end': 44, 'answer': 'very quick and easy way to battle'}\n",
            "{'score': 0.0010498978663235903, 'start': 110, 'end': 132, 'answer': 'you can; if not, leave'}\n",
            "{'score': 0.0007406551740132272, 'start': 104, 'end': 163, 'answer': 'on food remains, cover with your homemade cleaning solution'}\n",
            "['most', 'have in your home', 'often the filthiest part of a kitchen', 'YOUR OWN CLEANER', 'Hellewell', 'wonders to help remove', 'react', 'paste onto the area you need to treat and leave', '30', \"was the last time you removed the shelves from your oven?' asks Rik\", 'you keep', 'soak. Make sure you read the instructions on the cleaning product and wear', 'shelving from the resealable bag. Rinse', 'TOOTHBRUSH', 'toothbrush is an essential', 'you use an electric toothbrush', '4. USE', 'ideal', 'soak in oven cleaner and warm water, then scrape', '5', 'may sound strange, but you can remove', 'In fact, this technique will make clean-ups in the future', 'areas with all-purpose oven cleaner to ensure', '6', 'all cooked a wonderful meal', 'pungent', 'few drops in', '7. USE', 'hob can help remove built-up grease. Simply apply', 'hob clean, sprinkle', '8. POLISH WITH CREAM OF TARTAR', 'odd cleaning product to use on your oven, but', \"'Simply apply with a thin cloth, leave\", '9. REMOVE STUCK ON FOOD WITH DISHWASHER', 'pans in a dishwasher', \"'Take a dishwasher\", '10', 'very quick and easy way to battle', 'you can; if not, leave', 'on food remains, cover with your homemade cleaning solution']\n",
            "{'score': 0.006822675000876188, 'start': 9, 'end': 35, 'answer': 'in this world that’s worth'}\n",
            "{'score': 0.0016464532818645239, 'start': 20, 'end': 32, 'answer': 'the BuzzFeed'}\n",
            "{'score': 0.0019227450247853994, 'start': 42, 'end': 60, 'answer': 'maybes.\" – Poussay'}\n",
            "{'score': 0.001265195431187749, 'start': 49, 'end': 104, 'answer': 'good old days before you’ve actually left them.\" – Andy'}\n",
            "{'score': 0.00038650649366900325, 'start': 51, 'end': 117, 'answer': 'They are a reminder that our lives will get better if we just hold'}\n",
            "{'score': 0.0035560482647269964, 'start': 46, 'end': 52, 'answer': 'Khatun'}\n",
            "{'score': 0.0006255198386497796, 'start': 128, 'end': 150, 'answer': 'you want that, too?\" –'}\n",
            "{'score': 0.0005035065696574748, 'start': 108, 'end': 122, 'answer': 'undeniable.\" –'}\n",
            "{'score': 0.0008866194984875619, 'start': 54, 'end': 100, 'answer': 'how tightly you hold on, it\\'s already gone.\" –'}\n",
            "{'score': 0.0008342903456650674, 'start': 37, 'end': 77, 'answer': 'being compatible, or novels about shared'}\n",
            "{'score': 0.00040037184953689575, 'start': 157, 'end': 180, 'answer': 'don’t necessarily spoil'}\n",
            "{'score': 0.0017524982104077935, 'start': 53, 'end': 97, 'answer': 'indifference.\" – Bree Van de Kamp, Desperate'}\n",
            "{'score': 0.0004790934326592833, 'start': 165, 'end': 181, 'answer': 'they move on.\" –'}\n",
            "{'score': 0.00032947835279628634, 'start': 138, 'end': 182, 'answer': 'too much of a coward for that, then burn.\" –'}\n",
            "{'score': 0.11350803077220917, 'start': 0, 'end': 3, 'answer': '13.'}\n",
            "{'score': 0.0008099092519842088, 'start': 124, 'end': 141, 'answer': 'You don’t deserve'}\n",
            "{'score': 0.00031271367333829403, 'start': 190, 'end': 195, 'answer': 'still'}\n",
            "{'score': 0.11982730031013489, 'start': 0, 'end': 3, 'answer': '16.'}\n",
            "{'score': 0.0008717525051906705, 'start': 107, 'end': 129, 'answer': 'you’re supposed to.\" –'}\n",
            "{'score': 0.0013844029745087028, 'start': 91, 'end': 113, 'answer': 'few.\" – Debbie Novotny'}\n",
            "{'score': 0.11770529299974442, 'start': 0, 'end': 2, 'answer': '19'}\n",
            "{'score': 0.0003804331354331225, 'start': 205, 'end': 255, 'answer': 't just run out of answers. You run out of hope.\" –'}\n",
            "{'score': 0.00032624907908029854, 'start': 210, 'end': 235, 'answer': 'well, I think you deserve'}\n",
            "{'score': 0.12656810879707336, 'start': 0, 'end': 2, 'answer': '22'}\n",
            "{'score': 0.0007017424795776606, 'start': 44, 'end': 108, 'answer': 'the world will not. Wear it like armour and it can never be used'}\n",
            "{'score': 0.0007931831642054021, 'start': 91, 'end': 116, 'answer': 'all you will ever see.\" –'}\n",
            "{'score': 0.13137343525886536, 'start': 0, 'end': 2, 'answer': '25'}\n",
            "{'score': 0.0002758066402748227, 'start': 235, 'end': 257, 'answer': 'would have stopped.\" –'}\n",
            "{'score': 0.0011061138939112425, 'start': 27, 'end': 102, 'answer': 'did love you because it makes me think that I might be capable of something'}\n",
            "{'score': 0.12696228921413422, 'start': 0, 'end': 2, 'answer': '28'}\n",
            "{'score': 0.001024744939059019, 'start': 0, 'end': 2, 'answer': '29'}\n",
            "{'score': 0.002683784579858184, 'start': 5, 'end': 45, 'answer': 'to be featured in similar BuzzFeed posts'}\n",
            "['in this world that’s worth', 'the BuzzFeed', 'maybes.\" – Poussay', 'good old days before you’ve actually left them.\" – Andy', 'They are a reminder that our lives will get better if we just hold', 'Khatun', 'you want that, too?\" –', 'undeniable.\" –', 'how tightly you hold on, it\\'s already gone.\" –', 'being compatible, or novels about shared', 'don’t necessarily spoil', 'indifference.\" – Bree Van de Kamp, Desperate', 'they move on.\" –', 'too much of a coward for that, then burn.\" –', '13.', 'You don’t deserve', 'still', '16.', 'you’re supposed to.\" –', 'few.\" – Debbie Novotny', '19', 't just run out of answers. You run out of hope.\" –', 'well, I think you deserve', '22', 'the world will not. Wear it like armour and it can never be used', 'all you will ever see.\" –', '25', 'would have stopped.\" –', 'did love you because it makes me think that I might be capable of something', '28', '29', 'to be featured in similar BuzzFeed posts']\n",
            "{'score': 0.014784645289182663, 'start': 13, 'end': 15, 'answer': 'be'}\n",
            "{'score': 0.0032919924706220627, 'start': 34, 'end': 64, 'answer': 'sinister oracle with the power'}\n",
            "{'score': 0.007032027933746576, 'start': 48, 'end': 61, 'answer': 'the year 2000'}\n",
            "{'score': 0.003808785928413272, 'start': 15, 'end': 32, 'answer': 'might be in store'}\n",
            "{'score': 0.004389308393001556, 'start': 3, 'end': 21, 'answer': 'Some alt-right guy'}\n",
            "{'score': 0.006756598595529795, 'start': 21, 'end': 32, 'answer': 'the episode'}\n",
            "{'score': 0.00446291733533144, 'start': 3, 'end': 29, 'answer': 'There will be a referendum'}\n",
            "{'score': 0.009329492226243019, 'start': 18, 'end': 22, 'answer': 'Much'}\n",
            "{'score': 0.0021812778431922197, 'start': 3, 'end': 71, 'answer': 'Greedy, corrupt energy firms will cause an environmental catastrophe'}\n",
            "{'score': 0.01595182903110981, 'start': 4, 'end': 33, 'answer': 'dome appeared in The Simpsons'}\n",
            "{'score': 0.0041222781874239445, 'start': 18, 'end': 41, 'answer': 'in Elton John’s private'}\n",
            "{'score': 0.007473488803952932, 'start': 18, 'end': 19, 'answer': 'I'}\n",
            "{'score': 0.0066431923769414425, 'start': 19, 'end': 35, 'answer': 'illegal to teach'}\n",
            "{'score': 0.014297140762209892, 'start': 5, 'end': 33, 'answer': 'the episode \"The Monkey Suit'}\n",
            "{'score': 0.0018003995064646006, 'start': 48, 'end': 60, 'answer': 'also sarcasm'}\n",
            "{'score': 0.008442721329629421, 'start': 5, 'end': 32, 'answer': 'the episode \"The Saved Lisa'}\n",
            "{'score': 0.002708381973206997, 'start': 12, 'end': 31, 'answer': 'Jolie and Brad Pitt'}\n",
            "{'score': 0.0015201782807707787, 'start': 26, 'end': 78, 'answer': 'Whopper\" , it’s revealed that the celeb trainer Lyle'}\n",
            "{'score': 0.001312806038185954, 'start': 90, 'end': 161, 'answer': 'several actual clowns will stand in elections around the world. And win'}\n",
            "{'score': 0.007160686422139406, 'start': 5, 'end': 16, 'answer': 'the episode'}\n",
            "{'score': 0.0025171779561787844, 'start': 12, 'end': 53, 'answer': 'Cumberbatch will be cast as David Cameron'}\n",
            "{'score': 0.002529153833165765, 'start': 26, 'end': 41, 'answer': 'Many-Splintered'}\n",
            "{'score': 0.008123030886054039, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 0.0030851480551064014, 'start': 34, 'end': 45, 'answer': 'the episode'}\n",
            "{'score': 0.010095757432281971, 'start': 12, 'end': 30, 'answer': 'Hawking will learn'}\n",
            "{'score': 0.009425616823136806, 'start': 18, 'end': 33, 'answer': 'They Saved Lisa'}\n",
            "{'score': 0.005697390530258417, 'start': 0, 'end': 51, 'answer': '12. To cut costs, industry workers will be replaced'}\n",
            "{'score': 0.010316790081560612, 'start': 5, 'end': 16, 'answer': 'the episode'}\n",
            "{'score': 0.002457419177517295, 'start': 41, 'end': 48, 'answer': 'was won'}\n",
            "{'score': 0.002764604054391384, 'start': 3, 'end': 14, 'answer': 'the episode'}\n",
            "{'score': 0.013603299856185913, 'start': 0, 'end': 9, 'answer': '14. White'}\n",
            "{'score': 0.002979524899274111, 'start': 11, 'end': 59, 'answer': 'that’s already happening. From the episode \"Lisa'}\n",
            "{'score': 0.001206488348543644, 'start': 50, 'end': 116, 'answer': 'there will be a female president. The Simpsons said it will happen'}\n",
            "['be', 'sinister oracle with the power', 'the year 2000', 'might be in store', 'Some alt-right guy', 'the episode', 'There will be a referendum', 'Much', 'Greedy, corrupt energy firms will cause an environmental catastrophe', 'dome appeared in The Simpsons', 'in Elton John’s private', 'I', 'illegal to teach', 'the episode \"The Monkey Suit', 'also sarcasm', 'the episode \"The Saved Lisa', 'Jolie and Brad Pitt', 'Whopper\" , it’s revealed that the celeb trainer Lyle', 'several actual clowns will stand in elections around the world. And win', 'the episode', 'Cumberbatch will be cast as David Cameron', 'Many-Splintered', '10', 'the episode', 'Hawking will learn', 'They Saved Lisa', '12. To cut costs, industry workers will be replaced', 'the episode', 'was won', 'the episode', '14. White', 'that’s already happening. From the episode \"Lisa', 'there will be a female president. The Simpsons said it will happen']\n",
            "{'score': 0.0006784379365853965, 'start': 98, 'end': 146, 'answer': 'least a couple of his draft classmates are still'}\n",
            "{'score': 0.00023022624372970313, 'start': 58, 'end': 77, 'answer': 'Nowitzki, 38, hopes'}\n",
            "{'score': 0.0007434344734065235, 'start': 91, 'end': 116, 'answer': '- unless you count the No'}\n",
            "{'score': 0.00017789617413654923, 'start': 300, 'end': 356, 'answer': 'being out of the league for six years, Traylor died of a'}\n",
            "{'score': 0.000196487846551463, 'start': 55, 'end': 77, 'answer': 'LaFrentz, No. 4 Antawn'}\n",
            "{'score': 0.00017600294086150825, 'start': 210, 'end': 255, 'answer': 'Half Man, Half Amazing,\" Carter redefined his'}\n",
            "{'score': 0.0002888481831178069, 'start': 0, 'end': 32, 'answer': 'Nowitzki, the No. 9 pick despite'}\n",
            "{'score': 0.0005534219671972096, 'start': 97, 'end': 101, 'answer': 'most'}\n",
            "{'score': 0.00019955913012381643, 'start': 30, 'end': 33, 'answer': 'one'}\n",
            "{'score': 0.00013728033809456974, 'start': 0, 'end': 8, 'answer': 'Nowitzki'}\n",
            "{'score': 0.0032445841934531927, 'start': 8, 'end': 71, 'answer': 'greats separately sat down with ESPN recently for a three-way Q'}\n",
            "{'score': 7.295907562365755e-05, 'start': 377, 'end': 383, 'answer': 'd love'}\n",
            "{'score': 0.00012636497558560222, 'start': 270, 'end': 306, 'answer': 'division to the NBA. That was a huge'}\n",
            "{'score': 9.555267752148211e-05, 'start': 473, 'end': 486, 'answer': 'was literally'}\n",
            "{'score': 0.002064450876787305, 'start': 58, 'end': 72, 'answer': 'was incredible'}\n",
            "{'score': 0.004470381885766983, 'start': 5, 'end': 59, 'answer': 'Nowitzki, on his reaction to being drafted by the Mavs'}\n",
            "{'score': 9.869045607047155e-05, 'start': 327, 'end': 367, 'answer': 'Had a press conference. Never had a suit'}\n",
            "{'score': 0.00012304152187425643, 'start': 254, 'end': 278, 'answer': 'Strick [Erick Strickland'}\n",
            "{'score': 7.49568862374872e-05, 'start': 479, 'end': 521, 'answer': 'were a great team right [then], not really'}\n",
            "{'score': 0.00017081957776099443, 'start': 179, 'end': 197, 'answer': \"If they don't take\"}\n",
            "{'score': 0.0015423098811879754, 'start': 57, 'end': 68, 'answer': 'I was going'}\n",
            "{'score': 0.0004629725299309939, 'start': 84, 'end': 132, 'answer': \"was just weird. I thought I'd be in the top five\"}\n",
            "{'score': 0.0005062982672825456, 'start': 160, 'end': 168, 'answer': 'me to be'}\n",
            "{'score': 0.00013274510274641216, 'start': 127, 'end': 137, 'answer': 'Olowokandi'}\n",
            "{'score': 0.00019354400865267962, 'start': 32, 'end': 42, 'answer': 'Olowokandi'}\n",
            "{'score': 6.298589869402349e-05, 'start': 476, 'end': 508, 'answer': \"well come work out.' That's what\"}\n",
            "{'score': 0.0009755367645993829, 'start': 3, 'end': 77, 'answer': 'was introduced to the business of basketball pretty much in the first five'}\n",
            "{'score': 0.005944235250353813, 'start': 17, 'end': 47, 'answer': 'being traded from Golden State'}\n",
            "{'score': 0.0003529885725583881, 'start': 33, 'end': 51, 'answer': 'was just perplexed'}\n",
            "{'score': 0.00036075946991331875, 'start': 235, 'end': 243, 'answer': 'was just'}\n",
            "{'score': 0.00015103782061487436, 'start': 117, 'end': 126, 'answer': 'Antawn at'}\n",
            "{'score': 9.464671165915206e-05, 'start': 351, 'end': 417, 'answer': 'was already walking up to the stage. It blindsides me, pretty much'}\n",
            "{'score': 0.0001256906834896654, 'start': 430, 'end': 434, 'answer': 'each'}\n",
            "{'score': 0.0004104370018467307, 'start': 0, 'end': 8, 'answer': 'Nowitzki'}\n",
            "{'score': 0.0001429339754395187, 'start': 361, 'end': 367, 'answer': 'always'}\n",
            "{'score': 0.0002088548062602058, 'start': 305, 'end': 338, 'answer': 'was fun to watch during his prime'}\n",
            "{'score': 0.0004476677568163723, 'start': 63, 'end': 138, 'answer': 'athleticism and great shooting touch. Usually you see one without the other'}\n",
            "{'score': 0.00027948356000706553, 'start': 174, 'end': 184, 'answer': 'he was one'}\n",
            "{'score': 0.004249559249728918, 'start': 45, 'end': 64, 'answer': 'transcendent player'}\n",
            "{'score': 0.00018611073028296232, 'start': 239, 'end': 274, 'answer': \"loves to compete. And he's selfless\"}\n",
            "{'score': 0.00013425273937173188, 'start': 224, 'end': 226, 'answer': 'me'}\n",
            "{'score': 0.0001371527905575931, 'start': 198, 'end': 205, 'answer': 'in hell'}\n",
            "{'score': 0.00018058974819723517, 'start': 0, 'end': 8, 'answer': 'Nowitzki'}\n",
            "{'score': 0.00037177797639742494, 'start': 59, 'end': 75, 'answer': 'was a great flat'}\n",
            "{'score': 0.00031529387342743576, 'start': 112, 'end': 120, 'answer': 'McDonald'}\n",
            "{'score': 0.00027334835613146424, 'start': 263, 'end': 276, 'answer': 'you just hope'}\n",
            "{'score': 0.000550141092389822, 'start': 21, 'end': 39, 'answer': 'many great battles'}\n",
            "{'score': 9.630434215068817e-05, 'start': 260, 'end': 297, 'answer': 'was just sitting on my butt in my 20s'}\n",
            "{'score': 0.00026059444644488394, 'start': 57, 'end': 102, 'answer': 'mid-aged guy. Couple of young guys, but still'}\n",
            "{'score': 0.00024766550632193685, 'start': 244, 'end': 265, 'answer': 'hopefully I can [stay'}\n",
            "{'score': 0.00043504900531843305, 'start': 153, 'end': 179, 'answer': \"camaraderie that I'm going\"}\n",
            "{'score': 0.0003246614069212228, 'start': 132, 'end': 182, 'answer': 'lot of bus rides, a lot of pregame speeches, a lot'}\n",
            "{'score': 0.0028659573290497065, 'start': 33, 'end': 45, 'answer': \"I'm enjoying\"}\n",
            "{'score': 9.388775652041659e-05, 'start': 293, 'end': 308, 'answer': \"There's nothing\"}\n",
            "{'score': 0.00011112277570646256, 'start': 376, 'end': 419, 'answer': \"were just kind of like, 'Where do I go from\"}\n",
            "{'score': 0.00014241579629015177, 'start': 268, 'end': 293, 'answer': \"I go?' Then just spending\"}\n",
            "{'score': 6.237721390789375e-05, 'start': 297, 'end': 304, 'answer': \"I'm not\"}\n",
            "{'score': 9.529624367132783e-05, 'start': 250, 'end': 320, 'answer': 'have been doing it all these years but can see yourself [coaching full'}\n",
            "{'score': 0.00018811467452906072, 'start': 227, 'end': 245, 'answer': 'me, because I love'}\n",
            "{'score': 9.134034917224199e-05, 'start': 0, 'end': 46, 'answer': 'Nowitzki: [Heavy sigh.] That sounds like a lot'}\n",
            "{'score': 0.00013412097177933902, 'start': 25, 'end': 40, 'answer': \"tough. It's not\"}\n",
            "{'score': 0.000266108923824504, 'start': 210, 'end': 215, 'answer': 'going'}\n",
            "['least a couple of his draft classmates are still', 'Nowitzki, 38, hopes', '- unless you count the No', 'being out of the league for six years, Traylor died of a', 'LaFrentz, No. 4 Antawn', 'Half Man, Half Amazing,\" Carter redefined his', 'Nowitzki, the No. 9 pick despite', 'most', 'one', 'Nowitzki', 'greats separately sat down with ESPN recently for a three-way Q', 'd love', 'division to the NBA. That was a huge', 'was literally', 'was incredible', 'Nowitzki, on his reaction to being drafted by the Mavs', 'Had a press conference. Never had a suit', 'Strick [Erick Strickland', 'were a great team right [then], not really', \"If they don't take\", 'I was going', \"was just weird. I thought I'd be in the top five\", 'me to be', 'Olowokandi', 'Olowokandi', \"well come work out.' That's what\", 'was introduced to the business of basketball pretty much in the first five', 'being traded from Golden State', 'was just perplexed', 'was just', 'Antawn at', 'was already walking up to the stage. It blindsides me, pretty much', 'each', 'Nowitzki', 'always', 'was fun to watch during his prime', 'athleticism and great shooting touch. Usually you see one without the other', 'he was one', 'transcendent player', \"loves to compete. And he's selfless\", 'me', 'in hell', 'Nowitzki', 'was a great flat', 'McDonald', 'you just hope', 'many great battles', 'was just sitting on my butt in my 20s', 'mid-aged guy. Couple of young guys, but still', 'hopefully I can [stay', \"camaraderie that I'm going\", 'lot of bus rides, a lot of pregame speeches, a lot', \"I'm enjoying\", \"There's nothing\", \"were just kind of like, 'Where do I go from\", \"I go?' Then just spending\", \"I'm not\", 'have been doing it all these years but can see yourself [coaching full', 'me, because I love', 'Nowitzki: [Heavy sigh.] That sounds like a lot', \"tough. It's not\", 'going']\n",
            "{'score': 0.0005319294868968427, 'start': 134, 'end': 185, 'answer': 'there are easy ways to treat some small afflictions'}\n",
            "{'score': 0.0017109455075114965, 'start': 21, 'end': 88, 'answer': '-yourself remedies and get a quick fix for everything from earaches'}\n",
            "{'score': 0.0009548982488922775, 'start': 3, 'end': 16, 'answer': 'Mouthwash for'}\n",
            "{'score': 0.0005592452362179756, 'start': 3, 'end': 16, 'answer': 'Black tea for'}\n",
            "{'score': 0.0007859364850446582, 'start': 9, 'end': 26, 'answer': 'cider vinegar for'}\n",
            "{'score': 0.0008841571398079395, 'start': 32, 'end': 63, 'answer': 'often used as an energy booster'}\n",
            "{'score': 0.0021805823780596256, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.00035380711778998375, 'start': 12, 'end': 24, 'answer': 'peroxide for'}\n",
            "{'score': 0.0008414207259193063, 'start': 0, 'end': 34, 'answer': '7. Honey for cuts and small wounds'}\n",
            "{'score': 0.0014306219527497888, 'start': 0, 'end': 1, 'answer': '8'}\n",
            "{'score': 0.0013647625455632806, 'start': 0, 'end': 1, 'answer': '9'}\n",
            "{'score': 0.001105301664210856, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 0.0008831903105601668, 'start': 0, 'end': 2, 'answer': '11'}\n",
            "{'score': 0.0014833511086180806, 'start': 81, 'end': 99, 'answer': 'suffocate the wart'}\n",
            "{'score': 0.0008176041883416474, 'start': 0, 'end': 2, 'answer': '13'}\n",
            "{'score': 0.0016407478833571076, 'start': 37, 'end': 75, 'answer': 'they’re so easy. I’m going to remember'}\n",
            "['there are easy ways to treat some small afflictions', '-yourself remedies and get a quick fix for everything from earaches', 'Mouthwash for', 'Black tea for', 'cider vinegar for', 'often used as an energy booster', '5', 'peroxide for', '7. Honey for cuts and small wounds', '8', '9', '10', '11', 'suffocate the wart', '13', 'they’re so easy. I’m going to remember']\n",
            "{'score': 0.0031268747989088297, 'start': 9, 'end': 67, 'answer': 'high-pressured jobs with starting families and maintaining'}\n",
            "{'score': 0.002859757049009204, 'start': 11, 'end': 51, 'answer': 'there was a simple three-minute solution'}\n",
            "{'score': 0.0013197589432820678, 'start': 107, 'end': 124, 'answer': 'anyone can master'}\n",
            "{'score': 0.0006084433989599347, 'start': 12, 'end': 18, 'answer': 'FEMAIL'}\n",
            "{'score': 0.0007406706572510302, 'start': 23, 'end': 41, 'answer': 'all you need to do'}\n",
            "{'score': 0.001096229418180883, 'start': 130, 'end': 151, 'answer': 'in through two straws'}\n",
            "{'score': 0.0010589909506961703, 'start': 85, 'end': 101, 'answer': 'are going to hit'}\n",
            "{'score': 0.0030226418748497963, 'start': 31, 'end': 65, 'answer': 'in and out through the nose as per'}\n",
            "{'score': 0.0009302295511588454, 'start': 140, 'end': 162, 'answer': 'shoulders, eyes, mouth'}\n",
            "['high-pressured jobs with starting families and maintaining', 'there was a simple three-minute solution', 'anyone can master', 'FEMAIL', 'all you need to do', 'in through two straws', 'are going to hit', 'in and out through the nose as per', 'shoulders, eyes, mouth']\n",
            "{'score': 0.0017321701161563396, 'start': 6, 'end': 53, 'answer': 'ex-girlfriend of former basketball Alvin Japhet'}\n",
            "{'score': 0.0015431196661666036, 'start': 58, 'end': 81, 'answer': 'Investigation (NBI) for'}\n",
            "{'score': 0.002501219743862748, 'start': 2, 'end': 10, 'answer': 'Not only'}\n",
            "{'score': 0.0024259549099951982, 'start': 51, 'end': 83, 'answer': 'on the offense has now committed'}\n",
            "{'score': 0.0006883611204102635, 'start': 76, 'end': 92, 'answer': 'in an entrapment'}\n",
            "{'score': 0.005468619987368584, 'start': 2, 'end': 52, 'answer': 'mug shot of the suspect. (photo credit: gmanetwork'}\n",
            "{'score': 0.0007803403423167765, 'start': 0, 'end': 16, 'answer': 'According to GMA'}\n",
            "{'score': 0.0011910026660189033, 'start': 110, 'end': 141, 'answer': 'only lasted for a year after he'}\n",
            "{'score': 0.0004963662941008806, 'start': 97, 'end': 116, 'answer': 'hubad sa hallway ng'}\n",
            "{'score': 0.0006549227982759476, 'start': 61, 'end': 92, 'answer': 'strangles me, he tries to crush'}\n",
            "{'score': 0.0062185791321098804, 'start': 27, 'end': 66, 'answer': 'Almario has also threatened her parents'}\n",
            "{'score': 0.0005657114670611918, 'start': 145, 'end': 159, 'answer': 'common friends'}\n",
            "{'score': 0.0034116236492991447, 'start': 51, 'end': 84, 'answer': 'at him. (photo credit: gmanetwork'}\n",
            "{'score': 0.005000727251172066, 'start': 45, 'end': 48, 'answer': 'way'}\n",
            "{'score': 0.002137256320565939, 'start': 33, 'end': 41, 'answer': 'would do'}\n",
            "{'score': 0.0036838522646576166, 'start': 18, 'end': 61, 'answer': 'been able to speak up, the suspect remained'}\n",
            "{'score': 0.0016811923123896122, 'start': 29, 'end': 70, 'answer': 'CCD) chief Ronald Aguto Jr. (photo credit'}\n",
            "{'score': 0.0002419501543045044, 'start': 42, 'end': 45, 'answer': 'CCD'}\n",
            "{'score': 0.000576373771764338, 'start': 212, 'end': 222, 'answer': 'them.-Kami'}\n",
            "['ex-girlfriend of former basketball Alvin Japhet', 'Investigation (NBI) for', 'Not only', 'on the offense has now committed', 'in an entrapment', 'mug shot of the suspect. (photo credit: gmanetwork', 'According to GMA', 'only lasted for a year after he', 'hubad sa hallway ng', 'strangles me, he tries to crush', 'Almario has also threatened her parents', 'common friends', 'at him. (photo credit: gmanetwork', 'way', 'would do', 'been able to speak up, the suspect remained', 'CCD) chief Ronald Aguto Jr. (photo credit', 'CCD', 'them.-Kami']\n",
            "{'score': 0.0010034851729869843, 'start': 0, 'end': 55, 'answer': 'Did you know theres actually a right way to shower? Get'}\n",
            "{'score': 0.000500979833304882, 'start': 45, 'end': 49, 'answer': 'most'}\n",
            "{'score': 0.0006053614779375494, 'start': 13, 'end': 74, 'answer': 'you know that some of the most common shower habits might not'}\n",
            "{'score': 0.003842014819383621, 'start': 49, 'end': 58, 'answer': 'are doing'}\n",
            "{'score': 0.03203820809721947, 'start': 0, 'end': 1, 'answer': '1'}\n",
            "{'score': 0.0002604768378660083, 'start': 74, 'end': 113, 'answer': 'already in the shower. However, despite'}\n",
            "{'score': 0.00030106143094599247, 'start': 136, 'end': 166, 'answer': 'irritation—it could even burst'}\n",
            "{'score': 0.03156985342502594, 'start': 3, 'end': 6, 'answer': 'Not'}\n",
            "{'score': 0.0006244368269108236, 'start': 102, 'end': 155, 'answer': 'there’s no real reason to actually bend down and give'}\n",
            "{'score': 0.00042142579331994057, 'start': 8, 'end': 18, 'answer': 'you’re not'}\n",
            "{'score': 0.0010612166952341795, 'start': 11, 'end': 17, 'answer': 'excuse'}\n",
            "{'score': 0.010510949417948723, 'start': 3, 'end': 6, 'answer': 'Not'}\n",
            "{'score': 0.0009055019472725689, 'start': 101, 'end': 121, 'answer': 'that can be terrible'}\n",
            "{'score': 0.0009639484924264252, 'start': 67, 'end': 88, 'answer': 'you’re out, or create'}\n",
            "{'score': 0.029131431132555008, 'start': 0, 'end': 20, 'answer': '4. Using a Soap Dish'}\n",
            "{'score': 0.00017857334751170129, 'start': 320, 'end': 325, 'answer': 'going'}\n",
            "{'score': 0.0007569153676740825, 'start': 7, 'end': 19, 'answer': 'have reasons'}\n",
            "{'score': 0.028846418485045433, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.00045623781625181437, 'start': 206, 'end': 223, 'answer': 'be doing a number'}\n",
            "{'score': 0.00021917076082900167, 'start': 89, 'end': 120, 'answer': 'their soap as the first culprit'}\n",
            "{'score': 0.021031899377703667, 'start': 0, 'end': 1, 'answer': '6'}\n",
            "{'score': 0.0009590010740794241, 'start': 0, 'end': 24, 'answer': 'Some people may not even'}\n",
            "{'score': 0.00031174314790405333, 'start': 29, 'end': 101, 'answer': 'high concentration of minerals like magnesium and calcium, which can end'}\n",
            "{'score': 0.001071664155460894, 'start': 10, 'end': 74, 'answer': 'unable to add a water softener to your shower, try incorporating'}\n",
            "{'score': 0.03574070706963539, 'start': 0, 'end': 1, 'answer': '7'}\n",
            "{'score': 0.0013143267715349793, 'start': 0, 'end': 25, 'answer': 'Most people wouldn’t even'}\n",
            "{'score': 0.0004052228759974241, 'start': 276, 'end': 299, 'answer': 'stress you can tolerate'}\n",
            "{'score': 0.0015241466462612152, 'start': 79, 'end': 95, 'answer': 'regularly taking'}\n",
            "{'score': 0.027011170983314514, 'start': 0, 'end': 8, 'answer': '8. Using'}\n",
            "{'score': 0.0002321880019735545, 'start': 4, 'end': 43, 'answer': 'most of us, old razors aren’t something'}\n",
            "{'score': 0.0003981890040449798, 'start': 27, 'end': 74, 'answer': 'is shaving off your unwanted hairs doesn’t mean'}\n",
            "{'score': 0.017910826951265335, 'start': 0, 'end': 1, 'answer': '9'}\n",
            "{'score': 0.0002732618304435164, 'start': 157, 'end': 172, 'answer': 'plenty of nooks'}\n",
            "{'score': 0.0009525277419015765, 'start': 3, 'end': 12, 'answer': 'you don’t'}\n",
            "{'score': 0.03320171684026718, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 0.000611376715824008, 'start': 56, 'end': 122, 'answer': 'good idea, but doing so every day could actually be causing damage'}\n",
            "{'score': 0.00030866728047840297, 'start': 317, 'end': 322, 'answer': 'worth'}\n",
            "['Did you know theres actually a right way to shower? Get', 'most', 'you know that some of the most common shower habits might not', 'are doing', '1', 'already in the shower. However, despite', 'irritation—it could even burst', 'Not', 'there’s no real reason to actually bend down and give', 'you’re not', 'excuse', 'Not', 'that can be terrible', 'you’re out, or create', '4. Using a Soap Dish', 'going', 'have reasons', '5', 'be doing a number', 'their soap as the first culprit', '6', 'Some people may not even', 'high concentration of minerals like magnesium and calcium, which can end', 'unable to add a water softener to your shower, try incorporating', '7', 'Most people wouldn’t even', 'stress you can tolerate', 'regularly taking', '8. Using', 'most of us, old razors aren’t something', 'is shaving off your unwanted hairs doesn’t mean', '9', 'plenty of nooks', 'you don’t', '10', 'good idea, but doing so every day could actually be causing damage', 'worth']\n",
            "{'score': 2.5505858502583578e-05, 'start': 753, 'end': 757, 'answer': 'most'}\n",
            "{'score': 3.735965219675563e-05, 'start': 1950, 'end': 1993, 'answer': 'palliative care for physicians, people tend'}\n",
            "{'score': 1.8031201761914417e-05, 'start': 419, 'end': 445, 'answer': 'them comfortable, Campbell'}\n",
            "{'score': 1.6221392797888257e-05, 'start': 999, 'end': 1052, 'answer': 'tend to lose their abilities for complex or executive'}\n",
            "{'score': 1.364196214126423e-05, 'start': 1183, 'end': 1192, 'answer': 'coherence'}\n",
            "{'score': 1.535532283014618e-05, 'start': 933, 'end': 961, 'answer': 'Palliative Medicine. Seventy'}\n",
            "['most', 'palliative care for physicians, people tend', 'them comfortable, Campbell', 'tend to lose their abilities for complex or executive', 'coherence', 'Palliative Medicine. Seventy']\n",
            "{'score': 0.0008645580965094268, 'start': 62, 'end': 122, 'answer': 'my pictures posted on Match.com or another [website],\"  says'}\n",
            "{'score': 0.0004876910534221679, 'start': 175, 'end': 184, 'answer': 'York Post'}\n",
            "{'score': 0.0004277233383618295, 'start': 107, 'end': 160, 'answer': 'phony accounts filed a $1.5 billion class-action suit'}\n",
            "{'score': 0.00021013377408962697, 'start': 133, 'end': 145, 'answer': 'Yonkers, N.Y'}\n",
            "{'score': 0.00294738938100636, 'start': 0, 'end': 11, 'answer': 'Avalos said'}\n",
            "{'score': 0.0004196872469037771, 'start': 127, 'end': 140, 'answer': 'had to borrow'}\n",
            "{'score': 0.0005084277945570648, 'start': 61, 'end': 124, 'answer': 'preventable with the right software, ABC News reports. The Post'}\n",
            "{'score': 0.00026106814038939774, 'start': 114, 'end': 120, 'answer': 'filled'}\n",
            "{'score': 0.00023156013048719615, 'start': 182, 'end': 188, 'answer': 'misled'}\n",
            "['my pictures posted on Match.com or another [website],\"  says', 'York Post', 'phony accounts filed a $1.5 billion class-action suit', 'Yonkers, N.Y', 'Avalos said', 'had to borrow', 'preventable with the right software, ABC News reports. The Post', 'filled', 'misled']\n",
            "{'score': 0.00111570640001446, 'start': 21, 'end': 36, 'answer': \"'s bizarre road\"}\n",
            "{'score': 0.008719324134290218, 'start': 26, 'end': 40, 'answer': 'baffling tales'}\n",
            "{'score': 0.0006995924049988389, 'start': 30, 'end': 79, 'answer': 'Jacoba Tromp and their adult children Ella, Riana'}\n",
            "{'score': 0.00954566802829504, 'start': 33, 'end': 58, 'answer': 'with paperwork everywhere'}\n",
            "{'score': 0.004429172724485397, 'start': 0, 'end': 25, 'answer': 'As they drove towards NSW'}\n",
            "{'score': 0.002074215328320861, 'start': 0, 'end': 73, 'answer': 'One day later he left the family trip at Bathurst, describing his parents'}\n",
            "{'score': 0.0029329971875995398, 'start': 36, 'end': 57, 'answer': 'Goulburn, where Riana'}\n",
            "{'score': 0.0008511196938343346, 'start': 88, 'end': 101, 'answer': 'was following'}\n",
            "{'score': 0.003395768580958247, 'start': 29, 'end': 52, 'answer': 'had made their way back'}\n",
            "{'score': 0.0023032857570797205, 'start': 0, 'end': 12, 'answer': 'Their mother'}\n",
            "{'score': 0.0018014220986515284, 'start': 34, 'end': 88, 'answer': 'an end when Mark was found on a street near Wangaratta'}\n",
            "{'score': 0.0015892924275249243, 'start': 70, 'end': 116, 'answer': 'hard to explain\" and referred to the situation'}\n",
            "{'score': 0.003005062462761998, 'start': 0, 'end': 11, 'answer': 'At the time'}\n",
            "{'score': 0.001430621137842536, 'start': 38, 'end': 111, 'answer': 'the world, remains a mystery, but theories have included drugs, financial'}\n",
            "{'score': 0.0019532842561602592, 'start': 22, 'end': 65, 'answer': 'were found dead in far west New South Wales'}\n",
            "{'score': 0.002853585407137871, 'start': 14, 'end': 29, 'answer': 'being good feed'}\n",
            "{'score': 0.004912826232612133, 'start': 6, 'end': 56, 'answer': 'were sightings of between 5-50 dead kangaroos at a'}\n",
            "{'score': 0.0019849236123263836, 'start': 0, 'end': 10, 'answer': 'Former NSW'}\n",
            "{'score': 0.0017149044433608651, 'start': 1, 'end': 38, 'answer': \"All the work we've done says it's not\"}\n",
            "{'score': 0.0015504370676353574, 'start': 4, 'end': 33, 'answer': \"s possible it's an infectious\"}\n",
            "{'score': 0.0014213883550837636, 'start': 0, 'end': 38, 'answer': 'When a magnitude 7.8 earthquake struck'}\n",
            "{'score': 0.003707557450979948, 'start': 16, 'end': 67, 'answer': 'they witnessed the sky light up said it occurred at'}\n",
            "{'score': 0.0004385077045299113, 'start': 63, 'end': 86, 'answer': 'were] of colours mainly'}\n",
            "{'score': 0.0025850620586425066, 'start': 57, 'end': 66, 'answer': 'thousands'}\n",
            "{'score': 0.0010771637316793203, 'start': 156, 'end': 182, 'answer': 'gradients that \"accumulate'}\n",
            "{'score': 0.0022333066444844007, 'start': 0, 'end': 4, 'answer': 'High'}\n",
            "{'score': 0.0015224084490910172, 'start': 39, 'end': 53, 'answer': 'were at a loss'}\n",
            "{'score': 0.0011921225814148784, 'start': 11, 'end': 40, 'answer': 'a top hospital in the capital'}\n",
            "{'score': 0.001744094304740429, 'start': 71, 'end': 83, 'answer': 'also suffers'}\n",
            "{'score': 0.002635797718539834, 'start': 53, 'end': 54, 'answer': ','}\n",
            "{'score': 0.002363816136494279, 'start': 28, 'end': 42, 'answer': 'those suffered'}\n",
            "{'score': 0.0006678916979581118, 'start': 81, 'end': 97, 'answer': 'hijacker Dan \"DB'}\n",
            "{'score': 0.0029230762738734484, 'start': 74, 'end': 101, 'answer': 'had a bomb in his briefcase'}\n",
            "{'score': 0.002503430936485529, 'start': 59, 'end': 91, 'answer': '-coloured sticks inside his case'}\n",
            "{'score': 0.001841264427639544, 'start': 75, 'end': 91, 'answer': 'parachutes and $'}\n",
            "{'score': 0.0024602552875876427, 'start': 14, 'end': 39, 'answer': 'had landed in Seattle, he'}\n",
            "{'score': 0.004081208724528551, 'start': 5, 'end': 79, 'answer': 'several crew members still on board, he ordered the plane to fly to Mexico'}\n",
            "{'score': 0.0029047492425888777, 'start': 4, 'end': 13, 'answer': 'somewhere'}\n",
            "{'score': 0.016518816351890564, 'start': 8, 'end': 22, 'answer': 'was heard from'}\n",
            "{'score': 0.0017099054530262947, 'start': 93, 'end': 108, 'answer': 'longer actively'}\n",
            "[\"'s bizarre road\", 'baffling tales', 'Jacoba Tromp and their adult children Ella, Riana', 'with paperwork everywhere', 'As they drove towards NSW', 'One day later he left the family trip at Bathurst, describing his parents', 'Goulburn, where Riana', 'was following', 'had made their way back', 'Their mother', 'an end when Mark was found on a street near Wangaratta', 'hard to explain\" and referred to the situation', 'At the time', 'the world, remains a mystery, but theories have included drugs, financial', 'were found dead in far west New South Wales', 'being good feed', 'were sightings of between 5-50 dead kangaroos at a', 'Former NSW', \"All the work we've done says it's not\", \"s possible it's an infectious\", 'When a magnitude 7.8 earthquake struck', 'they witnessed the sky light up said it occurred at', 'were] of colours mainly', 'thousands', 'gradients that \"accumulate', 'High', 'were at a loss', 'a top hospital in the capital', 'also suffers', ',', 'those suffered', 'hijacker Dan \"DB', 'had a bomb in his briefcase', '-coloured sticks inside his case', 'parachutes and $', 'had landed in Seattle, he', 'several crew members still on board, he ordered the plane to fly to Mexico', 'somewhere', 'was heard from', 'longer actively']\n",
            "{'score': 0.00010910548735409975, 'start': 436, 'end': 450, 'answer': 'Herculean task'}\n",
            "{'score': 0.00011439614172559232, 'start': 188, 'end': 225, 'answer': 'will risk being sent back to the feds'}\n",
            "{'score': 3.891855521942489e-05, 'start': 292, 'end': 314, 'answer': \"wasn't in any position\"}\n",
            "{'score': 0.00872931256890297, 'start': 9, 'end': 47, 'answer': 'cattle ranchers via Wikimedia Creative'}\n",
            "{'score': 0.009010149165987968, 'start': 0, 'end': 31, 'answer': 'Mendoor Smith, 43-Year-Old from'}\n",
            "{'score': 0.026411689817905426, 'start': 0, 'end': 6, 'answer': 'Served'}\n",
            "{'score': 0.03229939937591553, 'start': 14, 'end': 29, 'answer': 'Custody in 2013'}\n",
            "{'score': 0.00016295058594550937, 'start': 186, 'end': 233, 'answer': \"halfway house I was placed in. It wasn't really\"}\n",
            "{'score': 3.558571916073561e-05, 'start': 520, 'end': 574, 'answer': '10 AM, the cow had died. All that work was for nothing'}\n",
            "{'score': 5.768663322669454e-05, 'start': 10, 'end': 59, 'answer': 'coworkers that knew about my [criminal] situation'}\n",
            "{'score': 0.008821451105177402, 'start': 6, 'end': 16, 'answer': 'Hibdon, 55'}\n",
            "{'score': 0.025242246687412262, 'start': 7, 'end': 19, 'answer': '10 Years for'}\n",
            "{'score': 0.031207868829369545, 'start': 14, 'end': 21, 'answer': 'Custody'}\n",
            "{'score': 3.381791975698434e-05, 'start': 844, 'end': 883, 'answer': 'halfway house to save up and buy a $500'}\n",
            "{'score': 0.00010192127228947356, 'start': 302, 'end': 304, 'answer': 'K2'}\n",
            "{'score': 0.00025727483443915844, 'start': 175, 'end': 228, 'answer': 'subcontracting myself out to do maintenance on rental'}\n",
            "{'score': 0.01067183818668127, 'start': 11, 'end': 40, 'answer': 'telemarketing call center via'}\n",
            "{'score': 0.008239355869591236, 'start': 15, 'end': 20, 'answer': '-Year'}\n",
            "{'score': 0.01828346960246563, 'start': 20, 'end': 21, 'answer': 'a'}\n",
            "{'score': 0.03185658901929855, 'start': 14, 'end': 29, 'answer': 'Custody in 2009'}\n",
            "{'score': 0.0001421954802935943, 'start': 3, 'end': 9, 'answer': \"wasn't\"}\n",
            "{'score': 0.00011542880383785814, 'start': 368, 'end': 415, 'answer': 'were an outsider. There was a lot of favoritism'}\n",
            "{'score': 5.7357290643267334e-05, 'start': 326, 'end': 366, 'answer': 'had something better lined up. It served'}\n",
            "['Herculean task', 'will risk being sent back to the feds', \"wasn't in any position\", 'cattle ranchers via Wikimedia Creative', 'Mendoor Smith, 43-Year-Old from', 'Served', 'Custody in 2013', \"halfway house I was placed in. It wasn't really\", '10 AM, the cow had died. All that work was for nothing', 'coworkers that knew about my [criminal] situation', 'Hibdon, 55', '10 Years for', 'Custody', 'halfway house to save up and buy a $500', 'K2', 'subcontracting myself out to do maintenance on rental', 'telemarketing call center via', '-Year', 'a', 'Custody in 2009', \"wasn't\", 'were an outsider. There was a lot of favoritism', 'had something better lined up. It served']\n",
            "{'score': 0.0001333801046712324, 'start': 36, 'end': 61, 'answer': 'high school... it was one'}\n",
            "{'score': 0.00028468601522035897, 'start': 47, 'end': 88, 'answer': 'Lapeer High School’s class of 2016 and he'}\n",
            "{'score': 9.10053204279393e-05, 'start': 347, 'end': 398, 'answer': 'would inevitably drift apart but he makes a promise'}\n",
            "['high school... it was one', 'Lapeer High School’s class of 2016 and he', 'would inevitably drift apart but he makes a promise']\n",
            "{'score': 0.0004140040255151689, 'start': 117, 'end': 126, 'answer': 'a serious'}\n",
            "{'score': 0.0018650128040462732, 'start': 21, 'end': 40, 'answer': 'impractical,\" Clark'}\n",
            "{'score': 0.0037013129331171513, 'start': 53, 'end': 63, 'answer': 'that great'}\n",
            "{'score': 0.0010352417593821883, 'start': 97, 'end': 108, 'answer': 'few crucial'}\n",
            "{'score': 0.00018183326756116003, 'start': 17, 'end': 69, 'answer': 'bulky. Their epinephrine solution isn’t particularly'}\n",
            "{'score': 0.00016355585830751806, 'start': 129, 'end': 171, 'answer': 'Mylan, which owns the EpiPen brand (though'}\n",
            "{'score': 0.00014507293235510588, 'start': 16, 'end': 21, 'answer': 'Mylan'}\n",
            "{'score': 0.0033729083370417356, 'start': 34, 'end': 39, 'answer': ', not'}\n",
            "{'score': 0.0005669568199664354, 'start': 154, 'end': 162, 'answer': 'displace'}\n",
            "{'score': 0.031944986432790756, 'start': 5, 'end': 10, 'answer': 's why'}\n",
            "{'score': 0.00911705382168293, 'start': 3, 'end': 8, 'answer': 'Mylan'}\n",
            "{'score': 0.0005336061585694551, 'start': 165, 'end': 194, 'answer': 'injector (to protect soldiers'}\n",
            "{'score': 0.0018831774359568954, 'start': 4, 'end': 9, 'answer': 'Mylan'}\n",
            "{'score': 0.0004671142960432917, 'start': 30, 'end': 38, 'answer': 'has been'}\n",
            "{'score': 0.0005007531144656241, 'start': 137, 'end': 142, 'answer': 'Mylan'}\n",
            "{'score': 0.00035780909820459783, 'start': 152, 'end': 181, 'answer': 'in that moment,\" said Matthew'}\n",
            "{'score': 0.0003048543294426054, 'start': 340, 'end': 345, 'answer': 'Mylan'}\n",
            "{'score': 0.0007822783081792295, 'start': 1, 'end': 13, 'answer': 'It would not'}\n",
            "{'score': 0.003448923584073782, 'start': 3, 'end': 13, 'answer': 'There’s no'}\n",
            "{'score': 0.0009316331706941128, 'start': 118, 'end': 139, 'answer': 'injector for the past'}\n",
            "{'score': 0.00044446176616474986, 'start': 187, 'end': 220, 'answer': 'in a pants pocket without getting'}\n",
            "{'score': 0.001062589231878519, 'start': 73, 'end': 101, 'answer': 'few years away from bringing'}\n",
            "{'score': 0.00022817908029537648, 'start': 44, 'end': 49, 'answer': 'Mylan'}\n",
            "{'score': 0.00023588638578075916, 'start': 289, 'end': 294, 'answer': 'Mylan'}\n",
            "{'score': 0.00010688288602977991, 'start': 83, 'end': 118, 'answer': 'injector shaped like a bulky credit'}\n",
            "{'score': 0.0020355081651359797, 'start': 27, 'end': 35, 'answer': 'injector'}\n",
            "{'score': 0.001324408920481801, 'start': 37, 'end': 42, 'answer': 'Mylan'}\n",
            "{'score': 0.000835905724670738, 'start': 109, 'end': 155, 'answer': 'injector by far,\" MannKind CEO Matthew Pfeffer'}\n",
            "{'score': 0.0002911317569669336, 'start': 150, 'end': 174, 'answer': 'exceedingly tough to get'}\n",
            "{'score': 0.00038651941576972604, 'start': 23, 'end': 70, 'answer': 'stymie an epinephrine inhaler, especially since'}\n",
            "{'score': 0.012392093427479267, 'start': 0, 'end': 1, 'answer': '4'}\n",
            "{'score': 0.0003333661297801882, 'start': 224, 'end': 227, 'answer': 'lot'}\n",
            "{'score': 0.0003647137200459838, 'start': 273, 'end': 282, 'answer': 'was worth'}\n",
            "{'score': 0.00043906806968152523, 'start': 29, 'end': 73, 'answer': 'high right now that Baum figures it is worth'}\n",
            "{'score': 0.005258591845631599, 'start': 1, 'end': 11, 'answer': 'We’re just'}\n",
            "{'score': 0.007510795723646879, 'start': 29, 'end': 40, 'answer': 'loud enough'}\n",
            "{'score': 0.0010776456911116838, 'start': 40, 'end': 64, 'answer': 'allergy, is a consultant'}\n",
            "{'score': 0.0008965909364633262, 'start': 4, 'end': 10, 'answer': 'though'}\n",
            "{'score': 0.0008039473905228078, 'start': 35, 'end': 73, 'answer': 'irritating to me, but not to the point'}\n",
            "{'score': 0.00032080404344014823, 'start': 73, 'end': 78, 'answer': 'Mylan'}\n",
            "{'score': 0.0006362612475641072, 'start': 9, 'end': 22, 'answer': 'Mylan’s motto'}\n",
            "['a serious', 'impractical,\" Clark', 'that great', 'few crucial', 'bulky. Their epinephrine solution isn’t particularly', 'Mylan, which owns the EpiPen brand (though', 'Mylan', ', not', 'displace', 's why', 'Mylan', 'injector (to protect soldiers', 'Mylan', 'has been', 'Mylan', 'in that moment,\" said Matthew', 'Mylan', 'It would not', 'There’s no', 'injector for the past', 'in a pants pocket without getting', 'few years away from bringing', 'Mylan', 'Mylan', 'injector shaped like a bulky credit', 'injector', 'Mylan', 'injector by far,\" MannKind CEO Matthew Pfeffer', 'exceedingly tough to get', 'stymie an epinephrine inhaler, especially since', '4', 'lot', 'was worth', 'high right now that Baum figures it is worth', 'We’re just', 'loud enough', 'allergy, is a consultant', 'though', 'irritating to me, but not to the point', 'Mylan', 'Mylan’s motto']\n",
            "{'score': 0.01093356404453516, 'start': 15, 'end': 25, 'answer': 'Gologursky'}\n",
            "{'score': 0.0005400016671046615, 'start': 24, 'end': 31, 'answer': 'Gwyneth'}\n",
            "{'score': 0.00023733369016554207, 'start': 185, 'end': 192, 'answer': 'Paltrow'}\n",
            "{'score': 0.03480859100818634, 'start': 3, 'end': 6, 'answer': 'Her'}\n",
            "{'score': 0.000984337879344821, 'start': 3, 'end': 49, 'answer': \"like to do a cleanse once a year. But it's not\"}\n",
            "{'score': 0.024565445259213448, 'start': 19, 'end': 31, 'answer': 'Her Daughter'}\n",
            "{'score': 0.00045337234041653574, 'start': 115, 'end': 151, 'answer': 'to be with her. We went out to lunch'}\n",
            "{'score': 0.031958986073732376, 'start': 3, 'end': 13, 'answer': 'Unplugging'}\n",
            "{'score': 0.0008067431626841426, 'start': 76, 'end': 141, 'answer': 'my phone away and I really listen, that is such money in the bank'}\n",
            "{'score': 0.010136205703020096, 'start': 8, 'end': 22, 'answer': 'gwynethpaltrow'}\n",
            "{'score': 0.0331854447722435, 'start': 0, 'end': 6, 'answer': 'On Her'}\n",
            "{'score': 0.00028399942675605416, 'start': 154, 'end': 199, 'answer': 'my life, and food is a big part of it. I love'}\n",
            "{'score': 0.0634336769580841, 'start': 0, 'end': 2, 'answer': 'On'}\n",
            "{'score': 0.001550054643303156, 'start': 24, 'end': 74, 'answer': 'on a shelf for years and you can open out of a bag'}\n",
            "{'score': 0.06965412944555283, 'start': 3, 'end': 8, 'answer': 'Cheat'}\n",
            "{'score': 0.00017473143816459924, 'start': 271, 'end': 329, 'answer': 'them growing up in a hippie vacuum,\" she once told Redbook'}\n",
            "{'score': 0.018637917935848236, 'start': 18, 'end': 23, 'answer': 'Being'}\n",
            "{'score': 0.0002854325284715742, 'start': 135, 'end': 166, 'answer': 'mindfulness. If you just parent'}\n",
            "{'score': 0.010136205703020096, 'start': 8, 'end': 22, 'answer': 'gwynethpaltrow'}\n",
            "{'score': 0.03207800164818764, 'start': 3, 'end': 9, 'answer': 'Taking'}\n",
            "{'score': 0.00019424771016929299, 'start': 263, 'end': 271, 'answer': 'at least'}\n",
            "{'score': 0.03631933033466339, 'start': 16, 'end': 26, 'answer': 'in Balance'}\n",
            "{'score': 0.0003499682352412492, 'start': 190, 'end': 248, 'answer': 'be modern and easy on ourselves as well,\" she told InStyle'}\n",
            "{'score': 0.03307672217488289, 'start': 0, 'end': 6, 'answer': 'On Her'}\n",
            "{'score': 0.00040336366510018706, 'start': 191, 'end': 204, 'answer': 'I get through'}\n",
            "{'score': 0.01583908125758171, 'start': 0, 'end': 2, 'answer': 'Is'}\n",
            "{'score': 0.007970109581947327, 'start': 0, 'end': 46, 'answer': 'Obese couples take longer to conceive suggests'}\n",
            "{'score': 0.010585346259176731, 'start': 22, 'end': 50, 'answer': 'Are SERIOUSLY Stressed, Says'}\n",
            "{'score': 0.006404952146112919, 'start': 15, 'end': 26, 'answer': '7 Valentine'}\n",
            "{'score': 0.003274019341915846, 'start': 31, 'end': 33, 'answer': 'in'}\n",
            "{'score': 0.014589976519346237, 'start': 18, 'end': 29, 'answer': 'Hairstylist'}\n",
            "{'score': 0.01607646979391575, 'start': 32, 'end': 37, 'answer': 'Going'}\n",
            "{'score': 0.009595753625035286, 'start': 13, 'end': 24, 'answer': 'Major Black'}\n",
            "{'score': 0.0026934114284813404, 'start': 5, 'end': 11, 'answer': 'Remini'}\n",
            "{'score': 0.004873951431363821, 'start': 49, 'end': 52, 'answer': 'Her'}\n",
            "{'score': 0.005795640870928764, 'start': 67, 'end': 78, 'answer': 'Mesmerizing'}\n",
            "{'score': 0.016037900000810623, 'start': 35, 'end': 42, 'answer': 'Stamina'}\n",
            "{'score': 0.004311217926442623, 'start': 28, 'end': 70, 'answer': 'SNL’ in the Midst of a Ratings Renaissance'}\n",
            "{'score': 0.0067100427113473415, 'start': 13, 'end': 44, 'answer': 'With Britney Spears Spends $80G'}\n",
            "{'score': 0.002650965703651309, 'start': 68, 'end': 73, 'answer': 'Nyong'}\n",
            "{'score': 0.006442059297114611, 'start': 50, 'end': 62, 'answer': 'the 2017 SAG'}\n",
            "{'score': 0.0040511093102395535, 'start': 44, 'end': 67, 'answer': 'Issues to Pose With Mom'}\n",
            "{'score': 0.01504653412848711, 'start': 32, 'end': 36, 'answer': 'Hair'}\n",
            "{'score': 0.00888846442103386, 'start': 16, 'end': 22, 'answer': ', Miss'}\n",
            "{'score': 0.0035806477535516024, 'start': 47, 'end': 58, 'answer': 'Have Missed'}\n",
            "{'score': 0.010785670951008797, 'start': 34, 'end': 43, 'answer': 'More Than'}\n",
            "{'score': 0.00781258661299944, 'start': 0, 'end': 18, 'answer': 'GNC Ad Booted From'}\n",
            "{'score': 0.007520357146859169, 'start': 18, 'end': 50, 'answer': 'Hair Looks Perfect for Valentine'}\n",
            "{'score': 0.014009985141456127, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.005797788500785828, 'start': 4, 'end': 11, 'answer': 'Selleck'}\n",
            "{'score': 0.010169284418225288, 'start': 37, 'end': 42, 'answer': 'Black'}\n",
            "{'score': 0.0027452372014522552, 'start': 0, 'end': 25, 'answer': 'Giambattista Valli Serves'}\n",
            "{'score': 0.004170380067080259, 'start': 2, 'end': 38, 'answer': 'Whimsical Beauty Looks From the Dior'}\n",
            "{'score': 0.0012661685468629003, 'start': 6, 'end': 55, 'answer': 'Hunch Helped Crack a Jogger’s 6-Month-Old Slaying'}\n",
            "{'score': 0.010695317760109901, 'start': 0, 'end': 3, 'answer': 'One'}\n",
            "{'score': 0.008308173157274723, 'start': 42, 'end': 63, 'answer': 'in Your Shopping Cart'}\n",
            "{'score': 0.003297506831586361, 'start': 21, 'end': 52, 'answer': '’ Star Richard Hatch Dead at 71'}\n",
            "{'score': 0.014373772777616978, 'start': 0, 'end': 7, 'answer': '5 Times'}\n",
            "['Gologursky', 'Gwyneth', 'Paltrow', 'Her', \"like to do a cleanse once a year. But it's not\", 'Her Daughter', 'to be with her. We went out to lunch', 'Unplugging', 'my phone away and I really listen, that is such money in the bank', 'gwynethpaltrow', 'On Her', 'my life, and food is a big part of it. I love', 'On', 'on a shelf for years and you can open out of a bag', 'Cheat', 'them growing up in a hippie vacuum,\" she once told Redbook', 'Being', 'mindfulness. If you just parent', 'gwynethpaltrow', 'Taking', 'at least', 'in Balance', 'be modern and easy on ourselves as well,\" she told InStyle', 'On Her', 'I get through', 'Is', 'Obese couples take longer to conceive suggests', 'Are SERIOUSLY Stressed, Says', '7 Valentine', 'in', 'Hairstylist', 'Going', 'Major Black', 'Remini', 'Her', 'Mesmerizing', 'Stamina', 'SNL’ in the Midst of a Ratings Renaissance', 'With Britney Spears Spends $80G', 'Nyong', 'the 2017 SAG', 'Issues to Pose With Mom', 'Hair', ', Miss', 'Have Missed', 'More Than', 'GNC Ad Booted From', 'Hair Looks Perfect for Valentine', '5', 'Selleck', 'Black', 'Giambattista Valli Serves', 'Whimsical Beauty Looks From the Dior', 'Hunch Helped Crack a Jogger’s 6-Month-Old Slaying', 'One', 'in Your Shopping Cart', '’ Star Richard Hatch Dead at 71', '5 Times']\n",
            "{'score': 0.0016866308869794011, 'start': 33, 'end': 44, 'answer': 'it’s ironic'}\n",
            "{'score': 0.0014243198093026876, 'start': 8, 'end': 25, 'answer': 'were legitimately'}\n",
            "{'score': 0.0009569392423145473, 'start': 138, 'end': 162, 'answer': '-watch Unbreakable Kimmy'}\n",
            "{'score': 0.0012064621550962329, 'start': 94, 'end': 101, 'answer': 'an HGTV'}\n",
            "{'score': 0.0015183385694399476, 'start': 96, 'end': 113, 'answer': 'who calls someone'}\n",
            "{'score': 0.004552882630378008, 'start': 9, 'end': 22, 'answer': \"it's probably\"}\n",
            "{'score': 0.0007601365214213729, 'start': 158, 'end': 175, 'answer': 'willing to endure'}\n",
            "{'score': 0.0018850999185815454, 'start': 48, 'end': 59, 'answer': 'the evening'}\n",
            "{'score': 0.0008030308526940644, 'start': 51, 'end': 81, 'answer': 'serums, etc. Make sure to give'}\n",
            "{'score': 0.0035139555111527443, 'start': 12, 'end': 39, 'answer': 'that pinot grigio and pinot'}\n",
            "{'score': 0.007419861853122711, 'start': 12, 'end': 47, 'answer': 'have an opinion on which you prefer'}\n",
            "{'score': 0.0040051997639238834, 'start': 32, 'end': 73, 'answer': '-unit laundry while looking at apartments'}\n",
            "{'score': 0.006150685250759125, 'start': 0, 'end': 21, 'answer': 'Who has time to waste'}\n",
            "{'score': 0.0026989297475665808, 'start': 38, 'end': 96, 'answer': 'kiosks at places like Target and Best Buy like a total pro'}\n",
            "{'score': 0.010408930480480194, 'start': 38, 'end': 56, 'answer': 'being intimidating'}\n",
            "{'score': 0.0021319391671568155, 'start': 4, 'end': 32, 'answer': 'Not only do you have friends'}\n",
            "{'score': 0.0012267839629203081, 'start': 76, 'end': 137, 'answer': 'when a new checker doesn’t recognize you and asks for your ID'}\n",
            "{'score': 0.009567511267960072, 'start': 8, 'end': 24, 'answer': 'have a preferred'}\n",
            "{'score': 0.005983893759548664, 'start': 4, 'end': 13, 'answer': 'You spend'}\n",
            "{'score': 0.007662088610231876, 'start': 4, 'end': 12, 'answer': 'you used'}\n",
            "{'score': 0.00307067739777267, 'start': 42, 'end': 68, 'answer': '-create some of the dishes'}\n",
            "{'score': 0.008943398483097553, 'start': 4, 'end': 32, 'answer': 'You mix up Kendall and Kylie'}\n",
            "{'score': 0.005706981290131807, 'start': 30, 'end': 37, 'answer': \"they're\"}\n",
            "{'score': 0.004743023309856653, 'start': 4, 'end': 53, 'answer': 'The last crazy concert you went to was...an opera'}\n",
            "{'score': 0.003449204610660672, 'start': 71, 'end': 87, 'answer': 'longer an option'}\n",
            "{'score': 0.0038558468222618103, 'start': 43, 'end': 65, 'answer': 'that you actually care'}\n",
            "{'score': 0.002399744698777795, 'start': 0, 'end': 2, 'answer': '20'}\n",
            "{'score': 0.004738264717161655, 'start': 8, 'end': 42, 'answer': 'still felt guilty and even managed'}\n",
            "{'score': 0.001036396948620677, 'start': 134, 'end': 149, 'answer': 'laughing matter'}\n",
            "{'score': 0.003053800668567419, 'start': 4, 'end': 16, 'answer': 'When someone'}\n",
            "{'score': 0.007751604076474905, 'start': 4, 'end': 62, 'answer': 'You know the difference between a traditional and Roth IRA'}\n",
            "{'score': 0.0055283489637076855, 'start': 28, 'end': 44, 'answer': 't just something'}\n",
            "['it’s ironic', 'were legitimately', '-watch Unbreakable Kimmy', 'an HGTV', 'who calls someone', \"it's probably\", 'willing to endure', 'the evening', 'serums, etc. Make sure to give', 'that pinot grigio and pinot', 'have an opinion on which you prefer', '-unit laundry while looking at apartments', 'Who has time to waste', 'kiosks at places like Target and Best Buy like a total pro', 'being intimidating', 'Not only do you have friends', 'when a new checker doesn’t recognize you and asks for your ID', 'have a preferred', 'You spend', 'you used', '-create some of the dishes', 'You mix up Kendall and Kylie', \"they're\", 'The last crazy concert you went to was...an opera', 'longer an option', 'that you actually care', '20', 'still felt guilty and even managed', 'laughing matter', 'When someone', 'You know the difference between a traditional and Roth IRA', 't just something']\n",
            "{'score': 0.0008096537203527987, 'start': 162, 'end': 194, 'answer': 'still work to do, although great'}\n",
            "{'score': 7.708383054705337e-05, 'start': 162, 'end': 194, 'answer': 'still work to do, although great'}\n",
            "{'score': 0.00011379030183888972, 'start': 429, 'end': 469, 'answer': 'you will see just how many people belong'}\n",
            "{'score': 0.00014625977200921625, 'start': 322, 'end': 396, 'answer': 'there any names on this list that really surprised you? Feel free to share'}\n",
            "{'score': 0.08856221288442612, 'start': 0, 'end': 18, 'answer': '15 Kristen Stewart'}\n",
            "{'score': 3.8414120353991166e-05, 'start': 591, 'end': 666, 'answer': 'Cargile have only been dating since July of 2016, but Stewart has expressed'}\n",
            "{'score': 0.07164355367422104, 'start': 0, 'end': 2, 'answer': '14'}\n",
            "{'score': 3.2586885936325416e-05, 'start': 588, 'end': 638, 'answer': 'most influential gay news magazines. Plaza did not'}\n",
            "{'score': 0.08043047040700912, 'start': 0, 'end': 2, 'answer': '13'}\n",
            "{'score': 3.778024984057993e-05, 'start': 767, 'end': 787, 'answer': '100% straight to 100'}\n",
            "{'score': 0.07562761753797531, 'start': 0, 'end': 9, 'answer': '12 Colton'}\n",
            "{'score': 4.11372420785483e-05, 'start': 499, 'end': 536, 'answer': 'all just enjoy life & have no regrets'}\n",
            "{'score': 0.07489759474992752, 'start': 0, 'end': 2, 'answer': '11'}\n",
            "{'score': 3.945262869819999e-05, 'start': 664, 'end': 674, 'answer': 'Dysmorphia'}\n",
            "{'score': 0.0797378197312355, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 3.9871069020591676e-05, 'start': 93, 'end': 122, 'answer': 'often perform hilarious skits'}\n",
            "{'score': 0.07423186302185059, 'start': 0, 'end': 6, 'answer': '9 Ryan'}\n",
            "{'score': 4.080107464687899e-05, 'start': 607, 'end': 613, 'answer': 'enough'}\n",
            "{'score': 0.04840464890003204, 'start': 0, 'end': 1, 'answer': '8'}\n",
            "{'score': 3.4188240533694625e-05, 'start': 600, 'end': 662, 'answer': 'By the end of the music video, Owen has found a guy that suits'}\n",
            "{'score': 0.07272320240736008, 'start': 0, 'end': 8, 'answer': '7 Gloria'}\n",
            "{'score': 4.043570879730396e-05, 'start': 329, 'end': 398, 'answer': 'had a lesbian relationship with one of her classmates. It was a piece'}\n",
            "{'score': 0.04620238393545151, 'start': 6, 'end': 13, 'answer': 'Warsame'}\n",
            "{'score': 4.641091436496936e-05, 'start': 351, 'end': 395, 'answer': 'number of mosques in Australia that will not'}\n",
            "['still work to do, although great', 'still work to do, although great', 'you will see just how many people belong', 'there any names on this list that really surprised you? Feel free to share', '15 Kristen Stewart', 'Cargile have only been dating since July of 2016, but Stewart has expressed', '14', 'most influential gay news magazines. Plaza did not', '13', '100% straight to 100', '12 Colton', 'all just enjoy life & have no regrets', '11', 'Dysmorphia', '10', 'often perform hilarious skits', '9 Ryan', 'enough', '8', 'By the end of the music video, Owen has found a guy that suits', '7 Gloria', 'had a lesbian relationship with one of her classmates. It was a piece', 'Warsame', 'number of mosques in Australia that will not']\n",
            "{'score': 0.00271105975843966, 'start': 15, 'end': 20, 'answer': \"isn't\"}\n",
            "{'score': 0.004737835377454758, 'start': 22, 'end': 68, 'answer': 'be a champion for young women in her situation'}\n",
            "{'score': 0.0069777220487594604, 'start': 18, 'end': 27, 'answer': 'had major'}\n",
            "{'score': 0.0029369513504207134, 'start': 24, 'end': 29, 'answer': 'great'}\n",
            "{'score': 0.0042594741098582745, 'start': 0, 'end': 27, 'answer': \"In fact, she's even joining\"}\n",
            "{'score': 0.0028116018511354923, 'start': 1, 'end': 13, 'answer': 'There are so'}\n",
            "{'score': 0.0040159448981285095, 'start': 27, 'end': 31, 'answer': 'have'}\n",
            "{'score': 0.0037247026339173317, 'start': 17, 'end': 27, 'answer': 'collecting'}\n",
            "{'score': 0.003569415770471096, 'start': 16, 'end': 80, 'answer': \"been through, she can't quite believe her current life situation\"}\n",
            "{'score': 0.000701206095982343, 'start': 25, 'end': 85, 'answer': \"pageant would want someone like me. It proves you don't need\"}\n",
            "[\"isn't\", 'be a champion for young women in her situation', 'had major', 'great', \"In fact, she's even joining\", 'There are so', 'have', 'collecting', \"been through, she can't quite believe her current life situation\", \"pageant would want someone like me. It proves you don't need\"]\n",
            "{'score': 0.0015943973558023572, 'start': 71, 'end': 106, 'answer': 'the weekend. Then, for good measure'}\n",
            "{'score': 0.0025007729418575764, 'start': 51, 'end': 81, 'answer': 'Feldman by—what else?—tweeting'}\n",
            "{'score': 0.0020089060999453068, 'start': 49, 'end': 79, 'answer': 'was beautiful; just everything'}\n",
            "{'score': 0.003809802932664752, 'start': 31, 'end': 78, 'answer': 'forty minutes later, she dropped THIS bombshell'}\n",
            "{'score': 0.0018139997264370322, 'start': 8, 'end': 41, 'answer': 'all the cynics out there, Guthrie'}\n",
            "{'score': 0.01361687108874321, 'start': 9, 'end': 19, 'answer': 'did YOU do'}\n",
            "['the weekend. Then, for good measure', 'Feldman by—what else?—tweeting', 'was beautiful; just everything', 'forty minutes later, she dropped THIS bombshell', 'all the cynics out there, Guthrie', 'did YOU do']\n",
            "{'score': 0.0001541721576359123, 'start': 37, 'end': 71, 'answer': 'a while, but the morphine and lack'}\n",
            "{'score': 0.0006025275797583163, 'start': 137, 'end': 168, 'answer': 'I have a) your attention, and b'}\n",
            "{'score': 0.002486438024789095, 'start': 82, 'end': 98, 'answer': 'at least another'}\n",
            "{'score': 0.00031384368776343763, 'start': 204, 'end': 241, 'answer': 'on her right side isn’t the no-biggie'}\n",
            "{'score': 0.0003392451035324484, 'start': 297, 'end': 310, 'answer': 'had just left'}\n",
            "{'score': 0.01825859397649765, 'start': 3, 'end': 33, 'answer': 'many plans instantly went poof'}\n",
            "{'score': 0.0006093239644542336, 'start': 138, 'end': 208, 'answer': 'my mother. No writers’ residencies at those wonderful schools in India'}\n",
            "{'score': 0.00930102914571762, 'start': 3, 'end': 9, 'answer': 'wonder'}\n",
            "{'score': 0.0007895285962149501, 'start': 76, 'end': 90, 'answer': 'in the present'}\n",
            "{'score': 0.0036680661141872406, 'start': 42, 'end': 59, 'answer': 'did it in one day'}\n",
            "{'score': 0.00022413628175854683, 'start': 140, 'end': 181, 'answer': 'had never met. I went to college out east'}\n",
            "{'score': 0.0005997144035063684, 'start': 16, 'end': 28, 'answer': 'were only 24'}\n",
            "{'score': 0.006953028030693531, 'start': 3, 'end': 20, 'answer': 'the end of dinner'}\n",
            "{'score': 0.01638105697929859, 'start': 15, 'end': 27, 'answer': 'a year later'}\n",
            "{'score': 0.0005274459253996611, 'start': 39, 'end': 62, 'answer': 'eHarmony, but I’m going'}\n",
            "{'score': 0.0017442539101466537, 'start': 61, 'end': 68, 'answer': '-pepper'}\n",
            "{'score': 0.003211143659427762, 'start': 36, 'end': 93, 'answer': 'in no particular order because everything feels important'}\n",
            "{'score': 0.00042541592847555876, 'start': 8, 'end': 75, 'answer': 'sharp dresser. Our young adult sons, Justin and Miles, often borrow'}\n",
            "{'score': 0.00019762157171498984, 'start': 12, 'end': 61, 'answer': 'could speak, it would add that Jason is uncannily'}\n",
            "{'score': 0.0007122380775399506, 'start': 79, 'end': 94, 'answer': 'should also add'}\n",
            "{'score': 0.0010433116694912314, 'start': 7, 'end': 45, 'answer': 'was working on my first memoir, I kept'}\n",
            "{'score': 0.0029426245018839836, 'start': 92, 'end': 103, 'answer': 'you can use'}\n",
            "{'score': 0.0009133108542300761, 'start': 13, 'end': 54, 'answer': 'would agree — he was indeed a captivating'}\n",
            "{'score': 0.0008444896666333079, 'start': 6, 'end': 19, 'answer': 'an absolutely'}\n",
            "{'score': 0.0007537706405855715, 'start': 125, 'end': 146, 'answer': 'most days from 9 to 5'}\n",
            "{'score': 0.00031098505132831633, 'start': 100, 'end': 108, 'answer': 'affinity'}\n",
            "{'score': 0.00035554636269807816, 'start': 128, 'end': 134, 'answer': 'always'}\n",
            "{'score': 0.0006317815277725458, 'start': 132, 'end': 147, 'answer': 'He knows I love'}\n",
            "{'score': 0.004319255705922842, 'start': 9, 'end': 27, 'answer': 'is you know enough'}\n",
            "{'score': 0.002652356866747141, 'start': 6, 'end': 69, 'answer': 'Did I mention that he is incredibly handsome? I’m going to miss'}\n",
            "{'score': 0.000461163988802582, 'start': 82, 'end': 85, 'answer': 'too'}\n",
            "{'score': 0.001097240368835628, 'start': 6, 'end': 33, 'answer': 'most recent memoir (written'}\n",
            "{'score': 0.0007672576466575265, 'start': 2, 'end': 47, 'answer': 'was totally serious about this and encouraged'}\n",
            "{'score': 0.0006227906560525298, 'start': 36, 'end': 85, 'answer': 'was based on an essay in the book where I mention'}\n",
            "{'score': 0.00016541402146685869, 'start': 205, 'end': 261, 'answer': 'was my second tattoo; the first is a small, lowercase \"j'}\n",
            "{'score': 0.0003822803555522114, 'start': 202, 'end': 215, 'answer': 'few days left'}\n",
            "{'score': 0.0007538548088632524, 'start': 0, 'end': 62, 'answer': 'I am wrapping this up on Valentine’s Day, and the most genuine'}\n",
            "{'score': 0.0030069195199757814, 'start': 65, 'end': 100, 'answer': 'you two the fresh start you deserve'}\n",
            "{'score': 0.027470793575048447, 'start': 5, 'end': 8, 'answer': 'all'}\n",
            "['a while, but the morphine and lack', 'I have a) your attention, and b', 'at least another', 'on her right side isn’t the no-biggie', 'had just left', 'many plans instantly went poof', 'my mother. No writers’ residencies at those wonderful schools in India', 'wonder', 'in the present', 'did it in one day', 'had never met. I went to college out east', 'were only 24', 'the end of dinner', 'a year later', 'eHarmony, but I’m going', '-pepper', 'in no particular order because everything feels important', 'sharp dresser. Our young adult sons, Justin and Miles, often borrow', 'could speak, it would add that Jason is uncannily', 'should also add', 'was working on my first memoir, I kept', 'you can use', 'would agree — he was indeed a captivating', 'an absolutely', 'most days from 9 to 5', 'affinity', 'always', 'He knows I love', 'is you know enough', 'Did I mention that he is incredibly handsome? I’m going to miss', 'too', 'most recent memoir (written', 'was totally serious about this and encouraged', 'was based on an essay in the book where I mention', 'was my second tattoo; the first is a small, lowercase \"j', 'few days left', 'I am wrapping this up on Valentine’s Day, and the most genuine', 'you two the fresh start you deserve', 'all']\n",
            "{'score': 0.0014424195978790522, 'start': 28, 'end': 68, 'answer': 'of his friends planned a trip to Majorca'}\n",
            "{'score': 0.0009469874203205109, 'start': 11, 'end': 32, 'answer': 'having to look at one'}\n",
            "{'score': 0.006710129324346781, 'start': 26, 'end': 34, 'answer': 'some Joe'}\n",
            "{'score': 0.07119883596897125, 'start': 0, 'end': 8, 'answer': 'He wrote'}\n",
            "{'score': 0.0005768690025433898, 'start': 141, 'end': 170, 'answer': 'It’s our friend Nathan’s 30th'}\n",
            "{'score': 0.007049262523651123, 'start': 11, 'end': 33, 'answer': '15 namesakes, but only'}\n",
            "{'score': 0.0020783664658665657, 'start': 21, 'end': 27, 'answer': '15 Joe'}\n",
            "{'score': 0.00511833094060421, 'start': 33, 'end': 43, 'answer': '99MQXdZVyw'}\n",
            "{'score': 0.004970825742930174, 'start': 46, 'end': 72, 'answer': 'legitimacy of the offer at'}\n",
            "{'score': 0.07119883596897125, 'start': 0, 'end': 8, 'answer': 'He wrote'}\n",
            "{'score': 0.0015983512857928872, 'start': 41, 'end': 97, 'answer': 'legit, I decided to take the plunge as my legendary boss'}\n",
            "{'score': 0.0017528190510347486, 'start': 110, 'end': 113, 'answer': 'all'}\n",
            "{'score': 0.0011523766443133354, 'start': 59, 'end': 86, 'answer': 'want to apologise to my mum'}\n",
            "['of his friends planned a trip to Majorca', 'having to look at one', 'some Joe', 'He wrote', 'It’s our friend Nathan’s 30th', '15 namesakes, but only', '15 Joe', '99MQXdZVyw', 'legitimacy of the offer at', 'He wrote', 'legit, I decided to take the plunge as my legendary boss', 'all', 'want to apologise to my mum']\n",
            "{'score': 0.004668757785111666, 'start': 14, 'end': 76, 'answer': 'of the most interesting and powerful photo stories from across'}\n",
            "{'score': 0.002808029530569911, 'start': 16, 'end': 70, 'answer': '-Seen Photos Behind the Scenes at the Women’s March\" —'}\n",
            "{'score': 0.00021485752949956805, 'start': 152, 'end': 202, 'answer': 'in terms of scale, coverage and inclusivity. Kisha'}\n",
            "{'score': 0.0060353949666023254, 'start': 6, 'end': 20, 'answer': 'Bubacz, senior'}\n",
            "{'score': 0.003887251252308488, 'start': 4, 'end': 41, 'answer': 'Honest Photos of Motherhood Challenge'}\n",
            "{'score': 0.00023033127945382148, 'start': 180, 'end': 195, 'answer': 'They don’t hold'}\n",
            "{'score': 0.009084819816052914, 'start': 29, 'end': 37, 'answer': 'BuzzFeed'}\n",
            "{'score': 0.00271049328148365, 'start': 62, 'end': 83, 'answer': 'The World\" — BuzzFeed'}\n",
            "{'score': 0.00015637732576578856, 'start': 254, 'end': 291, 'answer': 'intercommunication in the digital age'}\n",
            "{'score': 0.006108606234192848, 'start': 41, 'end': 49, 'answer': 'BuzzFeed'}\n",
            "{'score': 0.012570428662002087, 'start': 0, 'end': 5, 'answer': '4. \"A'}\n",
            "{'score': 0.00036579277366399765, 'start': 12, 'end': 14, 'answer': 'be'}\n",
            "{'score': 0.0431780144572258, 'start': 1, 'end': 2, 'answer': 'K'}\n",
            "{'score': 0.002871756674721837, 'start': 28, 'end': 92, 'answer': 'That Will Help You Understand the Refugee Experience\" — BuzzFeed'}\n",
            "{'score': 0.0004545769770629704, 'start': 159, 'end': 224, 'answer': 'all the more relevant as a nation of immigrants begins to grapple'}\n",
            "{'score': 0.0431780144572258, 'start': 1, 'end': 2, 'answer': 'K'}\n",
            "{'score': 0.004068097099661827, 'start': 46, 'end': 60, 'answer': 'Are Guaranteed'}\n",
            "{'score': 0.00017565477173775434, 'start': 341, 'end': 391, 'answer': 'my thumb on it, the collection constitutes a great'}\n",
            "{'score': 0.022147713229060173, 'start': 1, 'end': 2, 'answer': 'G'}\n",
            "{'score': 0.003352611092850566, 'start': 14, 'end': 52, 'answer': 'Nairobi’s Korogocho Slum\" — Al Jazeera'}\n",
            "{'score': 0.00022907867969479412, 'start': 4, 'end': 8, 'answer': 'most'}\n",
            "{'score': 0.03299376368522644, 'start': 0, 'end': 4, 'answer': '—A.M'}\n",
            "{'score': 0.0044816769659519196, 'start': 0, 'end': 1, 'answer': '8'}\n",
            "{'score': 0.00035060103982686996, 'start': 273, 'end': 322, 'answer': 'misconceptions and showing that women also belong'}\n",
            "{'score': 0.03299376368522644, 'start': 0, 'end': 4, 'answer': '—A.M'}\n",
            "{'score': 0.0037675618659704924, 'start': 7, 'end': 42, 'answer': 'of the Most Powerful Photos of this'}\n",
            "['of the most interesting and powerful photo stories from across', '-Seen Photos Behind the Scenes at the Women’s March\" —', 'in terms of scale, coverage and inclusivity. Kisha', 'Bubacz, senior', 'Honest Photos of Motherhood Challenge', 'They don’t hold', 'BuzzFeed', 'The World\" — BuzzFeed', 'intercommunication in the digital age', 'BuzzFeed', '4. \"A', 'be', 'K', 'That Will Help You Understand the Refugee Experience\" — BuzzFeed', 'all the more relevant as a nation of immigrants begins to grapple', 'K', 'Are Guaranteed', 'my thumb on it, the collection constitutes a great', 'G', 'Nairobi’s Korogocho Slum\" — Al Jazeera', 'most', '—A.M', '8', 'misconceptions and showing that women also belong', '—A.M', 'of the Most Powerful Photos of this']\n",
            "{'score': 0.002862948225811124, 'start': 97, 'end': 103, 'answer': 'common'}\n",
            "{'score': 0.00022734538652002811, 'start': 302, 'end': 331, 'answer': 'will.\" The message was always'}\n",
            "{'score': 0.0012819897383451462, 'start': 53, 'end': 96, 'answer': 'conscious,\" Rodriguez says. \"That’s the one'}\n",
            "{'score': 0.0002196251880377531, 'start': 210, 'end': 258, 'answer': 'each morning, they did a series of jumping jacks'}\n",
            "{'score': 0.020774710923433304, 'start': 15, 'end': 19, 'answer': 'Tsai'}\n",
            "{'score': 0.00017667017527855933, 'start': 13, 'end': 23, 'answer': 'were great'}\n",
            "{'score': 0.0002241979236714542, 'start': 267, 'end': 333, 'answer': 'in the country. And Gina Rodriguez won a Best Actress Golden Globe'}\n",
            "{'score': 0.0018382591661065817, 'start': 1, 'end': 52, 'answer': 'We lived the idea of the American Dream,\" Gina says'}\n",
            "{'score': 0.0846516415476799, 'start': 14, 'end': 20, 'answer': 'Family'}\n",
            "{'score': 0.015551473014056683, 'start': 9, 'end': 48, 'answer': 'Right: Courtesy of the Rodriguez Family'}\n",
            "{'score': 7.228142931126058e-05, 'start': 407, 'end': 418, 'answer': 'Srinivasans'}\n",
            "{'score': 0.0009880559518933296, 'start': 39, 'end': 48, 'answer': 'thousands'}\n",
            "{'score': 0.00016164415865205228, 'start': 271, 'end': 313, 'answer': 'well. And we defined success by leadership'}\n",
            "{'score': 0.00016881170449778438, 'start': 56, 'end': 121, 'answer': 'none of these siblings grew up rich, they were privileged in many'}\n",
            "{'score': 0.00016468993271701038, 'start': 388, 'end': 420, 'answer': 'most said they grew up with much'}\n",
            "{'score': 0.0006538748275488615, 'start': 76, 'end': 95, 'answer': 'Indians from Kansas'}\n",
            "{'score': 0.13796545565128326, 'start': 0, 'end': 15, 'answer': 'Immigrant Drive'}\n",
            "{'score': 0.0002014296333072707, 'start': 60, 'end': 119, 'answer': 'Saroja Srinivasan, a Hindu who is vegetarian, was mastering'}\n",
            "{'score': 0.00019908753165509552, 'start': 144, 'end': 214, 'answer': 'Saroja recalls. That meant cooking hot dogs and pizza as well as dosas'}\n",
            "{'score': 0.0003384426236152649, 'start': 208, 'end': 228, 'answer': 'Srinivasan household'}\n",
            "{'score': 0.0005172539385966957, 'start': 142, 'end': 196, 'answer': 'Srinija, the youngest. \"Put things away. Pay attention'}\n",
            "{'score': 0.00015560687461402267, 'start': 147, 'end': 205, 'answer': 'permissiveness that is way better than an allowance,\" says'}\n",
            "{'score': 0.02898113802075386, 'start': 4, 'end': 21, 'answer': 'Srinivasan Family'}\n",
            "{'score': 0.009450556710362434, 'start': 32, 'end': 49, 'answer': 'Srinivasan Family'}\n",
            "{'score': 0.0005298758042044938, 'start': 75, 'end': 93, 'answer': 'was more important'}\n",
            "{'score': 0.0001243266451638192, 'start': 357, 'end': 387, 'answer': 'Srinija is an entrepreneur who'}\n",
            "{'score': 0.0006861063884571195, 'start': 3, 'end': 36, 'answer': 'addition to Puerto Rico and India'}\n",
            "{'score': 7.220221596071497e-05, 'start': 84, 'end': 118, 'answer': '-selling author and New York Times'}\n",
            "{'score': 0.08752363175153732, 'start': 4, 'end': 14, 'answer': 'Gay Family'}\n",
            "{'score': 0.006102715618908405, 'start': 47, 'end': 53, 'answer': 'Hegger'}\n",
            "{'score': 0.00017566612223163247, 'start': 257, 'end': 302, 'answer': 'Good grades in school, that was not something'}\n",
            "{'score': 0.00016515664174221456, 'start': 0, 'end': 30, 'answer': 'Being from Haiti in particular'}\n",
            "{'score': 0.07613715529441833, 'start': 0, 'end': 15, 'answer': 'Parent-Teachers'}\n",
            "{'score': 0.00020782751380465925, 'start': 43, 'end': 64, 'answer': 'Srinivasans in Kansas'}\n",
            "{'score': 5.388281715568155e-05, 'start': 174, 'end': 198, 'answer': 'genetics company 23andMe'}\n",
            "{'score': 0.000264028727542609, 'start': 220, 'end': 256, 'answer': 'paper airplanes during presentations'}\n",
            "{'score': 0.000267998781055212, 'start': 138, 'end': 203, 'answer': 'lot of strong academics, I think one of the skills we have is not'}\n",
            "{'score': 0.02603193186223507, 'start': 4, 'end': 12, 'answer': 'Wojcicki'}\n",
            "{'score': 0.0038565672002732754, 'start': 22, 'end': 30, 'answer': 'Wojcicki'}\n",
            "{'score': 0.00010731140355346724, 'start': 417, 'end': 473, 'answer': 'game.\" She did arts and crafts projects with her toddler'}\n",
            "{'score': 0.00037996398168615997, 'start': 105, 'end': 129, 'answer': 'among the most important'}\n",
            "{'score': 0.00034148499253205955, 'start': 0, 'end': 3, 'answer': 'Not'}\n",
            "{'score': 0.00028998000198043883, 'start': 270, 'end': 291, 'answer': 'supplementary lessons'}\n",
            "{'score': 4.990470188204199e-05, 'start': 184, 'end': 212, 'answer': 'well-known actor, with major'}\n",
            "{'score': 0.05341716855764389, 'start': 4, 'end': 17, 'answer': 'Dungey Family'}\n",
            "{'score': 0.012408262118697166, 'start': 0, 'end': 45, 'answer': 'Left and Right: Courtesy of the Dungey Family'}\n",
            "{'score': 0.00018547744548413903, 'start': 8, 'end': 36, 'answer': 'Srinivasans, having a parent'}\n",
            "{'score': 0.11207427829504013, 'start': 10, 'end': 18, 'answer': 'Activism'}\n",
            "{'score': 0.0002770868595689535, 'start': 3, 'end': 7, 'answer': 'most'}\n",
            "{'score': 0.00018791912589222193, 'start': 119, 'end': 165, 'answer': 'vice provost at the University of Pennsylvania'}\n",
            "{'score': 0.00011593750969041139, 'start': 393, 'end': 454, 'answer': 'dinner was a test of current events.\" (The brothers also have'}\n",
            "{'score': 0.020774710923433304, 'start': 15, 'end': 19, 'answer': 'Tsai'}\n",
            "{'score': 0.00020192554802633822, 'start': 293, 'end': 316, 'answer': 'will change necessarily'}\n",
            "{'score': 0.00014265724166762084, 'start': 152, 'end': 180, 'answer': 'housing complexes, and never'}\n",
            "{'score': 0.08644240349531174, 'start': 4, 'end': 18, 'answer': 'Emanuel Family'}\n",
            "{'score': 0.004776905290782452, 'start': 0, 'end': 36, 'answer': 'Left: Courtesy of the Emanuel Family'}\n",
            "{'score': 9.927053179126233e-05, 'start': 511, 'end': 540, 'answer': 'construction site. Now adults'}\n",
            "{'score': 0.0004633486387319863, 'start': 4, 'end': 21, 'answer': 'had his own moral'}\n",
            "{'score': 0.1194823831319809, 'start': 0, 'end': 10, 'answer': 'ControlLed'}\n",
            "{'score': 0.00014231455861590803, 'start': 192, 'end': 226, 'answer': 'street fight against 12 other guys'}\n",
            "{'score': 0.0002216963330283761, 'start': 195, 'end': 272, 'answer': 'on our corner.\" That exposure also created motivation. \"Seeing tragedy always'}\n",
            "{'score': 0.020774710923433304, 'start': 15, 'end': 19, 'answer': 'Tsai'}\n",
            "{'score': 0.00013378847506828606, 'start': 73, 'end': 89, 'answer': 'multimillionaire'}\n",
            "{'score': 0.00018305015692021698, 'start': 53, 'end': 71, 'answer': 'violence than most'}\n",
            "{'score': 0.0003599903720896691, 'start': 0, 'end': 74, 'answer': 'Few recalled major rifts between their parents. But many of these siblings'}\n",
            "{'score': 0.0002423449041089043, 'start': 0, 'end': 29, 'answer': 'Mealtime debates could get so'}\n",
            "{'score': 0.09336036443710327, 'start': 12, 'end': 18, 'answer': 'Family'}\n",
            "{'score': 0.004030057694762945, 'start': 53, 'end': 72, 'answer': 'Behar—Sipa Press/AP'}\n",
            "{'score': 0.0002683810889720917, 'start': 156, 'end': 179, 'answer': 'basket. Susan and Janet'}\n",
            "{'score': 0.00012431298091541976, 'start': 300, 'end': 329, 'answer': 'weren’t home. Esther Wojcicki'}\n",
            "{'score': 0.00013080035569146276, 'start': 353, 'end': 369, 'answer': 'had to withstand'}\n",
            "{'score': 0.0006629822310060263, 'start': 52, 'end': 115, 'answer': 'motivate achievement, says New York University psychologist Ben'}\n",
            "{'score': 0.06460928916931152, 'start': 0, 'end': 7, 'answer': 'LESSONS'}\n",
            "{'score': 0.0011045384453609586, 'start': 29, 'end': 30, 'answer': 't'}\n",
            "{'score': 0.00010095539619214833, 'start': 466, 'end': 489, 'answer': 'motivated by a constant'}\n",
            "{'score': 8.467170846415684e-05, 'start': 298, 'end': 331, 'answer': 'gallbladder out, and I don’t want'}\n",
            "{'score': 0.05257600545883179, 'start': 4, 'end': 19, 'answer': 'Antonoff Family'}\n",
            "{'score': 0.007112980354577303, 'start': 0, 'end': 37, 'answer': 'Left: Courtesy of the Antonoff Family'}\n",
            "{'score': 8.965814049588516e-05, 'start': 479, 'end': 543, 'answer': 'violence. Rahm Emanuel nearly died as a teenager when a deep cut'}\n",
            "{'score': 0.0002163107565138489, 'start': 256, 'end': 268, 'answer': 'going to not'}\n",
            "{'score': 0.00019593648903537542, 'start': 243, 'end': 295, 'answer': 'didn’t insist they finish college, and she took Jack'}\n",
            "{'score': 0.0003763579297810793, 'start': 43, 'end': 52, 'answer': 'had a kid'}\n",
            "{'score': 0.03789138048887253, 'start': 7, 'end': 22, 'answer': 'range childhood'}\n",
            "{'score': 0.0004281932779122144, 'start': 5, 'end': 31, 'answer': 'many of the other siblings'}\n",
            "{'score': 0.0003160043270327151, 'start': 116, 'end': 131, 'answer': 'loathed so much'}\n",
            "{'score': 0.00014604281750507653, 'start': 33, 'end': 96, 'answer': 'Mao and ultimately became professors at Ohio University, didn’t'}\n",
            "{'score': 0.08973333239555359, 'start': 8, 'end': 14, 'answer': 'Family'}\n",
            "{'score': 0.01582331582903862, 'start': 9, 'end': 42, 'answer': 'Right: Courtesy of the Lin Family'}\n",
            "{'score': 0.0003082541225012392, 'start': 23, 'end': 80, 'answer': 'most of their time outside, or writing poems, or throwing'}\n",
            "{'score': 0.00017130786727648228, 'start': 0, 'end': 19, 'answer': 'Few of the siblings'}\n",
            "{'score': 0.0004668140027206391, 'start': 67, 'end': 122, 'answer': 'she allowed us to play and develop our own ideas,\" says'}\n",
            "{'score': 0.00021644937805831432, 'start': 7, 'end': 15, 'answer': 'Wojcicki'}\n",
            "{'score': 0.00035381290945224464, 'start': 126, 'end': 164, 'answer': 'often left to babysit 4-year-old Janet'}\n",
            "{'score': 0.0011856367345899343, 'start': 98, 'end': 133, 'answer': 'less empowered they feel,\" she says'}\n",
            "{'score': 0.00032054499024525285, 'start': 225, 'end': 284, 'answer': 'commonalities of our nine families combined to create drive'}\n",
            "{'score': 0.0002959715493489057, 'start': 179, 'end': 192, 'answer': 'will are five'}\n",
            "['common', 'will.\" The message was always', 'conscious,\" Rodriguez says. \"That’s the one', 'each morning, they did a series of jumping jacks', 'Tsai', 'were great', 'in the country. And Gina Rodriguez won a Best Actress Golden Globe', 'We lived the idea of the American Dream,\" Gina says', 'Family', 'Right: Courtesy of the Rodriguez Family', 'Srinivasans', 'thousands', 'well. And we defined success by leadership', 'none of these siblings grew up rich, they were privileged in many', 'most said they grew up with much', 'Indians from Kansas', 'Immigrant Drive', 'Saroja Srinivasan, a Hindu who is vegetarian, was mastering', 'Saroja recalls. That meant cooking hot dogs and pizza as well as dosas', 'Srinivasan household', 'Srinija, the youngest. \"Put things away. Pay attention', 'permissiveness that is way better than an allowance,\" says', 'Srinivasan Family', 'Srinivasan Family', 'was more important', 'Srinija is an entrepreneur who', 'addition to Puerto Rico and India', '-selling author and New York Times', 'Gay Family', 'Hegger', 'Good grades in school, that was not something', 'Being from Haiti in particular', 'Parent-Teachers', 'Srinivasans in Kansas', 'genetics company 23andMe', 'paper airplanes during presentations', 'lot of strong academics, I think one of the skills we have is not', 'Wojcicki', 'Wojcicki', 'game.\" She did arts and crafts projects with her toddler', 'among the most important', 'Not', 'supplementary lessons', 'well-known actor, with major', 'Dungey Family', 'Left and Right: Courtesy of the Dungey Family', 'Srinivasans, having a parent', 'Activism', 'most', 'vice provost at the University of Pennsylvania', 'dinner was a test of current events.\" (The brothers also have', 'Tsai', 'will change necessarily', 'housing complexes, and never', 'Emanuel Family', 'Left: Courtesy of the Emanuel Family', 'construction site. Now adults', 'had his own moral', 'ControlLed', 'street fight against 12 other guys', 'on our corner.\" That exposure also created motivation. \"Seeing tragedy always', 'Tsai', 'multimillionaire', 'violence than most', 'Few recalled major rifts between their parents. But many of these siblings', 'Mealtime debates could get so', 'Family', 'Behar—Sipa Press/AP', 'basket. Susan and Janet', 'weren’t home. Esther Wojcicki', 'had to withstand', 'motivate achievement, says New York University psychologist Ben', 'LESSONS', 't', 'motivated by a constant', 'gallbladder out, and I don’t want', 'Antonoff Family', 'Left: Courtesy of the Antonoff Family', 'violence. Rahm Emanuel nearly died as a teenager when a deep cut', 'going to not', 'didn’t insist they finish college, and she took Jack', 'had a kid', 'range childhood', 'many of the other siblings', 'loathed so much', 'Mao and ultimately became professors at Ohio University, didn’t', 'Family', 'Right: Courtesy of the Lin Family', 'most of their time outside, or writing poems, or throwing', 'Few of the siblings', 'she allowed us to play and develop our own ideas,\" says', 'Wojcicki', 'often left to babysit 4-year-old Janet', 'less empowered they feel,\" she says', 'commonalities of our nine families combined to create drive', 'will are five']\n",
            "{'score': 0.06560217589139938, 'start': 0, 'end': 2, 'answer': 'By'}\n",
            "{'score': 0.00026645910111255944, 'start': 157, 'end': 228, 'answer': 'Division I football for Missouri State University, Andrew was an honors'}\n",
            "{'score': 0.00019880708714481443, 'start': 259, 'end': 332, 'answer': 'more timely by the recent heroin-related death of Glee star Cory Monteith'}\n",
            "{'score': 8.652928227093071e-05, 'start': 97, 'end': 156, 'answer': 'much more powerful than before (purity can be as high as 90'}\n",
            "{'score': 0.0001446622482035309, 'start': 143, 'end': 160, 'answer': 'in routine wisdom'}\n",
            "{'score': 6.532804400194436e-05, 'start': 555, 'end': 580, 'answer': '—legally and on the black'}\n",
            "{'score': 8.702019840711728e-05, 'start': 334, 'end': 407, 'answer': 'was finally starting to get a handle on his addiction. Like Cory Monteith'}\n",
            "{'score': 6.292361649684608e-05, 'start': 272, 'end': 330, 'answer': 'some of the best high schools in the area. Public, private'}\n",
            "{'score': 0.00013940730423200876, 'start': 302, 'end': 324, 'answer': 'was like I was leading'}\n",
            "{'score': 0.00012190795678179711, 'start': 267, 'end': 308, 'answer': 'had to give something to him,\" she admits'}\n",
            "{'score': 0.00038199889240786433, 'start': 134, 'end': 147, 'answer': 'When a friend'}\n",
            "{'score': 7.597904914291576e-05, 'start': 382, 'end': 424, 'answer': 'length to get sober. I had to change every'}\n",
            "{'score': 5.0665094022406265e-05, 'start': 715, 'end': 719, 'answer': 'much'}\n",
            "{'score': 0.025353144854307175, 'start': 10, 'end': 14, 'answer': 'been'}\n",
            "['By', 'Division I football for Missouri State University, Andrew was an honors', 'more timely by the recent heroin-related death of Glee star Cory Monteith', 'much more powerful than before (purity can be as high as 90', 'in routine wisdom', '—legally and on the black', 'was finally starting to get a handle on his addiction. Like Cory Monteith', 'some of the best high schools in the area. Public, private', 'was like I was leading', 'had to give something to him,\" she admits', 'When a friend', 'length to get sober. I had to change every', 'much', 'been']\n",
            "{'score': 0.00022069428814575076, 'start': 147, 'end': 210, 'answer': 'eared giant, among them—and their triumphs over bullying adults'}\n",
            "{'score': 0.0002360543148824945, 'start': 231, 'end': 308, 'answer': 'evocative stories. In May, the Oxford University Press also published a Roald'}\n",
            "{'score': 0.00010101413499796763, 'start': 384, 'end': 423, 'answer': 'sizzle-pan\" to refer to a frying pan in'}\n",
            "{'score': 0.002217260655015707, 'start': 17, 'end': 79, 'answer': 'Dahlisms added to the OED, and the revised phrases, with notes'}\n",
            "{'score': 0.11931880563497543, 'start': 0, 'end': 11, 'answer': 'New entries'}\n",
            "{'score': 0.0004027275135740638, 'start': 97, 'end': 153, 'answer': 'loathsome adult characters, and gruesome or black humour'}\n",
            "{'score': 0.0002810201549436897, 'start': 48, 'end': 94, 'answer': 'in chocolate bars that granted access to Willy'}\n",
            "{'score': 0.00021794639178551733, 'start': 243, 'end': 281, 'answer': 'over a century older, having been used'}\n",
            "{'score': 0.0003523120249155909, 'start': 148, 'end': 215, 'answer': 'adaption of the book, starring Gene Wilder. Gupta called the phrase'}\n",
            "{'score': 0.006654852069914341, 'start': 0, 'end': 19, 'answer': 'Scrumdiddlyumptious'}\n",
            "{'score': 0.07014880329370499, 'start': 0, 'end': 9, 'answer': 'excellent'}\n",
            "{'score': 0.0002713536669034511, 'start': 245, 'end': 286, 'answer': 'scrumdiddlyumptious and some is uckyslush'}\n",
            "{'score': 0.00021875230595469475, 'start': 196, 'end': 250, 'answer': 'had the world to themselves.\" We can thank Shakespeare'}\n",
            "['eared giant, among them—and their triumphs over bullying adults', 'evocative stories. In May, the Oxford University Press also published a Roald', 'sizzle-pan\" to refer to a frying pan in', 'Dahlisms added to the OED, and the revised phrases, with notes', 'New entries', 'loathsome adult characters, and gruesome or black humour', 'in chocolate bars that granted access to Willy', 'over a century older, having been used', 'adaption of the book, starring Gene Wilder. Gupta called the phrase', 'Scrumdiddlyumptious', 'excellent', 'scrumdiddlyumptious and some is uckyslush', 'had the world to themselves.\" We can thank Shakespeare']\n",
            "{'score': 0.0032058183569461107, 'start': 44, 'end': 56, 'answer': 'have been up'}\n",
            "{'score': 9.996380686061457e-05, 'start': 241, 'end': 245, 'answer': 'hope'}\n",
            "{'score': 0.0002302885113749653, 'start': 100, 'end': 114, 'answer': 'longer meeting'}\n",
            "{'score': 0.0011548573384061456, 'start': 17, 'end': 29, 'answer': 'monetization'}\n",
            "{'score': 0.034266795963048935, 'start': 0, 'end': 32, 'answer': 'we announced Promoted User Posts'}\n",
            "{'score': 9.08650690689683e-05, 'start': 97, 'end': 103, 'answer': 'be met'}\n",
            "{'score': 0.00013093271991237998, 'start': 285, 'end': 288, 'answer': 'lot'}\n",
            "{'score': 0.0001337109279120341, 'start': 11, 'end': 16, 'answer': 'great'}\n",
            "{'score': 0.011128399521112442, 'start': 0, 'end': 43, 'answer': 'Happy to chat about this stuff, or anything'}\n",
            "['have been up', 'hope', 'longer meeting', 'monetization', 'we announced Promoted User Posts', 'be met', 'lot', 'great', 'Happy to chat about this stuff, or anything']\n",
            "{'score': 0.0006994717405177653, 'start': 19, 'end': 98, 'answer': 'Temple University students, alumni, faculty and staff gathered at the Liacouras'}\n",
            "{'score': 0.0016712879296392202, 'start': 58, 'end': 135, 'answer': ',303 being made and sent to charitable organizations in the Dallas/Fort Worth'}\n",
            "{'score': 0.0026634088717401028, 'start': 0, 'end': 75, 'answer': \"Temple shattered that record, according to the university's Twitter account\"}\n",
            "{'score': 0.004586049821227789, 'start': 0, 'end': 49, 'answer': 'Fifteen food banks and shelters across the Philly'}\n",
            "{'score': 0.0010611288016662002, 'start': 0, 'end': 44, 'answer': 'Congrats, Temple. And once again, as a thank'}\n",
            "['Temple University students, alumni, faculty and staff gathered at the Liacouras', ',303 being made and sent to charitable organizations in the Dallas/Fort Worth', \"Temple shattered that record, according to the university's Twitter account\", 'Fifteen food banks and shelters across the Philly', 'Congrats, Temple. And once again, as a thank']\n",
            "{'score': 0.003146599279716611, 'start': 83, 'end': 108, 'answer': 'are home sick from school'}\n",
            "{'score': 0.0017728307284414768, 'start': 66, 'end': 117, 'answer': 'a feud between him and President Trump, who remains'}\n",
            "{'score': 0.003668074728921056, 'start': 49, 'end': 58, 'answer': 'more than'}\n",
            "{'score': 0.002194825327023864, 'start': 60, 'end': 101, 'answer': 'on the unresponsive child when the mother'}\n",
            "{'score': 0.0029638372361660004, 'start': 76, 'end': 85, 'answer': 'are a top'}\n",
            "{'score': 0.0018996336730197072, 'start': 62, 'end': 83, 'answer': 'the proposal to deter'}\n",
            "{'score': 0.0024319570511579514, 'start': 15, 'end': 53, 'answer': 'had communications during the campaign'}\n",
            "{'score': 0.0018399651162326336, 'start': 112, 'end': 161, 'answer': 'may have had with Russia during the 2016 campaign'}\n",
            "{'score': 0.0012590711703523993, 'start': 67, 'end': 133, 'answer': 'have polycystic ovarian syndrome, and Dr. Jennifer Ashton explains'}\n",
            "{'score': 0.00211132550612092, 'start': 12, 'end': 78, 'answer': 'The Force Awakens\" star, Daisy Ridley, revealed a powerful message'}\n",
            "{'score': 0.0019315900281071663, 'start': 47, 'end': 110, 'answer': 'that she has been suffering from endometriosis since she was 15'}\n",
            "{'score': 0.06534292548894882, 'start': 0, 'end': 4, 'answer': 'View'}\n",
            "{'score': 0.006422468926757574, 'start': 0, 'end': 38, 'answer': \"'Star Wars' Actress Daisy Ridley Fires\"}\n",
            "{'score': 0.0035700243897736073, 'start': 37, 'end': 47, 'answer': \"'Star Wars\"}\n",
            "{'score': 0.0006863294984214008, 'start': 1, 'end': 77, 'answer': 'Endometriosis occurs when the normal uterine lining grows outside the uterus'}\n",
            "{'score': 0.0010799989104270935, 'start': 21, 'end': 50, 'answer': 'in women of child bearing age'}\n",
            "{'score': 0.0001797451841412112, 'start': 281, 'end': 305, 'answer': 'have polycycstic ovaries'}\n",
            "{'score': 0.0002892560150939971, 'start': 186, 'end': 196, 'answer': 'in tatters'}\n",
            "{'score': 0.0014375176979228854, 'start': 39, 'end': 62, 'answer': 'have polycystic ovarian'}\n",
            "{'score': 0.001191739458590746, 'start': 17, 'end': 84, 'answer': 'that with the help of dermatologists and diet changes, like cutting'}\n",
            "{'score': 0.0001504544197814539, 'start': 129, 'end': 150, 'answer': 'allergy testing; keep'}\n",
            "{'score': 0.002470540115609765, 'start': 38, 'end': 93, 'answer': 'over 200,000 likes and countless comments of outpouring'}\n",
            "['are home sick from school', 'a feud between him and President Trump, who remains', 'more than', 'on the unresponsive child when the mother', 'are a top', 'the proposal to deter', 'had communications during the campaign', 'may have had with Russia during the 2016 campaign', 'have polycystic ovarian syndrome, and Dr. Jennifer Ashton explains', 'The Force Awakens\" star, Daisy Ridley, revealed a powerful message', 'that she has been suffering from endometriosis since she was 15', 'View', \"'Star Wars' Actress Daisy Ridley Fires\", \"'Star Wars\", 'Endometriosis occurs when the normal uterine lining grows outside the uterus', 'in women of child bearing age', 'have polycycstic ovaries', 'in tatters', 'have polycystic ovarian', 'that with the help of dermatologists and diet changes, like cutting', 'allergy testing; keep', 'over 200,000 likes and countless comments of outpouring']\n",
            "{'score': 0.02135811187326908, 'start': 17, 'end': 32, 'answer': 'a better parent'}\n",
            "{'score': 0.007335757836699486, 'start': 41, 'end': 53, 'answer': 'on your kids'}\n",
            "{'score': 0.005710893776267767, 'start': 18, 'end': 25, 'answer': 'have no'}\n",
            "{'score': 0.007123506162315607, 'start': 7, 'end': 15, 'answer': 'the more'}\n",
            "{'score': 0.0027893062215298414, 'start': 31, 'end': 63, 'answer': 'you look like your kids do every'}\n",
            "{'score': 0.005257206503301859, 'start': 12, 'end': 50, 'answer': 'your kid is embarrassing you in public'}\n",
            "{'score': 0.014527992345392704, 'start': 16, 'end': 21, 'answer': 'happy'}\n",
            "{'score': 0.005082281772047281, 'start': 3, 'end': 60, 'answer': 'Your kids walk around explaining things so you don’t have'}\n",
            "{'score': 0.007230529095977545, 'start': 7, 'end': 16, 'answer': 'they also'}\n",
            "{'score': 0.005801317747682333, 'start': 11, 'end': 29, 'answer': 'a disturbing level'}\n",
            "{'score': 0.004141978919506073, 'start': 13, 'end': 57, 'answer': 'you get it you are one calm, cool badass mom'}\n",
            "{'score': 0.010818175040185452, 'start': 0, 'end': 29, 'answer': '11. This image perfectly sums'}\n",
            "{'score': 0.003487042849883437, 'start': 4, 'end': 21, 'answer': 'It doesn’t matter'}\n",
            "{'score': 0.005688148085027933, 'start': 9, 'end': 51, 'answer': 'it’s like liquid confidence for motherhood'}\n",
            "{'score': 0.003627625759691, 'start': 51, 'end': 69, 'answer': 'there is to handle'}\n",
            "{'score': 0.007207098882645369, 'start': 45, 'end': 62, 'answer': 'in your household'}\n",
            "{'score': 0.0018666060641407967, 'start': 94, 'end': 116, 'answer': 'much more pleasant mom'}\n",
            "{'score': 0.00434886384755373, 'start': 8, 'end': 68, 'answer': 'when someone asks how you mom so good, your answer is always'}\n",
            "['a better parent', 'on your kids', 'have no', 'the more', 'you look like your kids do every', 'your kid is embarrassing you in public', 'happy', 'Your kids walk around explaining things so you don’t have', 'they also', 'a disturbing level', 'you get it you are one calm, cool badass mom', '11. This image perfectly sums', 'It doesn’t matter', 'it’s like liquid confidence for motherhood', 'there is to handle', 'in your household', 'much more pleasant mom', 'when someone asks how you mom so good, your answer is always']\n",
            "{'score': 0.016734641045331955, 'start': 13, 'end': 21, 'answer': 'you need'}\n",
            "{'score': 0.0005336118047125638, 'start': 102, 'end': 105, 'answer': '100'}\n",
            "{'score': 0.0009870711946859956, 'start': 31, 'end': 63, 'answer': \"haven't done since 1995. The S&P\"}\n",
            "{'score': 0.0006435568211600184, 'start': 75, 'end': 132, 'answer': 'the summer of 1975. However, real wage growth slowed to 0'}\n",
            "{'score': 0.0005740192718803883, 'start': 149, 'end': 194, 'answer': \"Wilders's far-right party expected to perform\"}\n",
            "{'score': 0.00046831753570586443, 'start': 37, 'end': 81, 'answer': 'Intermediate crude oil trades up 1.7% at $48'}\n",
            "{'score': 0.0002212183753727004, 'start': 265, 'end': 294, 'answer': 'most of its shares after Jack'}\n",
            "{'score': 0.0005068394239060581, 'start': 0, 'end': 68, 'answer': 'Walgreens plans to sell more assets to win approval for its takeover'}\n",
            "{'score': 0.00033765516127459705, 'start': 143, 'end': 146, 'answer': 'S&P'}\n",
            "{'score': 0.00782186072319746, 'start': 22, 'end': 35, 'answer': 'light. Oracle'}\n",
            "{'score': 0.00038328595110215247, 'start': 123, 'end': 150, 'answer': 'Housing Market Index is due'}\n",
            "['you need', '100', \"haven't done since 1995. The S&P\", 'the summer of 1975. However, real wage growth slowed to 0', \"Wilders's far-right party expected to perform\", 'Intermediate crude oil trades up 1.7% at $48', 'most of its shares after Jack', 'Walgreens plans to sell more assets to win approval for its takeover', 'S&P', 'light. Oracle', 'Housing Market Index is due']\n",
            "{'score': 0.0007860806654207408, 'start': 1, 'end': 13, 'answer': 'Good Morning'}\n",
            "{'score': 0.002384609542787075, 'start': 73, 'end': 78, 'answer': 'a bit'}\n",
            "{'score': 0.0011229754891246557, 'start': 49, 'end': 55, 'answer': 're not'}\n",
            "{'score': 0.002651974791660905, 'start': 47, 'end': 58, 'answer': ', should be'}\n",
            "{'score': 0.0016792427049949765, 'start': 72, 'end': 83, 'answer': ', should be'}\n",
            "{'score': 0.0011171204969286919, 'start': 73, 'end': 78, 'answer': 'to be'}\n",
            "{'score': 0.12726454436779022, 'start': 0, 'end': 4, 'answer': 'View'}\n",
            "{'score': 0.0011379249626770616, 'start': 74, 'end': 141, 'answer': 'are generally good for a year. Aerosol spray products can last much'}\n",
            "{'score': 0.0005133238155394793, 'start': 139, 'end': 197, 'answer': 'is stored improperly — for example, in a place that is too'}\n",
            "{'score': 0.0009918775176629424, 'start': 97, 'end': 131, 'answer': 'they will have an exact expiration'}\n",
            "{'score': 0.0003045451594516635, 'start': 97, 'end': 114, 'answer': \"It's hard to keep\"}\n",
            "{'score': 0.0006889220094308257, 'start': 0, 'end': 65, 'answer': \"Franzino's tips to save money on beauty products include swapping\"}\n",
            "{'score': 0.0013783695176243782, 'start': 83, 'end': 113, 'answer': 'you may end up having to throw'}\n",
            "['Good Morning', 'a bit', 're not', ', should be', ', should be', 'to be', 'View', 'are generally good for a year. Aerosol spray products can last much', 'is stored improperly — for example, in a place that is too', 'they will have an exact expiration', \"It's hard to keep\", \"Franzino's tips to save money on beauty products include swapping\", 'you may end up having to throw']\n",
            "{'score': 0.009650937281548977, 'start': 30, 'end': 45, 'answer': 'on your big day'}\n",
            "{'score': 0.0006516791763715446, 'start': 56, 'end': 109, 'answer': 'distasteful to some may be perfectly normal to others'}\n",
            "{'score': 0.001164806541055441, 'start': 5, 'end': 41, 'answer': 'cringe-worthy dance routines, cheesy'}\n",
            "{'score': 0.0012912831734865904, 'start': 45, 'end': 84, 'answer': 'unquestionably tacky and definitely not'}\n",
            "{'score': 0.001963232411071658, 'start': 36, 'end': 41, 'answer': 'horde'}\n",
            "{'score': 0.0016059755580499768, 'start': 5, 'end': 65, 'answer': 'you seen that video doing the rounds on Facebook where a guy'}\n",
            "{'score': 0.0019270555349066854, 'start': 69, 'end': 106, 'answer': 'tackiest things you can do at someone'}\n",
            "{'score': 0.0021606856025755405, 'start': 12, 'end': 38, 'answer': 'livid. Like no. This is my'}\n",
            "{'score': 0.0008788614650256932, 'start': 82, 'end': 118, 'answer': 'inconsiderate,\" and quite simply, \"F'}\n",
            "{'score': 0.0051313238218426704, 'start': 12, 'end': 52, 'answer': 'peeve guests have at weddings are vulgar'}\n",
            "{'score': 0.0028658141382038593, 'start': 1, 'end': 35, 'answer': 'Miserable marriage jokes are never'}\n",
            "{'score': 0.001685641473159194, 'start': 11, 'end': 73, 'answer': 'toppers that show the bride dragging the groom and ring-bearer'}\n",
            "{'score': 0.0013243071734905243, 'start': 51, 'end': 94, 'answer': \"there under their own free will. S***'s not\"}\n",
            "{'score': 0.00524916360154748, 'start': 12, 'end': 49, 'answer': 'most common gripe among guests though'}\n",
            "{'score': 0.0011995425447821617, 'start': 88, 'end': 137, 'answer': 'had homes was fine, there were some circumstances'}\n",
            "{'score': 0.0009804603178054094, 'start': 128, 'end': 145, 'answer': 'the bride & groom'}\n",
            "{'score': 0.0019193674670532346, 'start': 55, 'end': 59, 'answer': 'very'}\n",
            "{'score': 0.002343174535781145, 'start': 29, 'end': 80, 'answer': \"aren't invited, but asks for a gift? GTF outta here\"}\n",
            "{'score': 0.0007268096087500453, 'start': 97, 'end': 117, 'answer': 'they had her husband'}\n",
            "{'score': 0.0010796296410262585, 'start': 28, 'end': 44, 'answer': 'there was a cash'}\n",
            "{'score': 0.0007880987832322717, 'start': 65, 'end': 75, 'answer': 'screeching'}\n",
            "['on your big day', 'distasteful to some may be perfectly normal to others', 'cringe-worthy dance routines, cheesy', 'unquestionably tacky and definitely not', 'horde', 'you seen that video doing the rounds on Facebook where a guy', 'tackiest things you can do at someone', 'livid. Like no. This is my', 'inconsiderate,\" and quite simply, \"F', 'peeve guests have at weddings are vulgar', 'Miserable marriage jokes are never', 'toppers that show the bride dragging the groom and ring-bearer', \"there under their own free will. S***'s not\", 'most common gripe among guests though', 'had homes was fine, there were some circumstances', 'the bride & groom', 'very', \"aren't invited, but asks for a gift? GTF outta here\", 'they had her husband', 'there was a cash', 'screeching']\n",
            "{'score': 0.0004596521030180156, 'start': 160, 'end': 218, 'answer': 'could have been possible if the ruler had sex about once a'}\n",
            "{'score': 0.0006030767690390348, 'start': 40, 'end': 91, 'answer': 'was the first great sultan of the Moroccan Alaouite'}\n",
            "{'score': 0.00018132822879124433, 'start': 252, 'end': 282, 'answer': 'most of them from enemy chiefs'}\n",
            "{'score': 0.0004601897089742124, 'start': 198, 'end': 231, 'answer': 'at one of his wives or concubines'}\n",
            "{'score': 0.00019544166570995003, 'start': 266, 'end': 318, 'answer': 'may actually have had 1,171 children from four wives'}\n",
            "{'score': 0.0002598878345452249, 'start': 207, 'end': 233, 'answer': 'infertility often afflicts'}\n",
            "{'score': 0.0007654005312360823, 'start': 0, 'end': 44, 'answer': 'To solve this question, scientists developed'}\n",
            "{'score': 0.0008105800952762365, 'start': 4, 'end': 82, 'answer': 'were as conservative as possible with our calculations, and Moulay could still'}\n",
            "{'score': 0.00019830476958304644, 'start': 243, 'end': 281, 'answer': \"were at fertilizing women's eggs as he\"}\n",
            "{'score': 0.0002411027526250109, 'start': 112, 'end': 174, 'answer': ',171 children in 32 years. Moreover, the sultan did not need a'}\n",
            "{'score': 0.0001689187774900347, 'start': 160, 'end': 200, 'answer': 'were all quite different from each other'}\n",
            "{'score': 0.0026219577994197607, 'start': 0, 'end': 11, 'answer': 'Oberzaucher'}\n",
            "['could have been possible if the ruler had sex about once a', 'was the first great sultan of the Moroccan Alaouite', 'most of them from enemy chiefs', 'at one of his wives or concubines', 'may actually have had 1,171 children from four wives', 'infertility often afflicts', 'To solve this question, scientists developed', 'were as conservative as possible with our calculations, and Moulay could still', \"were at fertilizing women's eggs as he\", ',171 children in 32 years. Moreover, the sultan did not need a', 'were all quite different from each other', 'Oberzaucher']\n",
            "{'score': 5.8835914387600496e-05, 'start': 347, 'end': 363, 'answer': 'ones who deserve'}\n",
            "{'score': 0.00870600901544094, 'start': 7, 'end': 14, 'answer': 'Lakisha'}\n",
            "{'score': 0.00014876227942295372, 'start': 4, 'end': 11, 'answer': 'Lakisha'}\n",
            "{'score': 5.3180468967184424e-05, 'start': 141, 'end': 165, 'answer': 'My oldest daughter Kiona'}\n",
            "{'score': 0.0011592621449381113, 'start': 0, 'end': 5, 'answer': 'Kiona'}\n",
            "{'score': 0.00019165566482115537, 'start': 208, 'end': 260, 'answer': 'Along with her work as a healer, Dr. Jenkins strives'}\n",
            "{'score': 0.00026258674915879965, 'start': 149, 'end': 194, 'answer': 'other people do and you’re more in a position'}\n",
            "{'score': 8.013742626644671e-05, 'start': 427, 'end': 462, 'answer': 'going to challenge you all the time'}\n",
            "{'score': 0.014397543855011463, 'start': 10, 'end': 11, 'answer': 'K'}\n",
            "{'score': 0.0006566990632563829, 'start': 55, 'end': 58, 'answer': 'due'}\n",
            "{'score': 0.0005960828857496381, 'start': 189, 'end': 274, 'answer': 'much anything related to the operations of cannabis businesses regulated by the state'}\n",
            "{'score': 9.617760952096432e-05, 'start': 1, 'end': 12, 'answer': 'I’ve always'}\n",
            "{'score': 9.539740131003782e-05, 'start': 154, 'end': 214, 'answer': 'lot of opportunities to blaze the trail, so to speak, no pun'}\n",
            "{'score': 0.006656315177679062, 'start': 9, 'end': 32, 'answer': 'Lyman, California State'}\n",
            "{'score': 0.00028555779135785997, 'start': 212, 'end': 270, 'answer': 'non-profit organization Drug Policy Alliance, \"the leading'}\n",
            "{'score': 0.001547517953440547, 'start': 1, 'end': 10, 'answer': 'We always'}\n",
            "{'score': 0.0006227957201190293, 'start': 190, 'end': 201, 'answer': 'didn’t pass'}\n",
            "{'score': 0.0006246638367883861, 'start': 185, 'end': 197, 'answer': 'were a vital'}\n",
            "{'score': 6.309022865025327e-05, 'start': 484, 'end': 487, 'answer': 'lot'}\n",
            "{'score': 8.073491335380822e-05, 'start': 265, 'end': 306, 'answer': 'been men’s faces at the forefront and yet'}\n",
            "{'score': 0.009006638079881668, 'start': 0, 'end': 1, 'answer': '4'}\n",
            "{'score': 0.0001382869522785768, 'start': 422, 'end': 438, 'answer': 'diversity summit'}\n",
            "{'score': 0.00019674526993185282, 'start': 36, 'end': 88, 'answer': 'many community leaders of color to come in and share'}\n",
            "{'score': 0.0001584822020959109, 'start': 74, 'end': 96, 'answer': 'in far from over. \"I’m'}\n",
            "{'score': 0.0002399457443971187, 'start': 238, 'end': 247, 'answer': 'I’m gonna'}\n",
            "{'score': 0.00017816956096794456, 'start': 253, 'end': 274, 'answer': 'that literally credit'}\n",
            "{'score': 0.009807554073631763, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.00015738072397653013, 'start': 287, 'end': 291, 'answer': 'FECO'}\n",
            "{'score': 0.000261622597463429, 'start': 70, 'end': 116, 'answer': 'lab grade, U.S. made, naturally extracted beta'}\n",
            "{'score': 0.00012715579941868782, 'start': 230, 'end': 325, 'answer': 'longer feeling stuck without options to address their reproductive concerns. \"Women have always'}\n",
            "['ones who deserve', 'Lakisha', 'Lakisha', 'My oldest daughter Kiona', 'Kiona', 'Along with her work as a healer, Dr. Jenkins strives', 'other people do and you’re more in a position', 'going to challenge you all the time', 'K', 'due', 'much anything related to the operations of cannabis businesses regulated by the state', 'I’ve always', 'lot of opportunities to blaze the trail, so to speak, no pun', 'Lyman, California State', 'non-profit organization Drug Policy Alliance, \"the leading', 'We always', 'didn’t pass', 'were a vital', 'lot', 'been men’s faces at the forefront and yet', '4', 'diversity summit', 'many community leaders of color to come in and share', 'in far from over. \"I’m', 'I’m gonna', 'that literally credit', '5', 'FECO', 'lab grade, U.S. made, naturally extracted beta', 'longer feeling stuck without options to address their reproductive concerns. \"Women have always']\n",
            "{'score': 0.002768212230876088, 'start': 27, 'end': 38, 'answer': 'Abraj Kudai'}\n",
            "{'score': 0.0031863139010965824, 'start': 16, 'end': 36, 'answer': 'would make the hotel'}\n",
            "{'score': 0.00030798627994954586, 'start': 59, 'end': 78, 'answer': 'helipads and a full'}\n",
            "{'score': 0.0011541499989107251, 'start': 38, 'end': 54, 'answer': 'Handasah , the $'}\n",
            "{'score': 0.0008596524712629616, 'start': 49, 'end': 92, 'answer': 'over 2 kilometers from the Masjid al-Ḥaram'}\n",
            "{'score': 0.050781264901161194, 'start': 0, 'end': 11, 'answer': 'Abraj Kudai'}\n",
            "{'score': 0.004769124556332827, 'start': 22, 'end': 65, 'answer': '10,000 hotel rooms, according to DesignMENA'}\n",
            "['Abraj Kudai', 'would make the hotel', 'helipads and a full', 'Handasah , the $', 'over 2 kilometers from the Masjid al-Ḥaram', 'Abraj Kudai', '10,000 hotel rooms, according to DesignMENA']\n",
            "{'score': 0.0015513194957748055, 'start': 43, 'end': 104, 'answer': 'moderate the first presidential debate Monday. (Photo by Jose'}\n",
            "{'score': 0.0006102992920204997, 'start': 147, 'end': 159, 'answer': 'have advised'}\n",
            "{'score': 0.005280410870909691, 'start': 30, 'end': 38, 'answer': 'are five'}\n",
            "{'score': 0.03396056219935417, 'start': 10, 'end': 31, 'answer': 'registered Republican'}\n",
            "{'score': 0.0005447732983157039, 'start': 249, 'end': 260, 'answer': 'into attack'}\n",
            "{'score': 0.00023169888299889863, 'start': 45, 'end': 58, 'answer': 'of indicative'}\n",
            "{'score': 0.0014246759237721562, 'start': 0, 'end': 14, 'answer': 'Conspiratorial'}\n",
            "{'score': 0.0007865334628149867, 'start': 111, 'end': 117, 'answer': 'a very'}\n",
            "{'score': 0.0005804087850265205, 'start': 33, 'end': 98, 'answer': 'lobbing questions at Republican Donald Trump and Democrat Hillary'}\n",
            "{'score': 0.0006245002732612193, 'start': 196, 'end': 226, 'answer': 'bias against him will be tough'}\n",
            "{'score': 0.010591340251266956, 'start': 18, 'end': 23, 'answer': 'black'}\n",
            "{'score': 0.000234605060541071, 'start': 297, 'end': 324, 'answer': 'been 24 years since a black'}\n",
            "{'score': 0.00010733595991041511, 'start': 378, 'end': 413, 'answer': \"I'm never going to pull a race card\"}\n",
            "{'score': 0.0008035727660171688, 'start': 49, 'end': 73, 'answer': 'moderated one of Hillary'}\n",
            "{'score': 0.00020271947141736746, 'start': 49, 'end': 78, 'answer': \"a huge distinction. We're not\"}\n",
            "{'score': 0.016947126016020775, 'start': 5, 'end': 8, 'answer': 'not'}\n",
            "{'score': 0.0009970071259886026, 'start': 26, 'end': 74, 'answer': 'in almost a month. He was fairly active while in'}\n",
            "{'score': 0.0005250042886473238, 'start': 35, 'end': 95, 'answer': \"I've never done before a newscast. Beach volleyball. Tonight\"}\n",
            "{'score': 0.000653560331556946, 'start': 89, 'end': 129, 'answer': 'xJ5MoYGtPZ — Lester Holt (@LesterHoltNBC'}\n",
            "{'score': 0.000756395747885108, 'start': 54, 'end': 122, 'answer': 'several days or even a week between tweets. His relative disinterest'}\n",
            "{'score': 0.021660687401890755, 'start': 3, 'end': 25, 'answer': 'moderated a Democratic'}\n",
            "{'score': 0.001845862832851708, 'start': 113, 'end': 144, 'answer': 'that night with Andrea Mitchell'}\n",
            "{'score': 0.000854850048199296, 'start': 72, 'end': 83, 'answer': 'willingness'}\n",
            "{'score': 0.00025890301913022995, 'start': 142, 'end': 177, 'answer': 'fomented a war in Ukraine, provided'}\n",
            "{'score': 0.006937427446246147, 'start': 5, 'end': 8, 'answer': 'has'}\n",
            "{'score': 0.000284011970506981, 'start': 198, 'end': 215, 'answer': 'me he plans to do'}\n",
            "{'score': 0.0013785480987280607, 'start': 10, 'end': 26, 'answer': 'California State'}\n",
            "{'score': 0.00013337556447368115, 'start': 67, 'end': 111, 'answer': 'was planning to drop out of California State'}\n",
            "{'score': 0.002187534235417843, 'start': 18, 'end': 61, 'answer': 'okay. Since dropping out, Holt has received'}\n",
            "['moderate the first presidential debate Monday. (Photo by Jose', 'have advised', 'are five', 'registered Republican', 'into attack', 'of indicative', 'Conspiratorial', 'a very', 'lobbing questions at Republican Donald Trump and Democrat Hillary', 'bias against him will be tough', 'black', 'been 24 years since a black', \"I'm never going to pull a race card\", 'moderated one of Hillary', \"a huge distinction. We're not\", 'not', 'in almost a month. He was fairly active while in', \"I've never done before a newscast. Beach volleyball. Tonight\", 'xJ5MoYGtPZ — Lester Holt (@LesterHoltNBC', 'several days or even a week between tweets. His relative disinterest', 'moderated a Democratic', 'that night with Andrea Mitchell', 'willingness', 'fomented a war in Ukraine, provided', 'has', 'me he plans to do', 'California State', 'was planning to drop out of California State', 'okay. Since dropping out, Holt has received']\n",
            "{'score': 0.000620719394646585, 'start': 136, 'end': 173, 'answer': 'you have or where it is, you’re going'}\n",
            "{'score': 0.0013344282051548362, 'start': 9, 'end': 48, 'answer': 'you don’t have to go broke just keeping'}\n",
            "{'score': 0.0002807849377859384, 'start': 259, 'end': 272, 'answer': 'You also miss'}\n",
            "{'score': 0.0008315275190398097, 'start': 73, 'end': 84, 'answer': 'well-served'}\n",
            "{'score': 0.0004200678667984903, 'start': 9, 'end': 16, 'answer': 'outgrow'}\n",
            "{'score': 0.00039326446130871773, 'start': 61, 'end': 67, 'answer': 'inFlow'}\n",
            "{'score': 0.00023375556338578463, 'start': 108, 'end': 115, 'answer': 'hiccups'}\n",
            "{'score': 0.0007428304525092244, 'start': 162, 'end': 188, 'answer': 'inFlow, Carta should offer'}\n",
            "{'score': 0.0002812314487528056, 'start': 90, 'end': 134, 'answer': 'invoice and receipt generation tools, geared'}\n",
            "{'score': 0.00012608288670890033, 'start': 412, 'end': 426, 'answer': 'can be managed'}\n",
            "{'score': 0.00028593739261850715, 'start': 203, 'end': 214, 'answer': 'be free for'}\n",
            "{'score': 0.00028206402203068137, 'start': 163, 'end': 207, 'answer': 'you’ll probably want to take advantage of at'}\n",
            "{'score': 0.0003215969481971115, 'start': 162, 'end': 190, 'answer': 'great open source answer for'}\n",
            "{'score': 0.0002610993687994778, 'start': 30, 'end': 72, 'answer': 'Almyta Control System. It’s a free package'}\n",
            "{'score': 0.00044393588905222714, 'start': 15, 'end': 52, 'answer': 'all free options, you’ll be supplying'}\n",
            "{'score': 0.11654369533061981, 'start': 6, 'end': 14, 'answer': 'thoughts'}\n",
            "{'score': 0.0004213498323224485, 'start': 32, 'end': 117, 'answer': 'most small business inventory requirements, with many offering flexibility to move up'}\n",
            "{'score': 0.003973526880145073, 'start': 64, 'end': 74, 'answer': 'us know in'}\n",
            "['you have or where it is, you’re going', 'you don’t have to go broke just keeping', 'You also miss', 'well-served', 'outgrow', 'inFlow', 'hiccups', 'inFlow, Carta should offer', 'invoice and receipt generation tools, geared', 'can be managed', 'be free for', 'you’ll probably want to take advantage of at', 'great open source answer for', 'Almyta Control System. It’s a free package', 'all free options, you’ll be supplying', 'thoughts', 'most small business inventory requirements, with many offering flexibility to move up', 'us know in']\n",
            "{'score': 0.0021155374124646187, 'start': 85, 'end': 88, 'answer': 'lot'}\n",
            "{'score': 0.0016137599013745785, 'start': 29, 'end': 32, 'answer': 'Kis'}\n",
            "{'score': 0.0013224683934822679, 'start': 60, 'end': 93, 'answer': 'your time, he shares the ultimate'}\n",
            "{'score': 0.000620818289462477, 'start': 167, 'end': 180, 'answer': 'many projects'}\n",
            "{'score': 0.0004212427302263677, 'start': 71, 'end': 86, 'answer': 'at least 10 per'}\n",
            "{'score': 0.0003463930625002831, 'start': 25, 'end': 86, 'answer': 'enough to be prepared to invest 10 per cent of your net worth'}\n",
            "{'score': 0.0008478095987811685, 'start': 54, 'end': 105, 'answer': 'can be run by a monkey, because one day it probably'}\n",
            "{'score': 0.0015200554626062512, 'start': 18, 'end': 78, 'answer': 'Multi-millionaire Sophia Amoruso, founder of Nasty Gal, says'}\n",
            "{'score': 0.001931249164044857, 'start': 49, 'end': 72, 'answer': 'the more time you spend'}\n",
            "{'score': 0.0006693422328680754, 'start': 65, 'end': 74, 'answer': 'has to be'}\n",
            "{'score': 0.0012257794151082635, 'start': 96, 'end': 113, 'answer': 'vacations are not'}\n",
            "{'score': 0.0004919281345792115, 'start': 102, 'end': 128, 'answer': 'their time. Indeed, as Kim'}\n",
            "{'score': 0.002278056927025318, 'start': 15, 'end': 35, 'answer': 'skilled in a certain'}\n",
            "['lot', 'Kis', 'your time, he shares the ultimate', 'many projects', 'at least 10 per', 'enough to be prepared to invest 10 per cent of your net worth', 'can be run by a monkey, because one day it probably', 'Multi-millionaire Sophia Amoruso, founder of Nasty Gal, says', 'the more time you spend', 'has to be', 'vacations are not', 'their time. Indeed, as Kim', 'skilled in a certain']\n",
            "{'score': 0.003839353332296014, 'start': 2, 'end': 39, 'answer': ', so, Oxford University is older than'}\n",
            "{'score': 0.0019342886516824365, 'start': 26, 'end': 67, 'answer': 'in time to the invention of Snapchat than'}\n",
            "{'score': 0.000729473598767072, 'start': 24, 'end': 55, 'answer': 'more than 2,000 years ago in 30'}\n",
            "{'score': 0.0032247600611299276, 'start': 67, 'end': 70, 'answer': 'are'}\n",
            "{'score': 0.0020529243629425764, 'start': 48, 'end': 53, 'answer': 'still'}\n",
            "{'score': 0.0018727832939475775, 'start': 27, 'end': 61, 'answer': 'was older to the Tyrannosaurus rex'}\n",
            "{'score': 0.0008124157320708036, 'start': 0, 'end': 55, 'answer': 'Not only did they not exist at the same time, but the T'}\n",
            "{'score': 0.003689955221489072, 'start': 37, 'end': 95, 'answer': 'closer to the signing of the US Constitution than to today'}\n",
            "{'score': 0.0008326294482685626, 'start': 12, 'end': 61, 'answer': 'Martinuzzi, the oldest living person today at age'}\n",
            "{'score': 0.0044134934432804585, 'start': 25, 'end': 84, 'answer': 'the United States has two grandchildren who are alive today'}\n",
            "{'score': 0.0005373249878175557, 'start': 11, 'end': 40, 'answer': 'had a son, Lyon Tyler, at age'}\n",
            "{'score': 0.0087931202724576, 'start': 0, 'end': 1, 'answer': '6'}\n",
            "{'score': 0.0009679416543804109, 'start': 73, 'end': 77, 'answer': 'most'}\n",
            "{'score': 0.0041189552284777164, 'start': 0, 'end': 1, 'answer': '7'}\n",
            "{'score': 0.00045413803309202194, 'start': 95, 'end': 154, 'answer': 'almost 50 years before Isaac Newton published his Principia'}\n",
            "{'score': 0.003508669091388583, 'start': 26, 'end': 33, 'answer': 'only 66'}\n",
            "{'score': 0.0008784410892985761, 'start': 91, 'end': 116, 'answer': 'There’s so much Americans'}\n",
            "{'score': 0.003365826793015003, 'start': 19, 'end': 66, 'answer': 'were still alive when the Great Pyramid at Giza'}\n",
            "{'score': 0.0014179800637066364, 'start': 90, 'end': 121, 'answer': ', which wasn’t until about 1560'}\n",
            "{'score': 0.002851647324860096, 'start': 0, 'end': 71, 'answer': '10. When the first Star Wars movie came out, France was still executing'}\n",
            "{'score': 0.0006192387081682682, 'start': 88, 'end': 104, 'answer': 'Hamida Djandoubi'}\n",
            "{'score': 0.0040431334637105465, 'start': 46, 'end': 56, 'answer': 'were still'}\n",
            "{'score': 0.0012684536632150412, 'start': 58, 'end': 112, 'answer': 'Just two years later, Scottish inventor Alexander Bain'}\n",
            "{'score': 0.006486600264906883, 'start': 8, 'end': 22, 'answer': 'Ottoman Empire'}\n",
            "{'score': 0.001508253742940724, 'start': 67, 'end': 70, 'answer': 'all'}\n",
            "{'score': 0.010635903105139732, 'start': 0, 'end': 2, 'answer': '13'}\n",
            "{'score': 0.001059665810316801, 'start': 18, 'end': 54, 'answer': 'that’s the year Betty White was born'}\n",
            "{'score': 0.002242129994556308, 'start': 46, 'end': 56, 'answer': 'Uncle Phil'}\n",
            "{'score': 0.0013706739991903305, 'start': 31, 'end': 87, 'answer': ', but Will Smith is now 48 years old. James Avery was 45'}\n",
            "{'score': 0.0008282680646516383, 'start': 0, 'end': 2, 'answer': '15'}\n",
            "{'score': 0.000986988190561533, 'start': 43, 'end': 97, 'answer': 'way after the end of the ’70s, but that gap is exactly'}\n",
            "{'score': 0.00469218660145998, 'start': 8, 'end': 14, 'answer': 'Eiffel'}\n",
            "{'score': 0.0007488882401958108, 'start': 26, 'end': 80, 'answer': 'Eiffel Tower was inaugurated for the 1889 World’s Fair'}\n",
            "{'score': 0.002412815112620592, 'start': 35, 'end': 37, 'answer': 'Jr'}\n",
            "{'score': 0.0013533345190808177, 'start': 48, 'end': 92, 'answer': 'in very different times, Anne Frank, Barbara'}\n",
            "{'score': 0.002753510372713208, 'start': 4, 'end': 51, 'answer': 'Some of the world’s whales that are alive today'}\n",
            "{'score': 0.0007186808506958187, 'start': 132, 'end': 173, 'answer': 'may be whales out there who are nearly 50'}\n",
            "{'score': 0.0014024917036294937, 'start': 10, 'end': 21, 'answer': 'didn’t even'}\n",
            "{'score': 0.00031732101342640817, 'start': 90, 'end': 130, 'answer': 'heartbreakingly demoted in 2006. Because'}\n",
            "{'score': 0.004142566584050655, 'start': 28, 'end': 69, 'answer': 'the fall of the Berlin Wall than to today'}\n",
            "{'score': 0.0021804701536893845, 'start': 30, 'end': 52, 'answer': 'only 12 years before 9'}\n",
            "{'score': 0.0012242661323398352, 'start': 0, 'end': 2, 'answer': '21'}\n",
            "{'score': 0.0003684171533677727, 'start': 52, 'end': 80, 'answer': 'If you compressed the entire'}\n",
            "{'score': 0.004779771436005831, 'start': 0, 'end': 2, 'answer': '22'}\n",
            "{'score': 0.0008807025151327252, 'start': 71, 'end': 150, 'answer': 'and medicine, the current human population living on Earth right now is about 6'}\n",
            "{'score': 0.006391744129359722, 'start': 32, 'end': 60, 'answer': 'in the past, not the present'}\n",
            "{'score': 0.0012344204587861896, 'start': 6, 'end': 23, 'answer': 'it takes about 50'}\n",
            "[', so, Oxford University is older than', 'in time to the invention of Snapchat than', 'more than 2,000 years ago in 30', 'are', 'still', 'was older to the Tyrannosaurus rex', 'Not only did they not exist at the same time, but the T', 'closer to the signing of the US Constitution than to today', 'Martinuzzi, the oldest living person today at age', 'the United States has two grandchildren who are alive today', 'had a son, Lyon Tyler, at age', '6', 'most', '7', 'almost 50 years before Isaac Newton published his Principia', 'only 66', 'There’s so much Americans', 'were still alive when the Great Pyramid at Giza', ', which wasn’t until about 1560', '10. When the first Star Wars movie came out, France was still executing', 'Hamida Djandoubi', 'were still', 'Just two years later, Scottish inventor Alexander Bain', 'Ottoman Empire', 'all', '13', 'that’s the year Betty White was born', 'Uncle Phil', ', but Will Smith is now 48 years old. James Avery was 45', '15', 'way after the end of the ’70s, but that gap is exactly', 'Eiffel', 'Eiffel Tower was inaugurated for the 1889 World’s Fair', 'Jr', 'in very different times, Anne Frank, Barbara', 'Some of the world’s whales that are alive today', 'may be whales out there who are nearly 50', 'didn’t even', 'heartbreakingly demoted in 2006. Because', 'the fall of the Berlin Wall than to today', 'only 12 years before 9', '21', 'If you compressed the entire', '22', 'and medicine, the current human population living on Earth right now is about 6', 'in the past, not the present', 'it takes about 50']\n",
            "{'score': 0.0019885720685124397, 'start': 45, 'end': 84, 'answer': 'happiest day of their life and the best'}\n",
            "{'score': 0.0022088922560214996, 'start': 15, 'end': 35, 'answer': 'sorely regret saying'}\n",
            "{'score': 0.0005553002119995654, 'start': 0, 'end': 54, 'answer': 'Plenty are sexual, with one woman admitting she misses'}\n",
            "{'score': 0.0010704771848395467, 'start': 104, 'end': 130, 'answer': \"his wife is simply 'taking\"}\n",
            "{'score': 0.0028321663849055767, 'start': 22, 'end': 34, 'answer': 'their spouse'}\n",
            "{'score': 0.0016410968964919448, 'start': 88, 'end': 91, 'answer': \"I'm\"}\n",
            "['happiest day of their life and the best', 'sorely regret saying', 'Plenty are sexual, with one woman admitting she misses', \"his wife is simply 'taking\", 'their spouse', \"I'm\"]\n",
            "{'score': 3.578258110792376e-05, 'start': 410, 'end': 468, 'answer': 'some of these items, but you won’t find any deep discounts'}\n",
            "{'score': 0.017627079039812088, 'start': 11, 'end': 26, 'answer': 'School Supplies'}\n",
            "{'score': 2.85853493551258e-05, 'start': 617, 'end': 684, 'answer': 'high profit margins — like binders, graph paper and computer memory'}\n",
            "{'score': 2.7184010832570493e-05, 'start': 784, 'end': 851, 'answer': 'you have to spend so much time waiting to see the attractions. Dave'}\n",
            "{'score': 3.831063077086583e-05, 'start': 582, 'end': 635, 'answer': 'in mind that popular stores like Sears and Home Depot'}\n",
            "{'score': 6.441838922910392e-05, 'start': 291, 'end': 354, 'answer': 'you need to purchase a new TV before the prime season, DealNews'}\n",
            "{'score': 0.00012556288857012987, 'start': 187, 'end': 259, 'answer': 'unveils their upcoming models in September or October, reported DealNews'}\n",
            "{'score': 5.427991345641203e-05, 'start': 594, 'end': 655, 'answer': 'more than a few years old, even if they are deeply discounted'}\n",
            "['some of these items, but you won’t find any deep discounts', 'School Supplies', 'high profit margins — like binders, graph paper and computer memory', 'you have to spend so much time waiting to see the attractions. Dave', 'in mind that popular stores like Sears and Home Depot', 'you need to purchase a new TV before the prime season, DealNews', 'unveils their upcoming models in September or October, reported DealNews', 'more than a few years old, even if they are deeply discounted']\n",
            "{'score': 0.0007973130559548736, 'start': 138, 'end': 161, 'answer': 'for a forever home ever'}\n",
            "{'score': 0.0006562719354405999, 'start': 51, 'end': 104, 'answer': 'undesirable to families looking to adopt. He also has'}\n",
            "{'score': 0.0012366772862151265, 'start': 35, 'end': 75, 'answer': 'for a home for Jingee since may, sending'}\n",
            "{'score': 0.002816290594637394, 'start': 8, 'end': 17, 'answer': 'resident,'}\n",
            "{'score': 0.00014494128117803484, 'start': 380, 'end': 389, 'answer': 'was worth'}\n",
            "{'score': 0.001644242787733674, 'start': 0, 'end': 34, 'answer': 'Hayley went to see Jingee with her'}\n",
            "{'score': 0.0005970445345155895, 'start': 155, 'end': 188, 'answer': 'few more nights she decided to go'}\n",
            "{'score': 0.014401428401470184, 'start': 0, 'end': 14, 'answer': 'She definitely'}\n",
            "{'score': 0.0005853770999237895, 'start': 7, 'end': 46, 'answer': 'was potty trained! Apparently somewhere'}\n",
            "{'score': 0.00045858428347855806, 'start': 150, 'end': 166, 'answer': 'was taught to be'}\n",
            "{'score': 0.006686100270599127, 'start': 19, 'end': 30, 'answer': 'could learn'}\n",
            "['for a forever home ever', 'undesirable to families looking to adopt. He also has', 'for a home for Jingee since may, sending', 'resident,', 'was worth', 'Hayley went to see Jingee with her', 'few more nights she decided to go', 'She definitely', 'was potty trained! Apparently somewhere', 'was taught to be', 'could learn']\n",
            "{'score': 0.020312214270234108, 'start': 0, 'end': 5, 'answer': 'Other'}\n",
            "{'score': 0.0016354048857465386, 'start': 8, 'end': 16, 'answer': 'you love'}\n",
            "{'score': 0.006508024875074625, 'start': 14, 'end': 55, 'answer': 'at a skill that you can share with others'}\n",
            "{'score': 0.004689274821430445, 'start': 49, 'end': 67, 'answer': 'on cooking for $30'}\n",
            "{'score': 0.0016036375891417265, 'start': 33, 'end': 36, 'answer': 'lot'}\n",
            "{'score': 0.0031925796065479517, 'start': 20, 'end': 27, 'answer': 'fucking'}\n",
            "{'score': 0.0067374310456216335, 'start': 8, 'end': 19, 'answer': 'mug for $22'}\n",
            "{'score': 0.003049657680094242, 'start': 63, 'end': 72, 'answer': 'attention'}\n",
            "{'score': 0.0014642238384112716, 'start': 42, 'end': 57, 'answer': 'mask for $24.30'}\n",
            "{'score': 0.0023477610666304827, 'start': 18, 'end': 68, 'answer': 'you love about yourself and show it off like every'}\n",
            "{'score': 0.02148188278079033, 'start': 4, 'end': 20, 'answer': 'the tank for $39'}\n",
            "{'score': 0.0026763135101646185, 'start': 42, 'end': 86, 'answer': 'on coffee table books that actually interest'}\n",
            "{'score': 0.007932247593998909, 'start': 24, 'end': 53, 'answer': 'this illustrated book for $15'}\n",
            "{'score': 0.0019503027433529496, 'start': 77, 'end': 97, 'answer': 'on the right for $17'}\n",
            "{'score': 0.0023565643932670355, 'start': 3, 'end': 45, 'answer': 'Declutter! You automatically look 10 times'}\n",
            "{'score': 0.0037929893005639315, 'start': 44, 'end': 77, 'answer': 'five-pack cable organizer for $30'}\n",
            "{'score': 0.004529639612883329, 'start': 6, 'end': 86, 'answer': 'revamp your creative space with a structurally intriguing desk organizer for $38'}\n",
            "{'score': 0.006055265199393034, 'start': 25, 'end': 43, 'answer': 'not have to please'}\n",
            "{'score': 0.004945504479110241, 'start': 35, 'end': 52, 'answer': 'Not Giving a Fuck'}\n",
            "{'score': 0.0021020022686570883, 'start': 5, 'end': 18, 'answer': 'you’ve nailed'}\n",
            "{'score': 0.008509375154972076, 'start': 0, 'end': 13, 'answer': '8. Don’t hide'}\n",
            "{'score': 0.005032634828239679, 'start': 25, 'end': 54, 'answer': '10 and the second shirt for $'}\n",
            "{'score': 0.0019303340231999755, 'start': 37, 'end': 45, 'answer': 'on every'}\n",
            "{'score': 0.004495740402489901, 'start': 8, 'end': 65, 'answer': 'five-year journal for $15 and the desk organizers for $40'}\n",
            "{'score': 0.007676576264202595, 'start': 0, 'end': 22, 'answer': '10. Buy a few distinct'}\n",
            "{'score': 0.0020439252257347107, 'start': 82, 'end': 116, 'answer': 'has with this galaxy cover for $20'}\n",
            "{'score': 0.004162063356488943, 'start': 0, 'end': 51, 'answer': '11. Smile (only when you want to) with the greatest'}\n",
            "{'score': 0.0044558229856193066, 'start': 44, 'end': 68, 'answer': 'whitening powder for $19'}\n",
            "{'score': 0.006514516193419695, 'start': 0, 'end': 2, 'answer': '12'}\n",
            "{'score': 0.002781294286251068, 'start': 29, 'end': 70, 'answer': 'the second for $15, and the third for $35'}\n",
            "{'score': 0.0019581292290240526, 'start': 0, 'end': 50, 'answer': '13. Experiment with your appearance: If life’s not'}\n",
            "{'score': 0.007941228337585926, 'start': 4, 'end': 27, 'answer': 'some semipermanent hair'}\n",
            "{'score': 0.0032776512671262026, 'start': 22, 'end': 25, 'answer': 'not'}\n",
            "{'score': 0.006573488935828209, 'start': 4, 'end': 21, 'answer': 'the coat for $150'}\n",
            "{'score': 0.0050755450502038, 'start': 0, 'end': 46, 'answer': '15. Instead of fearing your lack of creativity'}\n",
            "{'score': 0.003841496305540204, 'start': 4, 'end': 28, 'answer': 'the first book for $9.60'}\n",
            "{'score': 0.0020769096445292234, 'start': 0, 'end': 6, 'answer': '16. Be'}\n",
            "{'score': 0.0169615987688303, 'start': 4, 'end': 21, 'answer': 'a goals pad for $'}\n",
            "{'score': 0.005508412141352892, 'start': 9, 'end': 18, 'answer': 'of course'}\n",
            "{'score': 0.005321110598742962, 'start': 31, 'end': 52, 'answer': 'the second pair for $'}\n",
            "['Other', 'you love', 'at a skill that you can share with others', 'on cooking for $30', 'lot', 'fucking', 'mug for $22', 'attention', 'mask for $24.30', 'you love about yourself and show it off like every', 'the tank for $39', 'on coffee table books that actually interest', 'this illustrated book for $15', 'on the right for $17', 'Declutter! You automatically look 10 times', 'five-pack cable organizer for $30', 'revamp your creative space with a structurally intriguing desk organizer for $38', 'not have to please', 'Not Giving a Fuck', 'you’ve nailed', '8. Don’t hide', '10 and the second shirt for $', 'on every', 'five-year journal for $15 and the desk organizers for $40', '10. Buy a few distinct', 'has with this galaxy cover for $20', '11. Smile (only when you want to) with the greatest', 'whitening powder for $19', '12', 'the second for $15, and the third for $35', '13. Experiment with your appearance: If life’s not', 'some semipermanent hair', 'not', 'the coat for $150', '15. Instead of fearing your lack of creativity', 'the first book for $9.60', '16. Be', 'a goals pad for $', 'of course', 'the second pair for $']\n",
            "{'score': 0.0004587786679621786, 'start': 118, 'end': 183, 'answer': 'We’ll see the UK triggering Article 50, Trump take over the White'}\n",
            "{'score': 0.0013332158559933305, 'start': 16, 'end': 56, 'answer': 'to be a bigger year for some than others'}\n",
            "{'score': 0.06813710182905197, 'start': 0, 'end': 1, 'answer': '1'}\n",
            "{'score': 0.06671164184808731, 'start': 3, 'end': 6, 'answer': 'Amy'}\n",
            "{'score': 0.07215740531682968, 'start': 0, 'end': 1, 'answer': '3'}\n",
            "{'score': 0.06684114784002304, 'start': 0, 'end': 1, 'answer': '4'}\n",
            "{'score': 0.07747708261013031, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.07412787526845932, 'start': 0, 'end': 9, 'answer': '7. Lauren'}\n",
            "{'score': 0.078004390001297, 'start': 0, 'end': 1, 'answer': '8'}\n",
            "{'score': 0.07185951620340347, 'start': 0, 'end': 1, 'answer': '9'}\n",
            "{'score': 0.08292942494153976, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 0.0740695521235466, 'start': 0, 'end': 2, 'answer': '11'}\n",
            "{'score': 0.048448596149683, 'start': 4, 'end': 10, 'answer': 'Hayley'}\n",
            "{'score': 0.07317879050970078, 'start': 0, 'end': 9, 'answer': '13. Megan'}\n",
            "{'score': 0.07560332119464874, 'start': 0, 'end': 2, 'answer': '14'}\n",
            "{'score': 0.07278618216514587, 'start': 0, 'end': 3, 'answer': '15.'}\n",
            "{'score': 0.08283906430006027, 'start': 4, 'end': 9, 'answer': 'Katie'}\n",
            "{'score': 0.06836283206939697, 'start': 0, 'end': 3, 'answer': '17.'}\n",
            "{'score': 0.07631202042102814, 'start': 0, 'end': 3, 'answer': '18.'}\n",
            "{'score': 0.0668373852968216, 'start': 0, 'end': 3, 'answer': '19.'}\n",
            "{'score': 0.0863303691148758, 'start': 0, 'end': 2, 'answer': '20'}\n",
            "{'score': 0.00130847271066159, 'start': 46, 'end': 52, 'answer': 'the UK'}\n",
            "['We’ll see the UK triggering Article 50, Trump take over the White', 'to be a bigger year for some than others', '1', 'Amy', '3', '4', '5', '7. Lauren', '8', '9', '10', '11', 'Hayley', '13. Megan', '14', '15.', 'Katie', '17.', '18.', '19.', '20', 'the UK']\n",
            "{'score': 0.016734641045331955, 'start': 13, 'end': 21, 'answer': 'you need'}\n",
            "{'score': 0.0003208918496966362, 'start': 258, 'end': 279, 'answer': 'in two years. The S&P'}\n",
            "{'score': 0.0002274638827657327, 'start': 56, 'end': 80, 'answer': 'widely expected to leave'}\n",
            "{'score': 0.00027472403598949313, 'start': 156, 'end': 169, 'answer': '44.61 billion'}\n",
            "{'score': 0.00034186942502856255, 'start': 33, 'end': 115, 'answer': 'sharply lower. Data released by the Japanese government showed the economy grew at'}\n",
            "{'score': 0.001005082274787128, 'start': 57, 'end': 92, 'answer': 'gun\" evidence allegedly shows major'}\n",
            "{'score': 0.0005900778342038393, 'start': 71, 'end': 116, 'answer': \"AMF, France's markets regulator, told the BBC\"}\n",
            "{'score': 0.00016553082969039679, 'start': 155, 'end': 186, 'answer': 'Lululemon expects to earn $0.96'}\n",
            "{'score': 0.0006113135605119169, 'start': 53, 'end': 77, 'answer': \"copycat. China's highest\"}\n",
            "{'score': 0.0019948019180446863, 'start': 75, 'end': 99, 'answer': 'Broadcom and Restoration'}\n",
            "{'score': 0.0008281396003440022, 'start': 95, 'end': 137, 'answer': '10-year yield is up 3 basis points at 2.37'}\n",
            "['you need', 'in two years. The S&P', 'widely expected to leave', '44.61 billion', 'sharply lower. Data released by the Japanese government showed the economy grew at', 'gun\" evidence allegedly shows major', \"AMF, France's markets regulator, told the BBC\", 'Lululemon expects to earn $0.96', \"copycat. China's highest\", 'Broadcom and Restoration', '10-year yield is up 3 basis points at 2.37']\n",
            "{'score': 0.0012631546705961227, 'start': 10, 'end': 22, 'answer': 'Mizrahi a 28'}\n",
            "{'score': 0.0010307853808626533, 'start': 95, 'end': 102, 'answer': 'attempt'}\n",
            "{'score': 0.0004112091555725783, 'start': 98, 'end': 153, 'answer': 'handsome, charismatic and funny which, while admittedly'}\n",
            "{'score': 0.04964140057563782, 'start': 5, 'end': 12, 'answer': 'Insider'}\n",
            "{'score': 0.0008161824662238359, 'start': 130, 'end': 166, 'answer': 'raging bag of dick tips you’d expect'}\n",
            "{'score': 0.0006691619055345654, 'start': 170, 'end': 217, 'answer': 'laughing candid shot, and finally the dog owner'}\n",
            "{'score': 0.0010652325581759214, 'start': 70, 'end': 77, 'answer': 'I quote'}\n",
            "{'score': 0.0006568553508259356, 'start': 72, 'end': 128, 'answer': 'good thing, my sleeves always fall down and I don’t even'}\n",
            "['Mizrahi a 28', 'attempt', 'handsome, charismatic and funny which, while admittedly', 'Insider', 'raging bag of dick tips you’d expect', 'laughing candid shot, and finally the dog owner', 'I quote', 'good thing, my sleeves always fall down and I don’t even']\n",
            "{'score': 0.0012320849345996976, 'start': 78, 'end': 137, 'answer': 'some ideas, as do companies that have been trying to combat'}\n",
            "{'score': 0.03491439297795296, 'start': 8, 'end': 16, 'answer': 'Everyone'}\n",
            "{'score': 0.006051909644156694, 'start': 0, 'end': 14, 'answer': 'When employers'}\n",
            "{'score': 0.0005852828617207706, 'start': 78, 'end': 123, 'answer': 'transparency raises wages, in part by lending'}\n",
            "{'score': 0.0005930537590757012, 'start': 47, 'end': 106, 'answer': 'disclosing pay information is often required. Alexandre Mas'}\n",
            "{'score': 0.001315868692472577, 'start': 22, 'end': 29, 'answer': 'spurred'}\n",
            "{'score': 0.0006410412024706602, 'start': 252, 'end': 256, 'answer': 'most'}\n",
            "{'score': 0.0002911719784606248, 'start': 5, 'end': 19, 'answer': 'Benioff, the C'}\n",
            "{'score': 0.03690852224826813, 'start': 17, 'end': 20, 'answer': 'Not'}\n",
            "{'score': 0.004202794283628464, 'start': 41, 'end': 45, 'answer': 'much'}\n",
            "{'score': 0.0003696814819704741, 'start': 27, 'end': 29, 'answer': '51'}\n",
            "{'score': 0.000630147522315383, 'start': 74, 'end': 113, 'answer': 'do not bargain lose as much as $750,000'}\n",
            "{'score': 0.00022483970678877085, 'start': 320, 'end': 342, 'answer': 'difficult’ or ‘spoiled'}\n",
            "{'score': 0.0007326159975491464, 'start': 127, 'end': 166, 'answer': 'compensation are aware of the disparity'}\n",
            "{'score': 0.0006055532721802592, 'start': 72, 'end': 79, 'answer': 'Pao did'}\n",
            "{'score': 0.0014569633640348911, 'start': 12, 'end': 88, 'answer': 'onus on the company to pay fairly instead of on candidates to negotiate fair'}\n",
            "{'score': 0.019912876188755035, 'start': 0, 'end': 5, 'answer': 'Don’t'}\n",
            "{'score': 0.0011583933373913169, 'start': 87, 'end': 111, 'answer': 'that is already low, one'}\n",
            "{'score': 0.004631311632692814, 'start': 77, 'end': 82, 'answer': 'worth'}\n",
            "{'score': 0.0002656391588971019, 'start': 199, 'end': 247, 'answer': 'Cobert, explained that the practice particularly'}\n",
            "{'score': 0.0007030386477708817, 'start': 92, 'end': 120, 'answer': 'discrimination,\" Ms. Babcock'}\n",
            "{'score': 0.03482891991734505, 'start': 10, 'end': 28, 'answer': 'Easier for Mothers'}\n",
            "{'score': 0.0009971895487979054, 'start': 125, 'end': 164, 'answer': 'few years later when women start having'}\n",
            "{'score': 0.0005869606975466013, 'start': 0, 'end': 42, 'answer': 'Sometimes their pay lags because they take'}\n",
            "{'score': 0.0004137299256399274, 'start': 9, 'end': 23, 'answer': 'that help keep'}\n",
            "{'score': 0.0003391352656763047, 'start': 69, 'end': 100, 'answer': 'reapply for her job, that’s not'}\n",
            "{'score': 0.03490687906742096, 'start': 6, 'end': 30, 'answer': 'More Flexible Workplaces'}\n",
            "{'score': 0.00019782270828727633, 'start': 236, 'end': 288, 'answer': 'many tech jobs and when people can easily substitute'}\n",
            "{'score': 0.0007930209976620972, 'start': 158, 'end': 202, 'answer': 'it easier for different pharmacists to serve'}\n",
            "{'score': 0.0645146444439888, 'start': 7, 'end': 14, 'answer': 'the Law'}\n",
            "{'score': 0.0033622540067881346, 'start': 28, 'end': 32, 'answer': 'most'}\n",
            "{'score': 0.0002792506420519203, 'start': 114, 'end': 157, 'answer': 'must be paid the same for similar jobs, not'}\n",
            "{'score': 0.0007317817071452737, 'start': 131, 'end': 177, 'answer': 'grants for negotiation training and make class'}\n",
            "['some ideas, as do companies that have been trying to combat', 'Everyone', 'When employers', 'transparency raises wages, in part by lending', 'disclosing pay information is often required. Alexandre Mas', 'spurred', 'most', 'Benioff, the C', 'Not', 'much', '51', 'do not bargain lose as much as $750,000', 'difficult’ or ‘spoiled', 'compensation are aware of the disparity', 'Pao did', 'onus on the company to pay fairly instead of on candidates to negotiate fair', 'Don’t', 'that is already low, one', 'worth', 'Cobert, explained that the practice particularly', 'discrimination,\" Ms. Babcock', 'Easier for Mothers', 'few years later when women start having', 'Sometimes their pay lags because they take', 'that help keep', 'reapply for her job, that’s not', 'More Flexible Workplaces', 'many tech jobs and when people can easily substitute', 'it easier for different pharmacists to serve', 'the Law', 'most', 'must be paid the same for similar jobs, not', 'grants for negotiation training and make class']\n",
            "{'score': 0.0013270620256662369, 'start': 69, 'end': 89, 'answer': 'he loads and unloads'}\n",
            "{'score': 0.0072122071869671345, 'start': 2, 'end': 39, 'answer': ', and he had to walk to work and back'}\n",
            "{'score': 0.0015638271579518914, 'start': 11, 'end': 51, 'answer': '-has been working since he was 14 to pay'}\n",
            "{'score': 0.004643107298761606, 'start': 15, 'end': 22, 'answer': 'was too'}\n",
            "{'score': 0.006114919204264879, 'start': 7, 'end': 49, 'answer': \"had a driving license, but couldn't afford\"}\n",
            "{'score': 0.003878516610711813, 'start': 22, 'end': 66, 'answer': '-workers clubbed together and bought one for'}\n",
            "{'score': 0.002478023525327444, 'start': 6, 'end': 93, 'answer': 'was presented the car, his colleague said he wanted Taylor to know everyone appreciated'}\n",
            "{'score': 0.03208165615797043, 'start': 12, 'end': 21, 'answer': 'the Mail:'}\n",
            "{'score': 0.026907509192824364, 'start': 6, 'end': 17, 'answer': 'overwhelmed'}\n",
            "{'score': 0.001985166920349002, 'start': 69, 'end': 83, 'answer': \"I'm not really\"}\n",
            "['he loads and unloads', ', and he had to walk to work and back', '-has been working since he was 14 to pay', 'was too', \"had a driving license, but couldn't afford\", '-workers clubbed together and bought one for', 'was presented the car, his colleague said he wanted Taylor to know everyone appreciated', 'the Mail:', 'overwhelmed', \"I'm not really\"]\n",
            "{'score': 0.0002953356015495956, 'start': 248, 'end': 257, 'answer': 'most lack'}\n",
            "{'score': 0.00023177698312792927, 'start': 13, 'end': 61, 'answer': \"insanely talented salespeople, and they'll still\"}\n",
            "{'score': 0.07059606909751892, 'start': 15, 'end': 26, 'answer': 'Intelligent'}\n",
            "{'score': 0.00015275065379682928, 'start': 478, 'end': 494, 'answer': 'must be prepared'}\n",
            "{'score': 0.0006885858019813895, 'start': 20, 'end': 41, 'answer': 'intelligence comes in'}\n",
            "{'score': 0.0003306673897895962, 'start': 127, 'end': 136, 'answer': 'multitude'}\n",
            "{'score': 0.0001806700456654653, 'start': 87, 'end': 97, 'answer': 'contextual'}\n",
            "{'score': 0.00024896516697481275, 'start': 28, 'end': 89, 'answer': 'intelligence is relatively new. Sales managers and executives'}\n",
            "{'score': 0.032855115830898285, 'start': 13, 'end': 26, 'answer': 'productivity.'}\n",
            "{'score': 0.00014889719022903591, 'start': 84, 'end': 146, 'answer': 'most likely hired your reps on the basis of their sales acumen'}\n",
            "{'score': 0.02491014078259468, 'start': 12, 'end': 25, 'answer': 'potential ROI'}\n",
            "{'score': 0.0003092570404987782, 'start': 302, 'end': 323, 'answer': 'intelligence is worth'}\n",
            "{'score': 0.023193158209323883, 'start': 15, 'end': 18, 'answer': 'key'}\n",
            "{'score': 0.00019606997375376523, 'start': 199, 'end': 212, 'answer': 'confused than'}\n",
            "{'score': 0.0014462900580838323, 'start': 6, 'end': 30, 'answer': 'intelligence is critical'}\n",
            "['most lack', \"insanely talented salespeople, and they'll still\", 'Intelligent', 'must be prepared', 'intelligence comes in', 'multitude', 'contextual', 'intelligence is relatively new. Sales managers and executives', 'productivity.', 'most likely hired your reps on the basis of their sales acumen', 'potential ROI', 'intelligence is worth', 'key', 'confused than', 'intelligence is critical']\n",
            "{'score': 0.002283071167767048, 'start': 33, 'end': 40, 'answer': 'did not'}\n",
            "{'score': 0.00039798469515517354, 'start': 16, 'end': 32, 'answer': 'of America’s top'}\n",
            "{'score': 0.0003950083046220243, 'start': 21, 'end': 24, 'answer': 'IUD'}\n",
            "{'score': 0.0008338019833900034, 'start': 53, 'end': 78, 'answer': 'tough little lady! A post'}\n",
            "{'score': 0.0004427221429068595, 'start': 1, 'end': 65, 'answer': 'Tough little lady\" Abigail Ann Brown was born March 4, and Brown'}\n",
            "{'score': 0.0005629536462947726, 'start': 131, 'end': 178, 'answer': 'in her parents’ basement apartment in Warrenton'}\n",
            "{'score': 0.0001748581271385774, 'start': 284, 'end': 376, 'answer': 'quest to continue training for the Olympic Trials will never compare to the continuous quest'}\n",
            "{'score': 0.00016615769709460437, 'start': 201, 'end': 252, 'answer': 'hashtag #Mommyintraining — \"double meaning intended'}\n",
            "{'score': 0.0006054341210983694, 'start': 47, 'end': 63, 'answer': 'newmom #babygirl'}\n",
            "['did not', 'of America’s top', 'IUD', 'tough little lady! A post', 'Tough little lady\" Abigail Ann Brown was born March 4, and Brown', 'in her parents’ basement apartment in Warrenton', 'quest to continue training for the Olympic Trials will never compare to the continuous quest', 'hashtag #Mommyintraining — \"double meaning intended', 'newmom #babygirl']\n",
            "{'score': 0.000366981461411342, 'start': 166, 'end': 177, 'answer': 'Hogwarts. J'}\n",
            "{'score': 0.0025624162517488003, 'start': 37, 'end': 68, 'answer': 'interrogated and imprisoned for'}\n",
            "{'score': 0.0009815332014113665, 'start': 100, 'end': 112, 'answer': 'in the Kings'}\n",
            "{'score': 0.0009710408630780876, 'start': 117, 'end': 141, 'answer': 'hoof. It has not been re'}\n",
            "{'score': 0.002051993040367961, 'start': 0, 'end': 4, 'answer': '4/33'}\n",
            "{'score': 0.0020178635604679585, 'start': 13, 'end': 17, 'answer': 'Krum'}\n",
            "{'score': 0.0017015180783346295, 'start': 10, 'end': 65, 'answer': 'Death Eaters Dark Marks eventually faded to look like a'}\n",
            "{'score': 0.0018216850003227592, 'start': 10, 'end': 93, 'answer': 'Quibbler is back to publishing articles about the lunatic fringe and is appreciated'}\n",
            "{'score': 0.0005231410614214838, 'start': 170, 'end': 207, 'answer': 'did come to understand and appreciate'}\n",
            "{'score': 0.001086950534954667, 'start': 67, 'end': 133, 'answer': '. He never married, although he had a relationship with a giantess'}\n",
            "{'score': 0.0012994532007724047, 'start': 0, 'end': 5, 'answer': '10/33'}\n",
            "{'score': 0.00016058670007623732, 'start': 42, 'end': 97, 'answer': 'Hogwarts, the school for witchcraft and wizardry is led'}\n",
            "{'score': 0.003443556372076273, 'start': 7, 'end': 87, 'answer': 'Kingsley Shacklebolt became the Minister of Magic after the Second Wizarding War'}\n",
            "{'score': 0.006049445830285549, 'start': 28, 'end': 33, 'answer': 'to be'}\n",
            "{'score': 0.0030154800042510033, 'start': 26, 'end': 69, 'answer': 'be concentrated elsewhere and hes not going'}\n",
            "{'score': 0.0033387744333595037, 'start': 27, 'end': 34, 'answer': 'the war'}\n",
            "{'score': 0.0007339257863350213, 'start': 72, 'end': 135, 'answer': 'Hogwarts to complete their seventh year. Harry, Ron and Neville'}\n",
            "{'score': 0.0010537476046010852, 'start': 39, 'end': 63, 'answer': 'number of years, Neville'}\n",
            "{'score': 0.0010424955980852246, 'start': 102, 'end': 135, 'answer': 'Hogwarts since an academic career'}\n",
            "{'score': 0.0021656991448253393, 'start': 33, 'end': 94, 'answer': 'Weasleys Wizard Wheezes prior to officially becoming an auror'}\n",
            "{'score': 0.0005275688599795103, 'start': 21, 'end': 87, 'answer': 'was over, Hermiones first act was to find her parents in Australia'}\n",
            "{'score': 0.0009118274901993573, 'start': 30, 'end': 94, 'answer': 'Dementors as guardians. The number of Dementors has been greatly'}\n",
            "{'score': 0.00031153656891547143, 'start': 7, 'end': 48, 'answer': 'Hermione tells Scrimgeour that she is not'}\n",
            "{'score': 0.0007031606510281563, 'start': 85, 'end': 93, 'answer': 'Hermione'}\n",
            "{'score': 0.0008874537888914347, 'start': 52, 'end': 90, 'answer': 'they are like badges of honor. Neville'}\n",
            "['Hogwarts. J', 'interrogated and imprisoned for', 'in the Kings', 'hoof. It has not been re', '4/33', 'Krum', 'Death Eaters Dark Marks eventually faded to look like a', 'Quibbler is back to publishing articles about the lunatic fringe and is appreciated', 'did come to understand and appreciate', '. He never married, although he had a relationship with a giantess', '10/33', 'Hogwarts, the school for witchcraft and wizardry is led', 'Kingsley Shacklebolt became the Minister of Magic after the Second Wizarding War', 'to be', 'be concentrated elsewhere and hes not going', 'the war', 'Hogwarts to complete their seventh year. Harry, Ron and Neville', 'number of years, Neville', 'Hogwarts since an academic career', 'Weasleys Wizard Wheezes prior to officially becoming an auror', 'was over, Hermiones first act was to find her parents in Australia', 'Dementors as guardians. The number of Dementors has been greatly', 'Hermione tells Scrimgeour that she is not', 'Hermione', 'they are like badges of honor. Neville']\n",
            "{'score': 0.11667169630527496, 'start': 0, 'end': 3, 'answer': 'GIF'}\n",
            "{'score': 7.739057764410973e-05, 'start': 494, 'end': 536, 'answer': 'most common stress scenarios , but Gizmodo'}\n",
            "{'score': 0.0021114773117005825, 'start': 21, 'end': 77, 'answer': 'most shocking revelations, uncovered after an exhaustive'}\n",
            "{'score': 0.09914925694465637, 'start': 0, 'end': 9, 'answer': 'Hydraulic'}\n",
            "{'score': 0.11667169630527496, 'start': 0, 'end': 3, 'answer': 'GIF'}\n",
            "{'score': 0.004675596486777067, 'start': 0, 'end': 30, 'answer': 'By removing the headphone jack'}\n",
            "{'score': 0.0003697000502143055, 'start': 257, 'end': 274, 'answer': 'we certainly hope'}\n",
            "{'score': 0.06432372331619263, 'start': 9, 'end': 16, 'answer': 'Hammers'}\n",
            "{'score': 0.11667169630527496, 'start': 0, 'end': 3, 'answer': 'GIF'}\n",
            "{'score': 0.0011343543883413076, 'start': 0, 'end': 38, 'answer': 'Sure, the average iPhone user probably'}\n",
            "{'score': 0.0002650574315339327, 'start': 276, 'end': 304, 'answer': 'plenty of reasons to \"beware'}\n",
            "{'score': 0.19150254130363464, 'start': 0, 'end': 9, 'answer': 'Sponsored'}\n",
            "{'score': 0.0642017349600792, 'start': 6, 'end': 14, 'answer': 'Grinders'}\n",
            "{'score': 0.11667169630527496, 'start': 0, 'end': 3, 'answer': 'GIF'}\n",
            "{'score': 0.00030482513830065727, 'start': 208, 'end': 249, 'answer': 'high shine \"may show fine micro-abrasions'}\n",
            "{'score': 0.00014028631267137825, 'start': 208, 'end': 249, 'answer': 'high shine \"may show fine micro-abrasions'}\n",
            "{'score': 0.04190920665860176, 'start': 8, 'end': 11, 'answer': 'Men'}\n",
            "{'score': 0.11667169630527496, 'start': 0, 'end': 3, 'answer': 'GIF'}\n",
            "{'score': 0.015606990084052086, 'start': 0, 'end': 15, 'answer': 'Is the iPhone 7'}\n",
            "{'score': 0.0005626760539598763, 'start': 148, 'end': 196, 'answer': 'half with a little help from his furniture? Nyet'}\n",
            "{'score': 0.2049415558576584, 'start': 0, 'end': 4, 'answer': 'Axes'}\n",
            "{'score': 0.11667169630527496, 'start': 0, 'end': 3, 'answer': 'GIF'}\n",
            "{'score': 0.2149943709373474, 'start': 0, 'end': 4, 'answer': 'Fire'}\n",
            "{'score': 0.11667169630527496, 'start': 0, 'end': 3, 'answer': 'GIF'}\n",
            "{'score': 0.0014358139596879482, 'start': 49, 'end': 63, 'answer': 'headphone jack'}\n",
            "['GIF', 'most common stress scenarios , but Gizmodo', 'most shocking revelations, uncovered after an exhaustive', 'Hydraulic', 'GIF', 'By removing the headphone jack', 'we certainly hope', 'Hammers', 'GIF', 'Sure, the average iPhone user probably', 'plenty of reasons to \"beware', 'Sponsored', 'Grinders', 'GIF', 'high shine \"may show fine micro-abrasions', 'high shine \"may show fine micro-abrasions', 'Men', 'GIF', 'Is the iPhone 7', 'half with a little help from his furniture? Nyet', 'Axes', 'GIF', 'Fire', 'GIF', 'headphone jack']\n",
            "{'score': 0.0014552840730175376, 'start': 126, 'end': 138, 'answer': 'deceive you.'}\n",
            "{'score': 0.001535141607746482, 'start': 89, 'end': 106, 'answer': 'concerned someone'}\n",
            "{'score': 0.001207293476909399, 'start': 21, 'end': 33, 'answer': \"there is 'no\"}\n",
            "{'score': 0.001846296596340835, 'start': 8, 'end': 24, 'answer': 'all those claims'}\n",
            "{'score': 0.0023701556492596865, 'start': 58, 'end': 91, 'answer': \"of agitation like fidgeting,' she\"}\n",
            "{'score': 0.004096530843526125, 'start': 17, 'end': 40, 'answer': 'liar can easily deliver'}\n",
            "{'score': 0.0007703221635892987, 'start': 137, 'end': 140, 'answer': 'not'}\n",
            "{'score': 0.000768741185311228, 'start': 158, 'end': 195, 'answer': 'inventing the lie and the performance'}\n",
            "{'score': 0.0010889566037803888, 'start': 108, 'end': 164, 'answer': 'do you ask that?’ rather than a direct and open response'}\n",
            "{'score': 0.0015870259376242757, 'start': 99, 'end': 129, 'answer': 'we’re trying to hide something'}\n",
            "{'score': 0.00040122264181263745, 'start': 43, 'end': 74, 'answer': 'often accessing recalled memory'}\n",
            "{'score': 0.002272406592965126, 'start': 69, 'end': 76, 'answer': 'in most'}\n",
            "{'score': 0.0008667682996019721, 'start': 138, 'end': 150, 'answer': 'can often be'}\n",
            "{'score': 0.00038573096389882267, 'start': 68, 'end': 99, 'answer': 'gesticulating too much in a bid'}\n",
            "{'score': 0.0008047649171203375, 'start': 70, 'end': 105, 'answer': 'many assume less is more and almost'}\n",
            "{'score': 0.0007153022452257574, 'start': 45, 'end': 112, 'answer': 'often suffer a strong desire to hide their face from their audience'}\n",
            "{'score': 0.00045493218931369483, 'start': 86, 'end': 95, 'answer': 'are aimed'}\n",
            "{'score': 0.0004771631211042404, 'start': 150, 'end': 159, 'answer': 'often use'}\n",
            "{'score': 0.0007914943853393197, 'start': 144, 'end': 148, 'answer': 'skew'}\n",
            "{'score': 0.0014635255793109536, 'start': 77, 'end': 105, 'answer': 'liars often struggle to keep'}\n",
            "{'score': 0.0010586899006739259, 'start': 91, 'end': 96, 'answer': 'often'}\n",
            "{'score': 0.0011758782202377915, 'start': 88, 'end': 107, 'answer': 'Whodunnit? and says'}\n",
            "{'score': 0.0014096752274781466, 'start': 23, 'end': 57, 'answer': 'condone lying, this is the perfect'}\n",
            "{'score': 0.0007761167362332344, 'start': 144, 'end': 158, 'answer': 'the transcript'}\n",
            "{'score': 0.002101148245856166, 'start': 0, 'end': 39, 'answer': 'Visualisation is the nearest you’ll get'}\n",
            "{'score': 0.0007060836651362479, 'start': 131, 'end': 162, 'answer': 'shoulders, arms and hands. Keep'}\n",
            "{'score': 0.001084617804735899, 'start': 145, 'end': 161, 'answer': 'in your audience'}\n",
            "{'score': 0.00035017740447074175, 'start': 14, 'end': 24, 'answer': 'you’re not'}\n",
            "{'score': 0.0023333318531513214, 'start': 30, 'end': 98, 'answer': 'be better than over-sharing in terms of your body language giveaways'}\n",
            "{'score': 0.00021667916735168546, 'start': 85, 'end': 101, 'answer': 'I the best lover'}\n",
            "{'score': 0.0003396204556338489, 'start': 256, 'end': 303, 'answer': 'For more information visit www.whodunnit.org.uk'}\n",
            "['deceive you.', 'concerned someone', \"there is 'no\", 'all those claims', \"of agitation like fidgeting,' she\", 'liar can easily deliver', 'not', 'inventing the lie and the performance', 'do you ask that?’ rather than a direct and open response', 'we’re trying to hide something', 'often accessing recalled memory', 'in most', 'can often be', 'gesticulating too much in a bid', 'many assume less is more and almost', 'often suffer a strong desire to hide their face from their audience', 'are aimed', 'often use', 'skew', 'liars often struggle to keep', 'often', 'Whodunnit? and says', 'condone lying, this is the perfect', 'the transcript', 'Visualisation is the nearest you’ll get', 'shoulders, arms and hands. Keep', 'in your audience', 'you’re not', 'be better than over-sharing in terms of your body language giveaways', 'I the best lover', 'For more information visit www.whodunnit.org.uk']\n",
            "{'score': 0.0016025286167860031, 'start': 52, 'end': 58, 'answer': 'in his'}\n",
            "{'score': 0.000694231828674674, 'start': 160, 'end': 183, 'answer': 'would never support him'}\n",
            "{'score': 0.012610339559614658, 'start': 0, 'end': 12, 'answer': '35) Roseanne'}\n",
            "{'score': 0.00021645652304869145, 'start': 188, 'end': 226, 'answer': '’s up with that?\" Roseanne is just one'}\n",
            "{'score': 0.009044063277542591, 'start': 6, 'end': 12, 'answer': '\"Start'}\n",
            "{'score': 0.019100435078144073, 'start': 0, 'end': 2, 'answer': '34'}\n",
            "{'score': 9.088083606911823e-05, 'start': 336, 'end': 344, 'answer': 'was self'}\n",
            "{'score': 0.001576620270498097, 'start': 87, 'end': 98, 'answer': 'endorse him'}\n",
            "{'score': 0.016198517754673958, 'start': 0, 'end': 2, 'answer': '33'}\n",
            "{'score': 0.0002495960798114538, 'start': 141, 'end': 206, 'answer': 'realness of an all American, outdoor-sy family with an importance'}\n",
            "{'score': 0.0005771940923295915, 'start': 110, 'end': 128, 'answer': 'We both have wives'}\n",
            "{'score': 0.006540381815284491, 'start': 0, 'end': 9, 'answer': '32) Wayne'}\n",
            "{'score': 9.996475273510441e-05, 'start': 338, 'end': 383, 'answer': 'Well no one, anywhere, ever accused me of not'}\n",
            "{'score': 0.005692271515727043, 'start': 0, 'end': 65, 'answer': '31) Chris Christie – Former Opponent to Trump for this Republican'}\n",
            "{'score': 0.0005878261872567236, 'start': 192, 'end': 202, 'answer': 'in an epic'}\n",
            "{'score': 0.007564631290733814, 'start': 11, 'end': 19, 'answer': 'Kiyosaki'}\n",
            "{'score': 0.0002327823603991419, 'start': 325, 'end': 339, 'answer': 'endorse Donald'}\n",
            "{'score': 0.010691273026168346, 'start': 0, 'end': 2, 'answer': '29'}\n",
            "{'score': 0.0008853200124576688, 'start': 103, 'end': 132, 'answer': 'several times saying, \"Donald'}\n",
            "{'score': 0.0003515741555020213, 'start': 209, 'end': 232, 'answer': 'correctness is a public'}\n",
            "{'score': 0.010600718669593334, 'start': 22, 'end': 43, 'answer': 'Heisman Trophy Winner'}\n",
            "{'score': 0.0004289905773475766, 'start': 38, 'end': 77, 'answer': 'we going to get back to what’s best for'}\n",
            "{'score': 0.0034273937344551086, 'start': 22, 'end': 32, 'answer': 'Stallworth'}\n",
            "{'score': 0.0004232522624079138, 'start': 35, 'end': 81, 'answer': 'Stallworth went in to bat for Trump at a black'}\n",
            "{'score': 0.010481981560587883, 'start': 8, 'end': 64, 'answer': 'Coulter – Conservative author and television personality'}\n",
            "{'score': 0.00028263256535865366, 'start': 0, 'end': 23, 'answer': 'Coulter has been a huge'}\n",
            "{'score': 0.0036319629289209843, 'start': 8, 'end': 25, 'answer': 'Ferrigno – Former'}\n",
            "{'score': 0.000565922528039664, 'start': 158, 'end': 181, 'answer': 'our country and keeping'}\n",
            "{'score': 0.00573051068931818, 'start': 0, 'end': 8, 'answer': '24) Mike'}\n",
            "{'score': 0.0002703364589251578, 'start': 166, 'end': 173, 'answer': 's gotta'}\n",
            "{'score': 0.008898429572582245, 'start': 28, 'end': 38, 'answer': 'and former'}\n",
            "{'score': 0.0002981369907502085, 'start': 86, 'end': 144, 'answer': 'he’d make a great president. Because he’s not a politician'}\n",
            "{'score': 0.008480653166770935, 'start': 0, 'end': 38, 'answer': '22) Fran Drescher – Actress and cancer'}\n",
            "{'score': 0.00020026064885314554, 'start': 250, 'end': 308, 'answer': 'lot of things that other people don’t really have the guts'}\n",
            "{'score': 0.006208143662661314, 'start': 45, 'end': 69, 'answer': 'and celebrity apprentice'}\n",
            "{'score': 0.0006748405867256224, 'start': 30, 'end': 72, 'answer': 'the country needs and Trump ... he’s a guy'}\n",
            "{'score': 0.006664837244898081, 'start': 0, 'end': 2, 'answer': '20'}\n",
            "{'score': 0.0017229760996997356, 'start': 67, 'end': 113, 'answer': 'endorsing Trump concluding \"I am a huge Donald'}\n",
            "{'score': 0.01529920194298029, 'start': 4, 'end': 11, 'answer': 'Kirstie'}\n",
            "{'score': 0.0006634177989326417, 'start': 77, 'end': 92, 'answer': 'in an interview'}\n",
            "{'score': 0.018830200657248497, 'start': 4, 'end': 18, 'answer': 'California Rep'}\n",
            "{'score': 0.0004849738616030663, 'start': 43, 'end': 64, 'answer': 'endorse Trump, who he'}\n",
            "{'score': 0.01171344518661499, 'start': 18, 'end': 24, 'answer': 'Former'}\n",
            "{'score': 0.00015097887080628425, 'start': 147, 'end': 153, 'answer': 'suited'}\n",
            "{'score': 0.005191013682633638, 'start': 16, 'end': 21, 'answer': 'Super'}\n",
            "{'score': 0.000750638369936496, 'start': 79, 'end': 84, 'answer': 'Super'}\n",
            "{'score': 0.0003753839700948447, 'start': 246, 'end': 291, 'answer': 'laughingly replied, \"This is really important'}\n",
            "{'score': 0.006906871683895588, 'start': 9, 'end': 40, 'answer': 'Hogan – Former WWE professional'}\n",
            "{'score': 0.0005610344815067947, 'start': 174, 'end': 192, 'answer': 'I want to be Trump'}\n",
            "{'score': 0.006357296835631132, 'start': 0, 'end': 8, 'answer': '14) Gene'}\n",
            "{'score': 0.00011892166367033496, 'start': 325, 'end': 348, 'answer': 'ungentlemanly\" at times'}\n",
            "{'score': 0.01652919501066208, 'start': 9, 'end': 14, 'answer': 'Busey'}\n",
            "{'score': 0.00039262117934413254, 'start': 140, 'end': 183, 'answer': 'I know him professionally. He’s a great guy'}\n",
            "{'score': 0.01148905884474516, 'start': 0, 'end': 15, 'answer': '12) Robert Davi'}\n",
            "{'score': 0.0007559488876722753, 'start': 0, 'end': 49, 'answer': 'In an article published on Breitbart and authored'}\n",
            "{'score': 0.00034654271439649165, 'start': 166, 'end': 217, 'answer': 'deceiver who feeds us sugarcoated poison at bedtime'}\n",
            "{'score': 0.006208314094692469, 'start': 30, 'end': 36, 'answer': 'former'}\n",
            "{'score': 0.0006372218485921621, 'start': 68, 'end': 110, 'answer': 'great friend for many years. We don’t need'}\n",
            "{'score': 0.007757286075502634, 'start': 0, 'end': 38, 'answer': '10) Dana White – President of Ultimate'}\n",
            "{'score': 0.0003291247121524066, 'start': 243, 'end': 279, 'answer': 'me say a negative thing about Donald'}\n",
            "{'score': 0.009117711335420609, 'start': 7, 'end': 16, 'answer': 'Bilzerian'}\n",
            "{'score': 0.0009479805594310164, 'start': 85, 'end': 134, 'answer': 'the people who remain unfiltered @realDonaldTrump'}\n",
            "{'score': 0.012484398670494556, 'start': 8, 'end': 40, 'answer': 'Icahn – Billionaire entrepreneur'}\n",
            "{'score': 0.00024070886138360947, 'start': 213, 'end': 239, 'answer': 'no-brainer. You can’t keep'}\n",
            "{'score': 0.0054642134346067905, 'start': 19, 'end': 25, 'answer': 'Former'}\n",
            "{'score': 0.0007942566880956292, 'start': 35, 'end': 59, 'answer': 'I shocked my staff today'}\n",
            "{'score': 0.014393880032002926, 'start': 0, 'end': 7, 'answer': '6) Mike'}\n",
            "{'score': 0.0003599509072955698, 'start': 25, 'end': 34, 'answer': 'Hufington'}\n",
            "{'score': 0.010359778068959713, 'start': 26, 'end': 37, 'answer': 'and Western'}\n",
            "{'score': 0.0004311845696065575, 'start': 149, 'end': 191, 'answer': 'I just think he’s the only one who’s going'}\n",
            "{'score': 0.0036733155138790607, 'start': 24, 'end': 81, 'answer': 'Sheriff on the front lines of the illegal immigration war'}\n",
            "{'score': 0.0013010752154514194, 'start': 62, 'end': 116, 'answer': 'He produces results and is ready to get tough in order'}\n",
            "{'score': 0.00695766881108284, 'start': 1, 'end': 8, 'answer': ') Wayne'}\n",
            "{'score': 0.0007765188929624856, 'start': 82, 'end': 135, 'answer': 'would make a great president,\" Newton told host Steve'}\n",
            "{'score': 0.0002604301262181252, 'start': 187, 'end': 245, 'answer': 'he stays in, he doesn’t have to worry about how his family'}\n",
            "{'score': 0.0047055636532604694, 'start': 26, 'end': 34, 'answer': 'Treasure'}\n",
            "{'score': 0.00034428140497766435, 'start': 67, 'end': 100, 'answer': 'dysfunctional. Now, Donald is not'}\n",
            "{'score': 0.004746200516819954, 'start': 2, 'end': 16, 'answer': '+ Bonus) Sarah'}\n",
            "{'score': 0.0004850729601457715, 'start': 104, 'end': 157, 'answer': 'several minutes saying \"I’m proud to endorse Donald J'}\n",
            "{'score': 0.0010615005157887936, 'start': 106, 'end': 129, 'answer': 'endorsements for Donald'}\n",
            "{'score': 0.0035421247594058514, 'start': 0, 'end': 27, 'answer': 'Benghazi Survivors Mark \"Oz'}\n",
            "{'score': 0.00017542608838994056, 'start': 35, 'end': 92, 'answer': 'more than any Americans, know the absolute and imperative'}\n",
            "{'score': 0.0007664490840397775, 'start': 123, 'end': 181, 'answer': 'be avoided because our enemies will fear the United States'}\n",
            "{'score': 0.023002805188298225, 'start': 4, 'end': 22, 'answer': 'Voight – Hollywood'}\n",
            "{'score': 0.0002403623511781916, 'start': 0, 'end': 68, 'answer': 'In an interview with Breitbart the actor known from roles in Mission'}\n",
            "{'score': 0.016863858327269554, 'start': 0, 'end': 3, 'answer': 'Kid'}\n",
            "{'score': 0.0004041402426082641, 'start': 188, 'end': 201, 'answer': 'we should let'}\n",
            "{'score': 0.04238598793745041, 'start': 6, 'end': 14, 'answer': 'Carter –'}\n",
            "{'score': 0.0009929706575348973, 'start': 4, 'end': 46, 'answer': 'wildly popular singer responded to a Trump'}\n",
            "{'score': 0.03059733659029007, 'start': 15, 'end': 25, 'answer': 'Radio Host'}\n",
            "{'score': 0.0018199050100520253, 'start': 11, 'end': 25, 'answer': 'extraordinaire'}\n",
            "{'score': 0.014732002280652523, 'start': 7, 'end': 14, 'answer': 'Giudice'}\n",
            "{'score': 0.0006712989415973425, 'start': 107, 'end': 117, 'answer': 'I am going'}\n",
            "{'score': 0.008254943415522575, 'start': 31, 'end': 36, 'answer': '-wife'}\n",
            "{'score': 0.0004937108024023473, 'start': 220, 'end': 237, 'answer': 'to promote Donald'}\n",
            "{'score': 0.023923492059111595, 'start': 0, 'end': 5, 'answer': 'Kenny'}\n",
            "{'score': 0.0004763400065712631, 'start': 53, 'end': 101, 'answer': 'I have to admit. He can be president and not owe'}\n",
            "{'score': 0.018226904794573784, 'start': 25, 'end': 39, 'answer': 'Martial Artist'}\n",
            "{'score': 0.0003357737441547215, 'start': 90, 'end': 132, 'answer': 'Endorsing Trump. The actor blasted Hillary'}\n",
            "{'score': 0.03395702689886093, 'start': 25, 'end': 32, 'answer': 'Royalty'}\n",
            "{'score': 0.0006740661920048296, 'start': 162, 'end': 173, 'answer': 'have a case'}\n",
            "{'score': 0.019525282084941864, 'start': 0, 'end': 38, 'answer': 'Sylvestor Stallone – Hollywood Royalty'}\n",
            "{'score': 0.00022181407257448882, 'start': 136, 'end': 146, 'answer': 'Dickensian'}\n",
            "{'score': 0.02028985135257244, 'start': 27, 'end': 31, 'answer': 'Home'}\n",
            "{'score': 0.0010707435430958867, 'start': 29, 'end': 48, 'answer': 'we started The Home'}\n",
            "{'score': 0.0012443813029676676, 'start': 42, 'end': 87, 'answer': 'who can \"make America great again\" by cutting'}\n",
            "{'score': 0.011603634804487228, 'start': 19, 'end': 24, 'answer': 'Wayne'}\n",
            "{'score': 0.004517956171184778, 'start': 42, 'end': 45, 'answer': 'her'}\n",
            "{'score': 0.0004450739361345768, 'start': 59, 'end': 107, 'answer': 'We need someone, like Mr. Trump, with leadership'}\n",
            "{'score': 0.024163996800780296, 'start': 15, 'end': 36, 'answer': 'NCAA Basketball Coach'}\n",
            "{'score': 0.00025997389457188547, 'start': 230, 'end': 308, 'answer': 'Indiana during the primaries saying Trump is \"the most prepared man in history'}\n",
            "{'score': 0.03185387700796127, 'start': 0, 'end': 32, 'answer': 'The National Border Patrol Union'}\n",
            "{'score': 0.0009124858770519495, 'start': 181, 'end': 196, 'answer': 'endorsing Trump'}\n",
            "{'score': 0.000389460357837379, 'start': 0, 'end': 49, 'answer': 'In it they wrote, \"Mr. Trump will take on special'}\n",
            "{'score': 0.025941312313079834, 'start': 0, 'end': 4, 'answer': 'Scot'}\n",
            "{'score': 0.0004328091745264828, 'start': 226, 'end': 232, 'answer': 'common'}\n",
            "{'score': 0.010001049377024174, 'start': 6, 'end': 13, 'answer': 'Jeneane'}\n",
            "{'score': 0.0006407045875675976, 'start': 145, 'end': 159, 'answer': 'endorse Donald'}\n",
            "{'score': 0.01197561714798212, 'start': 15, 'end': 23, 'answer': 'Rifleman'}\n",
            "{'score': 0.00028556695906445384, 'start': 217, 'end': 293, 'answer': 'was seen as a testament to both Trumps 2nd amendment credentials and Hillary'}\n",
            "{'score': 0.0011194598628208041, 'start': 108, 'end': 121, 'answer': 'much more pro'}\n",
            "{'score': 0.00045201447210274637, 'start': 79, 'end': 131, 'answer': 'well that he was breaking ranks with the Bush family'}\n",
            "{'score': 0.010599445551633835, 'start': 0, 'end': 18, 'answer': 'David A. Clarke Jr'}\n",
            "{'score': 0.001602726406417787, 'start': 37, 'end': 46, 'answer': 'the black'}\n",
            "{'score': 0.025761738419532776, 'start': 6, 'end': 21, 'answer': 'Theil – Venture'}\n",
            "{'score': 0.0004413991700857878, 'start': 4, 'end': 45, 'answer': 'staunch libertarian and founder of Paypal'}\n",
            "{'score': 0.013354182243347168, 'start': 5, 'end': 33, 'answer': 'Hannity – Radio host and Fox'}\n",
            "{'score': 0.0008335291058756411, 'start': 118, 'end': 143, 'answer': 'I’ll be voting for Donald'}\n",
            "{'score': 0.019615720957517624, 'start': 5, 'end': 17, 'answer': 'Yiannopoulos'}\n",
            "{'score': 0.003916233777999878, 'start': 14, 'end': 22, 'answer': 'may have'}\n",
            "{'score': 0.0007031974964775145, 'start': 115, 'end': 164, 'answer': 'flamboyantly calling him \"Daddy.\" Milo also loves'}\n",
            "{'score': 0.026414358988404274, 'start': 7, 'end': 15, 'answer': 'Molyneux'}\n",
            "{'score': 0.00035829225089401007, 'start': 259, 'end': 278, 'answer': 'We will never solve'}\n",
            "{'score': 0.022221030667424202, 'start': 17, 'end': 18, 'answer': '–'}\n",
            "{'score': 0.0012174984440207481, 'start': 110, 'end': 147, 'answer': 'snapping the two have amassed an army'}\n",
            "{'score': 0.04299832507967949, 'start': 4, 'end': 12, 'answer': 'Wright –'}\n",
            "{'score': 0.00047710485523566604, 'start': 49, 'end': 97, 'answer': 'flock to youtube to get the truth, Wright is one'}\n",
            "{'score': 0.0007101222290657461, 'start': 219, 'end': 230, 'answer': 'our friends'}\n",
            "['in his', 'would never support him', '35) Roseanne', '’s up with that?\" Roseanne is just one', '\"Start', '34', 'was self', 'endorse him', '33', 'realness of an all American, outdoor-sy family with an importance', 'We both have wives', '32) Wayne', 'Well no one, anywhere, ever accused me of not', '31) Chris Christie – Former Opponent to Trump for this Republican', 'in an epic', 'Kiyosaki', 'endorse Donald', '29', 'several times saying, \"Donald', 'correctness is a public', 'Heisman Trophy Winner', 'we going to get back to what’s best for', 'Stallworth', 'Stallworth went in to bat for Trump at a black', 'Coulter – Conservative author and television personality', 'Coulter has been a huge', 'Ferrigno – Former', 'our country and keeping', '24) Mike', 's gotta', 'and former', 'he’d make a great president. Because he’s not a politician', '22) Fran Drescher – Actress and cancer', 'lot of things that other people don’t really have the guts', 'and celebrity apprentice', 'the country needs and Trump ... he’s a guy', '20', 'endorsing Trump concluding \"I am a huge Donald', 'Kirstie', 'in an interview', 'California Rep', 'endorse Trump, who he', 'Former', 'suited', 'Super', 'Super', 'laughingly replied, \"This is really important', 'Hogan – Former WWE professional', 'I want to be Trump', '14) Gene', 'ungentlemanly\" at times', 'Busey', 'I know him professionally. He’s a great guy', '12) Robert Davi', 'In an article published on Breitbart and authored', 'deceiver who feeds us sugarcoated poison at bedtime', 'former', 'great friend for many years. We don’t need', '10) Dana White – President of Ultimate', 'me say a negative thing about Donald', 'Bilzerian', 'the people who remain unfiltered @realDonaldTrump', 'Icahn – Billionaire entrepreneur', 'no-brainer. You can’t keep', 'Former', 'I shocked my staff today', '6) Mike', 'Hufington', 'and Western', 'I just think he’s the only one who’s going', 'Sheriff on the front lines of the illegal immigration war', 'He produces results and is ready to get tough in order', ') Wayne', 'would make a great president,\" Newton told host Steve', 'he stays in, he doesn’t have to worry about how his family', 'Treasure', 'dysfunctional. Now, Donald is not', '+ Bonus) Sarah', 'several minutes saying \"I’m proud to endorse Donald J', 'endorsements for Donald', 'Benghazi Survivors Mark \"Oz', 'more than any Americans, know the absolute and imperative', 'be avoided because our enemies will fear the United States', 'Voight – Hollywood', 'In an interview with Breitbart the actor known from roles in Mission', 'Kid', 'we should let', 'Carter –', 'wildly popular singer responded to a Trump', 'Radio Host', 'extraordinaire', 'Giudice', 'I am going', '-wife', 'to promote Donald', 'Kenny', 'I have to admit. He can be president and not owe', 'Martial Artist', 'Endorsing Trump. The actor blasted Hillary', 'Royalty', 'have a case', 'Sylvestor Stallone – Hollywood Royalty', 'Dickensian', 'Home', 'we started The Home', 'who can \"make America great again\" by cutting', 'Wayne', 'her', 'We need someone, like Mr. Trump, with leadership', 'NCAA Basketball Coach', 'Indiana during the primaries saying Trump is \"the most prepared man in history', 'The National Border Patrol Union', 'endorsing Trump', 'In it they wrote, \"Mr. Trump will take on special', 'Scot', 'common', 'Jeneane', 'endorse Donald', 'Rifleman', 'was seen as a testament to both Trumps 2nd amendment credentials and Hillary', 'much more pro', 'well that he was breaking ranks with the Bush family', 'David A. Clarke Jr', 'the black', 'Theil – Venture', 'staunch libertarian and founder of Paypal', 'Hannity – Radio host and Fox', 'I’ll be voting for Donald', 'Yiannopoulos', 'may have', 'flamboyantly calling him \"Daddy.\" Milo also loves', 'Molyneux', 'We will never solve', '–', 'snapping the two have amassed an army', 'Wright –', 'flock to youtube to get the truth, Wright is one', 'our friends']\n",
            "{'score': 0.001405556802637875, 'start': 3, 'end': 6, 'answer': 'SRK'}\n",
            "{'score': 0.00048432350740768015, 'start': 32, 'end': 59, 'answer': \"Laila Main Laila' song, SRK\"}\n",
            "{'score': 0.0021520245354622602, 'start': 36, 'end': 97, 'answer': \"Violence & Shutting Down Bigg Boss If They Don't Make Him Win\"}\n",
            "{'score': 0.0011133557418361306, 'start': 170, 'end': 178, 'answer': 'violence'}\n",
            "{'score': 0.004386578220874071, 'start': 64, 'end': 68, 'answer': 'Five'}\n",
            "{'score': 0.00046823336742818356, 'start': 126, 'end': 201, 'answer': 'good fortune that Maharashtra got a Chief Minister who has pledged to solve'}\n",
            "{'score': 0.0022047050297260284, 'start': 69, 'end': 78, 'answer': 'Bengaluru'}\n",
            "{'score': 0.0007083966629579663, 'start': 115, 'end': 156, 'answer': 'molesters, says the man in the shirt.#oxy'}\n",
            "{'score': 0.0028486771043390036, 'start': 46, 'end': 55, 'answer': 'Bengaluru'}\n",
            "{'score': 4.1719300497788936e-05, 'start': 673, 'end': 751, 'answer': 'when the situation will change and criminals will feel scared. It is important'}\n",
            "['SRK', \"Laila Main Laila' song, SRK\", \"Violence & Shutting Down Bigg Boss If They Don't Make Him Win\", 'violence', 'Five', 'good fortune that Maharashtra got a Chief Minister who has pledged to solve', 'Bengaluru', 'molesters, says the man in the shirt.#oxy', 'Bengaluru', 'when the situation will change and criminals will feel scared. It is important']\n",
            "{'score': 0.005854160524904728, 'start': 6, 'end': 37, 'answer': 'highlights The National Vietnam'}\n",
            "{'score': 0.012024089694023132, 'start': 15, 'end': 24, 'answer': 'less than'}\n",
            "{'score': 0.0003030526568181813, 'start': 152, 'end': 161, 'answer': 'more than'}\n",
            "{'score': 0.0006931065581738949, 'start': 146, 'end': 198, 'answer': 'less than 2 percent for actual veterans and veterans'}\n",
            "{'score': 0.0007459523039869964, 'start': 30, 'end': 33, 'answer': 'one'}\n",
            "{'score': 0.00015682063531130552, 'start': 292, 'end': 335, 'answer': 'some of them are family. So one can say, is'}\n",
            "{'score': 0.00031466392101719975, 'start': 14, 'end': 44, 'answer': 'most recently filed tax return'}\n",
            "['highlights The National Vietnam', 'less than', 'more than', 'less than 2 percent for actual veterans and veterans', 'one', 'some of them are family. So one can say, is', 'most recently filed tax return']\n",
            "{'score': 0.003181792562827468, 'start': 31, 'end': 51, 'answer': 'Mullin made a family'}\n",
            "{'score': 0.00031773251248523593, 'start': 204, 'end': 214, 'answer': 'great-aunt'}\n",
            "{'score': 0.0021237742621451616, 'start': 68, 'end': 102, 'answer': 'able to take on the responsibility'}\n",
            "{'score': 0.0018419284606352448, 'start': 9, 'end': 91, 'answer': 'Mullin approached her husband multiple times about adopting the girls and bringing'}\n",
            "{'score': 0.0021192808635532856, 'start': 48, 'end': 60, 'answer': 'could handle'}\n",
            "{'score': 0.004017187282443047, 'start': 21, 'end': 88, 'answer': 'when he met the girls last Christmas and witnessed their incredible'}\n",
            "{'score': 0.000389338587410748, 'start': 40, 'end': 61, 'answer': 'Mullin told the press'}\n",
            "{'score': 0.0009786523878574371, 'start': 36, 'end': 118, 'answer': 'was officially approved last Wednesday. The congressman now has a beautiful family'}\n",
            "{'score': 0.000229034194489941, 'start': 72, 'end': 93, 'answer': 'Mullin said at a town'}\n",
            "{'score': 0.018567385151982307, 'start': 9, 'end': 14, 'answer': 'Daily'}\n",
            "['Mullin made a family', 'great-aunt', 'able to take on the responsibility', 'Mullin approached her husband multiple times about adopting the girls and bringing', 'could handle', 'when he met the girls last Christmas and witnessed their incredible', 'Mullin told the press', 'was officially approved last Wednesday. The congressman now has a beautiful family', 'Mullin said at a town', 'Daily']\n",
            "{'score': 0.003420069348067045, 'start': 25, 'end': 49, 'answer': 'in the world, ranked The'}\n",
            "{'score': 0.020461251959204674, 'start': 0, 'end': 2, 'answer': '30'}\n",
            "{'score': 0.02886233851313591, 'start': 0, 'end': 2, 'answer': '29'}\n",
            "{'score': 0.02509213238954544, 'start': 0, 'end': 2, 'answer': '28'}\n",
            "{'score': 0.03613670915365219, 'start': 0, 'end': 2, 'answer': '27'}\n",
            "{'score': 0.020949838683009148, 'start': 0, 'end': 2, 'answer': '26'}\n",
            "{'score': 0.02872310020029545, 'start': 0, 'end': 2, 'answer': '25'}\n",
            "{'score': 0.019899796694517136, 'start': 4, 'end': 12, 'answer': 'Hengshui'}\n",
            "{'score': 0.01616930030286312, 'start': 0, 'end': 2, 'answer': '23'}\n",
            "{'score': 0.01085036899894476, 'start': 10, 'end': 20, 'answer': 'Gobindgarh'}\n",
            "{'score': 0.018946940079331398, 'start': 4, 'end': 19, 'answer': 'Amritsar, India'}\n",
            "{'score': 0.03667996823787689, 'start': 0, 'end': 2, 'answer': '20'}\n",
            "{'score': 0.02532578445971012, 'start': 4, 'end': 10, 'answer': 'Handan'}\n",
            "{'score': 0.03492759168148041, 'start': 0, 'end': 18, 'answer': '18. Lucknow, India'}\n",
            "{'score': 0.01889653690159321, 'start': 13, 'end': 20, 'answer': ', India'}\n",
            "{'score': 0.024514563381671906, 'start': 4, 'end': 17, 'answer': 'Khanna, India'}\n",
            "{'score': 0.024816060438752174, 'start': 4, 'end': 10, 'answer': 'Kanpur'}\n",
            "{'score': 0.012216654606163502, 'start': 4, 'end': 23, 'answer': 'Shijiazhuang, China'}\n",
            "{'score': 0.01558918971568346, 'start': 4, 'end': 10, 'answer': 'Dammam'}\n",
            "{'score': 0.019096916541457176, 'start': 0, 'end': 19, 'answer': '12. Ludhiana, India'}\n",
            "{'score': 0.03149501234292984, 'start': 9, 'end': 16, 'answer': ', India'}\n",
            "{'score': 0.026445772498846054, 'start': 0, 'end': 3, 'answer': '10.'}\n",
            "{'score': 0.019089307636022568, 'start': 0, 'end': 1, 'answer': '9'}\n",
            "{'score': 0.02130655013024807, 'start': 3, 'end': 10, 'answer': 'Bamenda'}\n",
            "{'score': 0.023686766624450684, 'start': 0, 'end': 1, 'answer': '7'}\n",
            "{'score': 0.03358326479792595, 'start': 0, 'end': 1, 'answer': '6'}\n",
            "{'score': 0.012726117856800556, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.015956681221723557, 'start': 3, 'end': 9, 'answer': 'Riyadh'}\n",
            "{'score': 0.0247514545917511, 'start': 12, 'end': 19, 'answer': ', India'}\n",
            "{'score': 0.021791383624076843, 'start': 3, 'end': 17, 'answer': 'Gwalior, India'}\n",
            "{'score': 0.02301892079412937, 'start': 3, 'end': 8, 'answer': 'Zabol'}\n",
            "['in the world, ranked The', '30', '29', '28', '27', '26', '25', 'Hengshui', '23', 'Gobindgarh', 'Amritsar, India', '20', 'Handan', '18. Lucknow, India', ', India', 'Khanna, India', 'Kanpur', 'Shijiazhuang, China', 'Dammam', '12. Ludhiana, India', ', India', '10.', '9', 'Bamenda', '7', '6', '5', 'Riyadh', ', India', 'Gwalior, India', 'Zabol']\n",
            "{'score': 0.022374093532562256, 'start': 4, 'end': 16, 'answer': 'Raedle/Getty'}\n",
            "{'score': 0.00012795488873962313, 'start': 355, 'end': 378, 'answer': 'long shot for the White'}\n",
            "{'score': 0.0036236713640391827, 'start': 22, 'end': 30, 'answer': 'Bouie is'}\n",
            "{'score': 0.00016441050684079528, 'start': 277, 'end': 280, 'answer': 'too'}\n",
            "{'score': 4.747693310491741e-05, 'start': 701, 'end': 719, 'answer': 'well-liked but not'}\n",
            "{'score': 7.205347355920821e-05, 'start': 152, 'end': 200, 'answer': 'aligned against him? The answer is easy: He wins'}\n",
            "{'score': 0.0021520485170185566, 'start': 58, 'end': 81, 'answer': 'are aligned against him'}\n",
            "{'score': 0.0005688191740773618, 'start': 168, 'end': 214, 'answer': 'millions of Democrats to switch teams, despite'}\n",
            "{'score': 5.1299924962222576e-05, 'start': 639, 'end': 677, 'answer': 'especially for a candidate who says he'}\n",
            "{'score': 7.826180808478966e-05, 'start': 51, 'end': 90, 'answer': 'hard to imagine a disorganized campaign'}\n",
            "{'score': 8.547045581508428e-05, 'start': 568, 'end': 577, 'answer': 'We’re due'}\n",
            "{'score': 0.0001932474842760712, 'start': 178, 'end': 237, 'answer': 'attuned to perceived outsiders—and immigrants in particular'}\n",
            "{'score': 3.815647869487293e-05, 'start': 102, 'end': 150, 'answer': 'unity is a prerequisite for national competition'}\n",
            "{'score': 0.00024336866044905037, 'start': 147, 'end': 161, 'answer': 'well-known for'}\n",
            "['Raedle/Getty', 'long shot for the White', 'Bouie is', 'too', 'well-liked but not', 'aligned against him? The answer is easy: He wins', 'are aligned against him', 'millions of Democrats to switch teams, despite', 'especially for a candidate who says he', 'hard to imagine a disorganized campaign', 'We’re due', 'attuned to perceived outsiders—and immigrants in particular', 'unity is a prerequisite for national competition', 'well-known for']\n",
            "{'score': 0.002484062919393182, 'start': 58, 'end': 68, 'answer': 'not enough'}\n",
            "{'score': 0.00028117731562815607, 'start': 324, 'end': 341, 'answer': 'as much as thirty'}\n",
            "{'score': 0.00036556771374307573, 'start': 185, 'end': 194, 'answer': 'are worth'}\n",
            "{'score': 0.00024284474784508348, 'start': 175, 'end': 201, 'answer': 'is not actually considered'}\n",
            "{'score': 0.0007556446944363415, 'start': 184, 'end': 192, 'answer': 'in other'}\n",
            "{'score': 0.00023771222913637757, 'start': 2, 'end': 42, 'answer': 'number of other studies have in the past'}\n",
            "{'score': 0.00031366178882308304, 'start': 223, 'end': 235, 'answer': 'of the blood'}\n",
            "{'score': 0.0011168137425556779, 'start': 28, 'end': 43, 'answer': 'there is a high'}\n",
            "['not enough', 'as much as thirty', 'are worth', 'is not actually considered', 'in other', 'number of other studies have in the past', 'of the blood', 'there is a high']\n",
            "{'score': 0.0029145516455173492, 'start': 61, 'end': 66, 'answer': 'to be'}\n",
            "{'score': 0.000681205652654171, 'start': 22, 'end': 45, 'answer': 'rising inequality, wild'}\n",
            "{'score': 0.0013246251037344337, 'start': 87, 'end': 90, 'answer': 'who'}\n",
            "{'score': 0.0023293565027415752, 'start': 52, 'end': 64, 'answer': 'WEF, Eurasia'}\n",
            "{'score': 0.010208665393292904, 'start': 10, 'end': 18, 'answer': 'turn for'}\n",
            "{'score': 0.0017093407223001122, 'start': 50, 'end': 56, 'answer': 'enough'}\n",
            "{'score': 0.0004691017675213516, 'start': 168, 'end': 195, 'answer': 'the world, according to Ian'}\n",
            "{'score': 0.0005762274959124625, 'start': 85, 'end': 96, 'answer': \"there's not\"}\n",
            "{'score': 0.004821354057639837, 'start': 44, 'end': 49, 'answer': 'bound'}\n",
            "{'score': 0.0007095899200066924, 'start': 81, 'end': 90, 'answer': 'World War'}\n",
            "{'score': 0.12493830919265747, 'start': 0, 'end': 12, 'answer': 'Angry voters'}\n",
            "{'score': 0.003401142777875066, 'start': 0, 'end': 26, 'answer': 'Widening gaps between rich'}\n",
            "{'score': 0.0003765783039852977, 'start': 0, 'end': 85, 'answer': 'WEF said that while inequality between countries has been decreasing over the past 30'}\n",
            "{'score': 0.0003929827071260661, 'start': 248, 'end': 267, 'answer': 'their own countries'}\n",
            "{'score': 0.0007045402307994664, 'start': 141, 'end': 206, 'answer': \", and further undermine the region's precarious political balance\"}\n",
            "{'score': 0.02304909937083721, 'start': 6, 'end': 27, 'answer': '- opportunity or risk'}\n",
            "{'score': 0.0009686194825917482, 'start': 117, 'end': 129, 'answer': '.S. position'}\n",
            "{'score': 0.003689216449856758, 'start': 37, 'end': 70, 'answer': \"the world's two biggest economies\"}\n",
            "{'score': 0.0018414827063679695, 'start': 89, 'end': 97, 'answer': 'in order'}\n",
            "{'score': 0.0013998773647472262, 'start': 71, 'end': 92, 'answer': 'longer mutual,\" wrote'}\n",
            "{'score': 0.0018304699333384633, 'start': 113, 'end': 144, 'answer': 'he promised during the campaign'}\n",
            "{'score': 0.0007133523467928171, 'start': 20, 'end': 30, 'answer': 'are vastly'}\n",
            "{'score': 0.11439678072929382, 'start': 8, 'end': 18, 'answer': 'disruption'}\n",
            "{'score': 0.0011961378622800112, 'start': 55, 'end': 89, 'answer': 'embolden Moscow to \"act as a rogue'}\n",
            "{'score': 0.001627039979211986, 'start': 32, 'end': 37, 'answer': \"'t be\"}\n",
            "{'score': 0.0004044280794914812, 'start': 183, 'end': 186, 'answer': 'too'}\n",
            "['to be', 'rising inequality, wild', 'who', 'WEF, Eurasia', 'turn for', 'enough', 'the world, according to Ian', \"there's not\", 'bound', 'World War', 'Angry voters', 'Widening gaps between rich', 'WEF said that while inequality between countries has been decreasing over the past 30', 'their own countries', \", and further undermine the region's precarious political balance\", '- opportunity or risk', '.S. position', \"the world's two biggest economies\", 'in order', 'longer mutual,\" wrote', 'he promised during the campaign', 'are vastly', 'disruption', 'embolden Moscow to \"act as a rogue', \"'t be\", 'too']\n",
            "{'score': 0.0004354030534159392, 'start': 132, 'end': 144, 'answer': 'your friends'}\n",
            "{'score': 0.0020727741066366434, 'start': 81, 'end': 87, 'answer': 'enough'}\n",
            "{'score': 0.0012462263694033027, 'start': 66, 'end': 74, 'answer': 'not even'}\n",
            "{'score': 0.0016120208892971277, 'start': 9, 'end': 67, 'answer': 'do you tell your sweet friends? Your nice and good friends'}\n",
            "{'score': 0.023426609113812447, 'start': 14, 'end': 24, 'answer': 'good ideas'}\n",
            "{'score': 0.004375827964395285, 'start': 41, 'end': 59, 'answer': 'are practicing for'}\n",
            "{'score': 0.016870636492967606, 'start': 8, 'end': 28, 'answer': ', the really big one'}\n",
            "{'score': 0.002566340146586299, 'start': 70, 'end': 81, 'answer': 'every Kanye'}\n",
            "{'score': 0.010651102289557457, 'start': 14, 'end': 28, 'answer': 'be responsible'}\n",
            "{'score': 0.001157574006356299, 'start': 41, 'end': 77, 'answer': 'have decided to wash your hair every'}\n",
            "{'score': 0.008675221353769302, 'start': 7, 'end': 26, 'answer': \"it's just something\"}\n",
            "{'score': 0.006389237474650145, 'start': 7, 'end': 46, 'answer': 'cannot go out tonight because it is not'}\n",
            "{'score': 0.01145743764936924, 'start': 28, 'end': 31, 'answer': 'not'}\n",
            "{'score': 0.0020721154287457466, 'start': 41, 'end': 60, 'answer': 'do not want to miss'}\n",
            "{'score': 0.009923005476593971, 'start': 12, 'end': 19, 'answer': 'present'}\n",
            "{'score': 0.003054963191971183, 'start': 37, 'end': 75, 'answer': 'you must watch the show your coworkers'}\n",
            "{'score': 0.00624906737357378, 'start': 14, 'end': 18, 'answer': 'good'}\n",
            "{'score': 0.00347779574804008, 'start': 37, 'end': 52, 'answer': 'you had chicken'}\n",
            "{'score': 0.011913419701159, 'start': 11, 'end': 16, 'answer': \"can't\"}\n",
            "{'score': 0.0034126017708331347, 'start': 50, 'end': 62, 'answer': \"aren't going\"}\n",
            "{'score': 0.015375182032585144, 'start': 0, 'end': 13, 'answer': 'The situation'}\n",
            "{'score': 0.0030424140859395266, 'start': 3, 'end': 28, 'answer': 'You cannot go out tonight'}\n",
            "{'score': 0.01229292992502451, 'start': 0, 'end': 4, 'answer': 'Kale'}\n",
            "{'score': 0.0031498013995587826, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 0.010907119140028954, 'start': 6, 'end': 18, 'answer': 'seeping from'}\n",
            "['your friends', 'enough', 'not even', 'do you tell your sweet friends? Your nice and good friends', 'good ideas', 'are practicing for', ', the really big one', 'every Kanye', 'be responsible', 'have decided to wash your hair every', \"it's just something\", 'cannot go out tonight because it is not', 'not', 'do not want to miss', 'present', 'you must watch the show your coworkers', 'good', 'you had chicken', \"can't\", \"aren't going\", 'The situation', 'You cannot go out tonight', 'Kale', '10', 'seeping from']\n",
            "{'score': 0.0013089467538520694, 'start': 29, 'end': 48, 'answer': 'Holley received a $'}\n",
            "{'score': 0.00092891207896173, 'start': 12, 'end': 83, 'answer': 'Holley gave back his awarded bonus because company shareholders had not'}\n",
            "{'score': 0.0015536673599854112, 'start': 18, 'end': 32, 'answer': 'Holley remains'}\n",
            "{'score': 0.004420253913849592, 'start': 22, 'end': 25, 'answer': 'not'}\n",
            "['Holley received a $', 'Holley gave back his awarded bonus because company shareholders had not', 'Holley remains', 'not']\n",
            "{'score': 0.0002465890720486641, 'start': 198, 'end': 204, 'answer': 'Watani'}\n",
            "{'score': 0.00044905213871970773, 'start': 156, 'end': 166, 'answer': 'AXVCD458Ji'}\n",
            "{'score': 0.0004612022021319717, 'start': 72, 'end': 133, 'answer': 'if she would ever get to attend the Oscars but life certainly'}\n",
            "{'score': 0.0010202352423220873, 'start': 111, 'end': 127, 'answer': 'would have given'}\n",
            "{'score': 0.0009356374503113329, 'start': 174, 'end': 180, 'answer': 'hijab.'}\n",
            "{'score': 0.0028346730396151543, 'start': 37, 'end': 58, 'answer': 'with a moving caption'}\n",
            "{'score': 0.00027062089066021144, 'start': 97, 'end': 103, 'answer': 'Watani'}\n",
            "{'score': 0.004497977439314127, 'start': 25, 'end': 27, 'answer': 'in'}\n",
            "{'score': 0.0006358824903145432, 'start': 123, 'end': 140, 'answer': 'had the privilege'}\n",
            "{'score': 0.0002773392479866743, 'start': 13, 'end': 36, 'answer': 'my collection is always'}\n",
            "{'score': 0.0003763297281693667, 'start': 225, 'end': 258, 'answer': 'and truly amazing @sweetbabyjamie'}\n",
            "{'score': 0.0005538429250009358, 'start': 208, 'end': 226, 'answer': 'who truly deserves'}\n",
            "['Watani', 'AXVCD458Ji', 'if she would ever get to attend the Oscars but life certainly', 'would have given', 'hijab.', 'with a moving caption', 'Watani', 'in', 'had the privilege', 'my collection is always', 'and truly amazing @sweetbabyjamie', 'who truly deserves']\n",
            "{'score': 0.00028475557337515056, 'start': 17, 'end': 28, 'answer': 'been served'}\n",
            "{'score': 0.00014876440400257707, 'start': 404, 'end': 414, 'answer': 'inflicting'}\n",
            "{'score': 0.0006344068679027259, 'start': 104, 'end': 111, 'answer': 'was too'}\n",
            "{'score': 0.00010659756662789732, 'start': 275, 'end': 352, 'answer': 'ten other inmates watched, the two women went to working beating Smith, using'}\n",
            "{'score': 0.000770776707213372, 'start': 42, 'end': 95, 'answer': 'they don’t feel bad for the murderer and she deserved'}\n",
            "{'score': 0.0003677546337712556, 'start': 18, 'end': 61, 'answer': 'lot of talk about attacking Smith, but most'}\n",
            "{'score': 0.002181060379371047, 'start': 44, 'end': 126, 'answer': 'weapon used in the attack, they admit that the attackers will receive disciplinary'}\n",
            "{'score': 0.006572639103978872, 'start': 4, 'end': 67, 'answer': 'commenters on the story agreed that Smith got what she deserved'}\n",
            "{'score': 0.002516077598556876, 'start': 7, 'end': 75, 'answer': 'them for giving her a taste of her medicine. They should be rewarded'}\n",
            "{'score': 0.02597084641456604, 'start': 4, 'end': 30, 'answer': 'others added the following'}\n",
            "{'score': 0.0010553366737440228, 'start': 70, 'end': 74, 'answer': 'hope'}\n",
            "{'score': 0.005995874758809805, 'start': 3, 'end': 8, 'answer': 'would'}\n",
            "{'score': 0.00393848167732358, 'start': 0, 'end': 55, 'answer': 'Everyone seemed to agree that this was definitely karma'}\n",
            "{'score': 0.002993050729855895, 'start': 6, 'end': 66, 'answer': 'them WELCOMING GALS a nice spa day. For JUSTICE BEING SERVED'}\n",
            "{'score': 0.0027428586035966873, 'start': 15, 'end': 40, 'answer': 'in for life? She deserves'}\n",
            "{'score': 0.002311070216819644, 'start': 51, 'end': 59, 'answer': 'sympathy'}\n",
            "['been served', 'inflicting', 'was too', 'ten other inmates watched, the two women went to working beating Smith, using', 'they don’t feel bad for the murderer and she deserved', 'lot of talk about attacking Smith, but most', 'weapon used in the attack, they admit that the attackers will receive disciplinary', 'commenters on the story agreed that Smith got what she deserved', 'them for giving her a taste of her medicine. They should be rewarded', 'others added the following', 'hope', 'would', 'Everyone seemed to agree that this was definitely karma', 'them WELCOMING GALS a nice spa day. For JUSTICE BEING SERVED', 'in for life? She deserves', 'sympathy']\n",
            "{'score': 0.0017318283207714558, 'start': 2, 'end': 50, 'answer': 'lifelike statue of a nearly nude man will remain'}\n",
            "{'score': 0.00018032404477708042, 'start': 197, 'end': 209, 'answer': 'hard to miss'}\n",
            "{'score': 0.0005155681283213198, 'start': 178, 'end': 185, 'answer': 'must do'}\n",
            "{'score': 0.00360368425026536, 'start': 11, 'end': 20, 'answer': 'wellesley'}\n",
            "{'score': 0.0012706005945801735, 'start': 12, 'end': 59, 'answer': 'your daughters here. pic.twitter.com/eRf1uJCxKA'}\n",
            "{'score': 0.00045550541835837066, 'start': 126, 'end': 133, 'answer': 'rondeau'}\n",
            "{'score': 0.00047811720287427306, 'start': 126, 'end': 153, 'answer': 'O3qLxPCqew — Polina Soshnin'}\n",
            "{'score': 0.0017583819571882486, 'start': 0, 'end': 22, 'answer': 'Nearly 1,000 people at'}\n",
            "{'score': 0.006285708397626877, 'start': 15, 'end': 59, 'answer': 'frequently called creepy, and triggering for'}\n",
            "{'score': 0.0020166225731372833, 'start': 6, 'end': 59, 'answer': 'Mahmood, a HuffPost campus editor-at-large, explained'}\n",
            "{'score': 0.00023308608797378838, 'start': 51, 'end': 69, 'answer': 'priority should be'}\n",
            "{'score': 0.00033296464243903756, 'start': 206, 'end': 232, 'answer': 'there. But who am I to say'}\n",
            "['lifelike statue of a nearly nude man will remain', 'hard to miss', 'must do', 'wellesley', 'your daughters here. pic.twitter.com/eRf1uJCxKA', 'rondeau', 'O3qLxPCqew — Polina Soshnin', 'Nearly 1,000 people at', 'frequently called creepy, and triggering for', 'Mahmood, a HuffPost campus editor-at-large, explained', 'priority should be', 'there. But who am I to say']\n",
            "{'score': 0.009130413644015789, 'start': 6, 'end': 9, 'answer': 'cut'}\n",
            "{'score': 0.0018148265080526471, 'start': 83, 'end': 121, 'answer': 'they never said it would be like this.'}\n",
            "{'score': 0.00012579567555803806, 'start': 199, 'end': 258, 'answer': 'angry about the dishes that never get put in the dishwasher'}\n",
            "{'score': 0.007011566311120987, 'start': 9, 'end': 23, 'answer': 'you’re dealing'}\n",
            "{'score': 0.0005902406410314143, 'start': 203, 'end': 223, 'answer': 'freaking hard either'}\n",
            "{'score': 0.0001221910206368193, 'start': 315, 'end': 386, 'answer': 'You see cute couples at the park on the weekend, pushing their toddlers'}\n",
            "{'score': 0.0004896997706964612, 'start': 0, 'end': 7, 'answer': 'Well, I'}\n",
            "{'score': 0.0027375167701393366, 'start': 30, 'end': 67, 'answer': 'no one tells you: Marriage is fucking'}\n",
            "{'score': 0.00095814821543172, 'start': 26, 'end': 68, 'answer': 'they don’t tell you? It’s OK that marriage'}\n",
            "{'score': 0.0008852755418047309, 'start': 133, 'end': 153, 'answer': 'crock-of-shit advice'}\n",
            "{'score': 0.036358777433633804, 'start': 0, 'end': 20, 'answer': 'There will be fights'}\n",
            "{'score': 9.394221706315875e-05, 'start': 61, 'end': 75, 'answer': 'you don’t even'}\n",
            "{'score': 0.035919640213251114, 'start': 0, 'end': 13, 'answer': 'There will be'}\n",
            "{'score': 9.520089952275157e-05, 'start': 198, 'end': 257, 'answer': 'blissfully as you get up in the middle of the night—again!—'}\n",
            "{'score': 0.022789454087615013, 'start': 0, 'end': 13, 'answer': 'There will be'}\n",
            "{'score': 0.0001498026686022058, 'start': 191, 'end': 203, 'answer': 'chauffeuring'}\n",
            "{'score': 0.021370261907577515, 'start': 4, 'end': 28, 'answer': 'there will be hard times'}\n",
            "{'score': 0.0009121154434978962, 'start': 4, 'end': 7, 'answer': 'not'}\n",
            "{'score': 0.002568063559010625, 'start': 11, 'end': 20, 'answer': 'something'}\n",
            "{'score': 0.00012266279372852296, 'start': 367, 'end': 418, 'answer': 'in the middle of the afternoon. And marriage is not'}\n",
            "{'score': 0.0004348951333668083, 'start': 41, 'end': 125, 'answer': 'difficult times now and then. Because when you share your freaking life with someone'}\n",
            "{'score': 0.0003954880521632731, 'start': 59, 'end': 91, 'answer': 'on the same team. You will fight'}\n",
            "{'score': 0.0003016177215613425, 'start': 259, 'end': 285, 'answer': 'on your side who will hold'}\n",
            "['cut', 'they never said it would be like this.', 'angry about the dishes that never get put in the dishwasher', 'you’re dealing', 'freaking hard either', 'You see cute couples at the park on the weekend, pushing their toddlers', 'Well, I', 'no one tells you: Marriage is fucking', 'they don’t tell you? It’s OK that marriage', 'crock-of-shit advice', 'There will be fights', 'you don’t even', 'There will be', 'blissfully as you get up in the middle of the night—again!—', 'There will be', 'chauffeuring', 'there will be hard times', 'not', 'something', 'in the middle of the afternoon. And marriage is not', 'difficult times now and then. Because when you share your freaking life with someone', 'on the same team. You will fight', 'on your side who will hold']\n",
            "{'score': 0.0010940873762592673, 'start': 21, 'end': 63, 'answer': 'enough to have paid time off are foregoing'}\n",
            "{'score': 0.0008673864649608731, 'start': 0, 'end': 7, 'answer': 'Some 52'}\n",
            "{'score': 0.003054603934288025, 'start': 25, 'end': 46, 'answer': 'workaholism\" to blame'}\n",
            "{'score': 0.0014035156928002834, 'start': 122, 'end': 133, 'answer': 'were saving'}\n",
            "{'score': 0.0008622928871773183, 'start': 6, 'end': 58, 'answer': 'a third of respondents said that they plan on taking'}\n",
            "{'score': 0.003700575092807412, 'start': 37, 'end': 65, 'answer': 'many U.S. workers feel bound'}\n",
            "{'score': 0.001042867312207818, 'start': 8, 'end': 73, 'answer': \"quarter of workers say they simply work too much and can't afford\"}\n",
            "{'score': 0.0023202234879136086, 'start': 48, 'end': 67, 'answer': \"doesn't necessarily\"}\n",
            "{'score': 0.00047941660159267485, 'start': 100, 'end': 168, 'answer': 'of which have a direct impact on their work performance,\" says Sarah'}\n",
            "{'score': 0.00034675048664212227, 'start': 120, 'end': 180, 'answer': 'stress in your off hours, consider taking up a hobby. Warren'}\n",
            "['enough to have paid time off are foregoing', 'Some 52', 'workaholism\" to blame', 'were saving', 'a third of respondents said that they plan on taking', 'many U.S. workers feel bound', \"quarter of workers say they simply work too much and can't afford\", \"doesn't necessarily\", 'of which have a direct impact on their work performance,\" says Sarah', 'stress in your off hours, consider taking up a hobby. Warren']\n",
            "{'score': 0.001617203583009541, 'start': 52, 'end': 88, 'answer': 'more and more homeowners are trading'}\n",
            "{'score': 0.0003636285837274045, 'start': 198, 'end': 261, 'answer': 'hefty price). And while having one of these spaces could hinder'}\n",
            "['more and more homeowners are trading', 'hefty price). And while having one of these spaces could hinder']\n",
            "{'score': 0.0016490838024765253, 'start': 17, 'end': 35, 'answer': 'often mean cutting'}\n",
            "{'score': 0.0017287745140492916, 'start': 45, 'end': 116, 'answer': 'Quidco can help you save thousands of pounds a year without sacrificing'}\n",
            "{'score': 0.0008768928819335997, 'start': 118, 'end': 186, 'answer': 'Others are as straightforward as asking big brands for a better deal'}\n",
            "{'score': 0.0007961619412526488, 'start': 52, 'end': 124, 'answer': 'of us want to be able to count our savings in pounds rather than pennies'}\n",
            "{'score': 0.0006577320164069533, 'start': 116, 'end': 134, 'answer': 'can quickly add up'}\n",
            "{'score': 0.006615104153752327, 'start': 6, 'end': 12, 'answer': 'FEMAIL'}\n",
            "{'score': 0.029985744506120682, 'start': 16, 'end': 25, 'answer': 'OF SEASON'}\n",
            "{'score': 0.001862811972387135, 'start': 66, 'end': 94, 'answer': 'seasonally can help you save'}\n",
            "{'score': 0.0010292627848684788, 'start': 25, 'end': 39, 'answer': 'be down to £50'}\n",
            "{'score': 0.0015100878663361073, 'start': 91, 'end': 122, 'answer': 'clearance sale prices can leave'}\n",
            "{'score': 0.017739465460181236, 'start': 0, 'end': 9, 'answer': 'STOCKPILE'}\n",
            "{'score': 0.0022459756582975388, 'start': 0, 'end': 35, 'answer': 'If you see a good deal on something'}\n",
            "{'score': 0.0014613595558330417, 'start': 77, 'end': 92, 'answer': 'your discounted'}\n",
            "{'score': 0.00039860070683062077, 'start': 156, 'end': 211, 'answer': \"tins when they're available at half price could put £52\"}\n",
            "{'score': 0.0007285824394784868, 'start': 22, 'end': 52, 'answer': 'non-perishable food goods, but'}\n",
            "{'score': 0.050235144793987274, 'start': 4, 'end': 17, 'answer': 'FOR DISCOUNTS'}\n",
            "{'score': 0.0018928818171843886, 'start': 44, 'end': 95, 'answer': 'would be surprised how often you can get a discount'}\n",
            "{'score': 0.001114581129513681, 'start': 81, 'end': 128, 'answer': 'electricals outlets, where flexible discounting'}\n",
            "{'score': 0.002210368402302265, 'start': 73, 'end': 101, 'answer': 'could help you save hundreds'}\n",
            "{'score': 0.0006596763269044459, 'start': 80, 'end': 89, 'answer': 'refunding'}\n",
            "{'score': 0.012005951255559921, 'start': 9, 'end': 25, 'answer': 'AFRAID TO PRAISE'}\n",
            "{'score': 0.005966825410723686, 'start': 15, 'end': 40, 'answer': 'when the people who enjoy'}\n",
            "{'score': 0.00037197445635683835, 'start': 96, 'end': 115, 'answer': 'goodies or vouchers'}\n",
            "{'score': 0.02683430165052414, 'start': 10, 'end': 25, 'answer': 'A CASHBACK DEAL'}\n",
            "{'score': 0.00027025913004763424, 'start': 129, 'end': 143, 'answer': 'commonly get 5'}\n",
            "{'score': 0.04625259339809418, 'start': 6, 'end': 23, 'answer': 'A SAVINGS ACCOUNT'}\n",
            "{'score': 0.0008054584031924605, 'start': 53, 'end': 98, 'answer': 'priorities for many of us because the returns'}\n",
            "['often mean cutting', 'Quidco can help you save thousands of pounds a year without sacrificing', 'Others are as straightforward as asking big brands for a better deal', 'of us want to be able to count our savings in pounds rather than pennies', 'can quickly add up', 'FEMAIL', 'OF SEASON', 'seasonally can help you save', 'be down to £50', 'clearance sale prices can leave', 'STOCKPILE', 'If you see a good deal on something', 'your discounted', \"tins when they're available at half price could put £52\", 'non-perishable food goods, but', 'FOR DISCOUNTS', 'would be surprised how often you can get a discount', 'electricals outlets, where flexible discounting', 'could help you save hundreds', 'refunding', 'AFRAID TO PRAISE', 'when the people who enjoy', 'goodies or vouchers', 'A CASHBACK DEAL', 'commonly get 5', 'A SAVINGS ACCOUNT', 'priorities for many of us because the returns']\n",
            "{'score': 0.0005437788786366582, 'start': 179, 'end': 186, 'answer': 'McClain'}\n",
            "{'score': 0.00017815343744587153, 'start': 296, 'end': 337, 'answer': \"series of changes to the state's tax code\"}\n",
            "{'score': 0.0007148134172894061, 'start': 123, 'end': 143, 'answer': '- and especially not'}\n",
            "{'score': 0.0003733759222086519, 'start': 74, 'end': 152, 'answer': 'are but a small sample. But the divergent experiences of California and Kansas'}\n",
            "{'score': 0.0003545965300872922, 'start': 248, 'end': 264, 'answer': 'was near the top'}\n",
            "{'score': 0.00020438274077605456, 'start': 137, 'end': 148, 'answer': 'as Nebraska'}\n",
            "{'score': 0.009488958865404129, 'start': 8, 'end': 29, 'answer': 'had the ultimate plan'}\n",
            "{'score': 0.0033275228925049305, 'start': 44, 'end': 54, 'answer': 'were meant'}\n",
            "{'score': 0.0003735216159839183, 'start': 189, 'end': 267, 'answer': 'Moody’s Investors Service have signaled that they could reduce Kansas’s credit'}\n",
            "{'score': 0.0007173578487709165, 'start': 4, 'end': 48, 'answer': 'shortfalls have forced Gov. Sam Brownback (R'}\n",
            "{'score': 0.0008877060608938336, 'start': 35, 'end': 63, 'answer': 'modestly increased taxes for'}\n",
            "{'score': 0.00022179844381753355, 'start': 12, 'end': 70, 'answer': '20 percent of households -- those making less than $23,000'}\n",
            "{'score': 0.001323311822488904, 'start': 64, 'end': 74, 'answer': 'at least $'}\n",
            "{'score': 0.00278764171525836, 'start': 51, 'end': 75, 'answer': 'as much as the bottom 90'}\n",
            "{'score': 0.00045897188829258084, 'start': 35, 'end': 40, 'answer': 'still'}\n",
            "{'score': 0.009028159081935883, 'start': 19, 'end': 29, 'answer': 'Chinn said'}\n",
            "{'score': 0.00029502296820282936, 'start': 161, 'end': 165, 'answer': 'high'}\n",
            "{'score': 0.0005322576616890728, 'start': 231, 'end': 242, 'answer': 'still beats'}\n",
            "{'score': 0.00499714445322752, 'start': 31, 'end': 68, 'answer': 'derail California’s economic comeback'}\n",
            "{'score': 0.000423362129367888, 'start': 0, 'end': 77, 'answer': 'Few, if any, economists would say today that the recovery has been sufficient'}\n",
            "['McClain', \"series of changes to the state's tax code\", '- and especially not', 'are but a small sample. But the divergent experiences of California and Kansas', 'was near the top', 'as Nebraska', 'had the ultimate plan', 'were meant', 'Moody’s Investors Service have signaled that they could reduce Kansas’s credit', 'shortfalls have forced Gov. Sam Brownback (R', 'modestly increased taxes for', '20 percent of households -- those making less than $23,000', 'at least $', 'as much as the bottom 90', 'still', 'Chinn said', 'high', 'still beats', 'derail California’s economic comeback', 'Few, if any, economists would say today that the recovery has been sufficient']\n",
            "{'score': 0.010700000450015068, 'start': 0, 'end': 19, 'answer': 'You and 3.2M others'}\n",
            "{'score': 0.010700000450015068, 'start': 0, 'end': 19, 'answer': 'You and 3.2M others'}\n",
            "{'score': 0.0007315466064028442, 'start': 92, 'end': 109, 'answer': 'I watch something'}\n",
            "{'score': 0.0033190364483743906, 'start': 13, 'end': 51, 'answer': 'on vacation, it’s the one thing I miss'}\n",
            "{'score': 0.0007042620563879609, 'start': 159, 'end': 162, 'answer': 'all'}\n",
            "{'score': 0.0014847523998469114, 'start': 17, 'end': 25, 'answer': 'how much'}\n",
            "{'score': 0.000998450443148613, 'start': 85, 'end': 106, 'answer': 'few super quick hacks'}\n",
            "{'score': 0.0006692616152577102, 'start': 178, 'end': 219, 'answer': 'high-quality option is checked (obviously'}\n",
            "{'score': 0.007983613759279251, 'start': 30, 'end': 33, 'answer': 'for'}\n",
            "{'score': 0.0007315922994166613, 'start': 32, 'end': 83, 'answer': 'could be causing your streaming issues? No, I’m not'}\n",
            "{'score': 0.0006852129590697587, 'start': 83, 'end': 113, 'answer': 'if you’re streaming on Firefox'}\n",
            "{'score': 0.0007702588918618858, 'start': 42, 'end': 102, 'answer': 'you use Internet Explorer (yes, really), Safari or Microsoft'}\n",
            "{'score': 0.011434357613325119, 'start': 0, 'end': 47, 'answer': 'Give yourself the streaming quality you deserve'}\n",
            "{'score': 0.015112005174160004, 'start': 10, 'end': 17, 'answer': 'there’s'}\n",
            "{'score': 0.0011212854878976941, 'start': 17, 'end': 86, 'answer': 'You can also use a little trick to avoid having to wait for something'}\n",
            "{'score': 0.0006969349924474955, 'start': 107, 'end': 160, 'answer': 'evasive Stream Manager menu. The options on this menu'}\n",
            "{'score': 0.00202588876709342, 'start': 29, 'end': 55, 'answer': 'down Ctrl+Shift+Alt or Opt'}\n",
            "{'score': 0.0023106911685317755, 'start': 25, 'end': 28, 'answer': 'for'}\n",
            "['You and 3.2M others', 'You and 3.2M others', 'I watch something', 'on vacation, it’s the one thing I miss', 'all', 'how much', 'few super quick hacks', 'high-quality option is checked (obviously', 'for', 'could be causing your streaming issues? No, I’m not', 'if you’re streaming on Firefox', 'you use Internet Explorer (yes, really), Safari or Microsoft', 'Give yourself the streaming quality you deserve', 'there’s', 'You can also use a little trick to avoid having to wait for something', 'evasive Stream Manager menu. The options on this menu', 'down Ctrl+Shift+Alt or Opt', 'for']\n",
            "{'score': 0.00021842654678039253, 'start': 14, 'end': 43, 'answer': 'Feig has been revealing quite'}\n",
            "{'score': 0.000561944383662194, 'start': 94, 'end': 106, 'answer': 'Feig replied'}\n",
            "{'score': 0.013548022136092186, 'start': 12, 'end': 22, 'answer': 'Feig wrote'}\n",
            "{'score': 0.000514190352987498, 'start': 135, 'end': 150, 'answer': 'Feig (@paulfeig'}\n",
            "{'score': 0.00022997027554083616, 'start': 252, 'end': 264, 'answer': 'Wiig is Erin'}\n",
            "{'score': 0.0001356366410618648, 'start': 135, 'end': 149, 'answer': 'Aykroyd), Egon'}\n",
            "{'score': 0.00011849270958919078, 'start': 121, 'end': 141, 'answer': 'York City, Michael K'}\n",
            "{'score': 0.0001663925067987293, 'start': 398, 'end': 411, 'answer': 'Feig can pull'}\n",
            "{'score': 0.0071314251981675625, 'start': 0, 'end': 12, 'answer': 'Ghostbusters'}\n",
            "['Feig has been revealing quite', 'Feig replied', 'Feig wrote', 'Feig (@paulfeig', 'Wiig is Erin', 'Aykroyd), Egon', 'York City, Michael K', 'Feig can pull', 'Ghostbusters']\n",
            "{'score': 0.0005716794403269887, 'start': 109, 'end': 117, 'answer': 'Unpacked'}\n",
            "{'score': 0.00045905474689789116, 'start': 11, 'end': 58, 'answer': 'rectangular black headset, and you can traverse'}\n",
            "{'score': 0.000280101754469797, 'start': 44, 'end': 67, 'answer': \"many believe it's still\"}\n",
            "{'score': 0.00022532387811224908, 'start': 238, 'end': 274, 'answer': 'cofounder and former CEO, to discuss'}\n",
            "{'score': 0.028766730800271034, 'start': 16, 'end': 24, 'answer': 'will get'}\n",
            "{'score': 0.0006270048907026649, 'start': 197, 'end': 226, 'answer': 'wield an imaginary paintbrush'}\n",
            "{'score': 0.00018014230590779334, 'start': 151, 'end': 169, 'answer': 'in your hand still'}\n",
            "{'score': 0.00026299740420654416, 'start': 133, 'end': 153, 'answer': \"you're a quarterback\"}\n",
            "{'score': 0.0009617874165996909, 'start': 134, 'end': 169, 'answer': 'far back as 1962 with the Sensorama'}\n",
            "{'score': 0.00015502657333854586, 'start': 160, 'end': 176, 'answer': \"Well that's just\"}\n",
            "{'score': 0.0002051917981589213, 'start': 60, 'end': 84, 'answer': 'Azor described will ever'}\n",
            "{'score': 0.020093990489840508, 'start': 23, 'end': 29, 'answer': 'effort'}\n",
            "{'score': 0.0010023898212239146, 'start': 11, 'end': 41, 'answer': 'Rift will likely be remembered'}\n",
            "{'score': 0.00030067688203416765, 'start': 0, 'end': 10, 'answer': 'Azor draws'}\n",
            "{'score': 0.0006960261380299926, 'start': 127, 'end': 151, 'answer': 'no one company can solve'}\n",
            "{'score': 0.008696016855537891, 'start': 28, 'end': 29, 'answer': 't'}\n",
            "{'score': 0.00022037027520127594, 'start': 217, 'end': 283, 'answer': 'Rift and the Vive. The former plug into your smartphone to deliver'}\n",
            "{'score': 0.0009286595741286874, 'start': 31, 'end': 109, 'answer': 'high-performance device like the Rift go wireless anytime soon, mostly because'}\n",
            "{'score': 0.00022041689953766763, 'start': 270, 'end': 294, 'answer': 'will be wired for a fair'}\n",
            "['Unpacked', 'rectangular black headset, and you can traverse', \"many believe it's still\", 'cofounder and former CEO, to discuss', 'will get', 'wield an imaginary paintbrush', 'in your hand still', \"you're a quarterback\", 'far back as 1962 with the Sensorama', \"Well that's just\", 'Azor described will ever', 'effort', 'Rift will likely be remembered', 'Azor draws', 'no one company can solve', 't', 'Rift and the Vive. The former plug into your smartphone to deliver', 'high-performance device like the Rift go wireless anytime soon, mostly because', 'will be wired for a fair']\n",
            "{'score': 0.0011414415203034878, 'start': 51, 'end': 71, 'answer': '25, The Weinstein Co'}\n",
            "{'score': 0.0011927186278626323, 'start': 123, 'end': 147, 'answer': '-South African president'}\n",
            "{'score': 0.00024386671429965645, 'start': 4, 'end': 12, 'answer': \"couldn't\"}\n",
            "{'score': 0.0004146228020545095, 'start': 130, 'end': 205, 'answer': 'Weinstein. \"Partnering with them ensures the picture will continue to honor'}\n",
            "{'score': 0.0008005857816897333, 'start': 154, 'end': 159, 'answer': 'maven'}\n",
            "{'score': 0.00019623438129201531, 'start': 265, 'end': 274, 'answer': 'good joke'}\n",
            "{'score': 0.0035590967163443565, 'start': 1, 'end': 26, 'answer': 'He will always be my hero'}\n",
            "['25, The Weinstein Co', '-South African president', \"couldn't\", 'Weinstein. \"Partnering with them ensures the picture will continue to honor', 'maven', 'good joke', 'He will always be my hero']\n",
            "{'score': 0.004898452199995518, 'start': 11, 'end': 33, 'answer': 'development of the 787'}\n",
            "{'score': 0.0011531675700098276, 'start': 39, 'end': 116, 'answer': 'much of the plane out of carbon-fiber reinforced plastics and other composite'}\n",
            "{'score': 0.0006681873928755522, 'start': 10, 'end': 79, 'answer': \"engineering of the composite airframe may have been a challenge, it's\"}\n",
            "{'score': 0.0005553776863962412, 'start': 155, 'end': 170, 'answer': 'fatigue,\" Blake'}\n",
            "{'score': 0.0009698325302451849, 'start': 11, 'end': 15, 'answer': 'most'}\n",
            "{'score': 0.0010838108137249947, 'start': 88, 'end': 129, 'answer': 'Emery added. \"It\\'s a bit counterintuitive'}\n",
            "{'score': 0.014870832674205303, 'start': 13, 'end': 28, 'answer': 'pressure matter'}\n",
            "{'score': 0.0010546516859903932, 'start': 114, 'end': 122, 'answer': 'appetite'}\n",
            "{'score': 0.0012907406780868769, 'start': 13, 'end': 24, 'answer': 'afflictions'}\n",
            "{'score': 0.007580705918371677, 'start': 35, 'end': 38, 'answer': 'far'}\n",
            "{'score': 0.0014236083952710032, 'start': 58, 'end': 68, 'answer': 'attributed'}\n",
            "{'score': 0.004508962854743004, 'start': 24, 'end': 38, 'answer': 'Oklahoma State'}\n",
            "{'score': 0.00014116331294644624, 'start': 55, 'end': 117, 'answer': 'discomfort characterized by symptoms similar to those of acute'}\n",
            "{'score': 0.005743940360844135, 'start': 15, 'end': 23, 'answer': 'annouced'}\n",
            "{'score': 0.00034117134055122733, 'start': 106, 'end': 150, 'answer': \"in their blood fall 4%. Although this didn't\"}\n",
            "{'score': 0.0007191416807472706, 'start': 40, 'end': 98, 'answer': 'reacted at 6,000 feet similar to that at sea level,\" Emery'}\n",
            "{'score': 0.000836079241707921, 'start': 77, 'end': 117, 'answer': 'saturation. As result, the body does not'}\n",
            "{'score': 0.0004450111009646207, 'start': 26, 'end': 37, 'answer': \"there isn't\"}\n",
            "{'score': 0.010544859804213047, 'start': 4, 'end': 11, 'answer': \"haven't\"}\n",
            "{'score': 0.0006352158379741013, 'start': 19, 'end': 32, 'answer': 't be the only'}\n",
            "{'score': 0.0014858009526506066, 'start': 74, 'end': 86, 'answer': 'landmark 777'}\n",
            "{'score': 0.0005528675974346697, 'start': 59, 'end': 103, 'answer': 'Craver, Boeing Commercial Airplanes regional'}\n",
            "{'score': 0.00297618773765862, 'start': 55, 'end': 75, 'answer': 'altitude on its next'}\n",
            "{'score': 0.0007630750769749284, 'start': 204, 'end': 236, 'answer': 'fatigue and shortens the service'}\n",
            "{'score': 0.0025157860945910215, 'start': 57, 'end': 106, 'answer': 'altitude on the 777X without going to a composite'}\n",
            "{'score': 0.00024967186618596315, 'start': 287, 'end': 334, 'answer': 'few local reinforcements and change those loads'}\n",
            "{'score': 0.00782507099211216, 'start': 19, 'end': 39, 'answer': 'set to enter service'}\n",
            "['development of the 787', 'much of the plane out of carbon-fiber reinforced plastics and other composite', \"engineering of the composite airframe may have been a challenge, it's\", 'fatigue,\" Blake', 'most', 'Emery added. \"It\\'s a bit counterintuitive', 'pressure matter', 'appetite', 'afflictions', 'far', 'attributed', 'Oklahoma State', 'discomfort characterized by symptoms similar to those of acute', 'annouced', \"in their blood fall 4%. Although this didn't\", 'reacted at 6,000 feet similar to that at sea level,\" Emery', 'saturation. As result, the body does not', \"there isn't\", \"haven't\", 't be the only', 'landmark 777', 'Craver, Boeing Commercial Airplanes regional', 'altitude on its next', 'fatigue and shortens the service', 'altitude on the 777X without going to a composite', 'few local reinforcements and change those loads', 'set to enter service']\n",
            "{'score': 0.00165206054225564, 'start': 97, 'end': 117, 'answer': '-day festival filled'}\n",
            "{'score': 0.012908960692584515, 'start': 5, 'end': 29, 'answer': 'crucifixion: Philippines'}\n",
            "{'score': 0.0001345840428257361, 'start': 255, 'end': 305, 'answer': 'at least three devotees to wooden crosses in front'}\n",
            "{'score': 0.031193610280752182, 'start': 15, 'end': 26, 'answer': 'New Zealand'}\n",
            "{'score': 0.0002516411477699876, 'start': 274, 'end': 320, 'answer': 'many bunnies as possible. The record currently'}\n",
            "{'score': 0.023416748270392418, 'start': 19, 'end': 24, 'answer': 'Corfu'}\n",
            "{'score': 0.00020184986351523548, 'start': 320, 'end': 382, 'answer': 'was adopted by the islanders and applied to the most important'}\n",
            "{'score': 0.018004313111305237, 'start': 0, 'end': 23, 'answer': 'Inter-church rocket war'}\n",
            "{'score': 0.00013524854148272425, 'start': 307, 'end': 353, 'answer': 'hundreds of homemade rockets at the opposition'}\n",
            "{'score': 0.05107874423265457, 'start': 0, 'end': 19, 'answer': 'Hill burning: Texas'}\n",
            "{'score': 0.0003072679683100432, 'start': 227, 'end': 247, 'answer': 'Easter Fires Pageant'}\n",
            "{'score': 0.02537149377167225, 'start': 0, 'end': 21, 'answer': 'Sprinting Virgin Mary'}\n",
            "{'score': 0.00013211469922680408, 'start': 241, 'end': 245, 'answer': 'Neri'}\n",
            "{'score': 0.02657407708466053, 'start': 6, 'end': 22, 'answer': 'omelette: France'}\n",
            "{'score': 0.00014823432138655335, 'start': 13, 'end': 26, 'answer': 'Haux, Gironde'}\n",
            "{'score': 0.04630563408136368, 'start': 4, 'end': 10, 'answer': 'Monday'}\n",
            "{'score': 0.0003546936495695263, 'start': 99, 'end': 150, 'answer': 'unsuspecting young woman when she answers her front'}\n",
            "{'score': 0.0327196903526783, 'start': 21, 'end': 27, 'answer': 'Sweden'}\n",
            "{'score': 0.0003746911243069917, 'start': 3, 'end': 72, 'answer': 'Maundy Thursday, Swedish children don face paint and grab broomsticks'}\n",
            "['-day festival filled', 'crucifixion: Philippines', 'at least three devotees to wooden crosses in front', 'New Zealand', 'many bunnies as possible. The record currently', 'Corfu', 'was adopted by the islanders and applied to the most important', 'Inter-church rocket war', 'hundreds of homemade rockets at the opposition', 'Hill burning: Texas', 'Easter Fires Pageant', 'Sprinting Virgin Mary', 'Neri', 'omelette: France', 'Haux, Gironde', 'Monday', 'unsuspecting young woman when she answers her front', 'Sweden', 'Maundy Thursday, Swedish children don face paint and grab broomsticks']\n",
            "{'score': 0.0004266363102942705, 'start': 57, 'end': 64, 'answer': 'several'}\n",
            "{'score': 0.003349547041580081, 'start': 71, 'end': 85, 'answer': 'of the project'}\n",
            "{'score': 0.0009959700983017683, 'start': 69, 'end': 80, 'answer': 'was only 57'}\n",
            "{'score': 0.0008162719313986599, 'start': 6, 'end': 31, 'answer': 'looked for a new endeavor'}\n",
            "{'score': 0.000445516750914976, 'start': 193, 'end': 238, 'answer': 'all that tax money should create a sufficient'}\n",
            "{'score': 0.0013776264386251569, 'start': 40, 'end': 83, 'answer': 'are things government doesn’t get to, and B'}\n",
            "{'score': 0.005493349861353636, 'start': 4, 'end': 19, 'answer': 'Ballmer replied'}\n",
            "{'score': 0.0003663795650936663, 'start': 140, 'end': 150, 'answer': 'long vexed'}\n",
            "{'score': 0.00022741650172974914, 'start': 272, 'end': 355, 'answer': 'nonpartisan effort to create a fully integrated look at revenue and spending across'}\n",
            "{'score': 0.00024402447161264718, 'start': 17, 'end': 61, 'answer': 'many police officers are employed in various'}\n",
            "{'score': 0.0018087970092892647, 'start': 42, 'end': 46, 'answer': '10-K'}\n",
            "{'score': 0.00022977343178354204, 'start': 112, 'end': 116, 'answer': '10-K'}\n",
            "{'score': 0.00016497151227667928, 'start': 389, 'end': 448, 'answer': 'lot of bets made during public policy debates at the dinner'}\n",
            "{'score': 0.00030820854590274394, 'start': 3, 'end': 13, 'answer': 'would like'}\n",
            "{'score': 0.0042989179491996765, 'start': 15, 'end': 23, 'answer': 'does one'}\n",
            "{'score': 0.004076551180332899, 'start': 53, 'end': 75, 'answer': 'must have already done'}\n",
            "{'score': 0.0004043764784000814, 'start': 173, 'end': 200, 'answer': 'there’s nothing I’m missing'}\n",
            "{'score': 0.00745056476444006, 'start': 4, 'end': 11, 'answer': 'neither'}\n",
            "{'score': 0.0003078449808526784, 'start': 103, 'end': 150, 'answer': 'don’t care whether I give my money to A, B or C'}\n",
            "{'score': 0.0005351733416318893, 'start': 204, 'end': 215, 'answer': 'more than $'}\n",
            "{'score': 0.0014119144761934876, 'start': 69, 'end': 74, 'answer': 'happy'}\n",
            "{'score': 0.0021251202560961246, 'start': 36, 'end': 46, 'answer': 'been worth'}\n",
            "{'score': 0.000562123314011842, 'start': 1, 'end': 7, 'answer': 'I love'}\n",
            "{'score': 0.0006482473108917475, 'start': 5, 'end': 57, 'answer': 'many people work for government in the United States'}\n",
            "{'score': 0.00023861975932959467, 'start': 112, 'end': 130, 'answer': 'bloated and filled'}\n",
            "{'score': 0.0006110463873483241, 'start': 76, 'end': 93, 'answer': 'Well, active-duty'}\n",
            "{'score': 0.000817777996417135, 'start': 170, 'end': 174, 'answer': 'glad'}\n",
            "{'score': 0.0008228474180214107, 'start': 91, 'end': 98, 'answer': 'somehow'}\n",
            "{'score': 0.03611433133482933, 'start': 4, 'end': 9, 'answer': 'other'}\n",
            "{'score': 0.00029728401568718255, 'start': 1, 'end': 53, 'answer': 'Most of the not-for-profits we work with would be 50'}\n",
            "{'score': 0.00034228494041599333, 'start': 42, 'end': 80, 'answer': 'be completely apolitical. He has given'}\n",
            "{'score': 0.0002902172855101526, 'start': 181, 'end': 189, 'answer': 'mortgage'}\n",
            "{'score': 0.0002837949723470956, 'start': 176, 'end': 189, 'answer': 'hundred bucks'}\n",
            "{'score': 0.0010189458262175322, 'start': 49, 'end': 59, 'answer': 'was to use'}\n",
            "{'score': 0.000884118489921093, 'start': 69, 'end': 138, 'answer': 'many firearms that are in this country? The government is not allowed'}\n",
            "{'score': 0.00031251556356437504, 'start': 147, 'end': 169, 'answer': 'I’m shocked! But the N'}\n",
            "{'score': 0.0009323233389295638, 'start': 65, 'end': 87, 'answer': 'hopes to open it up so'}\n",
            "{'score': 0.00018602536874823272, 'start': 321, 'end': 330, 'answer': 'more than'}\n",
            "['several', 'of the project', 'was only 57', 'looked for a new endeavor', 'all that tax money should create a sufficient', 'are things government doesn’t get to, and B', 'Ballmer replied', 'long vexed', 'nonpartisan effort to create a fully integrated look at revenue and spending across', 'many police officers are employed in various', '10-K', '10-K', 'lot of bets made during public policy debates at the dinner', 'would like', 'does one', 'must have already done', 'there’s nothing I’m missing', 'neither', 'don’t care whether I give my money to A, B or C', 'more than $', 'happy', 'been worth', 'I love', 'many people work for government in the United States', 'bloated and filled', 'Well, active-duty', 'glad', 'somehow', 'other', 'Most of the not-for-profits we work with would be 50', 'be completely apolitical. He has given', 'mortgage', 'hundred bucks', 'was to use', 'many firearms that are in this country? The government is not allowed', 'I’m shocked! But the N', 'hopes to open it up so', 'more than']\n",
            "{'score': 0.0001539530057925731, 'start': 246, 'end': 261, 'answer': 'your usual post'}\n",
            "{'score': 0.005824948661029339, 'start': 38, 'end': 57, 'answer': '-smelling essential'}\n",
            "{'score': 0.0005597363342531025, 'start': 97, 'end': 121, 'answer': 'your favourite essential'}\n",
            "{'score': 0.005268061067909002, 'start': 10, 'end': 30, 'answer': 'the perfect ambience'}\n",
            "{'score': 0.0003435693506617099, 'start': 278, 'end': 288, 'answer': 'are always'}\n",
            "{'score': 0.012151287868618965, 'start': 28, 'end': 30, 'answer': 'be'}\n",
            "{'score': 0.00029130696202628314, 'start': 101, 'end': 164, 'answer': 'on your laptop or phone, do it all away from the bed. Condition'}\n",
            "{'score': 0.01348629966378212, 'start': 18, 'end': 30, 'answer': 'to something'}\n",
            "{'score': 0.0004415758012328297, 'start': 152, 'end': 155, 'answer': 'not'}\n",
            "{'score': 0.021299581974744797, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.0009530315292067826, 'start': 101, 'end': 126, 'answer': 'that would make you happy'}\n",
            "{'score': 0.02838587760925293, 'start': 0, 'end': 1, 'answer': '6'}\n",
            "{'score': 0.0002043452113866806, 'start': 234, 'end': 245, 'answer': 'isn’t super'}\n",
            "{'score': 0.000606017536483705, 'start': 147, 'end': 151, 'answer': 'Most'}\n",
            "{'score': 0.00019619715749286115, 'start': 12, 'end': 19, 'answer': 'to keep'}\n",
            "['your usual post', '-smelling essential', 'your favourite essential', 'the perfect ambience', 'are always', 'be', 'on your laptop or phone, do it all away from the bed. Condition', 'to something', 'not', '5', 'that would make you happy', '6', 'isn’t super', 'Most', 'to keep']\n",
            "{'score': 9.195849997922778e-05, 'start': 487, 'end': 518, 'answer': 'inconveniently sentient Kleenex'}\n",
            "{'score': 5.5568689276697114e-05, 'start': 367, 'end': 401, 'answer': 'bulges her neck. He recalls taking'}\n",
            "{'score': 8.139930287143216e-05, 'start': 221, 'end': 229, 'answer': 'squalid.'}\n",
            "{'score': 0.0001476408215239644, 'start': 78, 'end': 107, 'answer': 'frequents. He finally manages'}\n",
            "{'score': 6.475457485066727e-05, 'start': 477, 'end': 491, 'answer': 'was unfaithful'}\n",
            "{'score': 3.7770107155665755e-05, 'start': 543, 'end': 577, 'answer': 'high school English teacher spends'}\n",
            "{'score': 5.555542520596646e-05, 'start': 617, 'end': 671, 'answer': 'squicky, selfish, and sociopathic inner selves of even'}\n",
            "{'score': 4.9791779019869864e-05, 'start': 207, 'end': 219, 'answer': 'squalor, but'}\n",
            "{'score': 0.042278267443180084, 'start': 0, 'end': 16, 'answer': 'The Bottom Line:'}\n",
            "{'score': 0.0011782631045207381, 'start': 108, 'end': 116, 'answer': 'but self'}\n",
            "{'score': 0.032297320663928986, 'start': 5, 'end': 20, 'answer': 'other reviewers'}\n",
            "{'score': 0.00032459510839544237, 'start': 8, 'end': 18, 'answer': 'York Times'}\n",
            "{'score': 0.00033527554478496313, 'start': 29, 'end': 81, 'answer': 'Homesick for Another World that’s anything less than'}\n",
            "{'score': 0.045011263340711594, 'start': 0, 'end': 12, 'answer': 'Who wrote it'}\n",
            "{'score': 0.00012181991041870788, 'start': 310, 'end': 385, 'answer': 'notoriously confessed to The Guardian that she’d written the book as a joke'}\n",
            "{'score': 0.03064039722084999, 'start': 4, 'end': 13, 'answer': 'will read'}\n",
            "{'score': 0.00218754168599844, 'start': 16, 'end': 82, 'answer': ', provocative fiction starring intensely disagreeable characters ―'}\n",
            "{'score': 0.06572234630584717, 'start': 8, 'end': 14, 'answer': 'lines:'}\n",
            "{'score': 9.753125050337985e-05, 'start': 257, 'end': 268, 'answer': 'was old and'}\n",
            "{'score': 0.06980393081903458, 'start': 0, 'end': 7, 'answer': 'Notable'}\n",
            "{'score': 0.00011041535617550835, 'start': 211, 'end': 271, 'answer': 'thighs appeared, I saw a black stain of blood at her crotch.'}\n",
            "{'score': 0.0022698361426591873, 'start': 2, 'end': 30, 'answer': 'Oh, shit,’ she said when she'}\n",
            "{'score': 0.0019510317360982299, 'start': 38, 'end': 68, 'answer': 'Moshfegh Penguin Press, $26.00'}\n",
            "{'score': 0.002599649364128709, 'start': 21, 'end': 44, 'answer': 'weekly review combining'}\n",
            "['inconveniently sentient Kleenex', 'bulges her neck. He recalls taking', 'squalid.', 'frequents. He finally manages', 'was unfaithful', 'high school English teacher spends', 'squicky, selfish, and sociopathic inner selves of even', 'squalor, but', 'The Bottom Line:', 'but self', 'other reviewers', 'York Times', 'Homesick for Another World that’s anything less than', 'Who wrote it', 'notoriously confessed to The Guardian that she’d written the book as a joke', 'will read', ', provocative fiction starring intensely disagreeable characters ―', 'lines:', 'was old and', 'Notable', 'thighs appeared, I saw a black stain of blood at her crotch.', 'Oh, shit,’ she said when she', 'Moshfegh Penguin Press, $26.00', 'weekly review combining']\n",
            "{'score': 0.0013691309140995145, 'start': 44, 'end': 74, 'answer': 'you probably think Millennials'}\n",
            "{'score': 0.00024682327057234943, 'start': 144, 'end': 180, 'answer': 'nearly three-quarters of Millennials'}\n",
            "{'score': 0.0002870305033866316, 'start': 254, 'end': 273, 'answer': 'nearly as important'}\n",
            "{'score': 0.0039113047532737255, 'start': 5, 'end': 39, 'answer': 'are five crucial moves Millennials'}\n",
            "{'score': 0.03558926656842232, 'start': 10, 'end': 19, 'answer': 'education'}\n",
            "{'score': 0.0009438125416636467, 'start': 0, 'end': 8, 'answer': 'At least'}\n",
            "{'score': 0.0002385107072768733, 'start': 10, 'end': 16, 'answer': 'plenty'}\n",
            "{'score': 0.030022352933883667, 'start': 7, 'end': 20, 'answer': 'hello to risk'}\n",
            "{'score': 0.0005276204319670796, 'start': 65, 'end': 112, 'answer': 'always comes through in a pinch. There might be'}\n",
            "{'score': 0.00033385149436071515, 'start': 73, 'end': 97, 'answer': 'that require you to take'}\n",
            "{'score': 0.00012719389633275568, 'start': 163, 'end': 213, 'answer': '100% bonds returned roughly half that, averaging 5'}\n",
            "{'score': 0.00012793365749530494, 'start': 66, 'end': 79, 'answer': 'as much as 70'}\n",
            "{'score': 0.015206217765808105, 'start': 3, 'end': 7, 'answer': 'Take'}\n",
            "{'score': 0.0003173869918100536, 'start': 21, 'end': 78, 'answer': 'reasonable stock allocation for your retirement portfolio'}\n",
            "{'score': 0.00046701738028787076, 'start': 39, 'end': 91, 'answer': 'many different investments in one swoop. You can buy'}\n",
            "{'score': 0.0024912776425480843, 'start': 0, 'end': 57, 'answer': 'You can learn more about building a diversified portfolio'}\n",
            "{'score': 0.021138640120625496, 'start': 0, 'end': 1, 'answer': '4'}\n",
            "{'score': 0.0006066581699997187, 'start': 185, 'end': 196, 'answer': 'in your 401'}\n",
            "{'score': 0.0002708123065531254, 'start': 283, 'end': 314, 'answer': 'more than 0.25%, you can likely'}\n",
            "{'score': 0.007388584781438112, 'start': 0, 'end': 31, 'answer': '5. Use a Roth IRA or a Roth 401'}\n",
            "{'score': 0.00027081824373453856, 'start': 0, 'end': 34, 'answer': 'Contributions to a traditional 401'}\n",
            "{'score': 0.0002196456480305642, 'start': 34, 'end': 51, 'answer': 'is lower now than'}\n",
            "['you probably think Millennials', 'nearly three-quarters of Millennials', 'nearly as important', 'are five crucial moves Millennials', 'education', 'At least', 'plenty', 'hello to risk', 'always comes through in a pinch. There might be', 'that require you to take', '100% bonds returned roughly half that, averaging 5', 'as much as 70', 'Take', 'reasonable stock allocation for your retirement portfolio', 'many different investments in one swoop. You can buy', 'You can learn more about building a diversified portfolio', '4', 'in your 401', 'more than 0.25%, you can likely', '5. Use a Roth IRA or a Roth 401', 'Contributions to a traditional 401', 'is lower now than']\n",
            "{'score': 0.00017336837481707335, 'start': 290, 'end': 316, 'answer': 'some as a means to provide'}\n",
            "{'score': 0.00029559110407717526, 'start': 44, 'end': 86, 'answer': 'less job security,\" says Matthew Krisiloff'}\n",
            "{'score': 0.009029616601765156, 'start': 12, 'end': 37, 'answer': 'you should know about UBI'}\n",
            "{'score': 0.02364388480782509, 'start': 0, 'end': 7, 'answer': 'What is'}\n",
            "{'score': 0.0009636183967813849, 'start': 7, 'end': 11, 'answer': 'most'}\n",
            "{'score': 0.0002538599947001785, 'start': 307, 'end': 348, 'answer': 'everyone gets a check from the government'}\n",
            "{'score': 0.031244657933712006, 'start': 4, 'end': 6, 'answer': 'is'}\n",
            "{'score': 0.00022372826060745865, 'start': 140, 'end': 162, 'answer': 'redistribute wealth to'}\n",
            "{'score': 0.0002602773020043969, 'start': 8, 'end': 82, 'answer': 'sporadic support on both sides of the aisle, UBI has historically remained'}\n",
            "{'score': 5.508123285835609e-05, 'start': 527, 'end': 539, 'answer': 'persistently'}\n",
            "{'score': 0.024619830772280693, 'start': 3, 'end': 17, 'answer': 'anyone getting'}\n",
            "{'score': 0.0001772725663613528, 'start': 0, 'end': 55, 'answer': 'No nation has implemented a universal basic income, but'}\n",
            "{'score': 0.00026007540873251855, 'start': 2, 'end': 24, 'answer': 'Combinator’s Krisiloff'}\n",
            "['some as a means to provide', 'less job security,\" says Matthew Krisiloff', 'you should know about UBI', 'What is', 'most', 'everyone gets a check from the government', 'is', 'redistribute wealth to', 'sporadic support on both sides of the aisle, UBI has historically remained', 'persistently', 'anyone getting', 'No nation has implemented a universal basic income, but', 'Combinator’s Krisiloff']\n",
            "{'score': 0.024045689031481743, 'start': 8, 'end': 11, 'answer': 'DLC'}\n",
            "{'score': 0.0003327552112750709, 'start': 35, 'end': 66, 'answer': 'well for big developers like CD'}\n",
            "{'score': 5.810659422422759e-05, 'start': 292, 'end': 352, 'answer': '053 reviews on Steam, of which 90 percent are positive. is a'}\n",
            "{'score': 0.0001639906404307112, 'start': 300, 'end': 332, 'answer': 'developers decided its major DLC'}\n",
            "{'score': 0.00037888059159740806, 'start': 58, 'end': 104, 'answer': 'which included 70 new events, a new main quest'}\n",
            "{'score': 0.00020992261124774814, 'start': 269, 'end': 305, 'answer': 'were usually selling without the DLC'}\n",
            "{'score': 0.172707661986351, 'start': 0, 'end': 9, 'answer': 'Sponsored'}\n",
            "{'score': 0.0001872466382337734, 'start': 362, 'end': 379, 'answer': 'was disheartening'}\n",
            "{'score': 0.0002031161420745775, 'start': 270, 'end': 307, 'answer': 'their friends,\" the developers wrote,'}\n",
            "{'score': 0.1075354516506195, 'start': 0, 'end': 3, 'answer': 'For'}\n",
            "{'score': 0.0005640040617436171, 'start': 57, 'end': 70, 'answer': 'more tactical'}\n",
            "{'score': 0.00015901036385912448, 'start': 376, 'end': 424, 'answer': 'we still think combining the two was the jackpot'}\n",
            "{'score': 0.0002001063257921487, 'start': 52, 'end': 79, 'answer': 'well, not really DLC at all'}\n",
            "{'score': 0.001184771885164082, 'start': 112, 'end': 117, 'answer': 'to be'}\n",
            "{'score': 8.38731721160002e-05, 'start': 240, 'end': 255, 'answer': 'lot of emphasis'}\n",
            "['DLC', 'well for big developers like CD', '053 reviews on Steam, of which 90 percent are positive. is a', 'developers decided its major DLC', 'which included 70 new events, a new main quest', 'were usually selling without the DLC', 'Sponsored', 'was disheartening', 'their friends,\" the developers wrote,', 'For', 'more tactical', 'we still think combining the two was the jackpot', 'well, not really DLC at all', 'to be', 'lot of emphasis']\n",
            "{'score': 0.00039345299592241645, 'start': 4, 'end': 70, 'answer': \"of the most consistent criticisms of Mad Men from those who aren't\"}\n",
            "{'score': 0.00022561333025805652, 'start': 197, 'end': 223, 'answer': \"Idov argued that it wasn't\"}\n",
            "{'score': 0.00012319440429564565, 'start': 207, 'end': 239, 'answer': 'few times — a much more perilous'}\n",
            "{'score': 0.0008073061471804976, 'start': 7, 'end': 24, 'answer': 'there are a bunch'}\n",
            "{'score': 0.015453553758561611, 'start': 1, 'end': 10, 'answer': ') Readers'}\n",
            "{'score': 0.00019551542936824262, 'start': 312, 'end': 340, 'answer': 'well-timed thinkpiece always'}\n",
            "{'score': 0.0010131398448720574, 'start': 21, 'end': 57, 'answer': 'overlaps so neatly with the audience'}\n",
            "{'score': 0.00017535180086269975, 'start': 142, 'end': 191, 'answer': \"far beyond any other show I've written about here\"}\n",
            "{'score': 0.0003994530125055462, 'start': 148, 'end': 192, 'answer': 'was also driven by the fact that our readers'}\n",
            "{'score': 0.0040376316756010056, 'start': 3, 'end': 60, 'answer': 'Mad Men debuted right after The Sopranos ended and filled'}\n",
            "{'score': 0.00016887488891370595, 'start': 73, 'end': 133, 'answer': 'few weeks before. The Wire (never as popular in terms of raw'}\n",
            "{'score': 0.005609701853245497, 'start': 13, 'end': 64, 'answer': 'benefitted from the rise of TV recapping in general'}\n",
            "{'score': 0.0002313808654434979, 'start': 156, 'end': 175, 'answer': 'surely as it filled'}\n",
            "{'score': 0.00017948079039342701, 'start': 318, 'end': 321, 'answer': 'fit'}\n",
            "{'score': 0.008556910790503025, 'start': 14, 'end': 20, 'answer': \"wasn't\"}\n",
            "{'score': 0.00019479836919344962, 'start': 212, 'end': 252, 'answer': 'Mad Men and later Breaking Bad picked up'}\n",
            "{'score': 9.313951159128919e-05, 'start': 155, 'end': 231, 'answer': 'in-depth reviews of comedies (a later development, largely driven by content'}\n",
            "{'score': 0.0023055807687342167, 'start': 0, 'end': 49, 'answer': 'Mad Men suggested every cable channel should have'}\n",
            "{'score': 9.762334229890257e-05, 'start': 351, 'end': 355, 'answer': 'much'}\n",
            "{'score': 0.004912703763693571, 'start': 11, 'end': 57, 'answer': 'was actually pretty popular, when all was said'}\n",
            "{'score': 0.00021206113160587847, 'start': 306, 'end': 321, 'answer': 'enough to drive'}\n",
            "{'score': 0.02009095996618271, 'start': 9, 'end': 22, 'answer': 'underestimate'}\n",
            "{'score': 0.0002228873927379027, 'start': 288, 'end': 356, 'answer': 'very few casual Mad Men fans. And those passionate fans tend to seek'}\n",
            "{'score': 0.005918511655181646, 'start': 31, 'end': 48, 'answer': 'Mad Men as a sort'}\n",
            "{'score': 0.00010929053678410128, 'start': 351, 'end': 377, 'answer': 'might have been a bit much'}\n",
            "{'score': 0.0005122924922034144, 'start': 129, 'end': 135, 'answer': 'do too'}\n",
            "{'score': 0.00022361167066264898, 'start': 186, 'end': 190, 'answer': 'even'}\n",
            "[\"of the most consistent criticisms of Mad Men from those who aren't\", \"Idov argued that it wasn't\", 'few times — a much more perilous', 'there are a bunch', ') Readers', 'well-timed thinkpiece always', 'overlaps so neatly with the audience', \"far beyond any other show I've written about here\", 'was also driven by the fact that our readers', 'Mad Men debuted right after The Sopranos ended and filled', 'few weeks before. The Wire (never as popular in terms of raw', 'benefitted from the rise of TV recapping in general', 'surely as it filled', 'fit', \"wasn't\", 'Mad Men and later Breaking Bad picked up', 'in-depth reviews of comedies (a later development, largely driven by content', 'Mad Men suggested every cable channel should have', 'much', 'was actually pretty popular, when all was said', 'enough to drive', 'underestimate', 'very few casual Mad Men fans. And those passionate fans tend to seek', 'Mad Men as a sort', 'might have been a bit much', 'do too', 'even']\n",
            "{'score': 0.0012510753003880382, 'start': 53, 'end': 95, 'answer': 'to getting information on eating to manage'}\n",
            "{'score': 0.0031158262863755226, 'start': 48, 'end': 82, 'answer': 'that tested the impact of specific'}\n",
            "{'score': 0.0010430148104205728, 'start': 88, 'end': 108, 'answer': 'in plants) and olive'}\n",
            "{'score': 0.0012198116164654493, 'start': 85, 'end': 108, 'answer': 'cholesterol (called LDL'}\n",
            "{'score': 0.001206092070788145, 'start': 81, 'end': 85, 'answer': 'Over'}\n",
            "{'score': 0.023820050060749054, 'start': 1, 'end': 6, 'answer': '. Eat'}\n",
            "{'score': 0.0015217161271721125, 'start': 43, 'end': 62, 'answer': 'kidney beans, chick'}\n",
            "{'score': 0.00272071803919971, 'start': 47, 'end': 81, 'answer': 'fewer than one in five Australians'}\n",
            "{'score': 0.0009098732843995094, 'start': 18, 'end': 53, 'answer': 'randomised control trials (the gold'}\n",
            "{'score': 0.002343448344618082, 'start': 32, 'end': 48, 'answer': 'was reduced by 5'}\n",
            "{'score': 0.0022580474615097046, 'start': 39, 'end': 44, 'answer': 'about'}\n",
            "{'score': 0.0028937403112649918, 'start': 48, 'end': 88, 'answer': 'They lower blood cholesterol in a number'}\n",
            "{'score': 0.0011403681710362434, 'start': 54, 'end': 107, 'answer': 'cholesterol absorption in the gut, while they promote'}\n",
            "{'score': 0.0015571084804832935, 'start': 107, 'end': 129, 'answer': \"they're part of a meal\"}\n",
            "{'score': 0.006787044461816549, 'start': 13, 'end': 32, 'answer': 'sterols, margarines'}\n",
            "{'score': 0.0012685173423960805, 'start': 80, 'end': 97, 'answer': 'are found in some'}\n",
            "{'score': 0.002398531883955002, 'start': 0, 'end': 21, 'answer': 'They are concentrated'}\n",
            "{'score': 0.0005311343120411038, 'start': 143, 'end': 166, 'answer': 'prawns, and cholesterol'}\n",
            "{'score': 0.002922617131844163, 'start': 34, 'end': 43, 'answer': 'the total'}\n",
            "{'score': 0.0017482915427535772, 'start': 71, 'end': 98, 'answer': '10 percent reduction in LDL'}\n",
            "{'score': 0.006885081063956022, 'start': 34, 'end': 61, 'answer': 'are mixed with is important'}\n",
            "{'score': 0.00027330763987265527, 'start': 194, 'end': 218, 'answer': 'were added to margarines'}\n",
            "{'score': 0.04522668942809105, 'start': 1, 'end': 6, 'answer': '. Eat'}\n",
            "{'score': 0.001547012128867209, 'start': 38, 'end': 85, 'answer': 'the amounts of polyunsaturated, monounsaturated'}\n",
            "{'score': 0.0007085348479449749, 'start': 15, 'end': 63, 'answer': '25 intervention trials, eating approximately 67g'}\n",
            "{'score': 0.0021799872629344463, 'start': 47, 'end': 55, 'answer': 'the more'}\n",
            "{'score': 0.0034959157928824425, 'start': 54, 'end': 62, 'answer': 'were not'}\n",
            "{'score': 0.0007895198068581522, 'start': 68, 'end': 74, 'answer': '1600kJ'}\n",
            "{'score': 0.035709526389837265, 'start': 0, 'end': 6, 'answer': '4. Use'}\n",
            "{'score': 0.001365190022625029, 'start': 111, 'end': 147, 'answer': 'a high proportion of monounsaturated'}\n",
            "{'score': 0.001022685901261866, 'start': 0, 'end': 12, 'answer': 'More than 80'}\n",
            "{'score': 0.0004770109080709517, 'start': 162, 'end': 189, 'answer': 'oxidised LDL (a type of LDL'}\n",
            "{'score': 0.0004950208822265267, 'start': 51, 'end': 121, 'answer': ',400 men and women at high risk of heart disease to follow three diets'}\n",
            "{'score': 0.0010988658759742975, 'start': 22, 'end': 78, 'answer': '-up, those in both the olive oil and nut groups had a 30'}\n",
            "{'score': 0.0006152474670670927, 'start': 41, 'end': 67, 'answer': 'randomised to substitute 4'}\n",
            "{'score': 0.002145156729966402, 'start': 24, 'end': 43, 'answer': 'cholesterol and LDL'}\n",
            "{'score': 0.001205984503030777, 'start': 39, 'end': 90, 'answer': 'had high blood cholesterol to start with. Switching'}\n",
            "{'score': 0.03415284678339958, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.0008078820537775755, 'start': 30, 'end': 56, 'answer': 'were able to make a number'}\n",
            "{'score': 0.0014369910350069404, 'start': 113, 'end': 120, 'answer': 'a wider'}\n",
            "{'score': 0.002887188922613859, 'start': 38, 'end': 68, 'answer': 'They lowered their cholesterol'}\n",
            "{'score': 0.0007355110719799995, 'start': 29, 'end': 44, 'answer': 'in diet quality'}\n",
            "{'score': 0.003211413975805044, 'start': 26, 'end': 36, 'answer': '-up almost'}\n",
            "{'score': 0.0013094512978568673, 'start': 10, 'end': 73, 'answer': 'had the biggest improvement in their diet quality score had a 7'}\n",
            "{'score': 0.0023930727038532495, 'start': 111, 'end': 118, 'answer': 'your GP'}\n",
            "['to getting information on eating to manage', 'that tested the impact of specific', 'in plants) and olive', 'cholesterol (called LDL', 'Over', '. Eat', 'kidney beans, chick', 'fewer than one in five Australians', 'randomised control trials (the gold', 'was reduced by 5', 'about', 'They lower blood cholesterol in a number', 'cholesterol absorption in the gut, while they promote', \"they're part of a meal\", 'sterols, margarines', 'are found in some', 'They are concentrated', 'prawns, and cholesterol', 'the total', '10 percent reduction in LDL', 'are mixed with is important', 'were added to margarines', '. Eat', 'the amounts of polyunsaturated, monounsaturated', '25 intervention trials, eating approximately 67g', 'the more', 'were not', '1600kJ', '4. Use', 'a high proportion of monounsaturated', 'More than 80', 'oxidised LDL (a type of LDL', ',400 men and women at high risk of heart disease to follow three diets', '-up, those in both the olive oil and nut groups had a 30', 'randomised to substitute 4', 'cholesterol and LDL', 'had high blood cholesterol to start with. Switching', '5', 'were able to make a number', 'a wider', 'They lowered their cholesterol', 'in diet quality', '-up almost', 'had the biggest improvement in their diet quality score had a 7', 'your GP']\n",
            "{'score': 0.0029778298921883106, 'start': 1, 'end': 41, 'answer': \"I don't watch the news, because it's too\"}\n",
            "{'score': 0.0016230839537456632, 'start': 52, 'end': 67, 'answer': 'might just need'}\n",
            "{'score': 0.0022174513433128595, 'start': 10, 'end': 68, 'answer': \"our pick of the year's most heartening stories — get ready\"}\n",
            "{'score': 0.001064586453139782, 'start': 15, 'end': 29, 'answer': 'Gallego is not'}\n",
            "{'score': 0.0011279403697699308, 'start': 12, 'end': 36, 'answer': 'Gallego has performed at'}\n",
            "{'score': 0.001222610124386847, 'start': 98, 'end': 101, 'answer': 'six'}\n",
            "{'score': 0.0006145656225271523, 'start': 89, 'end': 125, 'answer': 'had already decided they would spend'}\n",
            "{'score': 0.0007034160080365837, 'start': 69, 'end': 97, 'answer': 'on the ground after the east'}\n",
            "{'score': 0.0004920444334857166, 'start': 98, 'end': 176, 'answer': 'when the iconic little Australian was rescued — and named after rescuer Louise'}\n",
            "{'score': 0.0009307442232966423, 'start': 123, 'end': 158, 'answer': 'there was anything they could learn'}\n",
            "{'score': 0.0005605976912193, 'start': 162, 'end': 191, 'answer': 'in a remote part of the state'}\n",
            "{'score': 0.0006560672190971673, 'start': 8, 'end': 54, 'answer': \"that one day it gets to a point where it's not\"}\n",
            "{'score': 0.0008931134361773729, 'start': 42, 'end': 125, 'answer': \"Queensland locals started Australia's first integrated, edible streetscape in a bid\"}\n",
            "{'score': 0.0006955431890673935, 'start': 31, 'end': 80, 'answer': 'lined street is now an 11-street suburban enclave'}\n",
            "{'score': 0.001433075754903257, 'start': 15, 'end': 42, 'answer': 'flamboyant garments may not'}\n",
            "{'score': 0.000927434884943068, 'start': 106, 'end': 129, 'answer': 'when she was in her 40s'}\n",
            "{'score': 0.005702516064047813, 'start': 5, 'end': 35, 'answer': 'it comes to clothes, her motto'}\n",
            "{'score': 0.0009940983727574348, 'start': 39, 'end': 46, 'answer': 'may not'}\n",
            "{'score': 0.0013390473322942853, 'start': 55, 'end': 72, 'answer': ', and he captured'}\n",
            "{'score': 0.0015672545414417982, 'start': 47, 'end': 133, 'answer': \"'s first free mobile laundry for the homeless launched their second charitable venture\"}\n",
            "{'score': 0.001345844124443829, 'start': 35, 'end': 62, 'answer': 'Marchesi and Lucas Patchett'}\n",
            "{'score': 0.0011170358629897237, 'start': 15, 'end': 27, 'answer': 'was trialled'}\n",
            "{'score': 0.0009652029839344323, 'start': 86, 'end': 92, 'answer': 'bloody'}\n",
            "[\"I don't watch the news, because it's too\", 'might just need', \"our pick of the year's most heartening stories — get ready\", 'Gallego is not', 'Gallego has performed at', 'six', 'had already decided they would spend', 'on the ground after the east', 'when the iconic little Australian was rescued — and named after rescuer Louise', 'there was anything they could learn', 'in a remote part of the state', \"that one day it gets to a point where it's not\", \"Queensland locals started Australia's first integrated, edible streetscape in a bid\", 'lined street is now an 11-street suburban enclave', 'flamboyant garments may not', 'when she was in her 40s', 'it comes to clothes, her motto', 'may not', ', and he captured', \"'s first free mobile laundry for the homeless launched their second charitable venture\", 'Marchesi and Lucas Patchett', 'was trialled', 'bloody']\n",
            "{'score': 0.0007951759616844356, 'start': 129, 'end': 172, 'answer': 'have been discovered which may cause owners'}\n",
            "{'score': 0.0014021353563293815, 'start': 1, 'end': 45, 'answer': 'Great Features’ and ‘Nasty Surprises’ are my'}\n",
            "{'score': 0.015438718721270561, 'start': 0, 'end': 14, 'answer': 'Nasty Surprise'}\n",
            "{'score': 0.0004990342422388494, 'start': 141, 'end': 186, 'answer': 'durability tests and claims Apple has ditched'}\n",
            "{'score': 0.00031255630892701447, 'start': 27, 'end': 45, 'answer': 'JerryRigEverything'}\n",
            "{'score': 0.003497891826555133, 'start': 27, 'end': 64, 'answer': 'sure that it is regular glass and not'}\n",
            "{'score': 0.00021840533008798957, 'start': 171, 'end': 229, 'answer': 'toughened glass) on the home button and camera lens. Given'}\n",
            "{'score': 0.0009832379873842, 'start': 32, 'end': 99, 'answer': 'not tested the iPhone 7 Plus we cannot make assumptions here. Being'}\n",
            "{'score': 0.009382752701640129, 'start': 0, 'end': 16, 'answer': 'Nasty Surprise #'}\n",
            "{'score': 0.0009826966561377048, 'start': 87, 'end': 91, 'answer': 'Myke'}\n",
            "{'score': 0.0004325675836298615, 'start': 27, 'end': 80, 'answer': 'not react should you be wearing standard gloves since'}\n",
            "{'score': 0.0028147264383733273, 'start': 7, 'end': 37, 'answer': 'right, you get nothing. Hardly'}\n",
            "{'score': 0.00027012615464627743, 'start': 176, 'end': 213, 'answer': 'capacitive touchscreens respond (note'}\n",
            "{'score': 0.0009361958364024758, 'start': 23, 'end': 67, 'answer': \"AssistiveTouch, though that's primarily used\"}\n",
            "{'score': 0.019839314743876457, 'start': 0, 'end': 8, 'answer': 'Designed'}\n",
            "{'score': 0.0021719832438975573, 'start': 4, 'end': 19, 'answer': 'of which leaves'}\n",
            "{'score': 0.0003264551633037627, 'start': 295, 'end': 301, 'answer': 'iFixit'}\n",
            "{'score': 0.0007903664372861385, 'start': 65, 'end': 135, 'answer': 'utilise the additional space the headphone jack used. Personally a far'}\n",
            "{'score': 0.0002345362736377865, 'start': 142, 'end': 145, 'answer': '10x'}\n",
            "{'score': 0.0016012816922739148, 'start': 56, 'end': 96, 'answer': 'were increased compared to the iPhone 6S'}\n",
            "{'score': 0.0005971565842628479, 'start': 57, 'end': 90, 'answer': 'most notably in the iPhone 7 Plus'}\n",
            "{'score': 0.06260666251182556, 'start': 1, 'end': 2, 'answer': '_'}\n",
            "{'score': 0.08866628259420395, 'start': 0, 'end': 14, 'answer': 'More On Forbes'}\n",
            "{'score': 0.018034541979432106, 'start': 20, 'end': 32, 'answer': 'Great Secret'}\n",
            "{'score': 0.0077865589410066605, 'start': 10, 'end': 12, 'answer': '10'}\n",
            "{'score': 0.015240329317748547, 'start': 26, 'end': 38, 'answer': 'Great Secret'}\n",
            "{'score': 0.006847772281616926, 'start': 19, 'end': 25, 'answer': '7 Plus'}\n",
            "{'score': 0.006974581629037857, 'start': 7, 'end': 21, 'answer': '7 Vs iPhone 6S'}\n",
            "['have been discovered which may cause owners', 'Great Features’ and ‘Nasty Surprises’ are my', 'Nasty Surprise', 'durability tests and claims Apple has ditched', 'JerryRigEverything', 'sure that it is regular glass and not', 'toughened glass) on the home button and camera lens. Given', 'not tested the iPhone 7 Plus we cannot make assumptions here. Being', 'Nasty Surprise #', 'Myke', 'not react should you be wearing standard gloves since', 'right, you get nothing. Hardly', 'capacitive touchscreens respond (note', \"AssistiveTouch, though that's primarily used\", 'Designed', 'of which leaves', 'iFixit', 'utilise the additional space the headphone jack used. Personally a far', '10x', 'were increased compared to the iPhone 6S', 'most notably in the iPhone 7 Plus', '_', 'More On Forbes', 'Great Secret', '10', 'Great Secret', '7 Plus', '7 Vs iPhone 6S']\n",
            "{'score': 0.0017646196065470576, 'start': 3, 'end': 40, 'answer': 'the summer of 1996 after my sophomore'}\n",
            "{'score': 0.0007913919980637729, 'start': 48, 'end': 109, 'answer': 'had no idea what to expect. I asked my father and a professor'}\n",
            "{'score': 0.01710442267358303, 'start': 17, 'end': 23, 'answer': 'on who'}\n",
            "{'score': 0.0002658986777532846, 'start': 125, 'end': 156, 'answer': 'looking to connect with someone'}\n",
            "{'score': 0.008034180849790573, 'start': 13, 'end': 47, 'answer': 'your network of contacts, remember'}\n",
            "{'score': 0.0003354577929712832, 'start': 192, 'end': 233, 'answer': 'snail mail holiday cards to former bosses'}\n",
            "{'score': 0.01429804041981697, 'start': 0, 'end': 18, 'answer': 'In a new situation'}\n",
            "{'score': 0.0001970889134099707, 'start': 165, 'end': 176, 'answer': 'hierarchies'}\n",
            "{'score': 0.023233562707901, 'start': 6, 'end': 9, 'answer': 'for'}\n",
            "{'score': 0.00012045286712236702, 'start': 314, 'end': 339, 'answer': 'notch with tailored suits'}\n",
            "{'score': 0.015227263793349266, 'start': 14, 'end': 44, 'answer': 'willing to learn from any task'}\n",
            "{'score': 0.00018653422011993825, 'start': 115, 'end': 185, 'answer': 'were paid for the privilege of watching and learning as the higher-ups'}\n",
            "{'score': 0.0070443288423120975, 'start': 11, 'end': 14, 'answer': 'not'}\n",
            "{'score': 0.0003448988136369735, 'start': 127, 'end': 173, 'answer': 'my managers were aware of how my contributions'}\n",
            "{'score': 0.021094638854265213, 'start': 2, 'end': 41, 'answer': 'bad attitude will break your reputation'}\n",
            "{'score': 0.00024202729400712997, 'start': 41, 'end': 99, 'answer': 'frowned upon, and despite claims of a kinder, gentler 21st'}\n",
            "{'score': 0.016863271594047546, 'start': 0, 'end': 4, 'answer': 'Take'}\n",
            "{'score': 0.00015425009769387543, 'start': 402, 'end': 429, 'answer': 'will be responsible for 100'}\n",
            "{'score': 0.007172867190092802, 'start': 3, 'end': 28, 'answer': 'you want to keep a secret'}\n",
            "{'score': 0.00020712974946945906, 'start': 171, 'end': 198, 'answer': 'would share it with someone'}\n",
            "{'score': 0.02810334786772728, 'start': 3, 'end': 23, 'answer': 'respectful of others'}\n",
            "{'score': 0.00014753210416529328, 'start': 69, 'end': 144, 'answer': 'politely for networking conversations and check-in meetings with our bosses'}\n",
            "['the summer of 1996 after my sophomore', 'had no idea what to expect. I asked my father and a professor', 'on who', 'looking to connect with someone', 'your network of contacts, remember', 'snail mail holiday cards to former bosses', 'In a new situation', 'hierarchies', 'for', 'notch with tailored suits', 'willing to learn from any task', 'were paid for the privilege of watching and learning as the higher-ups', 'not', 'my managers were aware of how my contributions', 'bad attitude will break your reputation', 'frowned upon, and despite claims of a kinder, gentler 21st', 'Take', 'will be responsible for 100', 'you want to keep a secret', 'would share it with someone', 'respectful of others', 'politely for networking conversations and check-in meetings with our bosses']\n",
            "{'score': 0.006833833176642656, 'start': 23, 'end': 39, 'answer': 'most spectacular'}\n",
            "{'score': 0.006705376785248518, 'start': 19, 'end': 28, 'answer': 'we missed'}\n",
            "{'score': 0.023774564266204834, 'start': 10, 'end': 23, 'answer': 'of Modern Art'}\n",
            "{'score': 0.00020149494230281562, 'start': 34, 'end': 47, 'answer': 'glassy Yoshio'}\n",
            "{'score': 0.025520000606775284, 'start': 8, 'end': 12, 'answer': 'moma'}\n",
            "{'score': 0.024798862636089325, 'start': 3, 'end': 15, 'answer': 'Metropolitan'}\n",
            "{'score': 0.0010942614171653986, 'start': 67, 'end': 106, 'answer': 'you don’t narrow your focus. Don’t miss'}\n",
            "{'score': 0.02216053381562233, 'start': 8, 'end': 17, 'answer': 'metmuseum'}\n",
            "{'score': 0.07024255394935608, 'start': 3, 'end': 13, 'answer': 'Guggenheim'}\n",
            "{'score': 0.00026145961601287127, 'start': 213, 'end': 271, 'answer': 'in a constantly evolving collection of impressionist, post'}\n",
            "{'score': 0.009426997974514961, 'start': 41, 'end': 52, 'answer': 'York expert'}\n",
            "{'score': 0.014630848541855812, 'start': 0, 'end': 14, 'answer': '4. The Whitney'}\n",
            "{'score': 9.465774201089516e-05, 'start': 506, 'end': 511, 'answer': 'range'}\n",
            "{'score': 0.033230677247047424, 'start': 9, 'end': 16, 'answer': 'whitney'}\n",
            "{'score': 0.034755636006593704, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.00013529903662856668, 'start': 348, 'end': 415, 'answer': 'artefacts and French neoclassical and Romantic painting. The secret'}\n",
            "{'score': 0.03246866539120674, 'start': 8, 'end': 17, 'answer': 'louvre.fr'}\n",
            "{'score': 0.02199973165988922, 'start': 4, 'end': 15, 'answer': '20 greatest'}\n",
            "{'score': 0.011422484181821346, 'start': 9, 'end': 18, 'answer': 'Marmottan'}\n",
            "{'score': 0.0004399787576403469, 'start': 28, 'end': 31, 'answer': 'one'}\n",
            "{'score': 0.02131851390004158, 'start': 9, 'end': 18, 'answer': 'marmottan'}\n",
            "{'score': 0.004200211260467768, 'start': 16, 'end': 21, 'answer': 'Koons'}\n",
            "{'score': 0.02667371742427349, 'start': 0, 'end': 8, 'answer': '7. Musée'}\n",
            "{'score': 0.00021276769984979182, 'start': 69, 'end': 79, 'answer': 'unrivalled'}\n",
            "{'score': 0.01503581739962101, 'start': 15, 'end': 20, 'answer': 'rodin'}\n",
            "{'score': 0.011348506435751915, 'start': 10, 'end': 28, 'answer': 'Edwards, Telegraph'}\n",
            "{'score': 0.05110279843211174, 'start': 0, 'end': 1, 'answer': '8'}\n",
            "{'score': 0.00022634875494986773, 'start': 161, 'end': 214, 'answer': 'there’s plenty to enjoy along the way, from classical'}\n",
            "{'score': 0.03143391013145447, 'start': 17, 'end': 19, 'answer': 'va'}\n",
            "{'score': 0.024467259645462036, 'start': 3, 'end': 11, 'answer': 'Galleria'}\n",
            "{'score': 0.00024524718173779547, 'start': 273, 'end': 283, 'answer': 'worthwhile'}\n",
            "{'score': 0.016814997419714928, 'start': 8, 'end': 24, 'answer': 'galleriaborghese'}\n",
            "{'score': 0.010905948467552662, 'start': 2, 'end': 14, 'answer': 'Lee Marshall'}\n",
            "{'score': 0.02636057510972023, 'start': 6, 'end': 23, 'answer': 'free things to do'}\n",
            "{'score': 0.057827334851026535, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 7.435172301484272e-05, 'start': 143, 'end': 165, 'answer': 'on the edge of Holland'}\n",
            "{'score': 0.022992601618170738, 'start': 9, 'end': 21, 'answer': 'designmuseum'}\n",
            "{'score': 0.01373105589300394, 'start': 0, 'end': 7, 'answer': '11. Sir'}\n",
            "{'score': 0.00023706995125394315, 'start': 211, 'end': 257, 'answer': 'interlocking rooms on different levels crammed'}\n",
            "{'score': 0.00035361279151402414, 'start': 67, 'end': 95, 'answer': 'hoarding mentality of a pack'}\n",
            "{'score': 0.01762388087809086, 'start': 26, 'end': 33, 'answer': 'Dorment'}\n",
            "{'score': 0.020752187818288803, 'start': 0, 'end': 32, 'answer': '12. The Victoria & Albert Museum'}\n",
            "{'score': 0.00044891724246554077, 'start': 207, 'end': 302, 'answer': 'courtyard entrance and underground gallery forming part of the Exhibition Road Building Project'}\n",
            "{'score': 8.154602255672216e-05, 'start': 25, 'end': 104, 'answer': 'Courtyard will be through the arches of the 19th-century screen designed by Sir'}\n",
            "{'score': 0.00019842760229948908, 'start': 256, 'end': 286, 'answer': '10pm (Saturday as well at Tate'}\n",
            "{'score': 0.009276929311454296, 'start': 0, 'end': 6, 'answer': 'Secret'}\n",
            "{'score': 0.03718823194503784, 'start': 0, 'end': 9, 'answer': '13. Prado'}\n",
            "{'score': 0.0002821684174705297, 'start': 215, 'end': 236, 'answer': 'Titian and Tintoretto'}\n",
            "{'score': 0.016405072063207626, 'start': 9, 'end': 22, 'answer': 'museodelprado'}\n",
            "{'score': 0.01977694034576416, 'start': 28, 'end': 33, 'answer': 'Prado'}\n",
            "{'score': 0.000424233207013458, 'start': 95, 'end': 166, 'answer': 'late 2010, with new displays on the fourth floor. Picasso’s masterpiece'}\n",
            "{'score': 0.01375388354063034, 'start': 9, 'end': 24, 'answer': 'museoreinasofia'}\n",
            "{'score': 0.0003563973878044635, 'start': 0, 'end': 34, 'answer': 'Superlative collections of Western'}\n",
            "{'score': 0.022118667140603065, 'start': 9, 'end': 21, 'answer': 'museothyssen'}\n",
            "{'score': 0.009800534695386887, 'start': 33, 'end': 49, 'answer': '’s Madrid expert'}\n",
            "{'score': 0.00020543718710541725, 'start': 160, 'end': 208, 'answer': 'many more are on show alongside centuries’ worth'}\n",
            "{'score': 0.013647444546222687, 'start': 9, 'end': 20, 'answer': 'rijksmuseum'}\n",
            "{'score': 0.006153054069727659, 'start': 5, 'end': 50, 'answer': \"a complete visitor's guide to the Rijksmuseum\"}\n",
            "{'score': 0.0061875940300524235, 'start': 0, 'end': 11, 'answer': 'Rijksmuseum'}\n",
            "{'score': 0.0011485778959468007, 'start': 154, 'end': 170, 'answer': 'usually inspired'}\n",
            "{'score': 0.013038473203778267, 'start': 8, 'end': 21, 'answer': 'vangoghmuseum'}\n",
            "{'score': 0.011608424596488476, 'start': 2, 'end': 8, 'answer': 'Rodney'}\n",
            "{'score': 0.011900034733116627, 'start': 8, 'end': 16, 'answer': 'van Gogh'}\n",
            "{'score': 0.0004740352160297334, 'start': 238, 'end': 253, 'answer': 'Meier, is worth'}\n",
            "{'score': 0.029828732833266258, 'start': 9, 'end': 14, 'answer': 'macba'}\n",
            "{'score': 0.0010416798759251833, 'start': 14, 'end': 25, 'answer': 'most of his'}\n",
            "{'score': 0.008843536488711834, 'start': 9, 'end': 21, 'answer': 'museupicasso'}\n",
            "{'score': 0.012213758192956448, 'start': 8, 'end': 14, 'answer': 'Davies'}\n",
            "{'score': 0.005771851632744074, 'start': 5, 'end': 37, 'answer': 'coffee to cubism - a guided tour'}\n",
            "{'score': 0.0004809542733710259, 'start': 19, 'end': 25, 'answer': 'enough'}\n",
            "{'score': 0.02332044206559658, 'start': 9, 'end': 24, 'answer': 'hermitagemuseum'}\n",
            "{'score': 0.007455913815647364, 'start': 7, 'end': 26, 'answer': 'Bennetts, Telegraph'}\n",
            "{'score': 0.02051289565861225, 'start': 16, 'end': 41, 'answer': 'favourites: The Hermitage'}\n",
            "{'score': 9.560842590872198e-05, 'start': 346, 'end': 374, 'answer': 'Magi, Botticelli’s Primavera'}\n",
            "{'score': 0.013127095997333527, 'start': 8, 'end': 20, 'answer': 'firenzemusei'}\n",
            "{'score': 0.016222011297941208, 'start': 28, 'end': 34, 'answer': 'Uffizi'}\n",
            "{'score': 0.0001603071141289547, 'start': 171, 'end': 181, 'answer': 'well worth'}\n",
            "{'score': 0.01918417401611805, 'start': 16, 'end': 26, 'answer': '-medici.it'}\n",
            "{'score': 0.11380375176668167, 'start': 0, 'end': 8, 'answer': 'Florence'}\n",
            "{'score': 0.00010351964738219976, 'start': 448, 'end': 467, 'answer': 'difficult-to-please'}\n",
            "{'score': 0.011182724498212337, 'start': 13, 'end': 18, 'answer': 'unifi'}\n",
            "{'score': 0.01082540862262249, 'start': 2, 'end': 14, 'answer': 'Lee Marshall'}\n",
            "{'score': 7.665294106118381e-05, 'start': 501, 'end': 523, 'answer': 'are now in the British'}\n",
            "{'score': 0.013279059901833534, 'start': 8, 'end': 26, 'answer': 'theacropolismuseum'}\n",
            "{'score': 0.00014876127534080297, 'start': 254, 'end': 259, 'answer': 'hoard'}\n",
            "{'score': 0.026312122121453285, 'start': 9, 'end': 18, 'answer': 'benaki.gr'}\n",
            "{'score': 0.011204011738300323, 'start': 7, 'end': 24, 'answer': 'Foster, Telegraph'}\n",
            "{'score': 0.0002285004738951102, 'start': 218, 'end': 261, 'answer': 'Manneken Pis – the statue of the little boy'}\n",
            "{'score': 0.005125498864799738, 'start': 8, 'end': 26, 'answer': 'brusselsmuseums.be'}\n",
            "{'score': 0.0002175375266233459, 'start': 47, 'end': 116, 'answer': 'collection is a showcase for the brilliance of Belgian art. It begins'}\n",
            "{'score': 0.00024681718787178397, 'start': 162, 'end': 187, 'answer': 'Magritte, to whom a whole'}\n",
            "{'score': 0.013346191495656967, 'start': 13, 'end': 28, 'answer': '-arts-museum.be'}\n",
            "{'score': 0.00022129264834802598, 'start': 274, 'end': 339, 'answer': 'headphones bring the musical instruments alive; and the view over'}\n",
            "{'score': 0.0109027698636055, 'start': 9, 'end': 20, 'answer': 'mim.fgov.be'}\n",
            "{'score': 0.0012752991169691086, 'start': 78, 'end': 101, 'answer': '.twitter.com/tCWj2SZOb7'}\n",
            "{'score': 0.00045867153676226735, 'start': 18, 'end': 101, 'answer': 'hoard of international antiquities – by far the largest of a collection of heritage'}\n",
            "{'score': 0.00022155240003485233, 'start': 246, 'end': 306, 'answer': '50th anniversary of Belgian nationhood. The surrounding Parc'}\n",
            "{'score': 0.011834359727799892, 'start': 8, 'end': 20, 'answer': 'kmkg-mrah.be'}\n",
            "{'score': 0.02641744166612625, 'start': 9, 'end': 31, 'answer': 'Mason, Brussels expert'}\n",
            "{'score': 0.00012199770571896806, 'start': 11, 'end': 19, 'answer': 'heritage'}\n",
            "{'score': 0.009645192883908749, 'start': 33, 'end': 49, 'answer': '’s Berlin expert'}\n",
            "{'score': 0.0001256979157915339, 'start': 123, 'end': 186, 'answer': 'recreation of a First century Roman villa built by oil tycoon J'}\n",
            "{'score': 0.010828094556927681, 'start': 2, 'end': 43, 'answer': 'Lucie Young, Telegraph Travel’s LA expert'}\n",
            "{'score': 0.0002736880851443857, 'start': 9, 'end': 68, 'answer': 'Hadid-designed futuristic structure, featuring a curvaceous'}\n",
            "{'score': 0.014806385152041912, 'start': 16, 'end': 18, 'answer': 'kr'}\n",
            "{'score': 0.00014567357720807195, 'start': 101, 'end': 109, 'answer': 'deCaires'}\n",
            "{'score': 0.01433864887803793, 'start': 8, 'end': 21, 'answer': 'cactlanzarote'}\n",
            "{'score': 0.0003571858396753669, 'start': 270, 'end': 273, 'answer': 'one'}\n",
            "{'score': 0.00024269186542369425, 'start': 319, 'end': 386, 'answer': 'relationships past, exploring the \"love, pain, drama, irony, humour'}\n",
            "{'score': 0.02315092831850052, 'start': 0, 'end': 14, 'answer': 'Zagrebs Museum'}\n",
            "{'score': 0.0192326121032238, 'start': 9, 'end': 20, 'answer': 'brokenships'}\n",
            "{'score': 0.00021527637727558613, 'start': 128, 'end': 153, 'answer': 'structure. While it hosts'}\n",
            "{'score': 0.0006754740606993437, 'start': 122, 'end': 168, 'answer': 'Menenti #FutureWorldpic.twitter.com/YDdYSS0Slg'}\n",
            "{'score': 0.011300630867481232, 'start': 9, 'end': 23, 'answer': 'marinabaysands'}\n",
            "{'score': 0.0013101949589326978, 'start': 57, 'end': 119, 'answer': 'Sweden across the Sound, Louisiana Museum of Modern Art is one'}\n",
            "{'score': 0.00011073501809732988, 'start': 434, 'end': 450, 'answer': 'cannot be missed'}\n",
            "{'score': 0.01599605567753315, 'start': 9, 'end': 11, 'answer': 'en'}\n",
            "{'score': 0.00020171522919554263, 'start': 22, 'end': 30, 'answer': 'heritage'}\n",
            "{'score': 0.02253197319805622, 'start': 9, 'end': 23, 'answer': 'shanghaimuseum'}\n",
            "{'score': 0.005890985485166311, 'start': 9, 'end': 59, 'answer': \"Ceallaigh, Telegraph Travel's Luxury Travel editor\"}\n",
            "{'score': 7.279527198988944e-05, 'start': 99, 'end': 106, 'answer': 'Larsson'}\n",
            "{'score': 0.009370731189846992, 'start': 9, 'end': 19, 'answer': 'bildmuseet'}\n",
            "{'score': 0.00015053155948407948, 'start': 326, 'end': 353, 'answer': 'largely built to complement'}\n",
            "{'score': 0.011585243977606297, 'start': 9, 'end': 27, 'answer': 'benesse-artsite.jp'}\n",
            "{'score': 0.005890985485166311, 'start': 9, 'end': 59, 'answer': \"Ceallaigh, Telegraph Travel's Luxury Travel editor\"}\n",
            "{'score': 0.0003425056638661772, 'start': 195, 'end': 253, 'answer': 'grave markers to Taino spatulas, the latter used to induce'}\n",
            "{'score': 0.017842113971710205, 'start': 9, 'end': 24, 'answer': 'precolombino.cl'}\n",
            "['most spectacular', 'we missed', 'of Modern Art', 'glassy Yoshio', 'moma', 'Metropolitan', 'you don’t narrow your focus. Don’t miss', 'metmuseum', 'Guggenheim', 'in a constantly evolving collection of impressionist, post', 'York expert', '4. The Whitney', 'range', 'whitney', '5', 'artefacts and French neoclassical and Romantic painting. The secret', 'louvre.fr', '20 greatest', 'Marmottan', 'one', 'marmottan', 'Koons', '7. Musée', 'unrivalled', 'rodin', 'Edwards, Telegraph', '8', 'there’s plenty to enjoy along the way, from classical', 'va', 'Galleria', 'worthwhile', 'galleriaborghese', 'Lee Marshall', 'free things to do', '10', 'on the edge of Holland', 'designmuseum', '11. Sir', 'interlocking rooms on different levels crammed', 'hoarding mentality of a pack', 'Dorment', '12. The Victoria & Albert Museum', 'courtyard entrance and underground gallery forming part of the Exhibition Road Building Project', 'Courtyard will be through the arches of the 19th-century screen designed by Sir', '10pm (Saturday as well at Tate', 'Secret', '13. Prado', 'Titian and Tintoretto', 'museodelprado', 'Prado', 'late 2010, with new displays on the fourth floor. Picasso’s masterpiece', 'museoreinasofia', 'Superlative collections of Western', 'museothyssen', '’s Madrid expert', 'many more are on show alongside centuries’ worth', 'rijksmuseum', \"a complete visitor's guide to the Rijksmuseum\", 'Rijksmuseum', 'usually inspired', 'vangoghmuseum', 'Rodney', 'van Gogh', 'Meier, is worth', 'macba', 'most of his', 'museupicasso', 'Davies', 'coffee to cubism - a guided tour', 'enough', 'hermitagemuseum', 'Bennetts, Telegraph', 'favourites: The Hermitage', 'Magi, Botticelli’s Primavera', 'firenzemusei', 'Uffizi', 'well worth', '-medici.it', 'Florence', 'difficult-to-please', 'unifi', 'Lee Marshall', 'are now in the British', 'theacropolismuseum', 'hoard', 'benaki.gr', 'Foster, Telegraph', 'Manneken Pis – the statue of the little boy', 'brusselsmuseums.be', 'collection is a showcase for the brilliance of Belgian art. It begins', 'Magritte, to whom a whole', '-arts-museum.be', 'headphones bring the musical instruments alive; and the view over', 'mim.fgov.be', '.twitter.com/tCWj2SZOb7', 'hoard of international antiquities – by far the largest of a collection of heritage', '50th anniversary of Belgian nationhood. The surrounding Parc', 'kmkg-mrah.be', 'Mason, Brussels expert', 'heritage', '’s Berlin expert', 'recreation of a First century Roman villa built by oil tycoon J', 'Lucie Young, Telegraph Travel’s LA expert', 'Hadid-designed futuristic structure, featuring a curvaceous', 'kr', 'deCaires', 'cactlanzarote', 'one', 'relationships past, exploring the \"love, pain, drama, irony, humour', 'Zagrebs Museum', 'brokenships', 'structure. While it hosts', 'Menenti #FutureWorldpic.twitter.com/YDdYSS0Slg', 'marinabaysands', 'Sweden across the Sound, Louisiana Museum of Modern Art is one', 'cannot be missed', 'en', 'heritage', 'shanghaimuseum', \"Ceallaigh, Telegraph Travel's Luxury Travel editor\", 'Larsson', 'bildmuseet', 'largely built to complement', 'benesse-artsite.jp', \"Ceallaigh, Telegraph Travel's Luxury Travel editor\", 'grave markers to Taino spatulas, the latter used to induce', 'precolombino.cl']\n",
            "{'score': 0.008957038633525372, 'start': 29, 'end': 53, 'answer': 'Being Considered For GTA'}\n",
            "{'score': 0.0002697198069654405, 'start': 108, 'end': 139, 'answer': 'there is one thing that remains'}\n",
            "{'score': 0.0004916577599942684, 'start': 138, 'end': 201, 'answer': 'may be the next location for the epic that GTA 6 will surely be'}\n",
            "{'score': 0.0007876728195697069, 'start': 13, 'end': 23, 'answer': 'been a lot'}\n",
            "{'score': 0.0008388501591980457, 'start': 147, 'end': 186, 'answer': 'might be going in its sixth installment'}\n",
            "{'score': 0.12807618081569672, 'start': 0, 'end': 5, 'answer': 'Tokyo'}\n",
            "{'score': 0.00024587177904322743, 'start': 46, 'end': 55, 'answer': 'in with a'}\n",
            "{'score': 0.00030574691481888294, 'start': 239, 'end': 250, 'answer': 'would still'}\n",
            "{'score': 0.1142185851931572, 'start': 0, 'end': 7, 'answer': 'Chicago'}\n",
            "{'score': 0.0005148853524588048, 'start': 171, 'end': 216, 'answer': 'bullets and this would make a fitting context'}\n",
            "{'score': 0.0011310274712741375, 'start': 72, 'end': 115, 'answer': 'the U.S itself as GTA has also been a great'}\n",
            "{'score': 0.10475697368383408, 'start': 0, 'end': 7, 'answer': 'London:'}\n",
            "{'score': 0.000482638570247218, 'start': 178, 'end': 182, 'answer': 'most'}\n",
            "{'score': 0.002238300396129489, 'start': 52, 'end': 103, 'answer': 'lot more controversies that are common with the U.K'}\n",
            "{'score': 0.004608880262821913, 'start': 9, 'end': 41, 'answer': 'you think the next GTA should be'}\n",
            "['Being Considered For GTA', 'there is one thing that remains', 'may be the next location for the epic that GTA 6 will surely be', 'been a lot', 'might be going in its sixth installment', 'Tokyo', 'in with a', 'would still', 'Chicago', 'bullets and this would make a fitting context', 'the U.S itself as GTA has also been a great', 'London:', 'most', 'lot more controversies that are common with the U.K', 'you think the next GTA should be']\n",
            "{'score': 8.739522309042513e-05, 'start': 373, 'end': 405, 'answer': '-that). He turned me on to white'}\n",
            "{'score': 0.0004987700958736241, 'start': 138, 'end': 159, 'answer': 'rakes in $800 milly a'}\n",
            "{'score': 0.00543695455417037, 'start': 3, 'end': 54, 'answer': 'A SINGLE TABLESPOON HAS MORE SUGAR THAN A CHOCOLATE'}\n",
            "{'score': 0.032762560993433, 'start': 2, 'end': 10, 'answer': 'Provided'}\n",
            "{'score': 0.00022155478654894978, 'start': 275, 'end': 285, 'answer': 'had enough'}\n",
            "{'score': 0.010932394303381443, 'start': 6, 'end': 16, 'answer': 'OVERPOWERS'}\n",
            "{'score': 0.032762560993433, 'start': 2, 'end': 10, 'answer': 'Provided'}\n",
            "{'score': 0.0005292337154969573, 'start': 128, 'end': 161, 'answer': 'when you wipe it off with a paper'}\n",
            "{'score': 0.01040706504136324, 'start': 8, 'end': 14, 'answer': 'GLOPPY'}\n",
            "{'score': 0.00025324546732008457, 'start': 141, 'end': 168, 'answer': 'squirts out of that squeeze'}\n",
            "{'score': 0.03186916187405586, 'start': 0, 'end': 1, 'answer': '4'}\n",
            "{'score': 0.032762560993433, 'start': 2, 'end': 10, 'answer': 'Provided'}\n",
            "{'score': 0.0006259134970605373, 'start': 0, 'end': 12, 'answer': \"I don't have\"}\n",
            "{'score': 0.015211437828838825, 'start': 5, 'end': 14, 'answer': 'CAN NEVER'}\n",
            "{'score': 6.045808186172508e-05, 'start': 20, 'end': 64, 'answer': 'you can imagine the disappointment and utter'}\n",
            "{'score': 0.00941295363008976, 'start': 9, 'end': 16, 'answer': 'ARE TOO'}\n",
            "{'score': 0.00010667958849808201, 'start': 356, 'end': 415, 'answer': 'hash browns, grilled cheese, chicken nuggets all disappoint'}\n",
            "{'score': 0.006666919682174921, 'start': 11, 'end': 13, 'answer': \"'T\"}\n",
            "{'score': 0.0008268055389635265, 'start': 4, 'end': 13, 'answer': \", I'm not\"}\n",
            "{'score': 0.01129807811230421, 'start': 14, 'end': 38, 'answer': 'to Make Homemade Ketchup'}\n",
            "['-that). He turned me on to white', 'rakes in $800 milly a', 'A SINGLE TABLESPOON HAS MORE SUGAR THAN A CHOCOLATE', 'Provided', 'had enough', 'OVERPOWERS', 'Provided', 'when you wipe it off with a paper', 'GLOPPY', 'squirts out of that squeeze', '4', 'Provided', \"I don't have\", 'CAN NEVER', 'you can imagine the disappointment and utter', 'ARE TOO', 'hash browns, grilled cheese, chicken nuggets all disappoint', \"'T\", \", I'm not\", 'to Make Homemade Ketchup']\n",
            "{'score': 0.0011462756665423512, 'start': 25, 'end': 106, 'answer': 'least one story about a crazy uncle leaving some pretty amazing, unexpected items'}\n",
            "{'score': 0.001162425265647471, 'start': 80, 'end': 111, 'answer': 'upon Tyne in the United Kingdom'}\n",
            "{'score': 0.0008465040009468794, 'start': 39, 'end': 63, 'answer': 'hoarder, so the siblings'}\n",
            "{'score': 0.04398258402943611, 'start': 0, 'end': 9, 'answer': 'Wikimedia'}\n",
            "{'score': 0.0005063432618044317, 'start': 104, 'end': 123, 'answer': 'family knew he kept'}\n",
            "{'score': 0.0008636722341179848, 'start': 148, 'end': 157, 'answer': 'was worth'}\n",
            "{'score': 0.000850068696308881, 'start': 103, 'end': 145, 'answer': 'thousands of receipts and even a World War'}\n",
            "{'score': 0.000445303856395185, 'start': 20, 'end': 82, 'answer': 'auction for more than £3 million, or just over 4.3 million USD'}\n",
            "{'score': 0.025530170649290085, 'start': 16, 'end': 26, 'answer': 'MailOnline'}\n",
            "{'score': 0.000984918442554772, 'start': 46, 'end': 109, 'answer': 'were ever made and at least four of those are thought to belong'}\n",
            "{'score': 0.001524115796200931, 'start': 77, 'end': 85, 'answer': 'had some'}\n",
            "{'score': 0.0005487570888362825, 'start': 71, 'end': 91, 'answer': \"for sure. It's worth\"}\n",
            "{'score': 0.00043465528870001435, 'start': 105, 'end': 163, 'answer': \"delighted and we're going to make sure the money is shared\"}\n",
            "{'score': 0.0003868692147079855, 'start': 60, 'end': 78, 'answer': 'eccentric old gent'}\n",
            "{'score': 0.019738398492336273, 'start': 0, 'end': 22, 'answer': 'Bonhams via MailOnline'}\n",
            "{'score': 0.0004185437283013016, 'start': 106, 'end': 157, 'answer': 'hoarded everything in the house he refused to leave'}\n",
            "{'score': 0.0007320864242501557, 'start': 55, 'end': 113, 'answer': 'I am today,\" the nephew said. He also added that his uncle'}\n",
            "['least one story about a crazy uncle leaving some pretty amazing, unexpected items', 'upon Tyne in the United Kingdom', 'hoarder, so the siblings', 'Wikimedia', 'family knew he kept', 'was worth', 'thousands of receipts and even a World War', 'auction for more than £3 million, or just over 4.3 million USD', 'MailOnline', 'were ever made and at least four of those are thought to belong', 'had some', \"for sure. It's worth\", \"delighted and we're going to make sure the money is shared\", 'eccentric old gent', 'Bonhams via MailOnline', 'hoarded everything in the house he refused to leave', 'I am today,\" the nephew said. He also added that his uncle']\n",
            "{'score': 0.0006576606538146734, 'start': 164, 'end': 172, 'answer': 'bragging'}\n",
            "{'score': 0.0068616122007369995, 'start': 9, 'end': 37, 'answer': 'five extraordinary trips for'}\n",
            "{'score': 0.023259740322828293, 'start': 0, 'end': 1, 'answer': '1'}\n",
            "{'score': 0.0028786754701286554, 'start': 33, 'end': 62, 'answer': 'wondrous sights. Photo credit'}\n",
            "{'score': 0.00109816191252321, 'start': 43, 'end': 95, 'answer': 'dunes, salt lakes, towering peaks, glaciers, geysers'}\n",
            "{'score': 0.0002908699680119753, 'start': 316, 'end': 326, 'answer': 'gargantuan'}\n",
            "{'score': 0.00040383919258601964, 'start': 186, 'end': 214, 'answer': 'splendor, a sight guaranteed'}\n",
            "{'score': 0.0013974766479805112, 'start': 0, 'end': 31, 'answer': 'Chileans are friendly and hosts'}\n",
            "{'score': 0.010356735438108444, 'start': 0, 'end': 13, 'answer': 'Where to stay'}\n",
            "{'score': 0.023992039263248444, 'start': 3, 'end': 20, 'answer': 'Premium Christmas'}\n",
            "{'score': 0.0019165545236319304, 'start': 78, 'end': 89, 'answer': 'Sonderegger'}\n",
            "{'score': 0.0004104699764866382, 'start': 59, 'end': 91, 'answer': 'hard to beat. Think spellbinding'}\n",
            "{'score': 0.00014104234287515283, 'start': 377, 'end': 383, 'answer': 'filled'}\n",
            "{'score': 0.0002660364261828363, 'start': 56, 'end': 69, 'answer': 'free, leaving'}\n",
            "{'score': 0.0017854806501418352, 'start': 19, 'end': 44, 'answer': 'Dolder Grand (Zurich); Le'}\n",
            "{'score': 0.010568457655608654, 'start': 13, 'end': 37, 'answer': \"in Santa's home: Finland\"}\n",
            "{'score': 0.009738758206367493, 'start': 9, 'end': 38, 'answer': 'Lights, Finland. Photo credit'}\n",
            "{'score': 0.0003468842769507319, 'start': 225, 'end': 266, 'answer': 'Finnair, has been recently courting Asian'}\n",
            "{'score': 0.00016902606876101345, 'start': 340, 'end': 398, 'answer': 'reindeer farms, hunts for the Northern Lights with a guide'}\n",
            "{'score': 0.00031166672124527395, 'start': 234, 'end': 239, 'answer': 'worth'}\n",
            "{'score': 0.001125892624258995, 'start': 12, 'end': 30, 'answer': 'available to Asian'}\n",
            "{'score': 0.008742810226976871, 'start': 12, 'end': 15, 'answer': '-at'}\n",
            "{'score': 0.005064913537353277, 'start': 19, 'end': 23, 'answer': 'Zouk'}\n",
            "{'score': 0.0002691044646780938, 'start': 45, 'end': 70, 'answer': 'eschew your boarding pass'}\n",
            "{'score': 8.888575393939391e-05, 'start': 357, 'end': 374, 'answer': 'Penfolds flagship'}\n",
            "{'score': 0.014066738076508045, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.00221108621917665, 'start': 32, 'end': 54, 'answer': 'Randheli. Photo credit'}\n",
            "{'score': 0.0013172811595723033, 'start': 44, 'end': 111, 'answer': 'the second half of December to April, making it another destination'}\n",
            "{'score': 9.562301420373842e-05, 'start': 362, 'end': 390, 'answer': 'extensive facilities to suit'}\n",
            "['bragging', 'five extraordinary trips for', '1', 'wondrous sights. Photo credit', 'dunes, salt lakes, towering peaks, glaciers, geysers', 'gargantuan', 'splendor, a sight guaranteed', 'Chileans are friendly and hosts', 'Where to stay', 'Premium Christmas', 'Sonderegger', 'hard to beat. Think spellbinding', 'filled', 'free, leaving', 'Dolder Grand (Zurich); Le', \"in Santa's home: Finland\", 'Lights, Finland. Photo credit', 'Finnair, has been recently courting Asian', 'reindeer farms, hunts for the Northern Lights with a guide', 'worth', 'available to Asian', '-at', 'Zouk', 'eschew your boarding pass', 'Penfolds flagship', '5', 'Randheli. Photo credit', 'the second half of December to April, making it another destination', 'extensive facilities to suit']\n",
            "{'score': 9.349326865049079e-05, 'start': 357, 'end': 419, 'answer': 'hyped by nearly 300 exhibitors at the Electronic Entertainment'}\n",
            "{'score': 0.0004050239804200828, 'start': 10, 'end': 80, 'answer': 'allure of the annual Electronic Entertainment Expo remains blockbuster'}\n",
            "{'score': 0.00029468286084011197, 'start': 1, 'end': 65, 'answer': 'There are 2,000 products that are going to be shown to consumers'}\n",
            "{'score': 0.0002612983516883105, 'start': 287, 'end': 351, 'answer': '20,000 fans to show up for game demonstrations and other revelry'}\n",
            "{'score': 0.008827022276818752, 'start': 23, 'end': 35, 'answer': 'E3 prospects'}\n",
            "{'score': 0.06381992250680923, 'start': 0, 'end': 2, 'answer': '__'}\n",
            "{'score': 0.103129081428051, 'start': 7, 'end': 11, 'answer': 'WIND'}\n",
            "{'score': 0.00013211392797529697, 'start': 144, 'end': 190, 'answer': 'They include the stealth adventure \"Dishonored'}\n",
            "{'score': 0.06381992250680923, 'start': 0, 'end': 2, 'answer': '__'}\n",
            "{'score': 0.11354042589664459, 'start': 0, 'end': 11, 'answer': 'NEW REALITY'}\n",
            "{'score': 0.00013894987932872027, 'start': 160, 'end': 214, 'answer': 'many of the 50,000 attendees expected at E3. Gallagher'}\n",
            "{'score': 0.06381992250680923, 'start': 0, 'end': 2, 'answer': '__'}\n",
            "{'score': 0.11345329135656357, 'start': 0, 'end': 5, 'answer': 'FRESH'}\n",
            "{'score': 0.00010464263323228806, 'start': 510, 'end': 523, 'answer': '12, 2016. (AP'}\n",
            "{'score': 0.00014281418407335877, 'start': 270, 'end': 280, 'answer': 'Dishonored'}\n",
            "{'score': 0.06381992250680923, 'start': 0, 'end': 2, 'answer': '__'}\n",
            "{'score': 0.03279938921332359, 'start': 0, 'end': 8, 'answer': 'LOCATION'}\n",
            "{'score': 0.00013131453306414187, 'start': 97, 'end': 116, 'answer': 'Dogs 2\" is swapping'}\n",
            "{'score': 0.06381992250680923, 'start': 0, 'end': 2, 'answer': '__'}\n",
            "{'score': 0.13155081868171692, 'start': 0, 'end': 10, 'answer': 'GENERATION'}\n",
            "{'score': 0.00016036750457715243, 'start': 69, 'end': 124, 'answer': 'E3 press conferences and on the show floor—but probably'}\n",
            "{'score': 0.0043739015236496925, 'start': 69, 'end': 71, 'answer': 'E3'}\n",
            "{'score': 0.010472268797457218, 'start': 22, 'end': 28, 'answer': 'e3expo'}\n",
            "['hyped by nearly 300 exhibitors at the Electronic Entertainment', 'allure of the annual Electronic Entertainment Expo remains blockbuster', 'There are 2,000 products that are going to be shown to consumers', '20,000 fans to show up for game demonstrations and other revelry', 'E3 prospects', '__', 'WIND', 'They include the stealth adventure \"Dishonored', '__', 'NEW REALITY', 'many of the 50,000 attendees expected at E3. Gallagher', '__', 'FRESH', '12, 2016. (AP', 'Dishonored', '__', 'LOCATION', 'Dogs 2\" is swapping', '__', 'GENERATION', 'E3 press conferences and on the show floor—but probably', 'E3', 'e3expo']\n",
            "{'score': 0.004497761372476816, 'start': 20, 'end': 36, 'answer': 'When You Give $1'}\n",
            "{'score': 0.001091215992346406, 'start': 15, 'end': 74, 'answer': 'Oshien from Siaya, Kenya — A person who received just under'}\n",
            "{'score': 4.868813630309887e-05, 'start': 384, 'end': 434, 'answer': 'GiveDirectly in November 2015, an org that gives $'}\n",
            "{'score': 0.0006667291163466871, 'start': 46, 'end': 103, 'answer': 'GiveDirectly, and the concept of transferring cash is met'}\n",
            "{'score': 0.003241330850869417, 'start': 37, 'end': 47, 'answer': 'defrauding'}\n",
            "{'score': 0.006895630154758692, 'start': 28, 'end': 36, 'answer': 'squander'}\n",
            "{'score': 0.003033911343663931, 'start': 1, 'end': 20, 'answer': 'It probably doesn’t'}\n",
            "{'score': 0.000945987761951983, 'start': 9, 'end': 63, 'answer': 'angst about the \"Savior Barbie\" complex, where western'}\n",
            "{'score': 0.0241808220744133, 'start': 7, 'end': 11, 'answer': 'more'}\n",
            "{'score': 0.00020539799879770726, 'start': 23, 'end': 69, 'answer': 'frequent barrage of opposing views, but always'}\n",
            "{'score': 0.005433245562016964, 'start': 11, 'end': 56, 'answer': 'GiveDirectly’s Country Headquarters in Kisumu'}\n",
            "{'score': 0.00014980362902861089, 'start': 309, 'end': 320, 'answer': 'were really'}\n",
            "{'score': 8.742322825128213e-05, 'start': 542, 'end': 547, 'answer': 'still'}\n",
            "{'score': 8.871356840245426e-05, 'start': 389, 'end': 454, 'answer': 'GiveDirectly after having their own first real exposure to abject'}\n",
            "{'score': 0.0003840381104964763, 'start': 131, 'end': 174, 'answer': 'GiveDirectly’s work (for poverty-action.org'}\n",
            "{'score': 6.164373189676553e-05, 'start': 482, 'end': 498, 'answer': 'most competitive'}\n",
            "{'score': 0.0002777492336463183, 'start': 235, 'end': 278, 'answer': 'some rich country on a self-serving mission'}\n",
            "{'score': 0.00033848779276013374, 'start': 245, 'end': 269, 'answer': 'nepotism, and absolutely'}\n",
            "{'score': 4.59088732895907e-05, 'start': 438, 'end': 490, 'answer': 'randomized controlled trials (RCTs) — the holy grail'}\n",
            "{'score': 0.00017471247701905668, 'start': 32, 'end': 46, 'answer': 'GD gives isn’t'}\n",
            "{'score': 0.00015259411884471774, 'start': 133, 'end': 145, 'answer': 'GiveDirectly'}\n",
            "{'score': 0.0005233277915976942, 'start': 124, 'end': 136, 'answer': 'installments'}\n",
            "{'score': 0.00039166779606603086, 'start': 86, 'end': 116, 'answer': 'were fixing the following core'}\n",
            "{'score': 0.0002541439898777753, 'start': 106, 'end': 127, 'answer': 'Orimba and his family'}\n",
            "{'score': 0.002823392627760768, 'start': 3, 'end': 30, 'answer': 'Thatched roof — which leaks'}\n",
            "{'score': 0.005537999793887138, 'start': 0, 'end': 1, 'answer': 'i'}\n",
            "{'score': 0.00801099557429552, 'start': 13, 'end': 49, 'answer': 'frequent illness / sometimes chronic'}\n",
            "{'score': 0.014881942421197891, 'start': 21, 'end': 38, 'answer': 'frequently school'}\n",
            "{'score': 0.014598777517676353, 'start': 0, 'end': 2, 'answer': 'iv'}\n",
            "{'score': 0.0028460081666707993, 'start': 41, 'end': 50, 'answer': '10x12 one'}\n",
            "{'score': 0.003648723941296339, 'start': 0, 'end': 1, 'answer': 'c'}\n",
            "{'score': 0.0015296385390684009, 'start': 77, 'end': 83, 'answer': 'burrow'}\n",
            "{'score': 0.0002226533688372001, 'start': 240, 'end': 286, 'answer': 'thousands of kids to miss out on school from 5'}\n",
            "{'score': 0.00024124702031258494, 'start': 14, 'end': 26, 'answer': 'GiveDirectly'}\n",
            "{'score': 0.0004479338531382382, 'start': 114, 'end': 131, 'answer': 'few month’s worth'}\n",
            "{'score': 0.0009068084764294326, 'start': 62, 'end': 118, 'answer': 'GiveDirectly that sit in the recipients doorway / living'}\n",
            "{'score': 0.000606134592089802, 'start': 151, 'end': 184, 'answer': 'chronic illness (Cancer, HIV, etc'}\n",
            "{'score': 0.00021064456086605787, 'start': 317, 'end': 323, 'answer': 'others'}\n",
            "{'score': 0.000420588708948344, 'start': 5, 'end': 43, 'answer': 'GD’s rigorous measurement and auditing'}\n",
            "{'score': 0.001924297888763249, 'start': 16, 'end': 61, 'answer': 'consistent with a publication from World Bank'}\n",
            "{'score': 5.192364187678322e-05, 'start': 761, 'end': 803, 'answer': 'most, and 97% of that cash transfer served'}\n",
            "{'score': 0.00010391327668912709, 'start': 283, 'end': 316, 'answer': 'overpopulation, lack of education'}\n",
            "['When You Give $1', 'Oshien from Siaya, Kenya — A person who received just under', 'GiveDirectly in November 2015, an org that gives $', 'GiveDirectly, and the concept of transferring cash is met', 'defrauding', 'squander', 'It probably doesn’t', 'angst about the \"Savior Barbie\" complex, where western', 'more', 'frequent barrage of opposing views, but always', 'GiveDirectly’s Country Headquarters in Kisumu', 'were really', 'still', 'GiveDirectly after having their own first real exposure to abject', 'GiveDirectly’s work (for poverty-action.org', 'most competitive', 'some rich country on a self-serving mission', 'nepotism, and absolutely', 'randomized controlled trials (RCTs) — the holy grail', 'GD gives isn’t', 'GiveDirectly', 'installments', 'were fixing the following core', 'Orimba and his family', 'Thatched roof — which leaks', 'i', 'frequent illness / sometimes chronic', 'frequently school', 'iv', '10x12 one', 'c', 'burrow', 'thousands of kids to miss out on school from 5', 'GiveDirectly', 'few month’s worth', 'GiveDirectly that sit in the recipients doorway / living', 'chronic illness (Cancer, HIV, etc', 'others', 'GD’s rigorous measurement and auditing', 'consistent with a publication from World Bank', 'most, and 97% of that cash transfer served', 'overpopulation, lack of education']\n",
            "{'score': 0.005033986642956734, 'start': 28, 'end': 57, 'answer': '. 18 is National Cheeseburger'}\n",
            "{'score': 0.013670654967427254, 'start': 13, 'end': 19, 'answer': 'Tuscan'}\n",
            "{'score': 0.0010932503500953317, 'start': 29, 'end': 76, 'answer': 'piled high with lettuce and tomato or slathered'}\n",
            "{'score': 0.0004196107038296759, 'start': 0, 'end': 7, 'answer': 'Some 57'}\n",
            "{'score': 0.002789025194942951, 'start': 30, 'end': 51, 'answer': 'snag free, discounted'}\n",
            "{'score': 0.0006382886786013842, 'start': 133, 'end': 139, 'answer': 'coupon'}\n",
            "{'score': 0.0003374473890289664, 'start': 143, 'end': 149, 'answer': 'coupon'}\n",
            "{'score': 0.0010303374147042632, 'start': 124, 'end': 138, 'answer': 'BurgerFi sauce'}\n",
            "{'score': 0.0006228724378161132, 'start': 36, 'end': 80, 'answer': 'SHAK) burgers aboard select flights from JFK'}\n",
            "{'score': 0.0002746627142187208, 'start': 23, 'end': 61, 'answer': 'burgers aboard select flights from JFK'}\n",
            "{'score': 0.0009447300108149648, 'start': 99, 'end': 111, 'answer': 'been posting'}\n",
            "['. 18 is National Cheeseburger', 'Tuscan', 'piled high with lettuce and tomato or slathered', 'Some 57', 'snag free, discounted', 'coupon', 'coupon', 'BurgerFi sauce', 'SHAK) burgers aboard select flights from JFK', 'burgers aboard select flights from JFK', 'been posting']\n",
            "{'score': 0.0013088302221149206, 'start': 4, 'end': 54, 'answer': 'former union boss has a bold idea on how to ensure'}\n",
            "{'score': 0.0005712778074666858, 'start': 20, 'end': 67, 'answer': 'Universal Basic Income (UBI) is not necessarily'}\n",
            "{'score': 9.544470958644524e-05, 'start': 489, 'end': 525, 'answer': 'recent interview with CNBC\\'s \" Power'}\n",
            "{'score': 0.00013383747136685997, 'start': 364, 'end': 419, 'answer': 'threshold was $12,331 a year for an individual under 65'}\n",
            "{'score': 0.03197570517659187, 'start': 2, 'end': 10, 'answer': 'Provided'}\n",
            "{'score': 8.110575436148793e-05, 'start': 554, 'end': 578, 'answer': 'misperceived\" by a range'}\n",
            "{'score': 0.0009267123532481492, 'start': 4, 'end': 26, 'answer': 'Stern, who is a senior'}\n",
            "{'score': 0.00031004741322249174, 'start': 263, 'end': 284, 'answer': 'were at risk of being'}\n",
            "{'score': 0.00033216047449968755, 'start': 39, 'end': 63, 'answer': 'we would be crazy to not'}\n",
            "{'score': 0.0006221176008693874, 'start': 27, 'end': 44, 'answer': 'was also rejected'}\n",
            "{'score': 0.0008142921142280102, 'start': 19, 'end': 48, 'answer': 'undeterred, and has an answer'}\n",
            "{'score': 0.01086601335555315, 'start': 9, 'end': 50, 'answer': 'he suggests Social Security should remain'}\n",
            "{'score': 0.00045872657210566103, 'start': 23, 'end': 54, 'answer': 'all of them but certainly a lot'}\n",
            "{'score': 0.006118568126112223, 'start': 9, 'end': 34, 'answer': 'Kerima Greene contributed'}\n",
            "['former union boss has a bold idea on how to ensure', 'Universal Basic Income (UBI) is not necessarily', 'recent interview with CNBC\\'s \" Power', 'threshold was $12,331 a year for an individual under 65', 'Provided', 'misperceived\" by a range', 'Stern, who is a senior', 'were at risk of being', 'we would be crazy to not', 'was also rejected', 'undeterred, and has an answer', 'he suggests Social Security should remain', 'all of them but certainly a lot', 'Kerima Greene contributed']\n",
            "{'score': 0.0005593498353846371, 'start': 130, 'end': 140, 'answer': 'fortuitous'}\n",
            "{'score': 0.0007427891832776368, 'start': 49, 'end': 118, 'answer': 'hypothermic when she was found on the morning of April 1 in Garibaldi'}\n",
            "{'score': 0.000569123774766922, 'start': 155, 'end': 194, 'answer': 'Squamish Search and Rescue manager John'}\n",
            "{'score': 0.0005540461861528456, 'start': 64, 'end': 104, 'answer': 'was only discovered because her backpack'}\n",
            "{'score': 0.0003627112600952387, 'start': 62, 'end': 123, 'answer': 'were able to start performing CPR right away, Howe told Pique'}\n",
            "{'score': 0.00032551155891269445, 'start': 186, 'end': 233, 'answer': 'Squamish Search and Rescue and an ER doctor who'}\n",
            "{'score': 0.0015562123153358698, 'start': 44, 'end': 91, 'answer': 'Vancouver General Hospital, which has a special'}\n",
            "{'score': 0.0003233467577956617, 'start': 226, 'end': 233, 'answer': 'Willcox'}\n",
            "{'score': 0.0029282933101058006, 'start': 10, 'end': 57, 'answer': 'in stable condition in hospital and is expected'}\n",
            "{'score': 0.0006825918098911643, 'start': 19, 'end': 122, 'answer': 'skeleton athlete who is studying interactive arts and technology and business entrepreneurship at Simon'}\n",
            "{'score': 0.0005856272182427347, 'start': 39, 'end': 81, 'answer': 'skeleton athlete, received four continuous'}\n",
            "['fortuitous', 'hypothermic when she was found on the morning of April 1 in Garibaldi', 'Squamish Search and Rescue manager John', 'was only discovered because her backpack', 'were able to start performing CPR right away, Howe told Pique', 'Squamish Search and Rescue and an ER doctor who', 'Vancouver General Hospital, which has a special', 'Willcox', 'in stable condition in hospital and is expected', 'skeleton athlete who is studying interactive arts and technology and business entrepreneurship at Simon', 'skeleton athlete, received four continuous']\n",
            "{'score': 0.0020572973880916834, 'start': 70, 'end': 108, 'answer': 'no wonder hotel staff have some choice'}\n",
            "{'score': 0.002144948346540332, 'start': 61, 'end': 91, 'answer': 'some very unpleasant behaviour'}\n",
            "{'score': 0.0009303560364060104, 'start': 136, 'end': 204, 'answer': 'discarded under beds and women flashing the porter instead of giving'}\n",
            "{'score': 0.0009602547506801784, 'start': 111, 'end': 149, 'answer': 'numerous parents forgetting to collect'}\n",
            "{'score': 0.0008516697562299669, 'start': 19, 'end': 27, 'answer': 'too much'}\n",
            "{'score': 0.0013865020591765642, 'start': 103, 'end': 126, 'answer': 'others insist on answer'}\n",
            "{'score': 0.0012932908721268177, 'start': 91, 'end': 136, 'answer': 'had drunk from the mini bar and then refilled'}\n",
            "{'score': 0.004263180773705244, 'start': 45, 'end': 62, 'answer': 'to get a discount'}\n",
            "['no wonder hotel staff have some choice', 'some very unpleasant behaviour', 'discarded under beds and women flashing the porter instead of giving', 'numerous parents forgetting to collect', 'too much', 'others insist on answer', 'had drunk from the mini bar and then refilled', 'to get a discount']\n",
            "{'score': 0.010877542197704315, 'start': 0, 'end': 8, 'answer': \"Let's be\"}\n",
            "{'score': 0.0009864744497463107, 'start': 112, 'end': 153, 'answer': 'were standing in your room crying to Joni'}\n",
            "{'score': 0.01033980492502451, 'start': 22, 'end': 39, 'answer': 'was in good news.'}\n",
            "{'score': 0.0006299454253166914, 'start': 203, 'end': 211, 'answer': 'was at 7'}\n",
            "{'score': 0.00039714810554869473, 'start': 165, 'end': 222, 'answer': 'netted four golds and a bronze — that cemented her legacy'}\n",
            "{'score': 9.794747893465683e-05, 'start': 41, 'end': 49, 'answer': 'hard not'}\n",
            "{'score': 0.00011427771823946387, 'start': 502, 'end': 509, 'answer': 'Jayapal'}\n",
            "{'score': 0.000145217971294187, 'start': 380, 'end': 398, 'answer': 'Tribe Called Quest'}\n",
            "{'score': 9.461068111704662e-05, 'start': 4, 'end': 8, 'answer': 'most'}\n",
            "{'score': 0.00011569352500373498, 'start': 125, 'end': 130, 'answer': 'worth'}\n",
            "{'score': 0.00018328914302401245, 'start': 376, 'end': 384, 'answer': 'poaching'}\n",
            "[\"Let's be\", 'were standing in your room crying to Joni', 'was in good news.', 'was at 7', 'netted four golds and a bronze — that cemented her legacy', 'hard not', 'Jayapal', 'Tribe Called Quest', 'most', 'worth', 'poaching']\n",
            "{'score': 0.00016820734890643507, 'start': 256, 'end': 277, 'answer': 'recent New York Times'}\n",
            "{'score': 0.00010074477177113295, 'start': 417, 'end': 475, 'answer': \"Hogwarts, but he certainly hasn't forgotten, nor dismissed\"}\n",
            "{'score': 0.00039104168536141515, 'start': 162, 'end': 187, 'answer': \"It's not easy to redefine\"}\n",
            "{'score': 4.423725476954132e-05, 'start': 488, 'end': 499, 'answer': 'rather than'}\n",
            "{'score': 9.468180360272527e-05, 'start': 396, 'end': 414, 'answer': 'want to have loads'}\n",
            "{'score': 0.0008430654415860772, 'start': 45, 'end': 97, 'answer': 'was basically, \"Here\\'s Daniel Radcliffe\\'s first post'}\n",
            "{'score': 2.5662853659014218e-05, 'start': 358, 'end': 392, 'answer': 'was a really good movie. I may not'}\n",
            "{'score': 0.002870281459763646, 'start': 7, 'end': 24, 'answer': \"'re playing a guy\"}\n",
            "{'score': 2.4254233721876517e-05, 'start': 471, 'end': 541, 'answer': 'very often achieved in film and the fact we achieved it is a testament'}\n",
            "{'score': 0.005093029234558344, 'start': 37, 'end': 56, 'answer': 'had never watched \"'}\n",
            "{'score': 0.11307904869318008, 'start': 3, 'end': 4, 'answer': '.'}\n",
            "{'score': 0.011239451356232166, 'start': 0, 'end': 12, 'answer': 'Well, except'}\n",
            "{'score': 0.014916002750396729, 'start': 6, 'end': 21, 'answer': 'not tell anyone'}\n",
            "{'score': 0.006854899227619171, 'start': 9, 'end': 36, 'answer': 'to catch up before \"Episode'}\n",
            "{'score': 7.033866131678224e-05, 'start': 169, 'end': 199, 'answer': 'at least one guy, Digby Milner'}\n",
            "{'score': 0.01895546354353428, 'start': 3, 'end': 14, 'answer': 's come full'}\n",
            "{'score': 0.0036516590043902397, 'start': 11, 'end': 21, 'answer': 'they do at'}\n",
            "{'score': 0.0019079308258369565, 'start': 81, 'end': 98, 'answer': \"that's really not\"}\n",
            "{'score': 0.00013264788140077144, 'start': 386, 'end': 401, 'answer': 'buried treasure'}\n",
            "{'score': 0.002750593703240156, 'start': 69, 'end': 81, 'answer': 'was told not'}\n",
            "{'score': 8.219699520850554e-05, 'start': 536, 'end': 555, 'answer': 'had a great fucking'}\n",
            "{'score': 0.0020707326475530863, 'start': 14, 'end': 19, 'answer': 'a bad'}\n",
            "{'score': 0.01137486845254898, 'start': 19, 'end': 24, 'answer': 'a lot'}\n",
            "{'score': 0.00495242839679122, 'start': 5, 'end': 34, 'answer': \"when we're introduced to Jack\"}\n",
            "{'score': 0.0005233277915976942, 'start': 101, 'end': 109, 'answer': 'Krokidas'}\n",
            "{'score': 0.00098958401940763, 'start': 28, 'end': 39, 'answer': 'you heard J'}\n",
            "{'score': 2.868547926482279e-05, 'start': 67, 'end': 84, 'answer': 'be foolish enough'}\n",
            "{'score': 0.015560032799839973, 'start': 0, 'end': 16, 'answer': \"She doesn't need\"}\n",
            "{'score': 0.012836240231990814, 'start': 0, 'end': 14, 'answer': 'She definitely'}\n",
            "{'score': 0.0034370264038443565, 'start': 5, 'end': 41, 'answer': 'Ryan is senior writer for Huffington'}\n",
            "['recent New York Times', \"Hogwarts, but he certainly hasn't forgotten, nor dismissed\", \"It's not easy to redefine\", 'rather than', 'want to have loads', 'was basically, \"Here\\'s Daniel Radcliffe\\'s first post', 'was a really good movie. I may not', \"'re playing a guy\", 'very often achieved in film and the fact we achieved it is a testament', 'had never watched \"', '.', 'Well, except', 'not tell anyone', 'to catch up before \"Episode', 'at least one guy, Digby Milner', 's come full', 'they do at', \"that's really not\", 'buried treasure', 'was told not', 'had a great fucking', 'a bad', 'a lot', \"when we're introduced to Jack\", 'Krokidas', 'you heard J', 'be foolish enough', \"She doesn't need\", 'She definitely', 'Ryan is senior writer for Huffington']\n",
            "{'score': 0.00047372092376463115, 'start': 160, 'end': 214, 'answer': 'well to arm themselves with the intellectual firepower'}\n",
            "{'score': 0.0034067335072904825, 'start': 16, 'end': 58, 'answer': 'seven conservative classics that should be'}\n",
            "{'score': 0.01509095449000597, 'start': 9, 'end': 37, 'answer': 'Have Consequences by Richard'}\n",
            "{'score': 0.0002455991634633392, 'start': 66, 'end': 95, 'answer': 'corrosive influences of moral'}\n",
            "{'score': 0.005796806886792183, 'start': 15, 'end': 36, 'answer': 'Serfdom by F.A. Hayek'}\n",
            "{'score': 0.00014898861991241574, 'start': 87, 'end': 130, 'answer': 'well to read Friedrich Hayek’s 1944 classic'}\n",
            "{'score': 0.008049217984080315, 'start': 3, 'end': 6, 'answer': 'The'}\n",
            "{'score': 0.00016462526400573552, 'start': 22, 'end': 52, 'answer': 'rioters sparked violence at UC'}\n",
            "{'score': 0.006222852505743504, 'start': 0, 'end': 43, 'answer': '4. A Choice Not an Echo by Phyllis Schlafly'}\n",
            "{'score': 8.623122266726568e-05, 'start': 444, 'end': 527, 'answer': 'willing to fight for a voice within the Republican Party’s establishment leadership'}\n",
            "{'score': 0.018185153603553772, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.00017262664914596826, 'start': 282, 'end': 290, 'answer': 'deserves'}\n",
            "{'score': 0.010953857563436031, 'start': 5, 'end': 13, 'answer': 'Conflict'}\n",
            "{'score': 0.00012689054710790515, 'start': 409, 'end': 480, 'answer': 'Hobbes to Adam Smith to illustrate the intellectual impulses that drive'}\n",
            "{'score': 0.008127775974571705, 'start': 0, 'end': 8, 'answer': '7. Gulag'}\n",
            "{'score': 0.00016028988466132432, 'start': 359, 'end': 436, 'answer': 'ability to combine lyrical prose with piercing reportage of communism’s moral'}\n",
            "['well to arm themselves with the intellectual firepower', 'seven conservative classics that should be', 'Have Consequences by Richard', 'corrosive influences of moral', 'Serfdom by F.A. Hayek', 'well to read Friedrich Hayek’s 1944 classic', 'The', 'rioters sparked violence at UC', '4. A Choice Not an Echo by Phyllis Schlafly', 'willing to fight for a voice within the Republican Party’s establishment leadership', '5', 'deserves', 'Conflict', 'Hobbes to Adam Smith to illustrate the intellectual impulses that drive', '7. Gulag', 'ability to combine lyrical prose with piercing reportage of communism’s moral']\n",
            "{'score': 0.0011794720776379108, 'start': 62, 'end': 81, 'answer': 'Thanksgiving dinner'}\n",
            "{'score': 0.000983310746960342, 'start': 8, 'end': 18, 'answer': 'many as 35'}\n",
            "{'score': 0.0006751903565600514, 'start': 85, 'end': 103, 'answer': 'that is guaranteed'}\n",
            "{'score': 0.02960263378918171, 'start': 0, 'end': 8, 'answer': 'Specific'}\n",
            "{'score': 0.0004059843486174941, 'start': 222, 'end': 270, 'answer': 'there’s a lack of direct evidence about specific'}\n",
            "{'score': 0.00040433218237012625, 'start': 17, 'end': 22, 'answer': 'range'}\n",
            "{'score': 0.0009394062217324972, 'start': 11, 'end': 45, 'answer': 'there are indications that certain'}\n",
            "{'score': 0.00021779815142508596, 'start': 61, 'end': 82, 'answer': 'they can play a major'}\n",
            "{'score': 0.1487179845571518, 'start': 0, 'end': 4, 'answer': 'Kiwi'}\n",
            "{'score': 0.000542749185115099, 'start': 137, 'end': 193, 'answer': 'There are both green and gold varieties, but green kiwis'}\n",
            "{'score': 0.0020860640797764063, 'start': 50, 'end': 100, 'answer': 'most notably vitamins C and E as well as potassium'}\n",
            "{'score': 0.0007887132233008742, 'start': 79, 'end': 96, 'answer': 'who ate two kiwis'}\n",
            "{'score': 0.0006050353404134512, 'start': 16, 'end': 34, 'answer': 'for sure why kiwis'}\n",
            "{'score': 0.013552422635257244, 'start': 18, 'end': 35, 'answer': 'Tart Cherry Juice'}\n",
            "{'score': 0.0005201954627409577, 'start': 152, 'end': 176, 'answer': 'Montmorency, and English'}\n",
            "{'score': 0.0006121326005086303, 'start': 103, 'end': 154, 'answer': 'who drank two one-cup servings of tart cherry juice'}\n",
            "{'score': 0.0003625036624725908, 'start': 73, 'end': 86, 'answer': 'to have above'}\n",
            "{'score': 0.027018068358302116, 'start': 0, 'end': 30, 'answer': 'Malted Milk and Nighttime Milk'}\n",
            "{'score': 0.0004349998489487916, 'start': 214, 'end': 221, 'answer': 'Horlick'}\n",
            "{'score': 0.00084548513405025, 'start': 142, 'end': 173, 'answer': 'may have to do with the B and D'}\n",
            "{'score': 0.0004856931627728045, 'start': 159, 'end': 181, 'answer': 'be useful in providing'}\n",
            "{'score': 0.11392049491405487, 'start': 0, 'end': 5, 'answer': 'Fatty'}\n",
            "{'score': 0.0006575731677003205, 'start': 128, 'end': 182, 'answer': 'who ate salmon three times per week had better overall'}\n",
            "{'score': 0.0004252646176610142, 'start': 215, 'end': 260, 'answer': 'consumption during winter months when vitamin'}\n",
            "{'score': 0.23660896718502045, 'start': 0, 'end': 4, 'answer': 'Nuts'}\n",
            "{'score': 0.0001620140828890726, 'start': 44, 'end': 108, 'answer': 'cashews are often considered to be a good food for sleep. Though'}\n",
            "{'score': 0.291239857673645, 'start': 0, 'end': 4, 'answer': 'Rice'}\n",
            "{'score': 0.002186874160543084, 'start': 46, 'end': 104, 'answer': 'had mixed results overall, but some evidence connects rice'}\n",
            "{'score': 0.0003246355627197772, 'start': 280, 'end': 327, 'answer': 'glycemic index around four hours before bedtime'}\n",
            "{'score': 0.000401583150960505, 'start': 51, 'end': 99, 'answer': 'been tied to worse sleep, so it appears that not'}\n",
            "{'score': 0.00023006077390164137, 'start': 55, 'end': 74, 'answer': 'by what is consumed'}\n",
            "['Thanksgiving dinner', 'many as 35', 'that is guaranteed', 'Specific', 'there’s a lack of direct evidence about specific', 'range', 'there are indications that certain', 'they can play a major', 'Kiwi', 'There are both green and gold varieties, but green kiwis', 'most notably vitamins C and E as well as potassium', 'who ate two kiwis', 'for sure why kiwis', 'Tart Cherry Juice', 'Montmorency, and English', 'who drank two one-cup servings of tart cherry juice', 'to have above', 'Malted Milk and Nighttime Milk', 'Horlick', 'may have to do with the B and D', 'be useful in providing', 'Fatty', 'who ate salmon three times per week had better overall', 'consumption during winter months when vitamin', 'Nuts', 'cashews are often considered to be a good food for sleep. Though', 'Rice', 'had mixed results overall, but some evidence connects rice', 'glycemic index around four hours before bedtime', 'been tied to worse sleep, so it appears that not', 'by what is consumed']\n",
            "{'score': 0.0004590925818774849, 'start': 9, 'end': 11, 'answer': 'an'}\n",
            "{'score': 0.0006668270216323435, 'start': 142, 'end': 148, 'answer': 'wanted'}\n",
            "{'score': 0.0004299044667277485, 'start': 130, 'end': 144, 'answer': 'would never do'}\n",
            "{'score': 0.004517745226621628, 'start': 36, 'end': 67, 'answer': 'after someone called 911 to get'}\n",
            "{'score': 0.003200893523171544, 'start': 21, 'end': 30, 'answer': 'They need'}\n",
            "{'score': 0.0008715853909961879, 'start': 177, 'end': 181, 'answer': 'much'}\n",
            "{'score': 0.0012597617460414767, 'start': 55, 'end': 78, 'answer': 'WDJT. \"I do, and I hate'}\n",
            "{'score': 0.0003713454934768379, 'start': 125, 'end': 185, 'answer': 'Narcan, also known as naloxone, a prescription medicine that'}\n",
            "{'score': 0.0019536660984158516, 'start': 1, 'end': 33, 'answer': 'She almost killed herself,\" said'}\n",
            "{'score': 0.12234261631965637, 'start': 4, 'end': 6, 'answer': '58'}\n",
            "{'score': 0.0023534554056823254, 'start': 12, 'end': 59, 'answer': 'difficult to watch, Henry says the video forces'}\n",
            "{'score': 0.000600519182626158, 'start': 21, 'end': 65, 'answer': 'could live two different lives and you can’t'}\n",
            "{'score': 0.004594450816512108, 'start': 31, 'end': 39, 'answer': 'motivate'}\n",
            "{'score': 0.0016223862767219543, 'start': 42, 'end': 73, 'answer': 'fellow addicts. \"You don’t have'}\n",
            "{'score': 0.0008994783856905997, 'start': 97, 'end': 143, 'answer': 'inpatient rehabilitation center to help follow'}\n",
            "['an', 'wanted', 'would never do', 'after someone called 911 to get', 'They need', 'much', 'WDJT. \"I do, and I hate', 'Narcan, also known as naloxone, a prescription medicine that', 'She almost killed herself,\" said', '58', 'difficult to watch, Henry says the video forces', 'could live two different lives and you can’t', 'motivate', 'fellow addicts. \"You don’t have', 'inpatient rehabilitation center to help follow']\n",
            "{'score': 0.0022857605945318937, 'start': 23, 'end': 94, 'answer': 'they are pregnant, it might feel natural to touch their bump or comment'}\n",
            "{'score': 0.0008964329608716071, 'start': 152, 'end': 175, 'answer': 'hormonal roller coaster'}\n",
            "{'score': 0.000581443659029901, 'start': 62, 'end': 91, 'answer': 'Midwife & fertility guru Zita'}\n",
            "{'score': 0.015172977931797504, 'start': 6, 'end': 8, 'answer': \"'t\"}\n",
            "{'score': 0.0008861784008331597, 'start': 0, 'end': 39, 'answer': \"Invading people's personal space is not\"}\n",
            "{'score': 0.0006709553999826312, 'start': 3, 'end': 39, 'answer': 'you really want to, you can politely'}\n",
            "{'score': 0.00269904057495296, 'start': 3, 'end': 6, 'answer': 'her'}\n",
            "{'score': 0.0070012654177844524, 'start': 7, 'end': 8, 'answer': 't'}\n",
            "{'score': 0.0007579226512461901, 'start': 5, 'end': 35, 'answer': 'might not seem like a big deal'}\n",
            "{'score': 0.0011270492104813457, 'start': 37, 'end': 59, 'answer': 'our child John or Jane'}\n",
            "{'score': 0.0010996636701747775, 'start': 45, 'end': 90, 'answer': \"going to name her child, and you can't resist\"}\n",
            "{'score': 0.0011127486359328032, 'start': 39, 'end': 86, 'answer': \"stressful for mothers to be. It's easier to not\"}\n",
            "{'score': 0.0015685628168284893, 'start': 34, 'end': 50, 'answer': 'to perfectly fit'}\n",
            "{'score': 0.005314457230269909, 'start': 6, 'end': 8, 'answer': \"'t\"}\n",
            "{'score': 0.00042378876241855323, 'start': 84, 'end': 116, 'answer': 'they are pregnant, their friends'}\n",
            "{'score': 0.0008966241730377078, 'start': 64, 'end': 121, 'answer': \"Whether or not you've seen her maternal side doesn't mean\"}\n",
            "{'score': 0.0013137315399944782, 'start': 12, 'end': 54, 'answer': 'or not you think she fits into the classic'}\n",
            "{'score': 0.004275343846529722, 'start': 6, 'end': 8, 'answer': \"'t\"}\n",
            "{'score': 0.002299916697666049, 'start': 38, 'end': 71, 'answer': \"be really exciting, don't comment\"}\n",
            "{'score': 0.0021868133917450905, 'start': 0, 'end': 16, 'answer': 'Many of the most'}\n",
            "{'score': 0.0005957795074209571, 'start': 138, 'end': 176, 'answer': \"she's looking a large she doesn't need\"}\n",
            "{'score': 0.008172492496669292, 'start': 24, 'end': 38, 'answer': 'not big enough'}\n",
            "{'score': 0.0015656943432986736, 'start': 106, 'end': 128, 'answer': 'are you gaining enough'}\n",
            "{'score': 0.0005457866936922073, 'start': 14, 'end': 53, 'answer': \"you're paying a mama-to-be a compliment\"}\n",
            "{'score': 0.007647681050002575, 'start': 9, 'end': 21, 'answer': 'congratulate'}\n",
            "{'score': 0.0018957005813717842, 'start': 21, 'end': 55, 'answer': \"they're pregnant, they have chosen\"}\n",
            "{'score': 0.0005325060919858515, 'start': 96, 'end': 137, 'answer': 'congratulate them on social media because'}\n",
            "{'score': 0.008432963863015175, 'start': 6, 'end': 8, 'answer': \"'t\"}\n",
            "{'score': 0.0053727887570858, 'start': 22, 'end': 68, 'answer': 'in a way a medical condition, pregnancy is not'}\n",
            "{'score': 0.0004520902584772557, 'start': 253, 'end': 279, 'answer': 'they want is to be treated'}\n",
            "{'score': 0.001199004240334034, 'start': 114, 'end': 139, 'answer': 'their limits and how much'}\n",
            "{'score': 0.00361069617792964, 'start': 0, 'end': 53, 'answer': 'That said, pregnancy can make women tired so do offer'}\n",
            "{'score': 0.010733552277088165, 'start': 0, 'end': 1, 'answer': '8'}\n",
            "{'score': 0.0036692842841148376, 'start': 0, 'end': 44, 'answer': \"Whenever anyone's having a baby, others love\"}\n",
            "{'score': 0.0017231230158358812, 'start': 119, 'end': 138, 'answer': 'in your body is not'}\n",
            "{'score': 0.0006886585615575314, 'start': 123, 'end': 194, 'answer': 'most women get through it, and usually, once the baby arrives, memories'}\n",
            "{'score': 0.0020782325882464647, 'start': 3, 'end': 15, 'answer': 'is genuinely'}\n",
            "{'score': 0.0067146532237529755, 'start': 30, 'end': 32, 'answer': 'be'}\n",
            "{'score': 0.0012264803517609835, 'start': 41, 'end': 62, 'answer': 'Their lives are about'}\n",
            "{'score': 0.001453373464755714, 'start': 86, 'end': 100, 'answer': 'they might not'}\n",
            "{'score': 0.00026716318097896874, 'start': 14, 'end': 87, 'answer': 'some longer than others to take to motherhood, but that is understandable'}\n",
            "{'score': 0.000860034313518554, 'start': 120, 'end': 129, 'answer': 'no wonder'}\n",
            "{'score': 0.000583520857617259, 'start': 115, 'end': 139, 'answer': 'their new role admirably'}\n",
            "['they are pregnant, it might feel natural to touch their bump or comment', 'hormonal roller coaster', 'Midwife & fertility guru Zita', \"'t\", \"Invading people's personal space is not\", 'you really want to, you can politely', 'her', 't', 'might not seem like a big deal', 'our child John or Jane', \"going to name her child, and you can't resist\", \"stressful for mothers to be. It's easier to not\", 'to perfectly fit', \"'t\", 'they are pregnant, their friends', \"Whether or not you've seen her maternal side doesn't mean\", 'or not you think she fits into the classic', \"'t\", \"be really exciting, don't comment\", 'Many of the most', \"she's looking a large she doesn't need\", 'not big enough', 'are you gaining enough', \"you're paying a mama-to-be a compliment\", 'congratulate', \"they're pregnant, they have chosen\", 'congratulate them on social media because', \"'t\", 'in a way a medical condition, pregnancy is not', 'they want is to be treated', 'their limits and how much', 'That said, pregnancy can make women tired so do offer', '8', \"Whenever anyone's having a baby, others love\", 'in your body is not', 'most women get through it, and usually, once the baby arrives, memories', 'is genuinely', 'be', 'Their lives are about', 'they might not', 'some longer than others to take to motherhood, but that is understandable', 'no wonder', 'their new role admirably']\n",
            "{'score': 0.001338314265012741, 'start': 9, 'end': 19, 'answer': 'and deeply'}\n",
            "{'score': 0.0001365674106637016, 'start': 33, 'end': 41, 'answer': 'quagmire'}\n",
            "{'score': 0.0007186270668171346, 'start': 150, 'end': 158, 'answer': 'be quite'}\n",
            "{'score': 0.008235028944909573, 'start': 38, 'end': 48, 'answer': 'Headphones'}\n",
            "{'score': 0.0014778439654037356, 'start': 138, 'end': 151, 'answer': 'the same time'}\n",
            "{'score': 0.005297116935253143, 'start': 5, 'end': 22, 'answer': 'that doesn’t mean'}\n",
            "{'score': 0.0032035699114203453, 'start': 37, 'end': 61, 'answer': 'being approached because'}\n",
            "{'score': 0.0006192566361278296, 'start': 112, 'end': 125, 'answer': 'almost always'}\n",
            "{'score': 0.0007450192933902144, 'start': 130, 'end': 141, 'answer': 'have missed'}\n",
            "{'score': 0.0001427307288395241, 'start': 151, 'end': 205, 'answer': 'those blessed with an abundance of ego. It’s a defence'}\n",
            "{'score': 0.032307542860507965, 'start': 4, 'end': 15, 'answer': 'back to Dan'}\n",
            "{'score': 0.01932406984269619, 'start': 0, 'end': 10, 'answer': 'What to Do'}\n",
            "{'score': 0.0031697023659944534, 'start': 9, 'end': 17, 'answer': 'in front'}\n",
            "{'score': 0.00844570156186819, 'start': 3, 'end': 7, 'answer': 'Have'}\n",
            "{'score': 0.0007897508330643177, 'start': 10, 'end': 16, 'answer': 'hasn’t'}\n",
            "{'score': 0.0006677925121039152, 'start': 121, 'end': 133, 'answer': 'to be taking'}\n",
            "{'score': 0.0006232031155377626, 'start': 27, 'end': 31, 'answer': 'most'}\n",
            "{'score': 0.0006503383629024029, 'start': 3, 'end': 7, 'answer': 'most'}\n",
            "{'score': 0.0004340942541602999, 'start': 178, 'end': 235, 'answer': 'you understand that approaching a woman in this way isn’t'}\n",
            "{'score': 0.002453566761687398, 'start': 36, 'end': 59, 'answer': 'that you are a cool guy'}\n",
            "{'score': 0.00011007507418980822, 'start': 350, 'end': 370, 'answer': 'excited\" and I’m not'}\n",
            "{'score': 0.00012186487583676353, 'start': 270, 'end': 330, 'answer': 'any further action I take to extract myself from a situation'}\n",
            "{'score': 0.0005849212757311761, 'start': 39, 'end': 70, 'answer': 'bullied me into one of the most'}\n",
            "{'score': 0.0007461256464011967, 'start': 68, 'end': 76, 'answer': 'has used'}\n",
            "{'score': 0.00030954592511989176, 'start': 51, 'end': 66, 'answer': 'I know it’s not'}\n",
            "{'score': 0.00273020938038826, 'start': 16, 'end': 43, 'answer': 'flattered by the compliment'}\n",
            "{'score': 0.0007914625457488, 'start': 13, 'end': 23, 'answer': 'some humor'}\n",
            "{'score': 0.00691699655726552, 'start': 8, 'end': 50, 'answer': 'Most likely laughing, smiling and enjoying'}\n",
            "{'score': 0.00025110828573815525, 'start': 28, 'end': 42, 'answer': 'have something'}\n",
            "{'score': 0.0011015214258804917, 'start': 131, 'end': 173, 'answer': 'hunched shoulders, darting eyes and rictus'}\n",
            "{'score': 0.001724969712086022, 'start': 48, 'end': 80, 'answer': 'I’ve been it, seen it and spoken'}\n",
            "{'score': 0.0015442848671227694, 'start': 26, 'end': 45, 'answer': 'to be talked to but'}\n",
            "{'score': 0.01936831884086132, 'start': 18, 'end': 20, 'answer': 'me'}\n",
            "{'score': 0.0022002323530614376, 'start': 29, 'end': 60, 'answer': '****, I DIDN’T FANCY YOU ANYWAY'}\n",
            "{'score': 0.000206877026357688, 'start': 47, 'end': 59, 'answer': 'any surprise'}\n",
            "{'score': 0.0014735133154317737, 'start': 59, 'end': 107, 'answer': 'a woman who is wearing headphones. Sadly not one'}\n",
            "{'score': 0.0006287556025199592, 'start': 29, 'end': 61, 'answer': 'inoffensive, generic dating guff'}\n",
            "{'score': 0.01808454655110836, 'start': 0, 'end': 11, 'answer': '2. Allowing'}\n",
            "{'score': 0.004776386544108391, 'start': 12, 'end': 23, 'answer': 'are a great'}\n",
            "{'score': 0.0008646034402772784, 'start': 90, 'end': 113, 'answer': 'being determined to get'}\n",
            "{'score': 0.0013148024445399642, 'start': 46, 'end': 74, 'answer': ', a woman usually won’t give'}\n",
            "{'score': 0.00036870379699394107, 'start': 202, 'end': 216, 'answer': 'will he remain'}\n",
            "{'score': 0.0012668967247009277, 'start': 88, 'end': 129, 'answer': 'is mentally and emotionally strong enough'}\n",
            "{'score': 0.001628373982384801, 'start': 51, 'end': 108, 'answer': 'most women will be turned off by his mental and emotional'}\n",
            "{'score': 0.011664951220154762, 'start': 16, 'end': 23, 'answer': 'to take'}\n",
            "{'score': 0.0003338172100484371, 'start': 100, 'end': 148, 'answer': 'is more confident than her. A woman doesn’t want'}\n",
            "{'score': 0.00031143371597863734, 'start': 91, 'end': 110, 'answer': 'being too assertive'}\n",
            "{'score': 0.0001991545141208917, 'start': 207, 'end': 227, 'answer': 'million rape defence'}\n",
            "{'score': 0.00045395130291581154, 'start': 54, 'end': 70, 'answer': 'jaw-drop factor:'}\n",
            "{'score': 0.0001334594562649727, 'start': 170, 'end': 187, 'answer': 'be hunted and won'}\n",
            "{'score': 0.0002733241126406938, 'start': 40, 'end': 105, 'answer': 'frustrated man-babies how to handle rejection with grace, because'}\n",
            "{'score': 0.0020623388700187206, 'start': 20, 'end': 71, 'answer': 'whiny pissbabies ask, when am I allowed to approach'}\n",
            "{'score': 8.912229532143101e-05, 'start': 325, 'end': 350, 'answer': 'a good evening and toddle'}\n",
            "{'score': 0.0004222879360895604, 'start': 127, 'end': 153, 'answer': 'you’re looking for a horde'}\n",
            "{'score': 0.001987796975299716, 'start': 15, 'end': 24, 'answer': 'soon from'}\n",
            "['and deeply', 'quagmire', 'be quite', 'Headphones', 'the same time', 'that doesn’t mean', 'being approached because', 'almost always', 'have missed', 'those blessed with an abundance of ego. It’s a defence', 'back to Dan', 'What to Do', 'in front', 'Have', 'hasn’t', 'to be taking', 'most', 'most', 'you understand that approaching a woman in this way isn’t', 'that you are a cool guy', 'excited\" and I’m not', 'any further action I take to extract myself from a situation', 'bullied me into one of the most', 'has used', 'I know it’s not', 'flattered by the compliment', 'some humor', 'Most likely laughing, smiling and enjoying', 'have something', 'hunched shoulders, darting eyes and rictus', 'I’ve been it, seen it and spoken', 'to be talked to but', 'me', '****, I DIDN’T FANCY YOU ANYWAY', 'any surprise', 'a woman who is wearing headphones. Sadly not one', 'inoffensive, generic dating guff', '2. Allowing', 'are a great', 'being determined to get', ', a woman usually won’t give', 'will he remain', 'is mentally and emotionally strong enough', 'most women will be turned off by his mental and emotional', 'to take', 'is more confident than her. A woman doesn’t want', 'being too assertive', 'million rape defence', 'jaw-drop factor:', 'be hunted and won', 'frustrated man-babies how to handle rejection with grace, because', 'whiny pissbabies ask, when am I allowed to approach', 'a good evening and toddle', 'you’re looking for a horde', 'soon from']\n",
            "{'score': 0.0002949609188362956, 'start': 125, 'end': 133, 'answer': 'hundreds'}\n",
            "{'score': 0.0003530564717948437, 'start': 4, 'end': 22, 'answer': 'some games capture'}\n",
            "{'score': 0.02184305153787136, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.0002807636046782136, 'start': 195, 'end': 218, 'answer': 'butt when the situation'}\n",
            "{'score': 0.00012634594168048352, 'start': 32, 'end': 59, 'answer': 'to be the first installment'}\n",
            "{'score': 0.000988666550256312, 'start': 5, 'end': 72, 'answer': 'we might see it: Ubisoft maintains that this game is in development'}\n",
            "{'score': 0.03794093430042267, 'start': 0, 'end': 10, 'answer': '4. Kingdom'}\n",
            "{'score': 0.0004070272552780807, 'start': 181, 'end': 214, 'answer': 'you happen to fit into the target'}\n",
            "{'score': 0.00017325274529866874, 'start': 247, 'end': 303, 'answer': 'some would say — filler. Never fear. A third installment'}\n",
            "{'score': 0.01061258651316166, 'start': 5, 'end': 40, 'answer': 'we might see it: Hopefully by 2017.'}\n",
            "{'score': 0.032206542789936066, 'start': 1, 'end': 19, 'answer': '. Final Fantasy XV'}\n",
            "{'score': 0.0003554777358658612, 'start': 19, 'end': 100, 'answer': 'that’s currently called Final Fantasy XV began under the title Final Fantasy XIII'}\n",
            "{'score': 0.00035304954508319497, 'start': 91, 'end': 132, 'answer': 'somewhat hard times. The 13th installment'}\n",
            "{'score': 0.00029203822487033904, 'start': 79, 'end': 132, 'answer': 'a Big Important Game for the series’ 15th installment'}\n",
            "{'score': 0.011535532772541046, 'start': 5, 'end': 33, 'answer': 'we might see it: November 29'}\n",
            "{'score': 0.03416426107287407, 'start': 3, 'end': 20, 'answer': 'The Last Guardian'}\n",
            "{'score': 0.00016205720021389425, 'start': 172, 'end': 193, 'answer': 'they’re both singular'}\n",
            "{'score': 0.0005928215687163174, 'start': 17, 'end': 47, 'answer': 'a fresh look at the game at E3'}\n",
            "{'score': 0.005811438430100679, 'start': 5, 'end': 51, 'answer': 'we might see it: Sometime in 2016... hopefully'}\n",
            "{'score': 0.02473379485309124, 'start': 0, 'end': 1, 'answer': '1'}\n",
            "{'score': 0.00012536572467070073, 'start': 347, 'end': 405, 'answer': 'no stretch to say that the original Half-Life was probably'}\n",
            "{'score': 0.00011686682410072535, 'start': 34, 'end': 59, 'answer': 'that the last installment'}\n",
            "{'score': 0.0027066278271377087, 'start': 65, 'end': 79, 'answer': 'in development'}\n",
            "['hundreds', 'some games capture', '5', 'butt when the situation', 'to be the first installment', 'we might see it: Ubisoft maintains that this game is in development', '4. Kingdom', 'you happen to fit into the target', 'some would say — filler. Never fear. A third installment', 'we might see it: Hopefully by 2017.', '. Final Fantasy XV', 'that’s currently called Final Fantasy XV began under the title Final Fantasy XIII', 'somewhat hard times. The 13th installment', 'a Big Important Game for the series’ 15th installment', 'we might see it: November 29', 'The Last Guardian', 'they’re both singular', 'a fresh look at the game at E3', 'we might see it: Sometime in 2016... hopefully', '1', 'no stretch to say that the original Half-Life was probably', 'that the last installment', 'in development']\n",
            "{'score': 0.07658566534519196, 'start': 0, 'end': 6, 'answer': '+ READ'}\n",
            "{'score': 0.0004747732018586248, 'start': 172, 'end': 194, 'answer': 'did give Entertainment'}\n",
            "{'score': 0.005326040554791689, 'start': 40, 'end': 55, 'answer': 'we know so far.'}\n",
            "{'score': 0.0008496495429426432, 'start': 90, 'end': 166, 'answer': 'your friends the correct walkie talkies to discuss the finer points of Steve'}\n",
            "{'score': 2.9382759748841636e-05, 'start': 580, 'end': 585, 'answer': 'Ryder'}\n",
            "{'score': 0.00021637079771608114, 'start': 307, 'end': 320, 'answer': 'didn’t endure'}\n",
            "{'score': 3.8811118429293856e-05, 'start': 407, 'end': 451, 'answer': 'Terminator 2. I guess a lot of this is James'}\n",
            "{'score': 0.033335763961076736, 'start': 20, 'end': 28, 'answer': 'Stranger'}\n",
            "{'score': 0.00019959729979746044, 'start': 20, 'end': 42, 'answer': 'infested Hawkins won’t'}\n",
            "{'score': 4.83210023958236e-05, 'start': 325, 'end': 383, 'answer': 'curiosity door locked. They assure us the show will answer'}\n",
            "{'score': 8.553672523703426e-05, 'start': 212, 'end': 240, 'answer': 'any longer, it gets unwieldy'}\n",
            "['+ READ', 'did give Entertainment', 'we know so far.', 'your friends the correct walkie talkies to discuss the finer points of Steve', 'Ryder', 'didn’t endure', 'Terminator 2. I guess a lot of this is James', 'Stranger', 'infested Hawkins won’t', 'curiosity door locked. They assure us the show will answer', 'any longer, it gets unwieldy']\n",
            "{'score': 0.00017873107572086155, 'start': 100, 'end': 147, 'answer': 'in his hand. Sitting on a leather couch in Park'}\n",
            "{'score': 0.00014144765737000853, 'start': 425, 'end': 428, 'answer': 'his'}\n",
            "{'score': 0.0005223647458478808, 'start': 71, 'end': 100, 'answer': '10 years to make this happen,'}\n",
            "{'score': 0.01486892905086279, 'start': 15, 'end': 34, 'answer': 'spoilers throughout'}\n",
            "{'score': 0.004926328547298908, 'start': 5, 'end': 35, 'answer': 'did you originally come across'}\n",
            "{'score': 0.00028333129012025893, 'start': 168, 'end': 186, 'answer': 'to actually make a'}\n",
            "{'score': 8.781907672528177e-05, 'start': 198, 'end': 229, 'answer': 'had written a shitty screenplay'}\n",
            "{'score': 0.010480154305696487, 'start': 10, 'end': 39, 'answer': 'had put all that time into it'}\n",
            "{'score': 0.0001345164346275851, 'start': 297, 'end': 321, 'answer': 'going to write it anyway'}\n",
            "{'score': 0.0027143212500959635, 'start': 38, 'end': 42, 'answer': 'much'}\n",
            "{'score': 0.00022969793644733727, 'start': 229, 'end': 286, 'answer': 'few hours and crank it around a little bit and I wouldn’t'}\n",
            "{'score': 0.004181526135653257, 'start': 7, 'end': 11, 'answer': 'have'}\n",
            "{'score': 0.0004861471534240991, 'start': 107, 'end': 138, 'answer': 're like I gotta get out of here'}\n",
            "{'score': 0.014500056393444538, 'start': 4, 'end': 13, 'answer': 'live in L'}\n",
            "{'score': 0.0016602757386863232, 'start': 52, 'end': 85, 'answer': 'have a place I go surfing in Long'}\n",
            "{'score': 0.023928863927721977, 'start': 0, 'end': 5, 'answer': 'Isn’t'}\n",
            "{'score': 0.0007545652333647013, 'start': 33, 'end': 36, 'answer': 'all'}\n",
            "{'score': 0.002114957896992564, 'start': 72, 'end': 103, 'answer': 'What made you want to make this'}\n",
            "{'score': 0.00024618979659862816, 'start': 89, 'end': 110, 'answer': 'whether that makes me'}\n",
            "{'score': 6.85818595229648e-05, 'start': 420, 'end': 472, 'answer': 'would ever get without paying for it. So even though'}\n",
            "{'score': 0.00016057492757681757, 'start': 57, 'end': 91, 'answer': 'disappointment she feels. He’s not'}\n",
            "{'score': 0.01563941314816475, 'start': 0, 'end': 30, 'answer': 'Did you consider acting in the'}\n",
            "{'score': 0.0006278195069171488, 'start': 68, 'end': 93, 'answer': 'were like, \"good idea.\" ['}\n",
            "{'score': 0.004561806097626686, 'start': 18, 'end': 31, 'answer': 've directed a'}\n",
            "{'score': 0.00021275828476063907, 'start': 251, 'end': 269, 'answer': 'on one side of the'}\n",
            "{'score': 0.0001635145745240152, 'start': 67, 'end': 84, 'answer': 'stratosphere, but'}\n",
            "{'score': 0.001809037639759481, 'start': 101, 'end': 109, 'answer': 'Was Here'}\n",
            "{'score': 0.00018502752936910838, 'start': 60, 'end': 92, 'answer': 'there are all kinds of reasons –'}\n",
            "{'score': 0.0023785035591572523, 'start': 28, 'end': 67, 'answer': 'Did you just ask Christina Hendricks at'}\n",
            "{'score': 9.318476804764941e-05, 'start': 309, 'end': 347, 'answer': 'Shelburne. He called and said, \"I love'}\n",
            "{'score': 8.249464735854417e-05, 'start': 271, 'end': 335, 'answer': 'hope to get Phil. She was thrilled. I sent it to Richard Jenkins'}\n",
            "{'score': 0.0006185168749652803, 'start': 63, 'end': 100, 'answer': 'are below in the street looking up at'}\n",
            "{'score': 6.643875531153753e-05, 'start': 4, 'end': 27, 'answer': 'condoned this guy being'}\n",
            "{'score': 0.0017575881211087108, 'start': 22, 'end': 38, 'answer': 'that making this'}\n",
            "{'score': 6.844187737442553e-05, 'start': 303, 'end': 341, 'answer': 'well. I can’t play everything. I’m not'}\n",
            "{'score': 0.0005695755244232714, 'start': 28, 'end': 90, 'answer': 'are sophisticated degrees of performing. There’s actor A, B, C'}\n",
            "{'score': 0.012333103455603123, 'start': 0, 'end': 23, 'answer': 'That’s also a testament'}\n",
            "{'score': 0.0006191704305820167, 'start': 133, 'end': 147, 'answer': 'I should be so'}\n",
            "['in his hand. Sitting on a leather couch in Park', 'his', '10 years to make this happen,', 'spoilers throughout', 'did you originally come across', 'to actually make a', 'had written a shitty screenplay', 'had put all that time into it', 'going to write it anyway', 'much', 'few hours and crank it around a little bit and I wouldn’t', 'have', 're like I gotta get out of here', 'live in L', 'have a place I go surfing in Long', 'Isn’t', 'all', 'What made you want to make this', 'whether that makes me', 'would ever get without paying for it. So even though', 'disappointment she feels. He’s not', 'Did you consider acting in the', 'were like, \"good idea.\" [', 've directed a', 'on one side of the', 'stratosphere, but', 'Was Here', 'there are all kinds of reasons –', 'Did you just ask Christina Hendricks at', 'Shelburne. He called and said, \"I love', 'hope to get Phil. She was thrilled. I sent it to Richard Jenkins', 'are below in the street looking up at', 'condoned this guy being', 'that making this', 'well. I can’t play everything. I’m not', 'are sophisticated degrees of performing. There’s actor A, B, C', 'That’s also a testament', 'I should be so']\n",
            "{'score': 0.0039432053454220295, 'start': 6, 'end': 19, 'answer': 'Gailey serves'}\n",
            "{'score': 0.005214180331677198, 'start': 0, 'end': 38, 'answer': 'She tweeted her story, which should be'}\n",
            "{'score': 0.0037008223589509726, 'start': 11, 'end': 39, 'answer': 'Gather round, Twitter, and I'}\n",
            "{'score': 0.0010712610092014074, 'start': 53, 'end': 104, 'answer': \"I shouldn't have dated him. You know the type. Just\"}\n",
            "{'score': 0.0011307698441669345, 'start': 0, 'end': 3, 'answer': 'One'}\n",
            "{'score': 0.0016023784410208464, 'start': 13, 'end': 29, 'answer': 'were at a family'}\n",
            "{'score': 0.0011894337367266417, 'start': 73, 'end': 76, 'answer': 'Did'}\n",
            "{'score': 0.0007508993148803711, 'start': 26, 'end': 67, 'answer': 'fiddle with it. \"Put that down, you don\\'t'}\n",
            "{'score': 0.0017489551100879908, 'start': 61, 'end': 82, 'answer': 'do you imagine he did'}\n",
            "{'score': 0.002642435021698475, 'start': 28, 'end': 72, 'answer': 'in his hand to eye level, looked right at me'}\n",
            "{'score': 0.0011440729722380638, 'start': 2, 'end': 12, 'answer': 'was trying'}\n",
            "{'score': 0.002862720750272274, 'start': 52, 'end': 65, 'answer': 'have probably'}\n",
            "{'score': 0.0008943657157942653, 'start': 17, 'end': 36, 'answer': 'the uninitiated, is'}\n",
            "{'score': 0.0009548426023684442, 'start': 78, 'end': 94, 'answer': 'gnarled-up feet.'}\n",
            "{'score': 0.0012784813297912478, 'start': 25, 'end': 28, 'answer': 'lot'}\n",
            "{'score': 0.0011829036520794034, 'start': 62, 'end': 104, 'answer': 'frequently, it can get *pretty much packed'}\n",
            "{'score': 0.0011868749279528856, 'start': 49, 'end': 65, 'answer': 'level, looked at'}\n",
            "{'score': 0.002603034256026149, 'start': 19, 'end': 95, 'answer': 'shavings ERUPTED from within the Ped Egg like an explosion of flesh confetti'}\n",
            "{'score': 0.0015698589850217104, 'start': 73, 'end': 78, 'answer': 'whisk'}\n",
            "{'score': 0.001688198302872479, 'start': 57, 'end': 98, 'answer': 'peeing myself and the only word I managed'}\n",
            "{'score': 0.0010395104764029384, 'start': 95, 'end': 135, 'answer': 'in your mouth. And nose. And eyes. ~fin~'}\n",
            "{'score': 0.03097435273230076, 'start': 18, 'end': 21, 'answer': 'it.'}\n",
            "{'score': 0.0015332273906096816, 'start': 91, 'end': 131, 'answer': 'BUNION DUST GOOD PEOPLE WILL BE REWARDED'}\n",
            "{'score': 0.0014876769855618477, 'start': 71, 'end': 135, 'answer': 'that somehow, bonus footage of this wonderful moment is included'}\n",
            "{'score': 0.0010593733750283718, 'start': 70, 'end': 80, 'answer': 'yZnaWrHI1o'}\n",
            "{'score': 0.0026783044449985027, 'start': 3, 'end': 13, 'answer': \"that's not\"}\n",
            "{'score': 0.005216857884079218, 'start': 12, 'end': 17, 'answer': 'petty'}\n",
            "{'score': 0.032683081924915314, 'start': 5, 'end': 23, 'answer': 'scrolling for next'}\n",
            "['Gailey serves', 'She tweeted her story, which should be', 'Gather round, Twitter, and I', \"I shouldn't have dated him. You know the type. Just\", 'One', 'were at a family', 'Did', 'fiddle with it. \"Put that down, you don\\'t', 'do you imagine he did', 'in his hand to eye level, looked right at me', 'was trying', 'have probably', 'the uninitiated, is', 'gnarled-up feet.', 'lot', 'frequently, it can get *pretty much packed', 'level, looked at', 'shavings ERUPTED from within the Ped Egg like an explosion of flesh confetti', 'whisk', 'peeing myself and the only word I managed', 'in your mouth. And nose. And eyes. ~fin~', 'it.', 'BUNION DUST GOOD PEOPLE WILL BE REWARDED', 'that somehow, bonus footage of this wonderful moment is included', 'yZnaWrHI1o', \"that's not\", 'petty', 'scrolling for next']\n",
            "{'score': 0.0006313659832812846, 'start': 132, 'end': 156, 'answer': 'Good-Bye: Famed Carnegie'}\n",
            "{'score': 0.0008195614209398627, 'start': 84, 'end': 139, 'answer': 'had been hard at work in 2016 crafting new laws to take'}\n",
            "{'score': 0.0004257973632775247, 'start': 67, 'end': 112, 'answer': 'pitchforks or spears. Spearfishing has always'}\n",
            "{'score': 0.0003465980407781899, 'start': 170, 'end': 181, 'answer': 'do not like'}\n",
            "{'score': 0.0001941463997354731, 'start': 298, 'end': 369, 'answer': 'normally only from a distributor. For wines and spirits, Pennsylvanians'}\n",
            "['Good-Bye: Famed Carnegie', 'had been hard at work in 2016 crafting new laws to take', 'pitchforks or spears. Spearfishing has always', 'do not like', 'normally only from a distributor. For wines and spirits, Pennsylvanians']\n",
            "{'score': 0.0008694841526448727, 'start': 49, 'end': 105, 'answer': 'are formed on the lower back of women. However, some men'}\n",
            "{'score': 0.0014620287111029029, 'start': 0, 'end': 21, 'answer': 'They are located in a'}\n",
            "{'score': 0.004728738684207201, 'start': 32, 'end': 36, 'answer': 'good'}\n",
            "{'score': 0.0009071915992535651, 'start': 95, 'end': 136, 'answer': 'them with exercises. However, eliminating'}\n",
            "{'score': 0.0018696606857702136, 'start': 35, 'end': 63, 'answer': 'them for the looks but to be'}\n",
            "{'score': 0.005425424315035343, 'start': 16, 'end': 20, 'answer': 'http'}\n",
            "{'score': 0.0021258294582366943, 'start': 25, 'end': 65, 'answer': 'spinalmedical.co.uk/back_pain_causes.php'}\n",
            "['are formed on the lower back of women. However, some men', 'They are located in a', 'good', 'them with exercises. However, eliminating', 'them for the looks but to be', 'http', 'spinalmedical.co.uk/back_pain_causes.php']\n",
            "{'score': 0.008102643303573132, 'start': 6, 'end': 23, 'answer': 'you know, in case'}\n",
            "{'score': 0.0023102255072444677, 'start': 10, 'end': 35, 'answer': 'pointing any fingers here'}\n",
            "{'score': 0.0013262189459055662, 'start': 73, 'end': 83, 'answer': 'Davidowitz'}\n",
            "{'score': 0.0012475961120799184, 'start': 56, 'end': 81, 'answer': 'your goals. So we decided'}\n",
            "{'score': 0.001322596101090312, 'start': 75, 'end': 87, 'answer': 'that promise'}\n",
            "{'score': 0.00040652198367752135, 'start': 0, 'end': 51, 'answer': 'They... probably won\\'t work. \"You can only maximize'}\n",
            "{'score': 0.00021447397011797875, 'start': 305, 'end': 322, 'answer': 'There’s no actual'}\n",
            "{'score': 0.0009779317770153284, 'start': 0, 'end': 30, 'answer': '\"Here’s the thing,\" says Fisch'}\n",
            "{'score': 0.0004396397271193564, 'start': 202, 'end': 228, 'answer': 'would be less,\" says Fisch'}\n",
            "{'score': 0.0003727436996996403, 'start': 171, 'end': 192, 'answer': 'where to start, check'}\n",
            "{'score': 0.007286685053259134, 'start': 33, 'end': 48, 'answer': 'your pubic hair'}\n",
            "{'score': 0.00031370174838230014, 'start': 247, 'end': 267, 'answer': 'extender you can buy'}\n",
            "{'score': 0.0031463303603231907, 'start': 29, 'end': 48, 'answer': 'at maximum capacity'}\n",
            "{'score': 0.0008376521873287857, 'start': 43, 'end': 71, 'answer': 'you can’t get it bigger than'}\n",
            "{'score': 0.00018096443091053516, 'start': 23, 'end': 34, 'answer': 'they’re not'}\n",
            "{'score': 0.007114102598279715, 'start': 13, 'end': 46, 'answer': 'there are some pills you can take'}\n",
            "{'score': 0.00027784318081103265, 'start': 67, 'end': 108, 'answer': 'most common. While they won’t necessarily'}\n",
            "{'score': 0.0008048388990573585, 'start': 57, 'end': 82, 'answer': 'your vascular health or l'}\n",
            "{'score': 0.00024179861065931618, 'start': 3, 'end': 10, 'answer': 's worth'}\n",
            "{'score': 0.0036787523422390223, 'start': 21, 'end': 78, 'answer': 'you really shouldn’t worry so much about your size anyway'}\n",
            "{'score': 0.0003595289308577776, 'start': 163, 'end': 202, 'answer': 'fall within an inch of that, says Fisch'}\n",
            "{'score': 0.00021567058865912259, 'start': 312, 'end': 342, 'answer': 'possibly be unrelated entirely'}\n",
            "{'score': 0.003071265760809183, 'start': 9, 'end': 38, 'answer': 's have an honest conversation'}\n",
            "{'score': 0.0001486798282712698, 'start': 370, 'end': 373, 'answer': '100'}\n",
            "{'score': 0.002570175798609853, 'start': 67, 'end': 69, 'answer': 'OK'}\n",
            "{'score': 0.00034671826870180666, 'start': 50, 'end': 125, 'answer': \"tweaks to have the biggest and hardest penis that's physically possible for\"}\n",
            "['you know, in case', 'pointing any fingers here', 'Davidowitz', 'your goals. So we decided', 'that promise', 'They... probably won\\'t work. \"You can only maximize', 'There’s no actual', '\"Here’s the thing,\" says Fisch', 'would be less,\" says Fisch', 'where to start, check', 'your pubic hair', 'extender you can buy', 'at maximum capacity', 'you can’t get it bigger than', 'they’re not', 'there are some pills you can take', 'most common. While they won’t necessarily', 'your vascular health or l', 's worth', 'you really shouldn’t worry so much about your size anyway', 'fall within an inch of that, says Fisch', 'possibly be unrelated entirely', 's have an honest conversation', '100', 'OK', \"tweaks to have the biggest and hardest penis that's physically possible for\"]\n",
            "{'score': 0.02596646547317505, 'start': 25, 'end': 32, 'answer': 'Woolley'}\n",
            "{'score': 0.00014125941379461437, 'start': 202, 'end': 269, 'answer': 'those tempted to play the game while driving, it’s proven extremely'}\n",
            "{'score': 0.003693724051117897, 'start': 0, 'end': 25, 'answer': 'http://kotaku.com/pokemon'}\n",
            "{'score': 0.0004472064902074635, 'start': 40, 'end': 90, 'answer': 'there are some things that can be done to mitigate'}\n",
            "{'score': 0.014531643129885197, 'start': 12, 'end': 17, 'answer': 'Don’t'}\n",
            "{'score': 0.0025580034125596285, 'start': 23, 'end': 29, 'answer': 'me say'}\n",
            "{'score': 0.00020293405395932496, 'start': 7, 'end': 23, 'answer': 'there’s at least'}\n",
            "{'score': 0.20911014080047607, 'start': 0, 'end': 9, 'answer': 'Sponsored'}\n",
            "{'score': 0.0006018791464157403, 'start': 133, 'end': 183, 'answer': 'Poliwag in sight. Park somewhere where you’ll stay'}\n",
            "{'score': 0.000300685060210526, 'start': 236, 'end': 256, 'answer': 'you’re then focusing'}\n",
            "{'score': 0.00022240729595068842, 'start': 129, 'end': 143, 'answer': 'happy Pokémon'}\n",
            "{'score': 0.00032807461684569716, 'start': 30, 'end': 35, 'answer': 'going'}\n",
            "{'score': 0.0009191864519380033, 'start': 34, 'end': 45, 'answer': 'if you have'}\n",
            "{'score': 0.01468595489859581, 'start': 21, 'end': 33, 'answer': 'my next move'}\n",
            "{'score': 0.005458941217511892, 'start': 12, 'end': 41, 'answer': 'Scope Out Your Next Pokéstop'}\n",
            "{'score': 0.0003038175927940756, 'start': 76, 'end': 123, 'answer': 'You can tap on further away gyms and Pokéstops'}\n",
            "{'score': 0.00040193431777879596, 'start': 181, 'end': 195, 'answer': 'sure to follow'}\n",
            "{'score': 0.004973710980266333, 'start': 40, 'end': 57, 'answer': 'Silent And Hidden'}\n",
            "{'score': 0.00031877009314484894, 'start': 216, 'end': 222, 'answer': 'anyone'}\n",
            "{'score': 0.00023658230202272534, 'start': 77, 'end': 88, 'answer': 'well-suited'}\n",
            "{'score': 0.003693724051117897, 'start': 0, 'end': 25, 'answer': 'http://kotaku.com/pokemon'}\n",
            "{'score': 0.0038725065533071756, 'start': 24, 'end': 78, 'answer': 'hidden while charging, as illustrated in a Porsche 918'}\n",
            "{'score': 0.0003088103258050978, 'start': 197, 'end': 220, 'answer': 'you really have no self'}\n",
            "{'score': 0.0002532750368118286, 'start': 269, 'end': 279, 'answer': 'don’t want'}\n",
            "{'score': 0.004809525329619646, 'start': 7, 'end': 47, 'answer': 'many landmarks you’ll find as Pokéstops'}\n",
            "{'score': 0.008848046883940697, 'start': 9, 'end': 42, 'answer': '4: Get Out And Walk Around Anyway'}\n",
            "{'score': 0.0006282813264988363, 'start': 4, 'end': 10, 'answer': 'always'}\n",
            "{'score': 0.0008368542185053229, 'start': 14, 'end': 82, 'answer': 'was one step ahead of that idea. After my roughly 48-kilometer drive'}\n",
            "{'score': 0.00046501157339662313, 'start': 219, 'end': 225, 'answer': '20 kph'}\n",
            "{'score': 0.0002779253991320729, 'start': 53, 'end': 98, 'answer': 'puttering around at speeds slower than 20 kph'}\n",
            "{'score': 0.00038794000283814967, 'start': 11, 'end': 16, 'answer': 'worth'}\n",
            "{'score': 0.001763322507031262, 'start': 3, 'end': 54, 'answer': 'you’re playing around cars, make sure they’re going'}\n",
            "{'score': 0.0007016414892859757, 'start': 31, 'end': 45, 'answer': 'you to do: get'}\n",
            "{'score': 0.0003424540045671165, 'start': 153, 'end': 166, 'answer': 'my car anyway'}\n",
            "{'score': 0.00044604024151340127, 'start': 192, 'end': 217, 'answer': 'silent phone on a charger'}\n",
            "['Woolley', 'those tempted to play the game while driving, it’s proven extremely', 'http://kotaku.com/pokemon', 'there are some things that can be done to mitigate', 'Don’t', 'me say', 'there’s at least', 'Sponsored', 'Poliwag in sight. Park somewhere where you’ll stay', 'you’re then focusing', 'happy Pokémon', 'going', 'if you have', 'my next move', 'Scope Out Your Next Pokéstop', 'You can tap on further away gyms and Pokéstops', 'sure to follow', 'Silent And Hidden', 'anyone', 'well-suited', 'http://kotaku.com/pokemon', 'hidden while charging, as illustrated in a Porsche 918', 'you really have no self', 'don’t want', 'many landmarks you’ll find as Pokéstops', '4: Get Out And Walk Around Anyway', 'always', 'was one step ahead of that idea. After my roughly 48-kilometer drive', '20 kph', 'puttering around at speeds slower than 20 kph', 'worth', 'you’re playing around cars, make sure they’re going', 'you to do: get', 'my car anyway', 'silent phone on a charger']\n",
            "{'score': 0.00022916588932275772, 'start': 273, 'end': 309, 'answer': 'most cherished moments, exemplifying'}\n",
            "{'score': 0.003168302122503519, 'start': 35, 'end': 43, 'answer': \"wouldn't\"}\n",
            "{'score': 0.10911630839109421, 'start': 0, 'end': 3, 'answer': 'THE'}\n",
            "{'score': 0.00039107020711526275, 'start': 51, 'end': 130, 'answer': 'most sporting events, no piece of music is so deeply associated with a specific'}\n",
            "{'score': 0.0729558914899826, 'start': 4, 'end': 22, 'answer': 'MYSTERIOUS ORIGINS'}\n",
            "{'score': 0.00023965341097209603, 'start': 96, 'end': 146, 'answer': 'dates back to the days of President William Howard'}\n",
            "{'score': 0.0002795051841530949, 'start': 205, 'end': 236, 'answer': 'inventing \"the stretch\" (albeit'}\n",
            "{'score': 0.0008029115851968527, 'start': 107, 'end': 146, 'answer': 'in April of 1910. (Photo by Mark Rucker'}\n",
            "{'score': 0.03661857545375824, 'start': 4, 'end': 15, 'answer': 'CAMARADERIE'}\n",
            "{'score': 0.0008254378335550427, 'start': 123, 'end': 169, 'answer': 'you prefer, the seventh inning stretch remains'}\n",
            "{'score': 0.0006237131892703474, 'start': 152, 'end': 163, 'answer': 'appreciated'}\n",
            "{'score': 0.0029705779161304235, 'start': 54, 'end': 78, 'answer': 'tie to our history.\" (AP'}\n",
            "{'score': 0.11324861645698547, 'start': 4, 'end': 13, 'answer': 'TRADITION'}\n",
            "{'score': 0.00026486392016522586, 'start': 39, 'end': 64, 'answer': 'tie to our history,\" Tony'}\n",
            "{'score': 0.10871927440166473, 'start': 0, 'end': 3, 'answer': 'THE'}\n",
            "{'score': 0.00013341210433281958, 'start': 113, 'end': 152, 'answer': 'division into turn-based innings rather'}\n",
            "{'score': 0.0007443600334227085, 'start': 23, 'end': 57, 'answer': 'York Yankees outfielder and future'}\n",
            "{'score': 9.524531924398616e-05, 'start': 25, 'end': 31, 'answer': 'may be'}\n",
            "{'score': 0.012142875231802464, 'start': 0, 'end': 43, 'answer': 'Relive The Longest Game In Baseball History'}\n",
            "{'score': 0.0004409639223013073, 'start': 19, 'end': 41, 'answer': 'schultz@huffingtonpost'}\n",
            "['most cherished moments, exemplifying', \"wouldn't\", 'THE', 'most sporting events, no piece of music is so deeply associated with a specific', 'MYSTERIOUS ORIGINS', 'dates back to the days of President William Howard', 'inventing \"the stretch\" (albeit', 'in April of 1910. (Photo by Mark Rucker', 'CAMARADERIE', 'you prefer, the seventh inning stretch remains', 'appreciated', 'tie to our history.\" (AP', 'TRADITION', 'tie to our history,\" Tony', 'THE', 'division into turn-based innings rather', 'York Yankees outfielder and future', 'may be', 'Relive The Longest Game In Baseball History', 'schultz@huffingtonpost']\n",
            "{'score': 0.0010034939041361213, 'start': 9, 'end': 17, 'answer': '’t quite'}\n",
            "{'score': 0.0007636498776264489, 'start': 153, 'end': 175, 'answer': 'often in the strangest'}\n",
            "{'score': 0.0006420633872039616, 'start': 13, 'end': 17, 'answer': 'many'}\n",
            "{'score': 0.0006797824753448367, 'start': 114, 'end': 150, 'answer': 'family – and they’re trying to teach'}\n",
            "{'score': 0.0009466547635383904, 'start': 166, 'end': 172, 'answer': 'family'}\n",
            "{'score': 0.00030238827457651496, 'start': 11, 'end': 32, 'answer': 'unending stare can be'}\n",
            "{'score': 0.000975749921053648, 'start': 8, 'end': 39, 'answer': 'most creatures, cats don’t like'}\n",
            "{'score': 0.0006274004699662328, 'start': 67, 'end': 98, 'answer': 'they carry it, the more content'}\n",
            "{'score': 0.0004663979052565992, 'start': 123, 'end': 136, 'answer': 'their kittens'}\n",
            "{'score': 0.0026850386057049036, 'start': 23, 'end': 36, 'answer': 'butting, cats'}\n",
            "{'score': 0.0015022119041532278, 'start': 18, 'end': 26, 'answer': 'your cat'}\n",
            "{'score': 0.000898896949365735, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 0.0010649699252098799, 'start': 138, 'end': 142, 'answer': 'high'}\n",
            "['’t quite', 'often in the strangest', 'many', 'family – and they’re trying to teach', 'family', 'unending stare can be', 'most creatures, cats don’t like', 'they carry it, the more content', 'their kittens', 'butting, cats', 'your cat', '10', 'high']\n",
            "{'score': 0.0006346053560264409, 'start': 145, 'end': 190, 'answer': 'mogul Kathy Ireland. (Photo courtesy of Kathy'}\n",
            "{'score': 0.0003395714738871902, 'start': 84, 'end': 104, 'answer': 'you have a net worth'}\n",
            "{'score': 0.00019601080566644669, 'start': 168, 'end': 211, 'answer': 'Most interesting to us here at Women@Forbes'}\n",
            "{'score': 0.0012904893374070525, 'start': 32, 'end': 99, 'answer': 'we decided to take a look at how the other half   actually, the top'}\n",
            "{'score': 0.028667591512203217, 'start': 6, 'end': 19, 'answer': 'In The Forbes'}\n",
            "{'score': 0.0021136680152267218, 'start': 14, 'end': 65, 'answer': 's horse farm in California. (Photo courtesy of Sage'}\n",
            "{'score': 0.007050991989672184, 'start': 19, 'end': 24, 'answer': 'worth'}\n",
            "{'score': 4.139425800531171e-05, 'start': 315, 'end': 377, 'answer': 'homebody. It makes sense: Earlier this year Winfrey bought a $'}\n",
            "{'score': 0.0021775520872324705, 'start': 59, 'end': 73, 'answer': 'YAMIL LAGE/AFP'}\n",
            "{'score': 0.019187437370419502, 'start': 13, 'end': 18, 'answer': 'worth'}\n",
            "{'score': 3.3116382837761194e-05, 'start': 673, 'end': 692, 'answer': \"few. And that's not\"}\n",
            "{'score': 0.0019638757221400738, 'start': 5, 'end': 14, 'answer': 'no wonder'}\n",
            "{'score': 0.008965934626758099, 'start': 7, 'end': 27, 'answer': 'Streisand: net worth'}\n",
            "{'score': 0.0001320025767199695, 'start': 55, 'end': 99, 'answer': 'Streisand, who ranks number 19 on the Forbes'}\n",
            "{'score': 0.002436887938529253, 'start': 47, 'end': 106, 'answer': 'Ireland rents out in Palm Springs. (Photo courtesy of Kathy'}\n",
            "{'score': 0.015940429642796516, 'start': 6, 'end': 24, 'answer': 'Ireland: net worth'}\n",
            "{'score': 0.00011559229460544884, 'start': 503, 'end': 549, 'answer': 'staggeringly beautiful vacation villas: Greece'}\n",
            "{'score': 0.04688533395528793, 'start': 7, 'end': 14, 'answer': 'The Top'}\n",
            "{'score': 0.0014526266604661942, 'start': 75, 'end': 132, 'answer': 'wildly wealthy and definitely know how to travel in style'}\n",
            "{'score': 0.005301742348819971, 'start': 31, 'end': 53, 'answer': '(Photo courtesy of Inn'}\n",
            "{'score': 0.014631088823080063, 'start': 18, 'end': 23, 'answer': 'worth'}\n",
            "{'score': 0.00011512166383909062, 'start': 71, 'end': 87, 'answer': 'that really rake'}\n",
            "{'score': 0.002625034423545003, 'start': 4, 'end': 19, 'answer': 'Montage Beverly'}\n",
            "{'score': 0.015167986042797565, 'start': 16, 'end': 21, 'answer': 'worth'}\n",
            "{'score': 5.7095538068097085e-05, 'start': 118, 'end': 147, 'answer': 'Sheimdlin) has another career'}\n",
            "{'score': 0.002504622796550393, 'start': 66, 'end': 92, 'answer': '(Photo courtesy of Kenneth'}\n",
            "{'score': 0.015504305250942707, 'start': 21, 'end': 26, 'answer': 'worth'}\n",
            "{'score': 0.0002788542478810996, 'start': 122, 'end': 176, 'answer': 'Spreckels Mansion, an opulent 55-room Beaux Arts manse'}\n",
            "{'score': 0.0014542581047862768, 'start': 68, 'end': 71, 'answer': 'KCT'}\n",
            "{'score': 0.01482350379228592, 'start': 18, 'end': 28, 'answer': 'worth $255'}\n",
            "{'score': 0.00013718666741624475, 'start': 256, 'end': 275, 'answer': 'Hadid, Karlie Kloss'}\n",
            "{'score': 0.0018294020555913448, 'start': 10, 'end': 18, 'answer': 'St. Bart'}\n",
            "{'score': 0.010825030505657196, 'start': 6, 'end': 26, 'answer': 'Degeneres: net worth'}\n",
            "{'score': 0.00010843251220649108, 'start': 251, 'end': 285, 'answer': 'jetting off to the dreamy Tahitian'}\n",
            "{'score': 0.0023375232703983784, 'start': 47, 'end': 56, 'answer': 'hideaways'}\n",
            "{'score': 0.014749929308891296, 'start': 20, 'end': 25, 'answer': 'worth'}\n",
            "{'score': 0.00014058794477023184, 'start': 299, 'end': 308, 'answer': 'hideaways'}\n",
            "{'score': 0.009269115515053272, 'start': 2, 'end': 19, 'answer': 'Sardinian skyline'}\n",
            "{'score': 0.014003714546561241, 'start': 16, 'end': 21, 'answer': 'worth'}\n",
            "{'score': 0.00029649274074472487, 'start': 214, 'end': 249, 'answer': 'have also been to Hawaii and France'}\n",
            "{'score': 0.0008901000837795436, 'start': 100, 'end': 142, 'answer': 'sale. (Photo courtesy of MICHEL GANGNE/AFP'}\n",
            "{'score': 0.012559927999973297, 'start': 9, 'end': 25, 'answer': 'Jolie: net worth'}\n",
            "{'score': 8.12681537354365e-05, 'start': 594, 'end': 604, 'answer': 'a cool $60'}\n",
            "['mogul Kathy Ireland. (Photo courtesy of Kathy', 'you have a net worth', 'Most interesting to us here at Women@Forbes', 'we decided to take a look at how the other half   actually, the top', 'In The Forbes', 's horse farm in California. (Photo courtesy of Sage', 'worth', 'homebody. It makes sense: Earlier this year Winfrey bought a $', 'YAMIL LAGE/AFP', 'worth', \"few. And that's not\", 'no wonder', 'Streisand: net worth', 'Streisand, who ranks number 19 on the Forbes', 'Ireland rents out in Palm Springs. (Photo courtesy of Kathy', 'Ireland: net worth', 'staggeringly beautiful vacation villas: Greece', 'The Top', 'wildly wealthy and definitely know how to travel in style', '(Photo courtesy of Inn', 'worth', 'that really rake', 'Montage Beverly', 'worth', 'Sheimdlin) has another career', '(Photo courtesy of Kenneth', 'worth', 'Spreckels Mansion, an opulent 55-room Beaux Arts manse', 'KCT', 'worth $255', 'Hadid, Karlie Kloss', 'St. Bart', 'Degeneres: net worth', 'jetting off to the dreamy Tahitian', 'hideaways', 'worth', 'hideaways', 'Sardinian skyline', 'worth', 'have also been to Hawaii and France', 'sale. (Photo courtesy of MICHEL GANGNE/AFP', 'Jolie: net worth', 'a cool $60']\n",
            "{'score': 0.015533416531980038, 'start': 16, 'end': 24, 'answer': 'effusive'}\n",
            "{'score': 0.0008152619120664895, 'start': 23, 'end': 58, 'answer': 'in the Army, including three combat'}\n",
            "{'score': 0.004143864382058382, 'start': 54, 'end': 77, 'answer': 'I must visit Louisville'}\n",
            "{'score': 0.0011426013661548495, 'start': 33, 'end': 68, 'answer': 'awesome,\" Johnson told me. \"This is'}\n",
            "{'score': 0.0011055257637053728, 'start': 57, 'end': 92, 'answer': 'community of his dreams were it not'}\n",
            "{'score': 0.0010433744173496962, 'start': 30, 'end': 71, 'answer': 'more than 100,000 soldiers leaving active'}\n",
            "{'score': 0.0005323852528817952, 'start': 78, 'end': 152, 'answer': 'a new life as civilians. The greater Louisville, Kentucky, area where Fort'}\n",
            "{'score': 0.00556558882817626, 'start': 48, 'end': 56, 'answer': 'Kentucky'}\n",
            "{'score': 0.0013332018861547112, 'start': 31, 'end': 100, 'answer': 'was no coordinated effort to connect the soon-to-be civilians in Fort'}\n",
            "{'score': 0.0032815211452543736, 'start': 28, 'end': 72, 'answer': 'regional chambers of commerce launched Where'}\n",
            "{'score': 0.0006442306912504137, 'start': 20, 'end': 57, 'answer': 'enthusiastic backing of the U.S. Army'}\n",
            "{'score': 0.0007673550280742347, 'start': 121, 'end': 147, 'answer': 'navigating 10,000 veterans'}\n",
            "{'score': 0.07083353400230408, 'start': 0, 'end': 7, 'answer': 'Filling'}\n",
            "{'score': 0.0005444600246846676, 'start': 51, 'end': 68, 'answer': 'processed at Fort'}\n",
            "{'score': 0.0008441134123131633, 'start': 45, 'end': 72, 'answer': 'Herd said, helping soldiers'}\n",
            "{'score': 0.00032091030152514577, 'start': 144, 'end': 214, 'answer': 'often on premises at training sessions in Fort Knox to assess soldiers'}\n",
            "{'score': 0.0007878001197241247, 'start': 55, 'end': 87, 'answer': 'placement program. It just gives'}\n",
            "{'score': 0.00018921901937574148, 'start': 427, 'end': 448, 'answer': 'disabilities to adult'}\n",
            "{'score': 0.001157929189503193, 'start': 61, 'end': 116, 'answer': 'them not just to a job, but to a community. Retired Col'}\n",
            "{'score': 0.003074714681133628, 'start': 0, 'end': 30, 'answer': 'Herd said there is no veterans'}\n",
            "{'score': 0.0001678920816630125, 'start': 215, 'end': 242, 'answer': 'Herd said. \"The preparation'}\n",
            "{'score': 0.0011353601003065705, 'start': 116, 'end': 172, 'answer': 'skilled workers that they say would otherwise be lacking'}\n",
            "{'score': 0.0003150477132294327, 'start': 192, 'end': 209, 'answer': 'we’ve gotten past'}\n",
            "{'score': 0.0011712155537679791, 'start': 85, 'end': 102, 'answer': 'no small part due'}\n",
            "{'score': 0.00044018522021360695, 'start': 220, 'end': 265, 'answer': '10 percent in October 2009 to 5 percent today'}\n",
            "{'score': 0.003617115318775177, 'start': 34, 'end': 62, 'answer': 'Herd is director of the Army'}\n",
            "{'score': 0.0007028900436125696, 'start': 207, 'end': 212, 'answer': 'boast'}\n",
            "{'score': 0.00023386022076010704, 'start': 297, 'end': 351, 'answer': 'Yum! Brands, parent company of KFC, Pizza Hut and Taco'}\n",
            "{'score': 0.0017140309792011976, 'start': 43, 'end': 56, 'answer': 'mid- and high'}\n",
            "{'score': 0.0015827898168936372, 'start': 86, 'end': 118, 'answer': 'high school to get into the Army'}\n",
            "{'score': 0.0017465957207605243, 'start': 53, 'end': 137, 'answer': 'often translate into civilian occupations -- everything from truck driving to supply'}\n",
            "{'score': 0.00041599507676437497, 'start': 124, 'end': 170, 'answer': 'are virtually guaranteed to develop discipline'}\n",
            "{'score': 0.003291602712124586, 'start': 24, 'end': 95, 'answer': 'intangible qualities that make people reliable employees and innovators'}\n",
            "{'score': 0.0002514408261049539, 'start': 184, 'end': 252, 'answer': 'Herd said. \"So we take those people and we train them and discipline'}\n",
            "{'score': 0.0005859030061401427, 'start': 156, 'end': 193, 'answer': 'they stay out of trouble. Retired Col'}\n",
            "{'score': 0.008642494678497314, 'start': 4, 'end': 20, 'answer': 'Visit To An Army'}\n",
            "{'score': 0.0004885373055003583, 'start': 229, 'end': 250, 'answer': 'being deployed to war'}\n",
            "{'score': 0.0014871193561702967, 'start': 10, 'end': 40, 'answer': 'crucible that turns young high'}\n",
            "{'score': 0.0003081108443439007, 'start': 196, 'end': 241, 'answer': 'their worst day in the service happen at Fort'}\n",
            "{'score': 0.0004058003833051771, 'start': 195, 'end': 226, 'answer': 'they could make it through Fort'}\n",
            "{'score': 0.00208453880622983, 'start': 8, 'end': 13, 'answer': 'every'}\n",
            "{'score': 0.003464197274297476, 'start': 7, 'end': 56, 'answer': 'Marans Eileen Pickett, an economic consultant, co'}\n",
            "{'score': 0.007263789419084787, 'start': 12, 'end': 17, 'answer': '\"Army'}\n",
            "{'score': 0.002233734354376793, 'start': 67, 'end': 91, 'answer': 'one would think veterans'}\n",
            "{'score': 0.0025476599112153053, 'start': 82, 'end': 99, 'answer': 'non-veteran peers'}\n",
            "{'score': 0.00016181415412575006, 'start': 340, 'end': 382, 'answer': 'we are using annual data here for greatest'}\n",
            "{'score': 0.0006087377551011741, 'start': 66, 'end': 154, 'answer': 'stress disorder and traumatic brain injury among returning Iraq and Afghanistan veterans'}\n",
            "{'score': 0.0002618269936647266, 'start': 235, 'end': 260, 'answer': 'hard to make professional'}\n",
            "{'score': 0.00168738909997046, 'start': 0, 'end': 37, 'answer': 'Herd believes that departing soldiers'}\n",
            "{'score': 0.0010189166059717536, 'start': 4, 'end': 57, 'answer': 'hard part comes in translating those skills from Army'}\n",
            "{'score': 0.000762477982789278, 'start': 93, 'end': 118, 'answer': 'human resources executive'}\n",
            "{'score': 0.00024496190599165857, 'start': 67, 'end': 105, 'answer': 'ability to assess a vision and execute'}\n",
            "{'score': 0.00019096887263003737, 'start': 338, 'end': 376, 'answer': 'less likely to be unemployed than Army'}\n",
            "{'score': 0.0032029151916503906, 'start': 13, 'end': 87, 'answer': 'Fred Johnson volunteers with Healing and the Arts to help younger veterans'}\n",
            "{'score': 0.010768410749733448, 'start': 26, 'end': 43, 'answer': 'Community Change.'}\n",
            "{'score': 0.0007901574717834592, 'start': 137, 'end': 201, 'answer': 'him with a sense of purpose like the kind he enjoyed in the Army'}\n",
            "{'score': 0.0008853523177094758, 'start': 104, 'end': 168, 'answer': 'did not think he would have the luxury of finding a job that fit'}\n",
            "{'score': 0.006398823112249374, 'start': 41, 'end': 63, 'answer': 'Where Opportunity Knox'}\n",
            "{'score': 0.000638277328107506, 'start': 141, 'end': 165, 'answer': 'underprivileged schools.'}\n",
            "{'score': 0.00038115427014417946, 'start': 9, 'end': 16, 'answer': 'certain'}\n",
            "{'score': 0.00040070744580589235, 'start': 84, 'end': 146, 'answer': 'community building in the underserved west side of Louisville.'}\n",
            "{'score': 0.001013109926134348, 'start': 49, 'end': 118, 'answer': 'You can actually see the community change. Fred Johnson, Army veteran'}\n",
            "{'score': 0.00044143167906440794, 'start': 1, 'end': 51, 'answer': 'When we attacked that city it was like a wasteland'}\n",
            "{'score': 0.0004671997157856822, 'start': 35, 'end': 76, 'answer': 'in him a desire to be a part of something'}\n",
            "{'score': 0.00022494040604215115, 'start': 233, 'end': 270, 'answer': 'diverse. I fit in as well there as at'}\n",
            "{'score': 0.0007668599137105048, 'start': 205, 'end': 232, 'answer': 'stress disorder from combat'}\n",
            "{'score': 0.0002693895949050784, 'start': 227, 'end': 236, 'answer': 'more CEOs'}\n",
            "{'score': 0.0021576478611677885, 'start': 76, 'end': 83, 'answer': 'him one'}\n",
            "{'score': 0.0007387037621811032, 'start': 132, 'end': 203, 'answer': 'initiative called Arts and Healing. The group uses art to help veterans'}\n",
            "{'score': 0.001519818790256977, 'start': 8, 'end': 37, 'answer': 'them, ‘Follow your heart, not'}\n",
            "{'score': 0.0006033888785168529, 'start': 115, 'end': 141, 'answer': 'well for a civilian career'}\n",
            "{'score': 0.0003916527784895152, 'start': 3, 'end': 6, 'answer': 'lot'}\n",
            "['effusive', 'in the Army, including three combat', 'I must visit Louisville', 'awesome,\" Johnson told me. \"This is', 'community of his dreams were it not', 'more than 100,000 soldiers leaving active', 'a new life as civilians. The greater Louisville, Kentucky, area where Fort', 'Kentucky', 'was no coordinated effort to connect the soon-to-be civilians in Fort', 'regional chambers of commerce launched Where', 'enthusiastic backing of the U.S. Army', 'navigating 10,000 veterans', 'Filling', 'processed at Fort', 'Herd said, helping soldiers', 'often on premises at training sessions in Fort Knox to assess soldiers', 'placement program. It just gives', 'disabilities to adult', 'them not just to a job, but to a community. Retired Col', 'Herd said there is no veterans', 'Herd said. \"The preparation', 'skilled workers that they say would otherwise be lacking', 'we’ve gotten past', 'no small part due', '10 percent in October 2009 to 5 percent today', 'Herd is director of the Army', 'boast', 'Yum! Brands, parent company of KFC, Pizza Hut and Taco', 'mid- and high', 'high school to get into the Army', 'often translate into civilian occupations -- everything from truck driving to supply', 'are virtually guaranteed to develop discipline', 'intangible qualities that make people reliable employees and innovators', 'Herd said. \"So we take those people and we train them and discipline', 'they stay out of trouble. Retired Col', 'Visit To An Army', 'being deployed to war', 'crucible that turns young high', 'their worst day in the service happen at Fort', 'they could make it through Fort', 'every', 'Marans Eileen Pickett, an economic consultant, co', '\"Army', 'one would think veterans', 'non-veteran peers', 'we are using annual data here for greatest', 'stress disorder and traumatic brain injury among returning Iraq and Afghanistan veterans', 'hard to make professional', 'Herd believes that departing soldiers', 'hard part comes in translating those skills from Army', 'human resources executive', 'ability to assess a vision and execute', 'less likely to be unemployed than Army', 'Fred Johnson volunteers with Healing and the Arts to help younger veterans', 'Community Change.', 'him with a sense of purpose like the kind he enjoyed in the Army', 'did not think he would have the luxury of finding a job that fit', 'Where Opportunity Knox', 'underprivileged schools.', 'certain', 'community building in the underserved west side of Louisville.', 'You can actually see the community change. Fred Johnson, Army veteran', 'When we attacked that city it was like a wasteland', 'in him a desire to be a part of something', 'diverse. I fit in as well there as at', 'stress disorder from combat', 'more CEOs', 'him one', 'initiative called Arts and Healing. The group uses art to help veterans', 'them, ‘Follow your heart, not', 'well for a civilian career', 'lot']\n",
            "{'score': 0.00230527319945395, 'start': 65, 'end': 83, 'answer': 'Thiruvananthapuram'}\n",
            "{'score': 0.0001910396822495386, 'start': 292, 'end': 294, 'answer': '30'}\n",
            "{'score': 0.0008750518900342286, 'start': 0, 'end': 40, 'answer': 'Thiruvananthapuram has a rating of 19.83'}\n",
            "{'score': 0.0005283368518576026, 'start': 45, 'end': 98, 'answer': 'on the list are in the vast South Asian nation. Since'}\n",
            "{'score': 0.0005400190129876137, 'start': 8, 'end': 16, 'answer': 'Banerjee'}\n",
            "{'score': 0.004893111530691385, 'start': 9, 'end': 14, 'answer': 'other'}\n",
            "{'score': 0.018810439854860306, 'start': 18, 'end': 20, 'answer': '20'}\n",
            "{'score': 2.980079807457514e-05, 'start': 399, 'end': 410, 'answer': '459. Nagpur'}\n",
            "{'score': 0.0004022208449896425, 'start': 66, 'end': 105, 'answer': 'Hamilton, Bermuda, with an index of 141'}\n",
            "{'score': 0.0016184953274205327, 'start': 56, 'end': 95, 'answer': 'nearly 500 cities around the world. Red'}\n",
            "['Thiruvananthapuram', '30', 'Thiruvananthapuram has a rating of 19.83', 'on the list are in the vast South Asian nation. Since', 'Banerjee', 'other', '20', '459. Nagpur', 'Hamilton, Bermuda, with an index of 141', 'nearly 500 cities around the world. Red']\n",
            "{'score': 0.00010677947284420952, 'start': 538, 'end': 544, 'answer': 'enough'}\n",
            "{'score': 0.00010900264169322327, 'start': 39, 'end': 50, 'answer': 'Weise/Getty'}\n",
            "{'score': 9.235807374352589e-05, 'start': 340, 'end': 404, 'answer': \"construction materials if you're building a home. You need to be\"}\n",
            "{'score': 0.0002438521187286824, 'start': 226, 'end': 234, 'answer': 'still 50'}\n",
            "{'score': 0.00012290214363019913, 'start': 480, 'end': 483, 'answer': '100'}\n",
            "{'score': 0.00014081670087762177, 'start': 371, 'end': 408, 'answer': 'some extra cash by offering discounts'}\n",
            "{'score': 0.00010347451461711898, 'start': 225, 'end': 285, 'answer': 'shoestring. Even if you decide to set up shop in the capital'}\n",
            "{'score': 6.204453529790044e-05, 'start': 424, 'end': 460, 'answer': \"My Second Home Program. If you're 50\"}\n",
            "['enough', 'Weise/Getty', \"construction materials if you're building a home. You need to be\", 'still 50', '100', 'some extra cash by offering discounts', 'shoestring. Even if you decide to set up shop in the capital', \"My Second Home Program. If you're 50\"]\n",
            "{'score': 0.0010442637139931321, 'start': 71, 'end': 159, 'answer': 'were buzzing with discussions about the highly anticipated \"Beauty and the Beast\" remake'}\n",
            "{'score': 0.001069693942554295, 'start': 46, 'end': 77, 'answer': 'others thoroughly examined each'}\n",
            "{'score': 0.01251157931983471, 'start': 7, 'end': 29, 'answer': 'did the remake compare'}\n",
            "{'score': 0.0008343135705217719, 'start': 0, 'end': 18, 'answer': 'Well, that’s still'}\n",
            "{'score': 0.0009021332953125238, 'start': 117, 'end': 140, 'answer': 'not simply as a copycat'}\n",
            "{'score': 0.002721944358199835, 'start': 14, 'end': 60, 'answer': 'at nine ways the \"Beauty and the Beast\" remake'}\n",
            "{'score': 0.016524873673915863, 'start': 19, 'end': 36, 'answer': 'contains spoilers'}\n",
            "{'score': 0.0012646473478525877, 'start': 38, 'end': 47, 'answer': 'more than'}\n",
            "{'score': 0.00022362633899319917, 'start': 139, 'end': 177, 'answer': 'buried deep in a book -- and she’s not'}\n",
            "{'score': 0.0005718940519727767, 'start': 0, 'end': 30, 'answer': 'She held this impromptu lesson'}\n",
            "{'score': 0.0005717617459595203, 'start': 89, 'end': 94, 'answer': 'Kline'}\n",
            "{'score': 0.00015326966240536422, 'start': 282, 'end': 292, 'answer': 'disheveled'}\n",
            "{'score': 0.00018975770217366517, 'start': 292, 'end': 314, 'answer': 'disease as well. So he'}\n",
            "{'score': 0.0003552935959305614, 'start': 29, 'end': 73, 'answer': 'pompous and entitled -- but he wasn’t always'}\n",
            "{'score': 0.0001304523611906916, 'start': 370, 'end': 386, 'answer': 'him from his dad'}\n",
            "{'score': 0.00021627034584525973, 'start': 127, 'end': 187, 'answer': 'were new to moviegoers, \"Beauty and the Beast\" composer Alan'}\n",
            "{'score': 0.00022491136041935533, 'start': 254, 'end': 275, 'answer': 'they hadn’t been used'}\n",
            "{'score': 0.0007304692990146577, 'start': 90, 'end': 97, 'answer': 'was too'}\n",
            "{'score': 0.0009296197677031159, 'start': 41, 'end': 122, 'answer': 'highly educated, boasting about his expensive education while quoting Shakespeare'}\n",
            "{'score': 0.00020760783809237182, 'start': 174, 'end': 205, 'answer': 'bored with the books and agrees'}\n",
            "{'score': 0.0006402739672921598, 'start': 168, 'end': 170, 'answer': 'he'}\n",
            "{'score': 0.0003223109233658761, 'start': 208, 'end': 224, 'answer': 'had any siblings'}\n",
            "{'score': 0.00022163047106005251, 'start': 162, 'end': 217, 'answer': 'has taken his daughter, Belle, captive. So he and LeFou'}\n",
            "{'score': 8.129280467983335e-05, 'start': 456, 'end': 481, 'answer': 'in marriage. When Maurice'}\n",
            "{'score': 0.00027583929477259517, 'start': 15, 'end': 78, 'answer': 'uncomfortable with the idea of leaving Maurice for dead, pleads'}\n",
            "{'score': 0.00034246669383719563, 'start': 140, 'end': 162, 'answer': 'Gad’s character, LeFou'}\n",
            "{'score': 0.0003996244922745973, 'start': 166, 'end': 189, 'answer': 'he wants. It’s somebody'}\n",
            "{'score': 0.00010649026808096096, 'start': 275, 'end': 334, 'answer': 'soon switches to partner with one of Gaston’s henchmen, who'}\n",
            "{'score': 0.00047399254981428385, 'start': 101, 'end': 124, 'answer': 'there’s no set deadline'}\n",
            "{'score': 0.00010290549835190177, 'start': 126, 'end': 131, 'answer': 'knife'}\n",
            "{'score': 0.0002597836428321898, 'start': 35, 'end': 51, 'answer': 'enchantress, who'}\n",
            "['were buzzing with discussions about the highly anticipated \"Beauty and the Beast\" remake', 'others thoroughly examined each', 'did the remake compare', 'Well, that’s still', 'not simply as a copycat', 'at nine ways the \"Beauty and the Beast\" remake', 'contains spoilers', 'more than', 'buried deep in a book -- and she’s not', 'She held this impromptu lesson', 'Kline', 'disheveled', 'disease as well. So he', 'pompous and entitled -- but he wasn’t always', 'him from his dad', 'were new to moviegoers, \"Beauty and the Beast\" composer Alan', 'they hadn’t been used', 'was too', 'highly educated, boasting about his expensive education while quoting Shakespeare', 'bored with the books and agrees', 'he', 'had any siblings', 'has taken his daughter, Belle, captive. So he and LeFou', 'in marriage. When Maurice', 'uncomfortable with the idea of leaving Maurice for dead, pleads', 'Gad’s character, LeFou', 'he wants. It’s somebody', 'soon switches to partner with one of Gaston’s henchmen, who', 'there’s no set deadline', 'knife', 'enchantress, who']\n",
            "{'score': 0.0002010122552746907, 'start': 88, 'end': 124, 'answer': 'snarky quotes by anonymous \"insiders'}\n",
            "{'score': 0.0002438953088130802, 'start': 133, 'end': 154, 'answer': 'Hardly Wait.\" But his'}\n",
            "{'score': 0.0002667509252205491, 'start': 119, 'end': 160, 'answer': 'Fiona, with ex-wife Jennie Garth -- at GQ'}\n",
            "{'score': 0.01363216619938612, 'start': 0, 'end': 20, 'answer': 'When’s the last time'}\n",
            "{'score': 0.008855117484927177, 'start': 20, 'end': 34, 'answer': 'don’t remember'}\n",
            "{'score': 0.01586303487420082, 'start': 12, 'end': 30, 'answer': 'guiltiest pleasure'}\n",
            "{'score': 0.00044922137749381363, 'start': 129, 'end': 138, 'answer': 'been very'}\n",
            "{'score': 0.004028101451694965, 'start': 7, 'end': 19, 'answer': 'could commit'}\n",
            "{'score': 0.0447026863694191, 'start': 0, 'end': 11, 'answer': 'Jaywalking.'}\n",
            "{'score': 0.019726015627384186, 'start': 13, 'end': 15, 'answer': 'in'}\n",
            "{'score': 0.004269819241017103, 'start': 35, 'end': 36, 'answer': 'I'}\n",
            "{'score': 0.007947283796966076, 'start': 6, 'end': 21, 'answer': 'okay to recline'}\n",
            "{'score': 0.0005016328650526702, 'start': 143, 'end': 171, 'answer': 'if he reclined his seat than'}\n",
            "{'score': 0.012608515098690987, 'start': 15, 'end': 30, 'answer': 'overrated right'}\n",
            "{'score': 0.008206548169255257, 'start': 13, 'end': 17, 'answer': 'what'}\n",
            "{'score': 0.013135910034179688, 'start': 6, 'end': 23, 'answer': 'are you a twerker'}\n",
            "{'score': 0.006608996074646711, 'start': 4, 'end': 5, 'answer': 'I'}\n",
            "{'score': 0.005527942907065153, 'start': 13, 'end': 17, 'answer': 'time'}\n",
            "{'score': 0.0011462391121312976, 'start': 45, 'end': 90, 'answer': 'You’re stumping me and I feel like I’m losing'}\n",
            "{'score': 0.021015165373682976, 'start': 13, 'end': 17, 'answer': 'most'}\n",
            "{'score': 0.0005901131080463529, 'start': 2, 'end': 8, 'answer': 'always'}\n",
            "['snarky quotes by anonymous \"insiders', 'Hardly Wait.\" But his', 'Fiona, with ex-wife Jennie Garth -- at GQ', 'When’s the last time', 'don’t remember', 'guiltiest pleasure', 'been very', 'could commit', 'Jaywalking.', 'in', 'I', 'okay to recline', 'if he reclined his seat than', 'overrated right', 'what', 'are you a twerker', 'I', 'time', 'You’re stumping me and I feel like I’m losing', 'most', 'always']\n",
            "{'score': 0.0005171436350792646, 'start': 89, 'end': 162, 'answer': 'some jobs create more anxiety than others. Last week my colleague Karsten'}\n",
            "{'score': 0.00017400803335476667, 'start': 220, 'end': 271, 'answer': 'survey CareerCast relies largely on data from the U'}\n",
            "{'score': 0.0034178828354924917, 'start': 39, 'end': 51, 'answer': 'their median'}\n",
            "{'score': 0.0003366540477145463, 'start': 105, 'end': 165, 'answer': 'unimportant. Some, such as audiologist and tenured professor'}\n",
            "{'score': 0.0001378750312142074, 'start': 448, 'end': 471, 'answer': 'many interesting reader'}\n",
            "{'score': 0.0021870925556868315, 'start': 68, 'end': 106, 'answer': 'the least stressful jobs. Photo credit'}\n",
            "{'score': 0.0002792872837744653, 'start': 296, 'end': 341, 'answer': 'that lasts between one and four years. Median'}\n",
            "{'score': 0.0004688160552177578, 'start': 229, 'end': 249, 'answer': \"if they're following\"}\n",
            "{'score': 0.0014146429020911455, 'start': 35, 'end': 79, 'answer': 'eighth, with median income of $78,630. Using'}\n",
            "['some jobs create more anxiety than others. Last week my colleague Karsten', 'survey CareerCast relies largely on data from the U', 'their median', 'unimportant. Some, such as audiologist and tenured professor', 'many interesting reader', 'the least stressful jobs. Photo credit', 'that lasts between one and four years. Median', \"if they're following\", 'eighth, with median income of $78,630. Using']\n",
            "{'score': 0.000256081490078941, 'start': 10, 'end': 14, 'answer': 'most'}\n",
            "{'score': 0.0008869690354913473, 'start': 48, 'end': 54, 'answer': 'enough'}\n",
            "{'score': 0.00016196358774323016, 'start': 171, 'end': 191, 'answer': 'empathy, selfishness'}\n",
            "{'score': 0.00019768108904827386, 'start': 43, 'end': 81, 'answer': 'easily actionable) recent PsyBlog post'}\n",
            "{'score': 0.0034293700009584427, 'start': 78, 'end': 109, 'answer': 'Clergyperson Chef Civil servant'}\n",
            "{'score': 0.00019702342979144305, 'start': 0, 'end': 45, 'answer': 'Some of these are more surprising than others'}\n",
            "{'score': 0.00044669659109786153, 'start': 186, 'end': 253, 'answer': 'most are intensely focused on empathizing with or caring for others'}\n",
            "{'score': 0.0035604306031018496, 'start': 53, 'end': 83, 'answer': 'stylist Charity worker Teacher'}\n",
            "['most', 'enough', 'empathy, selfishness', 'easily actionable) recent PsyBlog post', 'Clergyperson Chef Civil servant', 'Some of these are more surprising than others', 'most are intensely focused on empathizing with or caring for others', 'stylist Charity worker Teacher']\n",
            "{'score': 0.0011171897640451789, 'start': 56, 'end': 99, 'answer': 'that are high in calories along with a lack'}\n",
            "{'score': 0.002621299820020795, 'start': 22, 'end': 56, 'answer': 'many of us, is getting the balance'}\n",
            "{'score': 0.0009373629582114518, 'start': 13, 'end': 37, 'answer': 'metabolism is not always'}\n",
            "{'score': 0.000482726696645841, 'start': 193, 'end': 205, 'answer': 'there really'}\n",
            "{'score': 0.0005527028697542846, 'start': 23, 'end': 83, 'answer': 'there are some foods that may help manage weight by boosting'}\n",
            "{'score': 0.0009689104626886547, 'start': 49, 'end': 83, 'answer': 'the muscles in the digestive tract'}\n",
            "{'score': 0.00046946346992626786, 'start': 9, 'end': 16, 'answer': 'certain'}\n",
            "{'score': 0.001636948436498642, 'start': 0, 'end': 74, 'answer': 'Thermogenesis kicks in after every meal and the digestive process continue'}\n",
            "{'score': 0.0019030945841223001, 'start': 97, 'end': 119, 'answer': 'in the diet as a whole'}\n",
            "{'score': 0.0006577349849976599, 'start': 133, 'end': 160, 'answer': 'it is important to remember'}\n",
            "{'score': 0.0027825688011944294, 'start': 10, 'end': 17, 'answer': 'in mind'}\n",
            "{'score': 0.04515378177165985, 'start': 3, 'end': 16, 'answer': 'CHILI PEPPERS'}\n",
            "{'score': 0.0006599729531444609, 'start': 25, 'end': 39, 'answer': 'chilli peppers'}\n",
            "{'score': 0.001131958095356822, 'start': 49, 'end': 60, 'answer': 'in the diet'}\n",
            "{'score': 0.0011082198470830917, 'start': 18, 'end': 49, 'answer': 'chilli flakes or cayenne powder'}\n",
            "{'score': 0.024333031848073006, 'start': 0, 'end': 8, 'answer': '2. WHOLE'}\n",
            "{'score': 0.0008755102753639221, 'start': 8, 'end': 41, 'answer': 'carbohydrates, such as brown rice'}\n",
            "{'score': 0.0018415054073557258, 'start': 0, 'end': 16, 'answer': 'The extra effort'}\n",
            "{'score': 0.0008421241655014455, 'start': 71, 'end': 150, 'answer': 'high portions of vegetables, and in particular the leafy greens such as spinach'}\n",
            "{'score': 0.0005743292858824134, 'start': 99, 'end': 106, 'answer': 'thermic'}\n",
            "{'score': 0.0009281202801503241, 'start': 68, 'end': 134, 'answer': 'a maximum of two are fruits. Choose fruits with high fibre content'}\n",
            "{'score': 0.049416132271289825, 'start': 3, 'end': 8, 'answer': 'BLACK'}\n",
            "{'score': 0.0016449718968942761, 'start': 50, 'end': 57, 'answer': 'thermic'}\n",
            "{'score': 0.001768334535881877, 'start': 116, 'end': 125, 'answer': 'your meal'}\n",
            "{'score': 0.07017265260219574, 'start': 0, 'end': 1, 'answer': '4'}\n",
            "{'score': 0.0010371922980993986, 'start': 101, 'end': 126, 'answer': 'in your food can speed up'}\n",
            "{'score': 0.0005650145467370749, 'start': 108, 'end': 123, 'answer': '-fries, curries'}\n",
            "{'score': 0.0024116213899105787, 'start': 19, 'end': 47, 'answer': 'grated from frozen or stored'}\n",
            "{'score': 0.07975472509860992, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.000581593019887805, 'start': 139, 'end': 183, 'answer': 'you enjoy the taste and include in marinades'}\n",
            "{'score': 0.07084815949201584, 'start': 0, 'end': 10, 'answer': '6. MUSTARD'}\n",
            "{'score': 0.0010178425582125783, 'start': 59, 'end': 82, 'answer': 'in particular capsaicin'}\n",
            "{'score': 0.002466855337843299, 'start': 69, 'end': 80, 'answer': 'a casserole'}\n",
            "{'score': 0.04716496169567108, 'start': 0, 'end': 1, 'answer': '7'}\n",
            "{'score': 0.0006722997641190886, 'start': 59, 'end': 73, 'answer': 'micronutrients'}\n",
            "{'score': 0.003573197638615966, 'start': 58, 'end': 76, 'answer': 'a healthy balanced'}\n",
            "{'score': 0.0719057247042656, 'start': 0, 'end': 1, 'answer': '8'}\n",
            "{'score': 0.000594919256400317, 'start': 60, 'end': 91, 'answer': 'in protein has a bigger thermic'}\n",
            "{'score': 0.001182649633847177, 'start': 16, 'end': 75, 'answer': 'you eat a chicken breast containing 300 calories, around 30'}\n",
            "{'score': 0.0012443745508790016, 'start': 79, 'end': 126, 'answer': 'in part also due to its positive effect on post'}\n",
            "{'score': 0.000828003860078752, 'start': 156, 'end': 181, 'answer': 'quinoa, beans, brown rice'}\n",
            "['that are high in calories along with a lack', 'many of us, is getting the balance', 'metabolism is not always', 'there really', 'there are some foods that may help manage weight by boosting', 'the muscles in the digestive tract', 'certain', 'Thermogenesis kicks in after every meal and the digestive process continue', 'in the diet as a whole', 'it is important to remember', 'in mind', 'CHILI PEPPERS', 'chilli peppers', 'in the diet', 'chilli flakes or cayenne powder', '2. WHOLE', 'carbohydrates, such as brown rice', 'The extra effort', 'high portions of vegetables, and in particular the leafy greens such as spinach', 'thermic', 'a maximum of two are fruits. Choose fruits with high fibre content', 'BLACK', 'thermic', 'your meal', '4', 'in your food can speed up', '-fries, curries', 'grated from frozen or stored', '5', 'you enjoy the taste and include in marinades', '6. MUSTARD', 'in particular capsaicin', 'a casserole', '7', 'micronutrients', 'a healthy balanced', '8', 'in protein has a bigger thermic', 'you eat a chicken breast containing 300 calories, around 30', 'in part also due to its positive effect on post', 'quinoa, beans, brown rice']\n",
            "{'score': 0.0009405833552591503, 'start': 0, 'end': 11, 'answer': 'After Tawny'}\n",
            "{'score': 7.951091538416222e-05, 'start': 52, 'end': 121, 'answer': 'been rough since her partner left — her vehicle was in such bad shape'}\n",
            "{'score': 0.0004354105331003666, 'start': 78, 'end': 110, 'answer': 'desperately tried to help, Tawny'}\n",
            "{'score': 0.00022310612257570028, 'start': 177, 'end': 205, 'answer': 'on its way and that his wife'}\n",
            "{'score': 0.0011203375179320574, 'start': 58, 'end': 89, 'answer': 'she could set up a payment plan'}\n",
            "{'score': 0.00027452694484964013, 'start': 197, 'end': 268, 'answer': 'more so than I care to explain, and without knowing us or our situation'}\n",
            "{'score': 0.0004873101133853197, 'start': 79, 'end': 146, 'answer': 'she was falling apart. And while she knows that she can never repay'}\n",
            "['After Tawny', 'been rough since her partner left — her vehicle was in such bad shape', 'desperately tried to help, Tawny', 'on its way and that his wife', 'she could set up a payment plan', 'more so than I care to explain, and without knowing us or our situation', 'she was falling apart. And while she knows that she can never repay']\n",
            "{'score': 0.0021807693410664797, 'start': 10, 'end': 70, 'answer': 'are more common than the idea of collecting as an investment'}\n",
            "{'score': 0.00030619659810326993, 'start': 140, 'end': 213, 'answer': \"candlesticks or a copy of the Declaration of Independence, there's always\"}\n",
            "{'score': 0.005988443270325661, 'start': 11, 'end': 24, 'answer': 'what could be'}\n",
            "{'score': 0.0003324673161841929, 'start': 43, 'end': 69, 'answer': 'pogs to marbles to Cabbage'}\n",
            "{'score': 0.0002893943164963275, 'start': 286, 'end': 344, 'answer': 'only really made sense in a specific time and a particular'}\n",
            "{'score': 0.00019922255887649953, 'start': 336, 'end': 366, 'answer': 'ten collections that are worth'}\n",
            "{'score': 0.030711272731423378, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 0.0007538181380368769, 'start': 48, 'end': 57, 'answer': 'education'}\n",
            "{'score': 0.0012429087655618787, 'start': 35, 'end': 38, 'answer': 'not'}\n",
            "{'score': 0.005503123626112938, 'start': 0, 'end': 15, 'answer': 'That particular'}\n",
            "{'score': 0.0001424795773345977, 'start': 60, 'end': 66, 'answer': 'enough'}\n",
            "{'score': 0.00018582613847684115, 'start': 254, 'end': 326, 'answer': 'most of those Coke-stamped products are now just inexpensive curiosities'}\n",
            "{'score': 0.08066030591726303, 'start': 0, 'end': 1, 'answer': '9'}\n",
            "{'score': 0.00024632466374896467, 'start': 250, 'end': 278, 'answer': 'collectors slept under Uncle'}\n",
            "{'score': 0.02536804787814617, 'start': 7, 'end': 18, 'answer': 'Not so much'}\n",
            "{'score': 0.0013820918975397944, 'start': 75, 'end': 108, 'answer': 'mid- and early-century definitely'}\n",
            "{'score': 8.460036042379215e-05, 'start': 578, 'end': 593, 'answer': 'more than knick'}\n",
            "{'score': 0.0005772646400146186, 'start': 40, 'end': 84, 'answer': 'that people think should,\" she said. \"is one'}\n",
            "{'score': 0.00146859313827008, 'start': 12, 'end': 14, 'answer': '99'}\n",
            "{'score': 0.03452359512448311, 'start': 0, 'end': 1, 'answer': '8'}\n",
            "{'score': 0.0004855031438637525, 'start': 147, 'end': 185, 'answer': 'what wiped out collectors of Roseville'}\n",
            "{'score': 0.0002168046630686149, 'start': 291, 'end': 306, 'answer': 'every Roseville'}\n",
            "{'score': 0.0028071224223822355, 'start': 48, 'end': 67, 'answer': 'all that, by taking'}\n",
            "{'score': 0.00018859414558392018, 'start': 301, 'end': 354, 'answer': 'was rare. With the internet, I could connect to every'}\n",
            "{'score': 0.00016670985496602952, 'start': 337, 'end': 396, 'answer': 'some hard bargains. When shoppers can go home and Google up'}\n",
            "{'score': 0.020649347454309464, 'start': 0, 'end': 1, 'answer': '7'}\n",
            "{'score': 0.0009081746102310717, 'start': 30, 'end': 83, 'answer': \"low by the internet, for a period of time in the '80s\"}\n",
            "{'score': 0.0001669781340751797, 'start': 33, 'end': 42, 'answer': 'was value'}\n",
            "{'score': 0.0008538836264051497, 'start': 114, 'end': 188, 'answer': 'slow collapse began in the early 2000s, culminating in a bankruptcy filing'}\n",
            "{'score': 8.803395758150145e-05, 'start': 309, 'end': 327, 'answer': 'scarcity\" as Dixey'}\n",
            "{'score': 0.021144747734069824, 'start': 0, 'end': 1, 'answer': '6'}\n",
            "{'score': 0.0005957740941084921, 'start': 154, 'end': 192, 'answer': 'meticulously sorted rows of tchotchkes'}\n",
            "{'score': 0.00018159950559493154, 'start': 279, 'end': 285, 'answer': 'enough'}\n",
            "{'score': 0.0002297305763931945, 'start': 112, 'end': 127, 'answer': 'Endless special'}\n",
            "{'score': 0.0005060289986431599, 'start': 189, 'end': 199, 'answer': 'few retain'}\n",
            "{'score': 0.04951586201786995, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.0006532646366395056, 'start': 109, 'end': 194, 'answer': 'There must be some good reason why otherwise sane people shell out sometimes millions'}\n",
            "{'score': 0.00024287360429298133, 'start': 226, 'end': 270, 'answer': 'masse. Hummel represented the end of the war'}\n",
            "{'score': 0.0010879265610128641, 'start': 73, 'end': 76, 'answer': 'far'}\n",
            "{'score': 0.00033159181475639343, 'start': 181, 'end': 218, 'answer': 'all based on comic book heroes is not'}\n",
            "{'score': 0.00021624784858431667, 'start': 77, 'end': 142, 'answer': 'paperbacks of their youth, the reality is far more mundane. Aside'}\n",
            "{'score': 0.04746057093143463, 'start': 0, 'end': 1, 'answer': '4'}\n",
            "{'score': 0.00285536190494895, 'start': 23, 'end': 90, 'answer': 'mid-century, the idea of memorializing shared moments on dinnerware'}\n",
            "{'score': 0.016229642555117607, 'start': 15, 'end': 20, 'answer': 'still'}\n",
            "{'score': 0.0008866308489814401, 'start': 174, 'end': 177, 'answer': 'QVC'}\n",
            "{'score': 0.0002709900727495551, 'start': 55, 'end': 112, 'answer': 'gatekeeper for any of these products, there was never any'}\n",
            "{'score': 0.00028912408743053675, 'start': 250, 'end': 302, 'answer': 'most Norman Rockwell ones going for $5 to $15 apiece'}\n",
            "{'score': 0.04474852606654167, 'start': 1, 'end': 17, 'answer': '. Baseball Cards'}\n",
            "{'score': 0.0003384506271686405, 'start': 146, 'end': 194, 'answer': 'them all, Magic the Gathering, can still command'}\n",
            "{'score': 0.006207493599504232, 'start': 35, 'end': 56, 'answer': 'frequently disappoint'}\n",
            "{'score': 0.00012799902469851077, 'start': 399, 'end': 462, 'answer': 'their youth, stacked up pieces of cardboard tucked away and sat'}\n",
            "{'score': 0.0002999634307343513, 'start': 226, 'end': 273, 'answer': 'almost anyone, and prices reflected that. Today'}\n",
            "{'score': 0.00018401944544166327, 'start': 376, 'end': 401, 'answer': 'were selling for hundreds'}\n",
            "{'score': 0.0008647087379358709, 'start': 35, 'end': 44, 'answer': 'few bucks'}\n",
            "{'score': 0.03076292760670185, 'start': 0, 'end': 2, 'answer': '2.'}\n",
            "{'score': 0.0005540242418646812, 'start': 69, 'end': 82, 'answer': 'furor,\" Dixey'}\n",
            "{'score': 0.005622935015708208, 'start': 6, 'end': 17, 'answer': 'had a front'}\n",
            "{'score': 0.00027887438773177564, 'start': 317, 'end': 324, 'answer': 'several'}\n",
            "{'score': 0.0033399437088519335, 'start': 16, 'end': 27, 'answer': 'Stern wrote'}\n",
            "{'score': 0.008115194737911224, 'start': 19, 'end': 25, 'answer': \"wasn't\"}\n",
            "{'score': 0.0003254695620853454, 'start': 32, 'end': 43, 'answer': 'to be worth'}\n",
            "{'score': 0.0007027835235930979, 'start': 129, 'end': 185, 'answer': 'the year... Today, the Britannia Beanie Baby sells for $'}\n",
            "{'score': 0.0003322087577544153, 'start': 106, 'end': 121, 'answer': 'of the Princess'}\n",
            "{'score': 0.044549331068992615, 'start': 3, 'end': 8, 'answer': 'Lunch'}\n",
            "{'score': 0.0002705121005419642, 'start': 284, 'end': 316, 'answer': \"them, these products just aren't\"}\n",
            "{'score': 0.0005855283816345036, 'start': 139, 'end': 184, 'answer': 'were indeed rare, and they were bringing lots'}\n",
            "{'score': 0.00041104169213213027, 'start': 164, 'end': 168, 'answer': 'glut'}\n",
            "{'score': 0.0005414084298536181, 'start': 84, 'end': 92, 'answer': 'mismatch'}\n",
            "{'score': 0.00023985723964869976, 'start': 9, 'end': 12, 'answer': 'lot'}\n",
            "{'score': 0.006201648619025946, 'start': 35, 'end': 43, 'answer': 'bursting'}\n",
            "['are more common than the idea of collecting as an investment', \"candlesticks or a copy of the Declaration of Independence, there's always\", 'what could be', 'pogs to marbles to Cabbage', 'only really made sense in a specific time and a particular', 'ten collections that are worth', '10', 'education', 'not', 'That particular', 'enough', 'most of those Coke-stamped products are now just inexpensive curiosities', '9', 'collectors slept under Uncle', 'Not so much', 'mid- and early-century definitely', 'more than knick', 'that people think should,\" she said. \"is one', '99', '8', 'what wiped out collectors of Roseville', 'every Roseville', 'all that, by taking', 'was rare. With the internet, I could connect to every', 'some hard bargains. When shoppers can go home and Google up', '7', \"low by the internet, for a period of time in the '80s\", 'was value', 'slow collapse began in the early 2000s, culminating in a bankruptcy filing', 'scarcity\" as Dixey', '6', 'meticulously sorted rows of tchotchkes', 'enough', 'Endless special', 'few retain', '5', 'There must be some good reason why otherwise sane people shell out sometimes millions', 'masse. Hummel represented the end of the war', 'far', 'all based on comic book heroes is not', 'paperbacks of their youth, the reality is far more mundane. Aside', '4', 'mid-century, the idea of memorializing shared moments on dinnerware', 'still', 'QVC', 'gatekeeper for any of these products, there was never any', 'most Norman Rockwell ones going for $5 to $15 apiece', '. Baseball Cards', 'them all, Magic the Gathering, can still command', 'frequently disappoint', 'their youth, stacked up pieces of cardboard tucked away and sat', 'almost anyone, and prices reflected that. Today', 'were selling for hundreds', 'few bucks', '2.', 'furor,\" Dixey', 'had a front', 'several', 'Stern wrote', \"wasn't\", 'to be worth', 'the year... Today, the Britannia Beanie Baby sells for $', 'of the Princess', 'Lunch', \"them, these products just aren't\", 'were indeed rare, and they were bringing lots', 'glut', 'mismatch', 'lot', 'bursting']\n",
            "{'score': 0.00438421405851841, 'start': 5, 'end': 11, 'answer': 'a crop'}\n",
            "{'score': 0.0007438668399117887, 'start': 40, 'end': 89, 'answer': 'of the most dangerous reality shows in TV history'}\n",
            "{'score': 0.0009674482862465084, 'start': 40, 'end': 104, 'answer': 'Wiggins - who announced his retirement from cycling last weekend'}\n",
            "{'score': 0.001034093089401722, 'start': 49, 'end': 110, 'answer': 'fellow gold medallists Jade Jones MBE (Taekwondo) and Kadeena'}\n",
            "{'score': 0.000812206300906837, 'start': 0, 'end': 12, 'answer': 'Former rugby'}\n",
            "{'score': 0.0014960371190682054, 'start': 17, 'end': 22, 'answer': 'array'}\n",
            "{'score': 0.0015739008085802197, 'start': 59, 'end': 90, 'answer': 'Caprice, model and TV presenter'}\n",
            "{'score': 0.0015844374429434538, 'start': 17, 'end': 31, 'answer': 'Gibson, winner'}\n",
            "{'score': 0.0013227883027866483, 'start': 145, 'end': 161, 'answer': 'Hobley all being'}\n",
            "{'score': 0.009189224801957607, 'start': 9, 'end': 27, 'answer': 'returns to Channel'}\n",
            "['a crop', 'of the most dangerous reality shows in TV history', 'Wiggins - who announced his retirement from cycling last weekend', 'fellow gold medallists Jade Jones MBE (Taekwondo) and Kadeena', 'Former rugby', 'array', 'Caprice, model and TV presenter', 'Gibson, winner', 'Hobley all being', 'returns to Channel']\n",
            "{'score': 0.0002921035047620535, 'start': 198, 'end': 249, 'answer': 'collection offered in cup sizes ranging from D to J'}\n",
            "{'score': 0.00018292386084794998, 'start': 219, 'end': 256, 'answer': 'I wear the pieces, which is important'}\n",
            "{'score': 0.0003236136108171195, 'start': 199, 'end': 255, 'answer': \"Panache's new collection below. Are these nifty knickers\"}\n",
            "['collection offered in cup sizes ranging from D to J', 'I wear the pieces, which is important', \"Panache's new collection below. Are these nifty knickers\"]\n",
            "{'score': 9.680112998466939e-05, 'start': 139, 'end': 151, 'answer': 'Farah Dhukai'}\n",
            "{'score': 0.14512228965759277, 'start': 0, 'end': 4, 'answer': 'Most'}\n",
            "{'score': 5.2227580454200506e-05, 'start': 581, 'end': 642, 'answer': 'has found that it can help prevent dental disease. And this D'}\n",
            "['Farah Dhukai', 'Most', 'has found that it can help prevent dental disease. And this D']\n",
            "{'score': 0.00019142156816087663, 'start': 240, 'end': 265, 'answer': 'mulitplayer lag is a huge'}\n",
            "{'score': 0.0001527592830825597, 'start': 200, 'end': 282, 'answer': 'chalked it up to all other players being located halfway across the world in Japan'}\n",
            "{'score': 0.0003383299335837364, 'start': 110, 'end': 170, 'answer': 'the world is amazing. But Smash is serious business. Despite'}\n",
            "{'score': 0.04207984358072281, 'start': 0, 'end': 6, 'answer': '(Smash'}\n",
            "{'score': 0.01141633652150631, 'start': 0, 'end': 5, 'answer': 'Super'}\n",
            "{'score': 0.0002826048294082284, 'start': 9, 'end': 26, 'answer': 'our testing using'}\n",
            "{'score': 0.00019279970729257911, 'start': 208, 'end': 213, 'answer': 'was a'}\n",
            "{'score': 0.04207984358072281, 'start': 0, 'end': 6, 'answer': '(Smash'}\n",
            "{'score': 0.0004150076420046389, 'start': 184, 'end': 220, 'answer': 'sure they register, you can complete'}\n",
            "{'score': 0.04207984358072281, 'start': 0, 'end': 6, 'answer': '(Smash'}\n",
            "{'score': 0.022368568927049637, 'start': 0, 'end': 4, 'answer': 'SSB4'}\n",
            "{'score': 0.00027972256066277623, 'start': 65, 'end': 76, 'answer': 'some reason'}\n",
            "{'score': 0.0004312512173783034, 'start': 183, 'end': 199, 'answer': \"couldn't be said\"}\n",
            "{'score': 0.00022122383234091103, 'start': 228, 'end': 248, 'answer': 't help the situation'}\n",
            "{'score': 0.000253865699050948, 'start': 117, 'end': 121, 'answer': 'much'}\n",
            "{'score': 0.04207984358072281, 'start': 0, 'end': 6, 'answer': '(Smash'}\n",
            "{'score': 0.007894893176853657, 'start': 26, 'end': 34, 'answer': 'Placebos'}\n",
            "{'score': 0.0002941415295936167, 'start': 168, 'end': 186, 'answer': 'enough to get used'}\n",
            "{'score': 0.0004680989950429648, 'start': 21, 'end': 44, 'answer': 'had lag because of my #'}\n",
            "{'score': 0.0006511490209959447, 'start': 80, 'end': 94, 'answer': 'in the charger'}\n",
            "{'score': 9.762903937371448e-05, 'start': 25, 'end': 79, 'answer': 'heavily on location so I really don’t know what to say'}\n",
            "{'score': 0.00033957057166844606, 'start': 282, 'end': 285, 'answer': 'not'}\n",
            "{'score': 0.04251719266176224, 'start': 0, 'end': 10, 'answer': '(Wordpress'}\n",
            "{'score': 0.01107861753553152, 'start': 0, 'end': 25, 'answer': 'The Part Where I Complain'}\n",
            "{'score': 0.00014489135355688632, 'start': 418, 'end': 446, 'answer': 'Not to mention OG 3DS owners'}\n",
            "{'score': 0.00014690418902318925, 'start': 352, 'end': 408, 'answer': 'that you could ever seriously play Smash on a smartphone'}\n",
            "{'score': 0.00019648067245725542, 'start': 321, 'end': 345, 'answer': 'may be likely to forgive'}\n",
            "{'score': 0.0029641028959304094, 'start': 0, 'end': 47, 'answer': 'Are you experiencing lag in your online battles'}\n",
            "['mulitplayer lag is a huge', 'chalked it up to all other players being located halfway across the world in Japan', 'the world is amazing. But Smash is serious business. Despite', '(Smash', 'Super', 'our testing using', 'was a', '(Smash', 'sure they register, you can complete', '(Smash', 'SSB4', 'some reason', \"couldn't be said\", 't help the situation', 'much', '(Smash', 'Placebos', 'enough to get used', 'had lag because of my #', 'in the charger', 'heavily on location so I really don’t know what to say', 'not', '(Wordpress', 'The Part Where I Complain', 'Not to mention OG 3DS owners', 'that you could ever seriously play Smash on a smartphone', 'may be likely to forgive', 'Are you experiencing lag in your online battles']\n",
            "{'score': 0.00877159833908081, 'start': 0, 'end': 31, 'answer': 'You like the best of things but'}\n",
            "{'score': 0.003944504074752331, 'start': 26, 'end': 40, 'answer': 'you won’t just'}\n",
            "{'score': 0.003304741345345974, 'start': 11, 'end': 74, 'answer': 'you’re partial to fancy hipster foods, like expensive artisanal'}\n",
            "{'score': 0.00314240506850183, 'start': 12, 'end': 32, 'answer': 'you’ll happily skimp'}\n",
            "{'score': 0.011241166852414608, 'start': 5, 'end': 33, 'answer': 'all about balance, after all'}\n",
            "{'score': 0.002135681454092264, 'start': 25, 'end': 67, 'answer': 'you like to drink and won’t order anything'}\n",
            "{'score': 0.01232864335179329, 'start': 0, 'end': 1, 'answer': '5'}\n",
            "{'score': 0.005248436704277992, 'start': 8, 'end': 50, 'answer': 'it comes to your appearance, you generally'}\n",
            "{'score': 0.0016687383176758885, 'start': 89, 'end': 112, 'answer': 'few hours to get ready.'}\n",
            "{'score': 0.006517945788800716, 'start': 3, 'end': 13, 'answer': 'You always'}\n",
            "{'score': 0.0037201205268502235, 'start': 19, 'end': 31, 'answer': 'tend to just'}\n",
            "{'score': 0.0008537803078070283, 'start': 14, 'end': 79, 'answer': 'ive worn the same shirt everyday for a week [packing for vacation'}\n",
            "{'score': 0.0016308929771184921, 'start': 0, 'end': 2, 'answer': '10'}\n",
            "{'score': 0.0013606372522190213, 'start': 11, 'end': 32, 'answer': 'you’re in a situation'}\n",
            "{'score': 0.0036815297789871693, 'start': 27, 'end': 88, 'answer': 'are pretty high, people expect the best from you at all times'}\n",
            "{'score': 0.0043875775299966335, 'start': 0, 'end': 69, 'answer': '13. Which can be an exhausting pressure because you’re actually quite'}\n",
            "{'score': 0.008809475228190422, 'start': 29, 'end': 52, 'answer': 'almost exclusively high'}\n",
            "{'score': 0.002817888045683503, 'start': 0, 'end': 20, 'answer': '15. But you can’t be'}\n",
            "{'score': 0.006835829466581345, 'start': 33, 'end': 37, 'answer': 'very'}\n",
            "{'score': 0.005073784850537777, 'start': 4, 'end': 8, 'answer': 'Most'}\n",
            "{'score': 0.003258193377405405, 'start': 29, 'end': 34, 'answer': 'strop'}\n",
            "{'score': 0.004084606189280748, 'start': 22, 'end': 45, 'answer': 'they don’t want to take'}\n",
            "{'score': 0.004044619854539633, 'start': 42, 'end': 47, 'answer': ', but'}\n",
            "{'score': 0.020442426204681396, 'start': 7, 'end': 13, 'answer': 'medium'}\n",
            "['You like the best of things but', 'you won’t just', 'you’re partial to fancy hipster foods, like expensive artisanal', 'you’ll happily skimp', 'all about balance, after all', 'you like to drink and won’t order anything', '5', 'it comes to your appearance, you generally', 'few hours to get ready.', 'You always', 'tend to just', 'ive worn the same shirt everyday for a week [packing for vacation', '10', 'you’re in a situation', 'are pretty high, people expect the best from you at all times', '13. Which can be an exhausting pressure because you’re actually quite', 'almost exclusively high', '15. But you can’t be', 'very', 'Most', 'strop', 'they don’t want to take', ', but', 'medium']\n",
            "{'score': 0.03413502126932144, 'start': 15, 'end': 24, 'answer': 'are about'}\n",
            "{'score': 0.026184817776083946, 'start': 5, 'end': 14, 'answer': 'are about'}\n",
            "{'score': 0.0006376055534929037, 'start': 32, 'end': 100, 'answer': 'some steam built up at work or while studying. The holy grail though'}\n",
            "{'score': 0.0004917365149594843, 'start': 0, 'end': 21, 'answer': \"They're easy to scoff\"}\n",
            "{'score': 0.0030210036784410477, 'start': 64, 'end': 89, 'answer': 'you really have to commit'}\n",
            "{'score': 0.07279915362596512, 'start': 0, 'end': 6, 'answer': 'BOOM –'}\n",
            "{'score': 0.0011443617986515164, 'start': 93, 'end': 143, 'answer': 'maelstrom of events encouraging people to converge'}\n",
            "{'score': 0.0020506898872554302, 'start': 24, 'end': 36, 'answer': 'be found but'}\n",
            "{'score': 0.0024077228736132383, 'start': 10, 'end': 15, 'answer': 'to be'}\n",
            "{'score': 0.024592893198132515, 'start': 8, 'end': 26, 'answer': 'in the Mountains –'}\n",
            "{'score': 0.0002987421175930649, 'start': 229, 'end': 278, 'answer': 'shacks and art installations out wood sustainably'}\n",
            "{'score': 0.004175642039626837, 'start': 9, 'end': 15, 'answer': 'throws'}\n",
            "{'score': 0.02709055319428444, 'start': 14, 'end': 19, 'answer': 'Black'}\n",
            "{'score': 0.0016165105625987053, 'start': 41, 'end': 97, 'answer': \"You already know the main details, so here's an anecdote\"}\n",
            "{'score': 4.8600959416944534e-05, 'start': 690, 'end': 710, 'answer': 'her camp.\"AfrikaBurn'}\n",
            "{'score': 0.016846811398863792, 'start': 18, 'end': 36, 'answer': 'Rothbury, Michigan'}\n",
            "{'score': 0.0009120904724113643, 'start': 5, 'end': 63, 'answer': 'hard to think of a festival more picturesque than this one'}\n",
            "{'score': 0.0008325756061822176, 'start': 38, 'end': 63, 'answer': 'tall trees being utilised'}\n",
            "{'score': 0.012117973528802395, 'start': 13, 'end': 25, 'answer': 'Tankwa Karoo'}\n",
            "{'score': 0.007572588510811329, 'start': 12, 'end': 21, 'answer': 'so much a'}\n",
            "{'score': 0.0007153503829613328, 'start': 25, 'end': 86, 'answer': 'decommodification, creativity, self-reliance and radical self'}\n",
            "{'score': 0.008523788303136826, 'start': 10, 'end': 27, 'answer': 's theme is simply'}\n",
            "{'score': 0.034019678831100464, 'start': 0, 'end': 16, 'answer': 'Envision - Costa'}\n",
            "{'score': 0.0009035409311763942, 'start': 38, 'end': 44, 'answer': 'enough'}\n",
            "{'score': 0.0010822321055456996, 'start': 105, 'end': 123, 'answer': 'Envision, which is'}\n",
            "{'score': 0.06476371735334396, 'start': 0, 'end': 9, 'answer': 'Nowhere –'}\n",
            "{'score': 0.009702029637992382, 'start': 9, 'end': 52, 'answer': 'we come to the appropriately named Nowhere.'}\n",
            "{'score': 0.0009476374252699316, 'start': 82, 'end': 122, 'answer': \"intense it's website comes with not only\"}\n",
            "['are about', 'are about', 'some steam built up at work or while studying. The holy grail though', \"They're easy to scoff\", 'you really have to commit', 'BOOM –', 'maelstrom of events encouraging people to converge', 'be found but', 'to be', 'in the Mountains –', 'shacks and art installations out wood sustainably', 'throws', 'Black', \"You already know the main details, so here's an anecdote\", 'her camp.\"AfrikaBurn', 'Rothbury, Michigan', 'hard to think of a festival more picturesque than this one', 'tall trees being utilised', 'Tankwa Karoo', 'so much a', 'decommodification, creativity, self-reliance and radical self', 's theme is simply', 'Envision - Costa', 'enough', 'Envision, which is', 'Nowhere –', 'we come to the appropriately named Nowhere.', \"intense it's website comes with not only\"]\n",
            "{'score': 0.0003234687028452754, 'start': 68, 'end': 145, 'answer': 'dashed for people who become millionaires before they can even walk, but Mary'}\n",
            "{'score': 8.414014882873744e-05, 'start': 195, 'end': 246, 'answer': 'bizarre lives since leaving the TGIF lineup. Though'}\n",
            "{'score': 0.04821950942277908, 'start': 8, 'end': 14, 'answer': 'on bad'}\n",
            "{'score': 0.0002552708610892296, 'start': 142, 'end': 203, 'answer': 'beaucoup bucks when the popular sitcom ended. Their net worth'}\n",
            "{'score': 7.227817695820704e-05, 'start': 46, 'end': 99, 'answer': 'unintentionally laughable direct-to-video movies — 45'}\n",
            "{'score': 0.0005289384280331433, 'start': 0, 'end': 8, 'answer': 'In spite'}\n",
            "{'score': 0.016476770862936974, 'start': 0, 'end': 8, 'answer': 'The Mary'}\n",
            "{'score': 0.00019993643218185753, 'start': 277, 'end': 285, 'answer': 'masseuse'}\n",
            "{'score': 0.00014251930406317115, 'start': 38, 'end': 93, 'answer': 'masseuse finally determined she should reach out to the'}\n",
            "{'score': 0.000462425610749051, 'start': 44, 'end': 71, 'answer': 'had anything to hide. \"Mary'}\n",
            "{'score': 0.0002619687293190509, 'start': 12, 'end': 28, 'answer': 'stonewall tactic'}\n",
            "{'score': 0.008582483045756817, 'start': 20, 'end': 33, 'answer': 'opioid crisis'}\n",
            "{'score': 0.0001930459402501583, 'start': 358, 'end': 365, 'answer': 'handbag'}\n",
            "{'score': 0.0001860143238445744, 'start': 119, 'end': 159, 'answer': 'high fashion. According to Entertainment'}\n",
            "{'score': 0.00010654318612068892, 'start': 18, 'end': 86, 'answer': 'ghastly accessory celebrating drug culture seems even more offensive'}\n",
            "{'score': 0.015061603859066963, 'start': 4, 'end': 9, 'answer': '-Kate'}\n",
            "{'score': 0.0002755818422883749, 'start': 4, 'end': 23, 'answer': 'most of their adult'}\n",
            "{'score': 0.00014963603462092578, 'start': 245, 'end': 270, 'answer': 'best approximation of due'}\n",
            "{'score': 0.000400444318074733, 'start': 140, 'end': 182, 'answer': 'unethical plastic surgeons who are willing'}\n",
            "{'score': 0.008608045056462288, 'start': 10, 'end': 17, 'answer': 'Paltrow'}\n",
            "{'score': 0.00020341196795925498, 'start': 48, 'end': 105, 'answer': 'some Christmas gift ideas in 2014. Perhaps unsurprisingly'}\n",
            "{'score': 0.00035508404835127294, 'start': 255, 'end': 287, 'answer': 'any convenience store for around'}\n",
            "{'score': 0.00044985138811171055, 'start': 72, 'end': 82, 'answer': 'exorbitant'}\n",
            "{'score': 0.027654660865664482, 'start': 13, 'end': 24, 'answer': 'remains one'}\n",
            "{'score': 0.00013067096006125212, 'start': 329, 'end': 332, 'answer': 'too'}\n",
            "{'score': 0.0001885171077447012, 'start': 171, 'end': 179, 'answer': 'I was 17'}\n",
            "{'score': 0.00014449641457758844, 'start': 82, 'end': 88, 'answer': 'snub a'}\n",
            "{'score': 0.019475426524877548, 'start': 19, 'end': 21, 'answer': 'no'}\n",
            "{'score': 0.0007110898150131106, 'start': 119, 'end': 181, 'answer': \"taking time before diving into the acting world isn't the only\"}\n",
            "{'score': 9.676103945821524e-05, 'start': 186, 'end': 212, 'answer': \"well. Baby sister's resume\"}\n",
            "{'score': 0.00018703668320085853, 'start': 18, 'end': 20, 'answer': 'no'}\n",
            "{'score': 0.00023188327031675726, 'start': 293, 'end': 347, 'answer': 'would it kill you to be a little more like your sister'}\n",
            "{'score': 0.01787436567246914, 'start': 12, 'end': 16, 'answer': 'Kool'}\n",
            "{'score': 0.0007045942475087941, 'start': 0, 'end': 13, 'answer': 'There are few'}\n",
            "{'score': 0.00012753008923027664, 'start': 136, 'end': 161, 'answer': 'bizarre, especially since'}\n",
            "{'score': 0.00019986719416920096, 'start': 51, 'end': 79, 'answer': 'were only 50, \"were required'}\n",
            "{'score': 0.0246114619076252, 'start': 0, 'end': 8, 'answer': 'They are'}\n",
            "{'score': 0.00010504927922738716, 'start': 413, 'end': 447, 'answer': 'that only takes calls from Candace'}\n",
            "{'score': 0.0001461123611079529, 'start': 0, 'end': 18, 'answer': \"There's definitely\"}\n",
            "{'score': 0.00847399141639471, 'start': 44, 'end': 49, 'answer': 'snobs'}\n",
            "{'score': 0.00016399598098360002, 'start': 0, 'end': 34, 'answer': 'In a profile in The New York Times'}\n",
            "{'score': 0.00021261489018797874, 'start': 199, 'end': 225, 'answer': 'tastefully appointed manse'}\n",
            "{'score': 0.0007559104706160724, 'start': 80, 'end': 92, 'answer': 'we can do $5'}\n",
            "{'score': 0.004027589224278927, 'start': 0, 'end': 24, 'answer': 'Did they build a billion'}\n",
            "{'score': 9.199347550747916e-05, 'start': 490, 'end': 493, 'answer': 'not'}\n",
            "{'score': 0.00010189433669438586, 'start': 481, 'end': 494, 'answer': 'whopping $530'}\n",
            "['dashed for people who become millionaires before they can even walk, but Mary', 'bizarre lives since leaving the TGIF lineup. Though', 'on bad', 'beaucoup bucks when the popular sitcom ended. Their net worth', 'unintentionally laughable direct-to-video movies — 45', 'In spite', 'The Mary', 'masseuse', 'masseuse finally determined she should reach out to the', 'had anything to hide. \"Mary', 'stonewall tactic', 'opioid crisis', 'handbag', 'high fashion. According to Entertainment', 'ghastly accessory celebrating drug culture seems even more offensive', '-Kate', 'most of their adult', 'best approximation of due', 'unethical plastic surgeons who are willing', 'Paltrow', 'some Christmas gift ideas in 2014. Perhaps unsurprisingly', 'any convenience store for around', 'exorbitant', 'remains one', 'too', 'I was 17', 'snub a', 'no', \"taking time before diving into the acting world isn't the only\", \"well. Baby sister's resume\", 'no', 'would it kill you to be a little more like your sister', 'Kool', 'There are few', 'bizarre, especially since', 'were only 50, \"were required', 'They are', 'that only takes calls from Candace', \"There's definitely\", 'snobs', 'In a profile in The New York Times', 'tastefully appointed manse', 'we can do $5', 'Did they build a billion', 'not', 'whopping $530']\n",
            "{'score': 0.00021939397265668958, 'start': 36, 'end': 41, 'answer': 'bound'}\n",
            "{'score': 0.0007783812470734119, 'start': 123, 'end': 151, 'answer': 'some of these needs to share'}\n",
            "{'score': 0.05545710027217865, 'start': 0, 'end': 6, 'answer': 'Klefki'}\n",
            "{'score': 9.924369805958122e-05, 'start': 271, 'end': 338, 'answer': 'There are a couple more Pokemon like this, where it seems as though'}\n",
            "{'score': 0.1287642866373062, 'start': 0, 'end': 5, 'answer': 'Rotom'}\n",
            "{'score': 0.000813889317214489, 'start': 124, 'end': 136, 'answer': 'yes, Pokemon'}\n",
            "{'score': 0.0003971590776927769, 'start': 242, 'end': 275, 'answer': 'anyone else realised this Pokemon'}\n",
            "{'score': 0.03490043804049492, 'start': 7, 'end': 12, 'answer': 'keeps'}\n",
            "{'score': 0.0860610082745552, 'start': 0, 'end': 7, 'answer': 'Luvdisk'}\n",
            "{'score': 0.0012887691846117377, 'start': 51, 'end': 57, 'answer': 'hadn’t'}\n",
            "{'score': 0.0002053161442745477, 'start': 297, 'end': 342, 'answer': 'laughable. The lost potential of this Pokemon'}\n",
            "{'score': 0.03875372186303139, 'start': 0, 'end': 14, 'answer': 'Unknown (Unown'}\n",
            "{'score': 0.0016152923926711082, 'start': 40, 'end': 99, 'answer': 'little functions apart from the ability of flight and group'}\n",
            "{'score': 0.00043946123332716525, 'start': 68, 'end': 82, 'answer': 'feeble attempt'}\n",
            "{'score': 0.05415146425366402, 'start': 0, 'end': 9, 'answer': 'Vanilluxe'}\n",
            "{'score': 0.0001384555798722431, 'start': 102, 'end': 146, 'answer': 'cone! The designers thought this Ice Pokemon'}\n",
            "{'score': 0.0019608037546277046, 'start': 30, 'end': 33, 'answer': 'ide'}\n",
            "{'score': 0.08657584339380264, 'start': 0, 'end': 4, 'answer': 'Jynx'}\n",
            "{'score': 0.0009614774025976658, 'start': 56, 'end': 113, 'answer': 'terrifying large-bosomed-womanhood made for mankind. Jynx'}\n",
            "{'score': 0.034152500331401825, 'start': 0, 'end': 10, 'answer': 'Cofagrigus'}\n",
            "{'score': 0.00025564286625012755, 'start': 154, 'end': 218, 'answer': 'bit silly. In its description on Bulbapedia, it says the Pokemon'}\n",
            "{'score': 0.07271759957075119, 'start': 0, 'end': 7, 'answer': 'Voltorb'}\n",
            "{'score': 0.0007904170779511333, 'start': 18, 'end': 33, 'answer': 'laziest Pokemon'}\n",
            "{'score': 0.0849989578127861, 'start': 0, 'end': 7, 'answer': 'Dedenne'}\n",
            "{'score': 0.0004724835744127631, 'start': 84, 'end': 133, 'answer': 'much-loved logo and everyone’s favourite, Pikachu'}\n",
            "{'score': 0.048691313713788986, 'start': 0, 'end': 9, 'answer': 'Druddigon'}\n",
            "{'score': 0.0002763883676379919, 'start': 19, 'end': 46, 'answer': 'poorly drawn dragon Pokemon'}\n",
            "{'score': 0.05074027180671692, 'start': 0, 'end': 9, 'answer': 'Exeggutor'}\n",
            "{'score': 0.0002743037766776979, 'start': 213, 'end': 277, 'answer': 've never heard of coconuts hatching from eggs but in the Pokemon'}\n",
            "{'score': 0.05268026515841484, 'start': 0, 'end': 8, 'answer': 'Garbodor'}\n",
            "{'score': 0.00021559311426244676, 'start': 265, 'end': 271, 'answer': 'enough'}\n",
            "{'score': 0.016775554046034813, 'start': 9, 'end': 17, 'answer': 'Japanese'}\n",
            "{'score': 0.0007021281053312123, 'start': 13, 'end': 37, 'answer': 'hasn’t been released yet'}\n",
            "['bound', 'some of these needs to share', 'Klefki', 'There are a couple more Pokemon like this, where it seems as though', 'Rotom', 'yes, Pokemon', 'anyone else realised this Pokemon', 'keeps', 'Luvdisk', 'hadn’t', 'laughable. The lost potential of this Pokemon', 'Unknown (Unown', 'little functions apart from the ability of flight and group', 'feeble attempt', 'Vanilluxe', 'cone! The designers thought this Ice Pokemon', 'ide', 'Jynx', 'terrifying large-bosomed-womanhood made for mankind. Jynx', 'Cofagrigus', 'bit silly. In its description on Bulbapedia, it says the Pokemon', 'Voltorb', 'laziest Pokemon', 'Dedenne', 'much-loved logo and everyone’s favourite, Pikachu', 'Druddigon', 'poorly drawn dragon Pokemon', 'Exeggutor', 've never heard of coconuts hatching from eggs but in the Pokemon', 'Garbodor', 'enough', 'Japanese', 'hasn’t been released yet']\n",
            "{'score': 0.0016641682013869286, 'start': 39, 'end': 85, 'answer': 'there’s no denying that Elizabeth Taylor was a'}\n",
            "{'score': 0.0004377867153380066, 'start': 189, 'end': 243, 'answer': 'quite a bit about relationships before she died at age'}\n",
            "{'score': 0.0014179694699123502, 'start': 109, 'end': 136, 'answer': 'fiercest old Hollywood dame'}\n",
            "{'score': 0.00013413064880296588, 'start': 361, 'end': 374, 'answer': 'wasn’t nearly'}\n",
            "{'score': 0.0023170795757323503, 'start': 51, 'end': 93, 'answer': 'waxed poetic about his wife in his private'}\n",
            "{'score': 0.00016508552653249353, 'start': 258, 'end': 308, 'answer': 'impossibilities and my drunkenness, she is an ache'}\n",
            "{'score': 0.0038534775376319885, 'start': 15, 'end': 43, 'answer': 'we could get used to someone'}\n",
            "{'score': 0.0005815151962451637, 'start': 39, 'end': 91, 'answer': 'awkward between Elizabeth Taylor and the late Debbie'}\n",
            "{'score': 0.00036667819949798286, 'start': 192, 'end': 215, 'answer': 'going to carry a grudge'}\n",
            "{'score': 0.0012919851578772068, 'start': 29, 'end': 66, 'answer': 'pave diamond-heart necklace after one'}\n",
            "{'score': 0.0001874489098554477, 'start': 54, 'end': 78, 'answer': 'afraid to grow up,\" Dame'}\n",
            "{'score': 0.0003474458062555641, 'start': 250, 'end': 317, 'answer': 'neighbors would be spared if one of their infamous lovers’ quarrels'}\n",
            "{'score': 9.658195631345734e-05, 'start': 1, 'end': 12, 'answer': 'I’ve always'}\n",
            "{'score': 0.0027011698111891747, 'start': 16, 'end': 26, 'answer': 'each other'}\n",
            "{'score': 0.0007534600445069373, 'start': 27, 'end': 57, 'answer': 'doesn’t work out? We’ve always'}\n",
            "['there’s no denying that Elizabeth Taylor was a', 'quite a bit about relationships before she died at age', 'fiercest old Hollywood dame', 'wasn’t nearly', 'waxed poetic about his wife in his private', 'impossibilities and my drunkenness, she is an ache', 'we could get used to someone', 'awkward between Elizabeth Taylor and the late Debbie', 'going to carry a grudge', 'pave diamond-heart necklace after one', 'afraid to grow up,\" Dame', 'neighbors would be spared if one of their infamous lovers’ quarrels', 'I’ve always', 'each other', 'doesn’t work out? We’ve always']\n",
            "{'score': 0.009975530207157135, 'start': 0, 'end': 47, 'answer': 'Her inspirational journey is encouraging others'}\n",
            "{'score': 0.0025259312242269516, 'start': 9, 'end': 59, 'answer': 'pageant contestant has taken to Instagram to share'}\n",
            "{'score': 0.0008472412009723485, 'start': 16, 'end': 93, 'answer': 'most common skincare problems that people experience but that doesn’t detract'}\n",
            "{'score': 0.0008465282735414803, 'start': 30, 'end': 85, 'answer': 'being bullied for her severe skin condition and despite'}\n",
            "{'score': 0.0006854545208625495, 'start': 151, 'end': 165, 'answer': 'some seriously'}\n",
            "{'score': 0.0009463761234655976, 'start': 100, 'end': 151, 'answer': 'be ashamed of with a litter of make-up free selfies'}\n",
            "{'score': 2.848559779522475e-05, 'start': 1413, 'end': 1458, 'answer': \"didn't sit at home comparing myself to others\"}\n",
            "{'score': 0.0011378010967746377, 'start': 35, 'end': 65, 'answer': 'ॐ (@asprinkleofhealthandbeauty'}\n",
            "{'score': 0.0017406034749001265, 'start': 24, 'end': 41, 'answer': 'most recent posts'}\n",
            "{'score': 0.0010732441442087293, 'start': 103, 'end': 126, 'answer': 'to be the main culprits'}\n",
            "{'score': 3.2258951250696555e-05, 'start': 286, 'end': 320, 'answer': 'good always comes out of something'}\n",
            "{'score': 0.0011403000680729747, 'start': 35, 'end': 65, 'answer': 'ॐ (@asprinkleofhealthandbeauty'}\n",
            "{'score': 0.0009374521323479712, 'start': 119, 'end': 141, 'answer': 'breakouts!\" she writes'}\n",
            "{'score': 0.0017338423058390617, 'start': 16, 'end': 47, 'answer': 'High fat vegan plant based diet'}\n",
            "{'score': 6.303347618086264e-05, 'start': 1128, 'end': 1155, 'answer': 'acnetreatment #loveyourself'}\n",
            "{'score': 0.0011411496670916677, 'start': 35, 'end': 65, 'answer': 'ॐ (@asprinkleofhealthandbeauty'}\n",
            "{'score': 0.0010011850390583277, 'start': 127, 'end': 138, 'answer': 'in the Miss'}\n",
            "['Her inspirational journey is encouraging others', 'pageant contestant has taken to Instagram to share', 'most common skincare problems that people experience but that doesn’t detract', 'being bullied for her severe skin condition and despite', 'some seriously', 'be ashamed of with a litter of make-up free selfies', \"didn't sit at home comparing myself to others\", 'ॐ (@asprinkleofhealthandbeauty', 'most recent posts', 'to be the main culprits', 'good always comes out of something', 'ॐ (@asprinkleofhealthandbeauty', 'breakouts!\" she writes', 'High fat vegan plant based diet', 'acnetreatment #loveyourself', 'ॐ (@asprinkleofhealthandbeauty', 'in the Miss']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spoilers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkP-ViMU2X3W",
        "outputId": "2f91300e-73c6-414b-dce5-0cdad050da3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Segall Maricopa', 'sheriff of Arizona’s Maricopa', 'were', 'had unusually harsh words for Arpaio', 'inequitable application of discipline', 'had encouraged', 'had violated the order \"out of spite', 'had violated the order unknowingly', 'contempt on two counts, and retired Chief Brian Sands and Lt', 'evidentiary hearing, Sheriff Arpaio and Chief Deputy Sheridan made multiple intentional misstatements', 'wither', 'investigator to look into comments Snow’s wife purportedly made in a restaurant', 'impartial and should recuse', 'disobeyed orders to gather evidence and continued', 'thousands of pieces of evidence from the plaintiffs and deleted', 'the sheriff to resign', 'be entrusted', 'the original case against Arpaio, demanded', 'investigations that root out and punish misconduct', 'was one'], ['less, to one singular staple', 'Iggy Pop, Johnny', \"CBGB's legacy\", 'are you up', \"'m just here\", 'will start [in', 'Are you more of a theater guy', 'was just, yeah, I’m enjoying', 'Were you familiar with the legacy', 'very much', 'was amazing. They just had so much', 'Did you grow up listening to the music depicted', 'Blondie', 'Blondie', 'Did you dress', 'was a new experience', 'did you come to learn', 'lot', 'Grint: Yeah, there wasn’t really a whole', 'was on set the whole', 'was such a nice guy', 'Did he give', 'lot of that. And he was such a nice guy', 'Was this', 'Grint:', 'Were you comfortable', 'Weirdly, yeah. It didn’t really feel that big a deal', \"that you'd be intimidated to have\", 'I think every', 'was quite a hard one. It’s quite', 'did you think of the band you were portraying', 'I’ve always', 'd ever pursue', 'I’ve tried to leverage', 'were your thoughts going into a character who was much', 'some get', 'Had you seen each', 'great', 'I don’t think I ever really saw him outside of that wig', 'most', 'I love her, she’s great', \"It's October. What's your favorite Halloween costume\", 'in it, and you’d get', 'had a good costume', 'course', 'a Play-Doh logo. With a yellow hat', 'a favorite Halloween', 'I don’t even', 'all just kind of elderly', 'in limited release now'], ['in ultra-sexy skivvies', 'Rossellini', 'of like a superhero suit', 'Wiedemann hosts an online cooking series for Vogue', 'my core. My diet stayed pretty much the same, except I cut', 'be \"sexier and curvier', \"we don't plan\"], [\"mid-'90s. Clark\", 'I really missed it,\" Clark', 'took up writing. Since leaving the courtroom, Clark', \"Wow, you're not\", 'did change me,\" Clark', '100'], ['selling her Beverly', 'well worth', 'too big for'], ['Instagram', 'good deal', 'straits when you realise we live', 'raking in seven-figure salaries every', 'Hathaway – £3', 'fanatic earns a small fortune', 'most of her selfies', 'Hathaway (@paigehathaway', 'Hathaway (@paigehathaway', 'Zales – £3', 'hair removal.', 'TeamNoFuzz with alarming regularity.', 'Zales (@chantelzales', 'Zales (@chantelzales', 'Cheri –', 'hell', 'We just hope', 'AnaCherí (@anacheri', 'anacheri) on Jul 25, 2016 at 2:42pm PDT', 'Ratchford – £2', 'of it rubbed', 'could definitely', 'i l', 'i l', 'Alende – £2', 'doppleganger gets', 'all back, she’s really just', 'Alende (@claudiaalende', 'Alende (@claudiaalende', 'Somers – £2', 'waist training wraps that look a little like tofu bacon', 'Somers (@lacikaysomers', 'Somers (@lacikaysomers', 'Amanda Lee – £1', 'protein shakes and hang', 'have', 'amandaeliselee) on Aug 29, 2016 at 5:22pm PDT', 'amandaeliselee) on Aug 19, 2015 at 1:42pm PDT', 'Falconi – £1', 'legitimate nutritionist would avoid', 'You know, for the health of their clients.', 'Falconi (@bellafalconi', 'Falconi (@bellafalconi', 'fillers to liposuction and private gym membership', 'fulfilling prophecy', 'GIPHY', 'judgement', 'curled the bags maybe their arm gains would match'], ['most', 'have in your home', 'often the filthiest part of a kitchen', 'YOUR OWN CLEANER', 'Hellewell', 'wonders to help remove', 'react', 'paste onto the area you need to treat and leave', '30', \"was the last time you removed the shelves from your oven?' asks Rik\", 'you keep', 'soak. Make sure you read the instructions on the cleaning product and wear', 'shelving from the resealable bag. Rinse', 'TOOTHBRUSH', 'toothbrush is an essential', 'you use an electric toothbrush', '4. USE', 'ideal', 'soak in oven cleaner and warm water, then scrape', '5', 'may sound strange, but you can remove', 'In fact, this technique will make clean-ups in the future', 'areas with all-purpose oven cleaner to ensure', '6', 'all cooked a wonderful meal', 'pungent', 'few drops in', '7. USE', 'hob can help remove built-up grease. Simply apply', 'hob clean, sprinkle', '8. POLISH WITH CREAM OF TARTAR', 'odd cleaning product to use on your oven, but', \"'Simply apply with a thin cloth, leave\", '9. REMOVE STUCK ON FOOD WITH DISHWASHER', 'pans in a dishwasher', \"'Take a dishwasher\", '10', 'very quick and easy way to battle', 'you can; if not, leave', 'on food remains, cover with your homemade cleaning solution'], ['in this world that’s worth', 'the BuzzFeed', 'maybes.\" – Poussay', 'good old days before you’ve actually left them.\" – Andy', 'They are a reminder that our lives will get better if we just hold', 'Khatun', 'you want that, too?\" –', 'undeniable.\" –', 'how tightly you hold on, it\\'s already gone.\" –', 'being compatible, or novels about shared', 'don’t necessarily spoil', 'indifference.\" – Bree Van de Kamp, Desperate', 'they move on.\" –', 'too much of a coward for that, then burn.\" –', '13.', 'You don’t deserve', 'still', '16.', 'you’re supposed to.\" –', 'few.\" – Debbie Novotny', '19', 't just run out of answers. You run out of hope.\" –', 'well, I think you deserve', '22', 'the world will not. Wear it like armour and it can never be used', 'all you will ever see.\" –', '25', 'would have stopped.\" –', 'did love you because it makes me think that I might be capable of something', '28', '29', 'to be featured in similar BuzzFeed posts'], ['be', 'sinister oracle with the power', 'the year 2000', 'might be in store', 'Some alt-right guy', 'the episode', 'There will be a referendum', 'Much', 'Greedy, corrupt energy firms will cause an environmental catastrophe', 'dome appeared in The Simpsons', 'in Elton John’s private', 'I', 'illegal to teach', 'the episode \"The Monkey Suit', 'also sarcasm', 'the episode \"The Saved Lisa', 'Jolie and Brad Pitt', 'Whopper\" , it’s revealed that the celeb trainer Lyle', 'several actual clowns will stand in elections around the world. And win', 'the episode', 'Cumberbatch will be cast as David Cameron', 'Many-Splintered', '10', 'the episode', 'Hawking will learn', 'They Saved Lisa', '12. To cut costs, industry workers will be replaced', 'the episode', 'was won', 'the episode', '14. White', 'that’s already happening. From the episode \"Lisa', 'there will be a female president. The Simpsons said it will happen'], ['least a couple of his draft classmates are still', 'Nowitzki, 38, hopes', '- unless you count the No', 'being out of the league for six years, Traylor died of a', 'LaFrentz, No. 4 Antawn', 'Half Man, Half Amazing,\" Carter redefined his', 'Nowitzki, the No. 9 pick despite', 'most', 'one', 'Nowitzki', 'greats separately sat down with ESPN recently for a three-way Q', 'd love', 'division to the NBA. That was a huge', 'was literally', 'was incredible', 'Nowitzki, on his reaction to being drafted by the Mavs', 'Had a press conference. Never had a suit', 'Strick [Erick Strickland', 'were a great team right [then], not really', \"If they don't take\", 'I was going', \"was just weird. I thought I'd be in the top five\", 'me to be', 'Olowokandi', 'Olowokandi', \"well come work out.' That's what\", 'was introduced to the business of basketball pretty much in the first five', 'being traded from Golden State', 'was just perplexed', 'was just', 'Antawn at', 'was already walking up to the stage. It blindsides me, pretty much', 'each', 'Nowitzki', 'always', 'was fun to watch during his prime', 'athleticism and great shooting touch. Usually you see one without the other', 'he was one', 'transcendent player', \"loves to compete. And he's selfless\", 'me', 'in hell', 'Nowitzki', 'was a great flat', 'McDonald', 'you just hope', 'many great battles', 'was just sitting on my butt in my 20s', 'mid-aged guy. Couple of young guys, but still', 'hopefully I can [stay', \"camaraderie that I'm going\", 'lot of bus rides, a lot of pregame speeches, a lot', \"I'm enjoying\", \"There's nothing\", \"were just kind of like, 'Where do I go from\", \"I go?' Then just spending\", \"I'm not\", 'have been doing it all these years but can see yourself [coaching full', 'me, because I love', 'Nowitzki: [Heavy sigh.] That sounds like a lot', \"tough. It's not\", 'going'], ['there are easy ways to treat some small afflictions', '-yourself remedies and get a quick fix for everything from earaches', 'Mouthwash for', 'Black tea for', 'cider vinegar for', 'often used as an energy booster', '5', 'peroxide for', '7. Honey for cuts and small wounds', '8', '9', '10', '11', 'suffocate the wart', '13', 'they’re so easy. I’m going to remember'], ['high-pressured jobs with starting families and maintaining', 'there was a simple three-minute solution', 'anyone can master', 'FEMAIL', 'all you need to do', 'in through two straws', 'are going to hit', 'in and out through the nose as per', 'shoulders, eyes, mouth'], ['ex-girlfriend of former basketball Alvin Japhet', 'Investigation (NBI) for', 'Not only', 'on the offense has now committed', 'in an entrapment', 'mug shot of the suspect. (photo credit: gmanetwork', 'According to GMA', 'only lasted for a year after he', 'hubad sa hallway ng', 'strangles me, he tries to crush', 'Almario has also threatened her parents', 'common friends', 'at him. (photo credit: gmanetwork', 'way', 'would do', 'been able to speak up, the suspect remained', 'CCD) chief Ronald Aguto Jr. (photo credit', 'CCD', 'them.-Kami'], ['Did you know theres actually a right way to shower? Get', 'most', 'you know that some of the most common shower habits might not', 'are doing', '1', 'already in the shower. However, despite', 'irritation—it could even burst', 'Not', 'there’s no real reason to actually bend down and give', 'you’re not', 'excuse', 'Not', 'that can be terrible', 'you’re out, or create', '4. Using a Soap Dish', 'going', 'have reasons', '5', 'be doing a number', 'their soap as the first culprit', '6', 'Some people may not even', 'high concentration of minerals like magnesium and calcium, which can end', 'unable to add a water softener to your shower, try incorporating', '7', 'Most people wouldn’t even', 'stress you can tolerate', 'regularly taking', '8. Using', 'most of us, old razors aren’t something', 'is shaving off your unwanted hairs doesn’t mean', '9', 'plenty of nooks', 'you don’t', '10', 'good idea, but doing so every day could actually be causing damage', 'worth'], ['most', 'palliative care for physicians, people tend', 'them comfortable, Campbell', 'tend to lose their abilities for complex or executive', 'coherence', 'Palliative Medicine. Seventy'], ['my pictures posted on Match.com or another [website],\"  says', 'York Post', 'phony accounts filed a $1.5 billion class-action suit', 'Yonkers, N.Y', 'Avalos said', 'had to borrow', 'preventable with the right software, ABC News reports. The Post', 'filled', 'misled'], [\"'s bizarre road\", 'baffling tales', 'Jacoba Tromp and their adult children Ella, Riana', 'with paperwork everywhere', 'As they drove towards NSW', 'One day later he left the family trip at Bathurst, describing his parents', 'Goulburn, where Riana', 'was following', 'had made their way back', 'Their mother', 'an end when Mark was found on a street near Wangaratta', 'hard to explain\" and referred to the situation', 'At the time', 'the world, remains a mystery, but theories have included drugs, financial', 'were found dead in far west New South Wales', 'being good feed', 'were sightings of between 5-50 dead kangaroos at a', 'Former NSW', \"All the work we've done says it's not\", \"s possible it's an infectious\", 'When a magnitude 7.8 earthquake struck', 'they witnessed the sky light up said it occurred at', 'were] of colours mainly', 'thousands', 'gradients that \"accumulate', 'High', 'were at a loss', 'a top hospital in the capital', 'also suffers', ',', 'those suffered', 'hijacker Dan \"DB', 'had a bomb in his briefcase', '-coloured sticks inside his case', 'parachutes and $', 'had landed in Seattle, he', 'several crew members still on board, he ordered the plane to fly to Mexico', 'somewhere', 'was heard from', 'longer actively'], ['Herculean task', 'will risk being sent back to the feds', \"wasn't in any position\", 'cattle ranchers via Wikimedia Creative', 'Mendoor Smith, 43-Year-Old from', 'Served', 'Custody in 2013', \"halfway house I was placed in. It wasn't really\", '10 AM, the cow had died. All that work was for nothing', 'coworkers that knew about my [criminal] situation', 'Hibdon, 55', '10 Years for', 'Custody', 'halfway house to save up and buy a $500', 'K2', 'subcontracting myself out to do maintenance on rental', 'telemarketing call center via', '-Year', 'a', 'Custody in 2009', \"wasn't\", 'were an outsider. There was a lot of favoritism', 'had something better lined up. It served'], ['high school... it was one', 'Lapeer High School’s class of 2016 and he', 'would inevitably drift apart but he makes a promise'], ['a serious', 'impractical,\" Clark', 'that great', 'few crucial', 'bulky. Their epinephrine solution isn’t particularly', 'Mylan, which owns the EpiPen brand (though', 'Mylan', ', not', 'displace', 's why', 'Mylan', 'injector (to protect soldiers', 'Mylan', 'has been', 'Mylan', 'in that moment,\" said Matthew', 'Mylan', 'It would not', 'There’s no', 'injector for the past', 'in a pants pocket without getting', 'few years away from bringing', 'Mylan', 'Mylan', 'injector shaped like a bulky credit', 'injector', 'Mylan', 'injector by far,\" MannKind CEO Matthew Pfeffer', 'exceedingly tough to get', 'stymie an epinephrine inhaler, especially since', '4', 'lot', 'was worth', 'high right now that Baum figures it is worth', 'We’re just', 'loud enough', 'allergy, is a consultant', 'though', 'irritating to me, but not to the point', 'Mylan', 'Mylan’s motto'], ['Gologursky', 'Gwyneth', 'Paltrow', 'Her', \"like to do a cleanse once a year. But it's not\", 'Her Daughter', 'to be with her. We went out to lunch', 'Unplugging', 'my phone away and I really listen, that is such money in the bank', 'gwynethpaltrow', 'On Her', 'my life, and food is a big part of it. I love', 'On', 'on a shelf for years and you can open out of a bag', 'Cheat', 'them growing up in a hippie vacuum,\" she once told Redbook', 'Being', 'mindfulness. If you just parent', 'gwynethpaltrow', 'Taking', 'at least', 'in Balance', 'be modern and easy on ourselves as well,\" she told InStyle', 'On Her', 'I get through', 'Is', 'Obese couples take longer to conceive suggests', 'Are SERIOUSLY Stressed, Says', '7 Valentine', 'in', 'Hairstylist', 'Going', 'Major Black', 'Remini', 'Her', 'Mesmerizing', 'Stamina', 'SNL’ in the Midst of a Ratings Renaissance', 'With Britney Spears Spends $80G', 'Nyong', 'the 2017 SAG', 'Issues to Pose With Mom', 'Hair', ', Miss', 'Have Missed', 'More Than', 'GNC Ad Booted From', 'Hair Looks Perfect for Valentine', '5', 'Selleck', 'Black', 'Giambattista Valli Serves', 'Whimsical Beauty Looks From the Dior', 'Hunch Helped Crack a Jogger’s 6-Month-Old Slaying', 'One', 'in Your Shopping Cart', '’ Star Richard Hatch Dead at 71', '5 Times'], ['it’s ironic', 'were legitimately', '-watch Unbreakable Kimmy', 'an HGTV', 'who calls someone', \"it's probably\", 'willing to endure', 'the evening', 'serums, etc. Make sure to give', 'that pinot grigio and pinot', 'have an opinion on which you prefer', '-unit laundry while looking at apartments', 'Who has time to waste', 'kiosks at places like Target and Best Buy like a total pro', 'being intimidating', 'Not only do you have friends', 'when a new checker doesn’t recognize you and asks for your ID', 'have a preferred', 'You spend', 'you used', '-create some of the dishes', 'You mix up Kendall and Kylie', \"they're\", 'The last crazy concert you went to was...an opera', 'longer an option', 'that you actually care', '20', 'still felt guilty and even managed', 'laughing matter', 'When someone', 'You know the difference between a traditional and Roth IRA', 't just something'], ['still work to do, although great', 'still work to do, although great', 'you will see just how many people belong', 'there any names on this list that really surprised you? Feel free to share', '15 Kristen Stewart', 'Cargile have only been dating since July of 2016, but Stewart has expressed', '14', 'most influential gay news magazines. Plaza did not', '13', '100% straight to 100', '12 Colton', 'all just enjoy life & have no regrets', '11', 'Dysmorphia', '10', 'often perform hilarious skits', '9 Ryan', 'enough', '8', 'By the end of the music video, Owen has found a guy that suits', '7 Gloria', 'had a lesbian relationship with one of her classmates. It was a piece', 'Warsame', 'number of mosques in Australia that will not'], [\"isn't\", 'be a champion for young women in her situation', 'had major', 'great', \"In fact, she's even joining\", 'There are so', 'have', 'collecting', \"been through, she can't quite believe her current life situation\", \"pageant would want someone like me. It proves you don't need\"], ['the weekend. Then, for good measure', 'Feldman by—what else?—tweeting', 'was beautiful; just everything', 'forty minutes later, she dropped THIS bombshell', 'all the cynics out there, Guthrie', 'did YOU do'], ['a while, but the morphine and lack', 'I have a) your attention, and b', 'at least another', 'on her right side isn’t the no-biggie', 'had just left', 'many plans instantly went poof', 'my mother. No writers’ residencies at those wonderful schools in India', 'wonder', 'in the present', 'did it in one day', 'had never met. I went to college out east', 'were only 24', 'the end of dinner', 'a year later', 'eHarmony, but I’m going', '-pepper', 'in no particular order because everything feels important', 'sharp dresser. Our young adult sons, Justin and Miles, often borrow', 'could speak, it would add that Jason is uncannily', 'should also add', 'was working on my first memoir, I kept', 'you can use', 'would agree — he was indeed a captivating', 'an absolutely', 'most days from 9 to 5', 'affinity', 'always', 'He knows I love', 'is you know enough', 'Did I mention that he is incredibly handsome? I’m going to miss', 'too', 'most recent memoir (written', 'was totally serious about this and encouraged', 'was based on an essay in the book where I mention', 'was my second tattoo; the first is a small, lowercase \"j', 'few days left', 'I am wrapping this up on Valentine’s Day, and the most genuine', 'you two the fresh start you deserve', 'all'], ['of his friends planned a trip to Majorca', 'having to look at one', 'some Joe', 'He wrote', 'It’s our friend Nathan’s 30th', '15 namesakes, but only', '15 Joe', '99MQXdZVyw', 'legitimacy of the offer at', 'He wrote', 'legit, I decided to take the plunge as my legendary boss', 'all', 'want to apologise to my mum'], ['of the most interesting and powerful photo stories from across', '-Seen Photos Behind the Scenes at the Women’s March\" —', 'in terms of scale, coverage and inclusivity. Kisha', 'Bubacz, senior', 'Honest Photos of Motherhood Challenge', 'They don’t hold', 'BuzzFeed', 'The World\" — BuzzFeed', 'intercommunication in the digital age', 'BuzzFeed', '4. \"A', 'be', 'K', 'That Will Help You Understand the Refugee Experience\" — BuzzFeed', 'all the more relevant as a nation of immigrants begins to grapple', 'K', 'Are Guaranteed', 'my thumb on it, the collection constitutes a great', 'G', 'Nairobi’s Korogocho Slum\" — Al Jazeera', 'most', '—A.M', '8', 'misconceptions and showing that women also belong', '—A.M', 'of the Most Powerful Photos of this'], ['common', 'will.\" The message was always', 'conscious,\" Rodriguez says. \"That’s the one', 'each morning, they did a series of jumping jacks', 'Tsai', 'were great', 'in the country. And Gina Rodriguez won a Best Actress Golden Globe', 'We lived the idea of the American Dream,\" Gina says', 'Family', 'Right: Courtesy of the Rodriguez Family', 'Srinivasans', 'thousands', 'well. And we defined success by leadership', 'none of these siblings grew up rich, they were privileged in many', 'most said they grew up with much', 'Indians from Kansas', 'Immigrant Drive', 'Saroja Srinivasan, a Hindu who is vegetarian, was mastering', 'Saroja recalls. That meant cooking hot dogs and pizza as well as dosas', 'Srinivasan household', 'Srinija, the youngest. \"Put things away. Pay attention', 'permissiveness that is way better than an allowance,\" says', 'Srinivasan Family', 'Srinivasan Family', 'was more important', 'Srinija is an entrepreneur who', 'addition to Puerto Rico and India', '-selling author and New York Times', 'Gay Family', 'Hegger', 'Good grades in school, that was not something', 'Being from Haiti in particular', 'Parent-Teachers', 'Srinivasans in Kansas', 'genetics company 23andMe', 'paper airplanes during presentations', 'lot of strong academics, I think one of the skills we have is not', 'Wojcicki', 'Wojcicki', 'game.\" She did arts and crafts projects with her toddler', 'among the most important', 'Not', 'supplementary lessons', 'well-known actor, with major', 'Dungey Family', 'Left and Right: Courtesy of the Dungey Family', 'Srinivasans, having a parent', 'Activism', 'most', 'vice provost at the University of Pennsylvania', 'dinner was a test of current events.\" (The brothers also have', 'Tsai', 'will change necessarily', 'housing complexes, and never', 'Emanuel Family', 'Left: Courtesy of the Emanuel Family', 'construction site. Now adults', 'had his own moral', 'ControlLed', 'street fight against 12 other guys', 'on our corner.\" That exposure also created motivation. \"Seeing tragedy always', 'Tsai', 'multimillionaire', 'violence than most', 'Few recalled major rifts between their parents. But many of these siblings', 'Mealtime debates could get so', 'Family', 'Behar—Sipa Press/AP', 'basket. Susan and Janet', 'weren’t home. Esther Wojcicki', 'had to withstand', 'motivate achievement, says New York University psychologist Ben', 'LESSONS', 't', 'motivated by a constant', 'gallbladder out, and I don’t want', 'Antonoff Family', 'Left: Courtesy of the Antonoff Family', 'violence. Rahm Emanuel nearly died as a teenager when a deep cut', 'going to not', 'didn’t insist they finish college, and she took Jack', 'had a kid', 'range childhood', 'many of the other siblings', 'loathed so much', 'Mao and ultimately became professors at Ohio University, didn’t', 'Family', 'Right: Courtesy of the Lin Family', 'most of their time outside, or writing poems, or throwing', 'Few of the siblings', 'she allowed us to play and develop our own ideas,\" says', 'Wojcicki', 'often left to babysit 4-year-old Janet', 'less empowered they feel,\" she says', 'commonalities of our nine families combined to create drive', 'will are five'], ['By', 'Division I football for Missouri State University, Andrew was an honors', 'more timely by the recent heroin-related death of Glee star Cory Monteith', 'much more powerful than before (purity can be as high as 90', 'in routine wisdom', '—legally and on the black', 'was finally starting to get a handle on his addiction. Like Cory Monteith', 'some of the best high schools in the area. Public, private', 'was like I was leading', 'had to give something to him,\" she admits', 'When a friend', 'length to get sober. I had to change every', 'much', 'been'], ['eared giant, among them—and their triumphs over bullying adults', 'evocative stories. In May, the Oxford University Press also published a Roald', 'sizzle-pan\" to refer to a frying pan in', 'Dahlisms added to the OED, and the revised phrases, with notes', 'New entries', 'loathsome adult characters, and gruesome or black humour', 'in chocolate bars that granted access to Willy', 'over a century older, having been used', 'adaption of the book, starring Gene Wilder. Gupta called the phrase', 'Scrumdiddlyumptious', 'excellent', 'scrumdiddlyumptious and some is uckyslush', 'had the world to themselves.\" We can thank Shakespeare'], ['have been up', 'hope', 'longer meeting', 'monetization', 'we announced Promoted User Posts', 'be met', 'lot', 'great', 'Happy to chat about this stuff, or anything'], ['Temple University students, alumni, faculty and staff gathered at the Liacouras', ',303 being made and sent to charitable organizations in the Dallas/Fort Worth', \"Temple shattered that record, according to the university's Twitter account\", 'Fifteen food banks and shelters across the Philly', 'Congrats, Temple. And once again, as a thank'], ['are home sick from school', 'a feud between him and President Trump, who remains', 'more than', 'on the unresponsive child when the mother', 'are a top', 'the proposal to deter', 'had communications during the campaign', 'may have had with Russia during the 2016 campaign', 'have polycystic ovarian syndrome, and Dr. Jennifer Ashton explains', 'The Force Awakens\" star, Daisy Ridley, revealed a powerful message', 'that she has been suffering from endometriosis since she was 15', 'View', \"'Star Wars' Actress Daisy Ridley Fires\", \"'Star Wars\", 'Endometriosis occurs when the normal uterine lining grows outside the uterus', 'in women of child bearing age', 'have polycycstic ovaries', 'in tatters', 'have polycystic ovarian', 'that with the help of dermatologists and diet changes, like cutting', 'allergy testing; keep', 'over 200,000 likes and countless comments of outpouring'], ['a better parent', 'on your kids', 'have no', 'the more', 'you look like your kids do every', 'your kid is embarrassing you in public', 'happy', 'Your kids walk around explaining things so you don’t have', 'they also', 'a disturbing level', 'you get it you are one calm, cool badass mom', '11. This image perfectly sums', 'It doesn’t matter', 'it’s like liquid confidence for motherhood', 'there is to handle', 'in your household', 'much more pleasant mom', 'when someone asks how you mom so good, your answer is always'], ['you need', '100', \"haven't done since 1995. The S&P\", 'the summer of 1975. However, real wage growth slowed to 0', \"Wilders's far-right party expected to perform\", 'Intermediate crude oil trades up 1.7% at $48', 'most of its shares after Jack', 'Walgreens plans to sell more assets to win approval for its takeover', 'S&P', 'light. Oracle', 'Housing Market Index is due'], ['Good Morning', 'a bit', 're not', ', should be', ', should be', 'to be', 'View', 'are generally good for a year. Aerosol spray products can last much', 'is stored improperly — for example, in a place that is too', 'they will have an exact expiration', \"It's hard to keep\", \"Franzino's tips to save money on beauty products include swapping\", 'you may end up having to throw'], ['on your big day', 'distasteful to some may be perfectly normal to others', 'cringe-worthy dance routines, cheesy', 'unquestionably tacky and definitely not', 'horde', 'you seen that video doing the rounds on Facebook where a guy', 'tackiest things you can do at someone', 'livid. Like no. This is my', 'inconsiderate,\" and quite simply, \"F', 'peeve guests have at weddings are vulgar', 'Miserable marriage jokes are never', 'toppers that show the bride dragging the groom and ring-bearer', \"there under their own free will. S***'s not\", 'most common gripe among guests though', 'had homes was fine, there were some circumstances', 'the bride & groom', 'very', \"aren't invited, but asks for a gift? GTF outta here\", 'they had her husband', 'there was a cash', 'screeching'], ['could have been possible if the ruler had sex about once a', 'was the first great sultan of the Moroccan Alaouite', 'most of them from enemy chiefs', 'at one of his wives or concubines', 'may actually have had 1,171 children from four wives', 'infertility often afflicts', 'To solve this question, scientists developed', 'were as conservative as possible with our calculations, and Moulay could still', \"were at fertilizing women's eggs as he\", ',171 children in 32 years. Moreover, the sultan did not need a', 'were all quite different from each other', 'Oberzaucher'], ['ones who deserve', 'Lakisha', 'Lakisha', 'My oldest daughter Kiona', 'Kiona', 'Along with her work as a healer, Dr. Jenkins strives', 'other people do and you’re more in a position', 'going to challenge you all the time', 'K', 'due', 'much anything related to the operations of cannabis businesses regulated by the state', 'I’ve always', 'lot of opportunities to blaze the trail, so to speak, no pun', 'Lyman, California State', 'non-profit organization Drug Policy Alliance, \"the leading', 'We always', 'didn’t pass', 'were a vital', 'lot', 'been men’s faces at the forefront and yet', '4', 'diversity summit', 'many community leaders of color to come in and share', 'in far from over. \"I’m', 'I’m gonna', 'that literally credit', '5', 'FECO', 'lab grade, U.S. made, naturally extracted beta', 'longer feeling stuck without options to address their reproductive concerns. \"Women have always'], ['Abraj Kudai', 'would make the hotel', 'helipads and a full', 'Handasah , the $', 'over 2 kilometers from the Masjid al-Ḥaram', 'Abraj Kudai', '10,000 hotel rooms, according to DesignMENA'], ['moderate the first presidential debate Monday. (Photo by Jose', 'have advised', 'are five', 'registered Republican', 'into attack', 'of indicative', 'Conspiratorial', 'a very', 'lobbing questions at Republican Donald Trump and Democrat Hillary', 'bias against him will be tough', 'black', 'been 24 years since a black', \"I'm never going to pull a race card\", 'moderated one of Hillary', \"a huge distinction. We're not\", 'not', 'in almost a month. He was fairly active while in', \"I've never done before a newscast. Beach volleyball. Tonight\", 'xJ5MoYGtPZ — Lester Holt (@LesterHoltNBC', 'several days or even a week between tweets. His relative disinterest', 'moderated a Democratic', 'that night with Andrea Mitchell', 'willingness', 'fomented a war in Ukraine, provided', 'has', 'me he plans to do', 'California State', 'was planning to drop out of California State', 'okay. Since dropping out, Holt has received'], ['you have or where it is, you’re going', 'you don’t have to go broke just keeping', 'You also miss', 'well-served', 'outgrow', 'inFlow', 'hiccups', 'inFlow, Carta should offer', 'invoice and receipt generation tools, geared', 'can be managed', 'be free for', 'you’ll probably want to take advantage of at', 'great open source answer for', 'Almyta Control System. It’s a free package', 'all free options, you’ll be supplying', 'thoughts', 'most small business inventory requirements, with many offering flexibility to move up', 'us know in'], ['lot', 'Kis', 'your time, he shares the ultimate', 'many projects', 'at least 10 per', 'enough to be prepared to invest 10 per cent of your net worth', 'can be run by a monkey, because one day it probably', 'Multi-millionaire Sophia Amoruso, founder of Nasty Gal, says', 'the more time you spend', 'has to be', 'vacations are not', 'their time. Indeed, as Kim', 'skilled in a certain'], [', so, Oxford University is older than', 'in time to the invention of Snapchat than', 'more than 2,000 years ago in 30', 'are', 'still', 'was older to the Tyrannosaurus rex', 'Not only did they not exist at the same time, but the T', 'closer to the signing of the US Constitution than to today', 'Martinuzzi, the oldest living person today at age', 'the United States has two grandchildren who are alive today', 'had a son, Lyon Tyler, at age', '6', 'most', '7', 'almost 50 years before Isaac Newton published his Principia', 'only 66', 'There’s so much Americans', 'were still alive when the Great Pyramid at Giza', ', which wasn’t until about 1560', '10. When the first Star Wars movie came out, France was still executing', 'Hamida Djandoubi', 'were still', 'Just two years later, Scottish inventor Alexander Bain', 'Ottoman Empire', 'all', '13', 'that’s the year Betty White was born', 'Uncle Phil', ', but Will Smith is now 48 years old. James Avery was 45', '15', 'way after the end of the ’70s, but that gap is exactly', 'Eiffel', 'Eiffel Tower was inaugurated for the 1889 World’s Fair', 'Jr', 'in very different times, Anne Frank, Barbara', 'Some of the world’s whales that are alive today', 'may be whales out there who are nearly 50', 'didn’t even', 'heartbreakingly demoted in 2006. Because', 'the fall of the Berlin Wall than to today', 'only 12 years before 9', '21', 'If you compressed the entire', '22', 'and medicine, the current human population living on Earth right now is about 6', 'in the past, not the present', 'it takes about 50'], ['happiest day of their life and the best', 'sorely regret saying', 'Plenty are sexual, with one woman admitting she misses', \"his wife is simply 'taking\", 'their spouse', \"I'm\"], ['some of these items, but you won’t find any deep discounts', 'School Supplies', 'high profit margins — like binders, graph paper and computer memory', 'you have to spend so much time waiting to see the attractions. Dave', 'in mind that popular stores like Sears and Home Depot', 'you need to purchase a new TV before the prime season, DealNews', 'unveils their upcoming models in September or October, reported DealNews', 'more than a few years old, even if they are deeply discounted'], ['for a forever home ever', 'undesirable to families looking to adopt. He also has', 'for a home for Jingee since may, sending', 'resident,', 'was worth', 'Hayley went to see Jingee with her', 'few more nights she decided to go', 'She definitely', 'was potty trained! Apparently somewhere', 'was taught to be', 'could learn'], ['Other', 'you love', 'at a skill that you can share with others', 'on cooking for $30', 'lot', 'fucking', 'mug for $22', 'attention', 'mask for $24.30', 'you love about yourself and show it off like every', 'the tank for $39', 'on coffee table books that actually interest', 'this illustrated book for $15', 'on the right for $17', 'Declutter! You automatically look 10 times', 'five-pack cable organizer for $30', 'revamp your creative space with a structurally intriguing desk organizer for $38', 'not have to please', 'Not Giving a Fuck', 'you’ve nailed', '8. Don’t hide', '10 and the second shirt for $', 'on every', 'five-year journal for $15 and the desk organizers for $40', '10. Buy a few distinct', 'has with this galaxy cover for $20', '11. Smile (only when you want to) with the greatest', 'whitening powder for $19', '12', 'the second for $15, and the third for $35', '13. Experiment with your appearance: If life’s not', 'some semipermanent hair', 'not', 'the coat for $150', '15. Instead of fearing your lack of creativity', 'the first book for $9.60', '16. Be', 'a goals pad for $', 'of course', 'the second pair for $'], ['We’ll see the UK triggering Article 50, Trump take over the White', 'to be a bigger year for some than others', '1', 'Amy', '3', '4', '5', '7. Lauren', '8', '9', '10', '11', 'Hayley', '13. Megan', '14', '15.', 'Katie', '17.', '18.', '19.', '20', 'the UK'], ['you need', 'in two years. The S&P', 'widely expected to leave', '44.61 billion', 'sharply lower. Data released by the Japanese government showed the economy grew at', 'gun\" evidence allegedly shows major', \"AMF, France's markets regulator, told the BBC\", 'Lululemon expects to earn $0.96', \"copycat. China's highest\", 'Broadcom and Restoration', '10-year yield is up 3 basis points at 2.37'], ['Mizrahi a 28', 'attempt', 'handsome, charismatic and funny which, while admittedly', 'Insider', 'raging bag of dick tips you’d expect', 'laughing candid shot, and finally the dog owner', 'I quote', 'good thing, my sleeves always fall down and I don’t even'], ['some ideas, as do companies that have been trying to combat', 'Everyone', 'When employers', 'transparency raises wages, in part by lending', 'disclosing pay information is often required. Alexandre Mas', 'spurred', 'most', 'Benioff, the C', 'Not', 'much', '51', 'do not bargain lose as much as $750,000', 'difficult’ or ‘spoiled', 'compensation are aware of the disparity', 'Pao did', 'onus on the company to pay fairly instead of on candidates to negotiate fair', 'Don’t', 'that is already low, one', 'worth', 'Cobert, explained that the practice particularly', 'discrimination,\" Ms. Babcock', 'Easier for Mothers', 'few years later when women start having', 'Sometimes their pay lags because they take', 'that help keep', 'reapply for her job, that’s not', 'More Flexible Workplaces', 'many tech jobs and when people can easily substitute', 'it easier for different pharmacists to serve', 'the Law', 'most', 'must be paid the same for similar jobs, not', 'grants for negotiation training and make class'], ['he loads and unloads', ', and he had to walk to work and back', '-has been working since he was 14 to pay', 'was too', \"had a driving license, but couldn't afford\", '-workers clubbed together and bought one for', 'was presented the car, his colleague said he wanted Taylor to know everyone appreciated', 'the Mail:', 'overwhelmed', \"I'm not really\"], ['most lack', \"insanely talented salespeople, and they'll still\", 'Intelligent', 'must be prepared', 'intelligence comes in', 'multitude', 'contextual', 'intelligence is relatively new. Sales managers and executives', 'productivity.', 'most likely hired your reps on the basis of their sales acumen', 'potential ROI', 'intelligence is worth', 'key', 'confused than', 'intelligence is critical'], ['did not', 'of America’s top', 'IUD', 'tough little lady! A post', 'Tough little lady\" Abigail Ann Brown was born March 4, and Brown', 'in her parents’ basement apartment in Warrenton', 'quest to continue training for the Olympic Trials will never compare to the continuous quest', 'hashtag #Mommyintraining — \"double meaning intended', 'newmom #babygirl'], ['Hogwarts. J', 'interrogated and imprisoned for', 'in the Kings', 'hoof. It has not been re', '4/33', 'Krum', 'Death Eaters Dark Marks eventually faded to look like a', 'Quibbler is back to publishing articles about the lunatic fringe and is appreciated', 'did come to understand and appreciate', '. He never married, although he had a relationship with a giantess', '10/33', 'Hogwarts, the school for witchcraft and wizardry is led', 'Kingsley Shacklebolt became the Minister of Magic after the Second Wizarding War', 'to be', 'be concentrated elsewhere and hes not going', 'the war', 'Hogwarts to complete their seventh year. Harry, Ron and Neville', 'number of years, Neville', 'Hogwarts since an academic career', 'Weasleys Wizard Wheezes prior to officially becoming an auror', 'was over, Hermiones first act was to find her parents in Australia', 'Dementors as guardians. The number of Dementors has been greatly', 'Hermione tells Scrimgeour that she is not', 'Hermione', 'they are like badges of honor. Neville'], ['GIF', 'most common stress scenarios , but Gizmodo', 'most shocking revelations, uncovered after an exhaustive', 'Hydraulic', 'GIF', 'By removing the headphone jack', 'we certainly hope', 'Hammers', 'GIF', 'Sure, the average iPhone user probably', 'plenty of reasons to \"beware', 'Sponsored', 'Grinders', 'GIF', 'high shine \"may show fine micro-abrasions', 'high shine \"may show fine micro-abrasions', 'Men', 'GIF', 'Is the iPhone 7', 'half with a little help from his furniture? Nyet', 'Axes', 'GIF', 'Fire', 'GIF', 'headphone jack'], ['deceive you.', 'concerned someone', \"there is 'no\", 'all those claims', \"of agitation like fidgeting,' she\", 'liar can easily deliver', 'not', 'inventing the lie and the performance', 'do you ask that?’ rather than a direct and open response', 'we’re trying to hide something', 'often accessing recalled memory', 'in most', 'can often be', 'gesticulating too much in a bid', 'many assume less is more and almost', 'often suffer a strong desire to hide their face from their audience', 'are aimed', 'often use', 'skew', 'liars often struggle to keep', 'often', 'Whodunnit? and says', 'condone lying, this is the perfect', 'the transcript', 'Visualisation is the nearest you’ll get', 'shoulders, arms and hands. Keep', 'in your audience', 'you’re not', 'be better than over-sharing in terms of your body language giveaways', 'I the best lover', 'For more information visit www.whodunnit.org.uk'], ['in his', 'would never support him', '35) Roseanne', '’s up with that?\" Roseanne is just one', '\"Start', '34', 'was self', 'endorse him', '33', 'realness of an all American, outdoor-sy family with an importance', 'We both have wives', '32) Wayne', 'Well no one, anywhere, ever accused me of not', '31) Chris Christie – Former Opponent to Trump for this Republican', 'in an epic', 'Kiyosaki', 'endorse Donald', '29', 'several times saying, \"Donald', 'correctness is a public', 'Heisman Trophy Winner', 'we going to get back to what’s best for', 'Stallworth', 'Stallworth went in to bat for Trump at a black', 'Coulter – Conservative author and television personality', 'Coulter has been a huge', 'Ferrigno – Former', 'our country and keeping', '24) Mike', 's gotta', 'and former', 'he’d make a great president. Because he’s not a politician', '22) Fran Drescher – Actress and cancer', 'lot of things that other people don’t really have the guts', 'and celebrity apprentice', 'the country needs and Trump ... he’s a guy', '20', 'endorsing Trump concluding \"I am a huge Donald', 'Kirstie', 'in an interview', 'California Rep', 'endorse Trump, who he', 'Former', 'suited', 'Super', 'Super', 'laughingly replied, \"This is really important', 'Hogan – Former WWE professional', 'I want to be Trump', '14) Gene', 'ungentlemanly\" at times', 'Busey', 'I know him professionally. He’s a great guy', '12) Robert Davi', 'In an article published on Breitbart and authored', 'deceiver who feeds us sugarcoated poison at bedtime', 'former', 'great friend for many years. We don’t need', '10) Dana White – President of Ultimate', 'me say a negative thing about Donald', 'Bilzerian', 'the people who remain unfiltered @realDonaldTrump', 'Icahn – Billionaire entrepreneur', 'no-brainer. You can’t keep', 'Former', 'I shocked my staff today', '6) Mike', 'Hufington', 'and Western', 'I just think he’s the only one who’s going', 'Sheriff on the front lines of the illegal immigration war', 'He produces results and is ready to get tough in order', ') Wayne', 'would make a great president,\" Newton told host Steve', 'he stays in, he doesn’t have to worry about how his family', 'Treasure', 'dysfunctional. Now, Donald is not', '+ Bonus) Sarah', 'several minutes saying \"I’m proud to endorse Donald J', 'endorsements for Donald', 'Benghazi Survivors Mark \"Oz', 'more than any Americans, know the absolute and imperative', 'be avoided because our enemies will fear the United States', 'Voight – Hollywood', 'In an interview with Breitbart the actor known from roles in Mission', 'Kid', 'we should let', 'Carter –', 'wildly popular singer responded to a Trump', 'Radio Host', 'extraordinaire', 'Giudice', 'I am going', '-wife', 'to promote Donald', 'Kenny', 'I have to admit. He can be president and not owe', 'Martial Artist', 'Endorsing Trump. The actor blasted Hillary', 'Royalty', 'have a case', 'Sylvestor Stallone – Hollywood Royalty', 'Dickensian', 'Home', 'we started The Home', 'who can \"make America great again\" by cutting', 'Wayne', 'her', 'We need someone, like Mr. Trump, with leadership', 'NCAA Basketball Coach', 'Indiana during the primaries saying Trump is \"the most prepared man in history', 'The National Border Patrol Union', 'endorsing Trump', 'In it they wrote, \"Mr. Trump will take on special', 'Scot', 'common', 'Jeneane', 'endorse Donald', 'Rifleman', 'was seen as a testament to both Trumps 2nd amendment credentials and Hillary', 'much more pro', 'well that he was breaking ranks with the Bush family', 'David A. Clarke Jr', 'the black', 'Theil – Venture', 'staunch libertarian and founder of Paypal', 'Hannity – Radio host and Fox', 'I’ll be voting for Donald', 'Yiannopoulos', 'may have', 'flamboyantly calling him \"Daddy.\" Milo also loves', 'Molyneux', 'We will never solve', '–', 'snapping the two have amassed an army', 'Wright –', 'flock to youtube to get the truth, Wright is one', 'our friends'], ['SRK', \"Laila Main Laila' song, SRK\", \"Violence & Shutting Down Bigg Boss If They Don't Make Him Win\", 'violence', 'Five', 'good fortune that Maharashtra got a Chief Minister who has pledged to solve', 'Bengaluru', 'molesters, says the man in the shirt.#oxy', 'Bengaluru', 'when the situation will change and criminals will feel scared. It is important'], ['highlights The National Vietnam', 'less than', 'more than', 'less than 2 percent for actual veterans and veterans', 'one', 'some of them are family. So one can say, is', 'most recently filed tax return'], ['Mullin made a family', 'great-aunt', 'able to take on the responsibility', 'Mullin approached her husband multiple times about adopting the girls and bringing', 'could handle', 'when he met the girls last Christmas and witnessed their incredible', 'Mullin told the press', 'was officially approved last Wednesday. The congressman now has a beautiful family', 'Mullin said at a town', 'Daily'], ['in the world, ranked The', '30', '29', '28', '27', '26', '25', 'Hengshui', '23', 'Gobindgarh', 'Amritsar, India', '20', 'Handan', '18. Lucknow, India', ', India', 'Khanna, India', 'Kanpur', 'Shijiazhuang, China', 'Dammam', '12. Ludhiana, India', ', India', '10.', '9', 'Bamenda', '7', '6', '5', 'Riyadh', ', India', 'Gwalior, India', 'Zabol'], ['Raedle/Getty', 'long shot for the White', 'Bouie is', 'too', 'well-liked but not', 'aligned against him? The answer is easy: He wins', 'are aligned against him', 'millions of Democrats to switch teams, despite', 'especially for a candidate who says he', 'hard to imagine a disorganized campaign', 'We’re due', 'attuned to perceived outsiders—and immigrants in particular', 'unity is a prerequisite for national competition', 'well-known for'], ['not enough', 'as much as thirty', 'are worth', 'is not actually considered', 'in other', 'number of other studies have in the past', 'of the blood', 'there is a high'], ['to be', 'rising inequality, wild', 'who', 'WEF, Eurasia', 'turn for', 'enough', 'the world, according to Ian', \"there's not\", 'bound', 'World War', 'Angry voters', 'Widening gaps between rich', 'WEF said that while inequality between countries has been decreasing over the past 30', 'their own countries', \", and further undermine the region's precarious political balance\", '- opportunity or risk', '.S. position', \"the world's two biggest economies\", 'in order', 'longer mutual,\" wrote', 'he promised during the campaign', 'are vastly', 'disruption', 'embolden Moscow to \"act as a rogue', \"'t be\", 'too'], ['your friends', 'enough', 'not even', 'do you tell your sweet friends? Your nice and good friends', 'good ideas', 'are practicing for', ', the really big one', 'every Kanye', 'be responsible', 'have decided to wash your hair every', \"it's just something\", 'cannot go out tonight because it is not', 'not', 'do not want to miss', 'present', 'you must watch the show your coworkers', 'good', 'you had chicken', \"can't\", \"aren't going\", 'The situation', 'You cannot go out tonight', 'Kale', '10', 'seeping from'], ['Holley received a $', 'Holley gave back his awarded bonus because company shareholders had not', 'Holley remains', 'not'], ['Watani', 'AXVCD458Ji', 'if she would ever get to attend the Oscars but life certainly', 'would have given', 'hijab.', 'with a moving caption', 'Watani', 'in', 'had the privilege', 'my collection is always', 'and truly amazing @sweetbabyjamie', 'who truly deserves'], ['been served', 'inflicting', 'was too', 'ten other inmates watched, the two women went to working beating Smith, using', 'they don’t feel bad for the murderer and she deserved', 'lot of talk about attacking Smith, but most', 'weapon used in the attack, they admit that the attackers will receive disciplinary', 'commenters on the story agreed that Smith got what she deserved', 'them for giving her a taste of her medicine. They should be rewarded', 'others added the following', 'hope', 'would', 'Everyone seemed to agree that this was definitely karma', 'them WELCOMING GALS a nice spa day. For JUSTICE BEING SERVED', 'in for life? She deserves', 'sympathy'], ['lifelike statue of a nearly nude man will remain', 'hard to miss', 'must do', 'wellesley', 'your daughters here. pic.twitter.com/eRf1uJCxKA', 'rondeau', 'O3qLxPCqew — Polina Soshnin', 'Nearly 1,000 people at', 'frequently called creepy, and triggering for', 'Mahmood, a HuffPost campus editor-at-large, explained', 'priority should be', 'there. But who am I to say'], ['cut', 'they never said it would be like this.', 'angry about the dishes that never get put in the dishwasher', 'you’re dealing', 'freaking hard either', 'You see cute couples at the park on the weekend, pushing their toddlers', 'Well, I', 'no one tells you: Marriage is fucking', 'they don’t tell you? It’s OK that marriage', 'crock-of-shit advice', 'There will be fights', 'you don’t even', 'There will be', 'blissfully as you get up in the middle of the night—again!—', 'There will be', 'chauffeuring', 'there will be hard times', 'not', 'something', 'in the middle of the afternoon. And marriage is not', 'difficult times now and then. Because when you share your freaking life with someone', 'on the same team. You will fight', 'on your side who will hold'], ['enough to have paid time off are foregoing', 'Some 52', 'workaholism\" to blame', 'were saving', 'a third of respondents said that they plan on taking', 'many U.S. workers feel bound', \"quarter of workers say they simply work too much and can't afford\", \"doesn't necessarily\", 'of which have a direct impact on their work performance,\" says Sarah', 'stress in your off hours, consider taking up a hobby. Warren'], ['more and more homeowners are trading', 'hefty price). And while having one of these spaces could hinder'], ['often mean cutting', 'Quidco can help you save thousands of pounds a year without sacrificing', 'Others are as straightforward as asking big brands for a better deal', 'of us want to be able to count our savings in pounds rather than pennies', 'can quickly add up', 'FEMAIL', 'OF SEASON', 'seasonally can help you save', 'be down to £50', 'clearance sale prices can leave', 'STOCKPILE', 'If you see a good deal on something', 'your discounted', \"tins when they're available at half price could put £52\", 'non-perishable food goods, but', 'FOR DISCOUNTS', 'would be surprised how often you can get a discount', 'electricals outlets, where flexible discounting', 'could help you save hundreds', 'refunding', 'AFRAID TO PRAISE', 'when the people who enjoy', 'goodies or vouchers', 'A CASHBACK DEAL', 'commonly get 5', 'A SAVINGS ACCOUNT', 'priorities for many of us because the returns'], ['McClain', \"series of changes to the state's tax code\", '- and especially not', 'are but a small sample. But the divergent experiences of California and Kansas', 'was near the top', 'as Nebraska', 'had the ultimate plan', 'were meant', 'Moody’s Investors Service have signaled that they could reduce Kansas’s credit', 'shortfalls have forced Gov. Sam Brownback (R', 'modestly increased taxes for', '20 percent of households -- those making less than $23,000', 'at least $', 'as much as the bottom 90', 'still', 'Chinn said', 'high', 'still beats', 'derail California’s economic comeback', 'Few, if any, economists would say today that the recovery has been sufficient'], ['You and 3.2M others', 'You and 3.2M others', 'I watch something', 'on vacation, it’s the one thing I miss', 'all', 'how much', 'few super quick hacks', 'high-quality option is checked (obviously', 'for', 'could be causing your streaming issues? No, I’m not', 'if you’re streaming on Firefox', 'you use Internet Explorer (yes, really), Safari or Microsoft', 'Give yourself the streaming quality you deserve', 'there’s', 'You can also use a little trick to avoid having to wait for something', 'evasive Stream Manager menu. The options on this menu', 'down Ctrl+Shift+Alt or Opt', 'for'], ['Feig has been revealing quite', 'Feig replied', 'Feig wrote', 'Feig (@paulfeig', 'Wiig is Erin', 'Aykroyd), Egon', 'York City, Michael K', 'Feig can pull', 'Ghostbusters'], ['Unpacked', 'rectangular black headset, and you can traverse', \"many believe it's still\", 'cofounder and former CEO, to discuss', 'will get', 'wield an imaginary paintbrush', 'in your hand still', \"you're a quarterback\", 'far back as 1962 with the Sensorama', \"Well that's just\", 'Azor described will ever', 'effort', 'Rift will likely be remembered', 'Azor draws', 'no one company can solve', 't', 'Rift and the Vive. The former plug into your smartphone to deliver', 'high-performance device like the Rift go wireless anytime soon, mostly because', 'will be wired for a fair'], ['25, The Weinstein Co', '-South African president', \"couldn't\", 'Weinstein. \"Partnering with them ensures the picture will continue to honor', 'maven', 'good joke', 'He will always be my hero'], ['development of the 787', 'much of the plane out of carbon-fiber reinforced plastics and other composite', \"engineering of the composite airframe may have been a challenge, it's\", 'fatigue,\" Blake', 'most', 'Emery added. \"It\\'s a bit counterintuitive', 'pressure matter', 'appetite', 'afflictions', 'far', 'attributed', 'Oklahoma State', 'discomfort characterized by symptoms similar to those of acute', 'annouced', \"in their blood fall 4%. Although this didn't\", 'reacted at 6,000 feet similar to that at sea level,\" Emery', 'saturation. As result, the body does not', \"there isn't\", \"haven't\", 't be the only', 'landmark 777', 'Craver, Boeing Commercial Airplanes regional', 'altitude on its next', 'fatigue and shortens the service', 'altitude on the 777X without going to a composite', 'few local reinforcements and change those loads', 'set to enter service'], ['-day festival filled', 'crucifixion: Philippines', 'at least three devotees to wooden crosses in front', 'New Zealand', 'many bunnies as possible. The record currently', 'Corfu', 'was adopted by the islanders and applied to the most important', 'Inter-church rocket war', 'hundreds of homemade rockets at the opposition', 'Hill burning: Texas', 'Easter Fires Pageant', 'Sprinting Virgin Mary', 'Neri', 'omelette: France', 'Haux, Gironde', 'Monday', 'unsuspecting young woman when she answers her front', 'Sweden', 'Maundy Thursday, Swedish children don face paint and grab broomsticks'], ['several', 'of the project', 'was only 57', 'looked for a new endeavor', 'all that tax money should create a sufficient', 'are things government doesn’t get to, and B', 'Ballmer replied', 'long vexed', 'nonpartisan effort to create a fully integrated look at revenue and spending across', 'many police officers are employed in various', '10-K', '10-K', 'lot of bets made during public policy debates at the dinner', 'would like', 'does one', 'must have already done', 'there’s nothing I’m missing', 'neither', 'don’t care whether I give my money to A, B or C', 'more than $', 'happy', 'been worth', 'I love', 'many people work for government in the United States', 'bloated and filled', 'Well, active-duty', 'glad', 'somehow', 'other', 'Most of the not-for-profits we work with would be 50', 'be completely apolitical. He has given', 'mortgage', 'hundred bucks', 'was to use', 'many firearms that are in this country? The government is not allowed', 'I’m shocked! But the N', 'hopes to open it up so', 'more than'], ['your usual post', '-smelling essential', 'your favourite essential', 'the perfect ambience', 'are always', 'be', 'on your laptop or phone, do it all away from the bed. Condition', 'to something', 'not', '5', 'that would make you happy', '6', 'isn’t super', 'Most', 'to keep'], ['inconveniently sentient Kleenex', 'bulges her neck. He recalls taking', 'squalid.', 'frequents. He finally manages', 'was unfaithful', 'high school English teacher spends', 'squicky, selfish, and sociopathic inner selves of even', 'squalor, but', 'The Bottom Line:', 'but self', 'other reviewers', 'York Times', 'Homesick for Another World that’s anything less than', 'Who wrote it', 'notoriously confessed to The Guardian that she’d written the book as a joke', 'will read', ', provocative fiction starring intensely disagreeable characters ―', 'lines:', 'was old and', 'Notable', 'thighs appeared, I saw a black stain of blood at her crotch.', 'Oh, shit,’ she said when she', 'Moshfegh Penguin Press, $26.00', 'weekly review combining'], ['you probably think Millennials', 'nearly three-quarters of Millennials', 'nearly as important', 'are five crucial moves Millennials', 'education', 'At least', 'plenty', 'hello to risk', 'always comes through in a pinch. There might be', 'that require you to take', '100% bonds returned roughly half that, averaging 5', 'as much as 70', 'Take', 'reasonable stock allocation for your retirement portfolio', 'many different investments in one swoop. You can buy', 'You can learn more about building a diversified portfolio', '4', 'in your 401', 'more than 0.25%, you can likely', '5. Use a Roth IRA or a Roth 401', 'Contributions to a traditional 401', 'is lower now than'], ['some as a means to provide', 'less job security,\" says Matthew Krisiloff', 'you should know about UBI', 'What is', 'most', 'everyone gets a check from the government', 'is', 'redistribute wealth to', 'sporadic support on both sides of the aisle, UBI has historically remained', 'persistently', 'anyone getting', 'No nation has implemented a universal basic income, but', 'Combinator’s Krisiloff'], ['DLC', 'well for big developers like CD', '053 reviews on Steam, of which 90 percent are positive. is a', 'developers decided its major DLC', 'which included 70 new events, a new main quest', 'were usually selling without the DLC', 'Sponsored', 'was disheartening', 'their friends,\" the developers wrote,', 'For', 'more tactical', 'we still think combining the two was the jackpot', 'well, not really DLC at all', 'to be', 'lot of emphasis'], [\"of the most consistent criticisms of Mad Men from those who aren't\", \"Idov argued that it wasn't\", 'few times — a much more perilous', 'there are a bunch', ') Readers', 'well-timed thinkpiece always', 'overlaps so neatly with the audience', \"far beyond any other show I've written about here\", 'was also driven by the fact that our readers', 'Mad Men debuted right after The Sopranos ended and filled', 'few weeks before. The Wire (never as popular in terms of raw', 'benefitted from the rise of TV recapping in general', 'surely as it filled', 'fit', \"wasn't\", 'Mad Men and later Breaking Bad picked up', 'in-depth reviews of comedies (a later development, largely driven by content', 'Mad Men suggested every cable channel should have', 'much', 'was actually pretty popular, when all was said', 'enough to drive', 'underestimate', 'very few casual Mad Men fans. And those passionate fans tend to seek', 'Mad Men as a sort', 'might have been a bit much', 'do too', 'even'], ['to getting information on eating to manage', 'that tested the impact of specific', 'in plants) and olive', 'cholesterol (called LDL', 'Over', '. Eat', 'kidney beans, chick', 'fewer than one in five Australians', 'randomised control trials (the gold', 'was reduced by 5', 'about', 'They lower blood cholesterol in a number', 'cholesterol absorption in the gut, while they promote', \"they're part of a meal\", 'sterols, margarines', 'are found in some', 'They are concentrated', 'prawns, and cholesterol', 'the total', '10 percent reduction in LDL', 'are mixed with is important', 'were added to margarines', '. Eat', 'the amounts of polyunsaturated, monounsaturated', '25 intervention trials, eating approximately 67g', 'the more', 'were not', '1600kJ', '4. Use', 'a high proportion of monounsaturated', 'More than 80', 'oxidised LDL (a type of LDL', ',400 men and women at high risk of heart disease to follow three diets', '-up, those in both the olive oil and nut groups had a 30', 'randomised to substitute 4', 'cholesterol and LDL', 'had high blood cholesterol to start with. Switching', '5', 'were able to make a number', 'a wider', 'They lowered their cholesterol', 'in diet quality', '-up almost', 'had the biggest improvement in their diet quality score had a 7', 'your GP'], [\"I don't watch the news, because it's too\", 'might just need', \"our pick of the year's most heartening stories — get ready\", 'Gallego is not', 'Gallego has performed at', 'six', 'had already decided they would spend', 'on the ground after the east', 'when the iconic little Australian was rescued — and named after rescuer Louise', 'there was anything they could learn', 'in a remote part of the state', \"that one day it gets to a point where it's not\", \"Queensland locals started Australia's first integrated, edible streetscape in a bid\", 'lined street is now an 11-street suburban enclave', 'flamboyant garments may not', 'when she was in her 40s', 'it comes to clothes, her motto', 'may not', ', and he captured', \"'s first free mobile laundry for the homeless launched their second charitable venture\", 'Marchesi and Lucas Patchett', 'was trialled', 'bloody'], ['have been discovered which may cause owners', 'Great Features’ and ‘Nasty Surprises’ are my', 'Nasty Surprise', 'durability tests and claims Apple has ditched', 'JerryRigEverything', 'sure that it is regular glass and not', 'toughened glass) on the home button and camera lens. Given', 'not tested the iPhone 7 Plus we cannot make assumptions here. Being', 'Nasty Surprise #', 'Myke', 'not react should you be wearing standard gloves since', 'right, you get nothing. Hardly', 'capacitive touchscreens respond (note', \"AssistiveTouch, though that's primarily used\", 'Designed', 'of which leaves', 'iFixit', 'utilise the additional space the headphone jack used. Personally a far', '10x', 'were increased compared to the iPhone 6S', 'most notably in the iPhone 7 Plus', '_', 'More On Forbes', 'Great Secret', '10', 'Great Secret', '7 Plus', '7 Vs iPhone 6S'], ['the summer of 1996 after my sophomore', 'had no idea what to expect. I asked my father and a professor', 'on who', 'looking to connect with someone', 'your network of contacts, remember', 'snail mail holiday cards to former bosses', 'In a new situation', 'hierarchies', 'for', 'notch with tailored suits', 'willing to learn from any task', 'were paid for the privilege of watching and learning as the higher-ups', 'not', 'my managers were aware of how my contributions', 'bad attitude will break your reputation', 'frowned upon, and despite claims of a kinder, gentler 21st', 'Take', 'will be responsible for 100', 'you want to keep a secret', 'would share it with someone', 'respectful of others', 'politely for networking conversations and check-in meetings with our bosses'], ['most spectacular', 'we missed', 'of Modern Art', 'glassy Yoshio', 'moma', 'Metropolitan', 'you don’t narrow your focus. Don’t miss', 'metmuseum', 'Guggenheim', 'in a constantly evolving collection of impressionist, post', 'York expert', '4. The Whitney', 'range', 'whitney', '5', 'artefacts and French neoclassical and Romantic painting. The secret', 'louvre.fr', '20 greatest', 'Marmottan', 'one', 'marmottan', 'Koons', '7. Musée', 'unrivalled', 'rodin', 'Edwards, Telegraph', '8', 'there’s plenty to enjoy along the way, from classical', 'va', 'Galleria', 'worthwhile', 'galleriaborghese', 'Lee Marshall', 'free things to do', '10', 'on the edge of Holland', 'designmuseum', '11. Sir', 'interlocking rooms on different levels crammed', 'hoarding mentality of a pack', 'Dorment', '12. The Victoria & Albert Museum', 'courtyard entrance and underground gallery forming part of the Exhibition Road Building Project', 'Courtyard will be through the arches of the 19th-century screen designed by Sir', '10pm (Saturday as well at Tate', 'Secret', '13. Prado', 'Titian and Tintoretto', 'museodelprado', 'Prado', 'late 2010, with new displays on the fourth floor. Picasso’s masterpiece', 'museoreinasofia', 'Superlative collections of Western', 'museothyssen', '’s Madrid expert', 'many more are on show alongside centuries’ worth', 'rijksmuseum', \"a complete visitor's guide to the Rijksmuseum\", 'Rijksmuseum', 'usually inspired', 'vangoghmuseum', 'Rodney', 'van Gogh', 'Meier, is worth', 'macba', 'most of his', 'museupicasso', 'Davies', 'coffee to cubism - a guided tour', 'enough', 'hermitagemuseum', 'Bennetts, Telegraph', 'favourites: The Hermitage', 'Magi, Botticelli’s Primavera', 'firenzemusei', 'Uffizi', 'well worth', '-medici.it', 'Florence', 'difficult-to-please', 'unifi', 'Lee Marshall', 'are now in the British', 'theacropolismuseum', 'hoard', 'benaki.gr', 'Foster, Telegraph', 'Manneken Pis – the statue of the little boy', 'brusselsmuseums.be', 'collection is a showcase for the brilliance of Belgian art. It begins', 'Magritte, to whom a whole', '-arts-museum.be', 'headphones bring the musical instruments alive; and the view over', 'mim.fgov.be', '.twitter.com/tCWj2SZOb7', 'hoard of international antiquities – by far the largest of a collection of heritage', '50th anniversary of Belgian nationhood. The surrounding Parc', 'kmkg-mrah.be', 'Mason, Brussels expert', 'heritage', '’s Berlin expert', 'recreation of a First century Roman villa built by oil tycoon J', 'Lucie Young, Telegraph Travel’s LA expert', 'Hadid-designed futuristic structure, featuring a curvaceous', 'kr', 'deCaires', 'cactlanzarote', 'one', 'relationships past, exploring the \"love, pain, drama, irony, humour', 'Zagrebs Museum', 'brokenships', 'structure. While it hosts', 'Menenti #FutureWorldpic.twitter.com/YDdYSS0Slg', 'marinabaysands', 'Sweden across the Sound, Louisiana Museum of Modern Art is one', 'cannot be missed', 'en', 'heritage', 'shanghaimuseum', \"Ceallaigh, Telegraph Travel's Luxury Travel editor\", 'Larsson', 'bildmuseet', 'largely built to complement', 'benesse-artsite.jp', \"Ceallaigh, Telegraph Travel's Luxury Travel editor\", 'grave markers to Taino spatulas, the latter used to induce', 'precolombino.cl'], ['Being Considered For GTA', 'there is one thing that remains', 'may be the next location for the epic that GTA 6 will surely be', 'been a lot', 'might be going in its sixth installment', 'Tokyo', 'in with a', 'would still', 'Chicago', 'bullets and this would make a fitting context', 'the U.S itself as GTA has also been a great', 'London:', 'most', 'lot more controversies that are common with the U.K', 'you think the next GTA should be'], ['-that). He turned me on to white', 'rakes in $800 milly a', 'A SINGLE TABLESPOON HAS MORE SUGAR THAN A CHOCOLATE', 'Provided', 'had enough', 'OVERPOWERS', 'Provided', 'when you wipe it off with a paper', 'GLOPPY', 'squirts out of that squeeze', '4', 'Provided', \"I don't have\", 'CAN NEVER', 'you can imagine the disappointment and utter', 'ARE TOO', 'hash browns, grilled cheese, chicken nuggets all disappoint', \"'T\", \", I'm not\", 'to Make Homemade Ketchup'], ['least one story about a crazy uncle leaving some pretty amazing, unexpected items', 'upon Tyne in the United Kingdom', 'hoarder, so the siblings', 'Wikimedia', 'family knew he kept', 'was worth', 'thousands of receipts and even a World War', 'auction for more than £3 million, or just over 4.3 million USD', 'MailOnline', 'were ever made and at least four of those are thought to belong', 'had some', \"for sure. It's worth\", \"delighted and we're going to make sure the money is shared\", 'eccentric old gent', 'Bonhams via MailOnline', 'hoarded everything in the house he refused to leave', 'I am today,\" the nephew said. He also added that his uncle'], ['bragging', 'five extraordinary trips for', '1', 'wondrous sights. Photo credit', 'dunes, salt lakes, towering peaks, glaciers, geysers', 'gargantuan', 'splendor, a sight guaranteed', 'Chileans are friendly and hosts', 'Where to stay', 'Premium Christmas', 'Sonderegger', 'hard to beat. Think spellbinding', 'filled', 'free, leaving', 'Dolder Grand (Zurich); Le', \"in Santa's home: Finland\", 'Lights, Finland. Photo credit', 'Finnair, has been recently courting Asian', 'reindeer farms, hunts for the Northern Lights with a guide', 'worth', 'available to Asian', '-at', 'Zouk', 'eschew your boarding pass', 'Penfolds flagship', '5', 'Randheli. Photo credit', 'the second half of December to April, making it another destination', 'extensive facilities to suit'], ['hyped by nearly 300 exhibitors at the Electronic Entertainment', 'allure of the annual Electronic Entertainment Expo remains blockbuster', 'There are 2,000 products that are going to be shown to consumers', '20,000 fans to show up for game demonstrations and other revelry', 'E3 prospects', '__', 'WIND', 'They include the stealth adventure \"Dishonored', '__', 'NEW REALITY', 'many of the 50,000 attendees expected at E3. Gallagher', '__', 'FRESH', '12, 2016. (AP', 'Dishonored', '__', 'LOCATION', 'Dogs 2\" is swapping', '__', 'GENERATION', 'E3 press conferences and on the show floor—but probably', 'E3', 'e3expo'], ['When You Give $1', 'Oshien from Siaya, Kenya — A person who received just under', 'GiveDirectly in November 2015, an org that gives $', 'GiveDirectly, and the concept of transferring cash is met', 'defrauding', 'squander', 'It probably doesn’t', 'angst about the \"Savior Barbie\" complex, where western', 'more', 'frequent barrage of opposing views, but always', 'GiveDirectly’s Country Headquarters in Kisumu', 'were really', 'still', 'GiveDirectly after having their own first real exposure to abject', 'GiveDirectly’s work (for poverty-action.org', 'most competitive', 'some rich country on a self-serving mission', 'nepotism, and absolutely', 'randomized controlled trials (RCTs) — the holy grail', 'GD gives isn’t', 'GiveDirectly', 'installments', 'were fixing the following core', 'Orimba and his family', 'Thatched roof — which leaks', 'i', 'frequent illness / sometimes chronic', 'frequently school', 'iv', '10x12 one', 'c', 'burrow', 'thousands of kids to miss out on school from 5', 'GiveDirectly', 'few month’s worth', 'GiveDirectly that sit in the recipients doorway / living', 'chronic illness (Cancer, HIV, etc', 'others', 'GD’s rigorous measurement and auditing', 'consistent with a publication from World Bank', 'most, and 97% of that cash transfer served', 'overpopulation, lack of education'], ['. 18 is National Cheeseburger', 'Tuscan', 'piled high with lettuce and tomato or slathered', 'Some 57', 'snag free, discounted', 'coupon', 'coupon', 'BurgerFi sauce', 'SHAK) burgers aboard select flights from JFK', 'burgers aboard select flights from JFK', 'been posting'], ['former union boss has a bold idea on how to ensure', 'Universal Basic Income (UBI) is not necessarily', 'recent interview with CNBC\\'s \" Power', 'threshold was $12,331 a year for an individual under 65', 'Provided', 'misperceived\" by a range', 'Stern, who is a senior', 'were at risk of being', 'we would be crazy to not', 'was also rejected', 'undeterred, and has an answer', 'he suggests Social Security should remain', 'all of them but certainly a lot', 'Kerima Greene contributed'], ['fortuitous', 'hypothermic when she was found on the morning of April 1 in Garibaldi', 'Squamish Search and Rescue manager John', 'was only discovered because her backpack', 'were able to start performing CPR right away, Howe told Pique', 'Squamish Search and Rescue and an ER doctor who', 'Vancouver General Hospital, which has a special', 'Willcox', 'in stable condition in hospital and is expected', 'skeleton athlete who is studying interactive arts and technology and business entrepreneurship at Simon', 'skeleton athlete, received four continuous'], ['no wonder hotel staff have some choice', 'some very unpleasant behaviour', 'discarded under beds and women flashing the porter instead of giving', 'numerous parents forgetting to collect', 'too much', 'others insist on answer', 'had drunk from the mini bar and then refilled', 'to get a discount'], [\"Let's be\", 'were standing in your room crying to Joni', 'was in good news.', 'was at 7', 'netted four golds and a bronze — that cemented her legacy', 'hard not', 'Jayapal', 'Tribe Called Quest', 'most', 'worth', 'poaching'], ['recent New York Times', \"Hogwarts, but he certainly hasn't forgotten, nor dismissed\", \"It's not easy to redefine\", 'rather than', 'want to have loads', 'was basically, \"Here\\'s Daniel Radcliffe\\'s first post', 'was a really good movie. I may not', \"'re playing a guy\", 'very often achieved in film and the fact we achieved it is a testament', 'had never watched \"', '.', 'Well, except', 'not tell anyone', 'to catch up before \"Episode', 'at least one guy, Digby Milner', 's come full', 'they do at', \"that's really not\", 'buried treasure', 'was told not', 'had a great fucking', 'a bad', 'a lot', \"when we're introduced to Jack\", 'Krokidas', 'you heard J', 'be foolish enough', \"She doesn't need\", 'She definitely', 'Ryan is senior writer for Huffington'], ['well to arm themselves with the intellectual firepower', 'seven conservative classics that should be', 'Have Consequences by Richard', 'corrosive influences of moral', 'Serfdom by F.A. Hayek', 'well to read Friedrich Hayek’s 1944 classic', 'The', 'rioters sparked violence at UC', '4. A Choice Not an Echo by Phyllis Schlafly', 'willing to fight for a voice within the Republican Party’s establishment leadership', '5', 'deserves', 'Conflict', 'Hobbes to Adam Smith to illustrate the intellectual impulses that drive', '7. Gulag', 'ability to combine lyrical prose with piercing reportage of communism’s moral'], ['Thanksgiving dinner', 'many as 35', 'that is guaranteed', 'Specific', 'there’s a lack of direct evidence about specific', 'range', 'there are indications that certain', 'they can play a major', 'Kiwi', 'There are both green and gold varieties, but green kiwis', 'most notably vitamins C and E as well as potassium', 'who ate two kiwis', 'for sure why kiwis', 'Tart Cherry Juice', 'Montmorency, and English', 'who drank two one-cup servings of tart cherry juice', 'to have above', 'Malted Milk and Nighttime Milk', 'Horlick', 'may have to do with the B and D', 'be useful in providing', 'Fatty', 'who ate salmon three times per week had better overall', 'consumption during winter months when vitamin', 'Nuts', 'cashews are often considered to be a good food for sleep. Though', 'Rice', 'had mixed results overall, but some evidence connects rice', 'glycemic index around four hours before bedtime', 'been tied to worse sleep, so it appears that not', 'by what is consumed'], ['an', 'wanted', 'would never do', 'after someone called 911 to get', 'They need', 'much', 'WDJT. \"I do, and I hate', 'Narcan, also known as naloxone, a prescription medicine that', 'She almost killed herself,\" said', '58', 'difficult to watch, Henry says the video forces', 'could live two different lives and you can’t', 'motivate', 'fellow addicts. \"You don’t have', 'inpatient rehabilitation center to help follow'], ['they are pregnant, it might feel natural to touch their bump or comment', 'hormonal roller coaster', 'Midwife & fertility guru Zita', \"'t\", \"Invading people's personal space is not\", 'you really want to, you can politely', 'her', 't', 'might not seem like a big deal', 'our child John or Jane', \"going to name her child, and you can't resist\", \"stressful for mothers to be. It's easier to not\", 'to perfectly fit', \"'t\", 'they are pregnant, their friends', \"Whether or not you've seen her maternal side doesn't mean\", 'or not you think she fits into the classic', \"'t\", \"be really exciting, don't comment\", 'Many of the most', \"she's looking a large she doesn't need\", 'not big enough', 'are you gaining enough', \"you're paying a mama-to-be a compliment\", 'congratulate', \"they're pregnant, they have chosen\", 'congratulate them on social media because', \"'t\", 'in a way a medical condition, pregnancy is not', 'they want is to be treated', 'their limits and how much', 'That said, pregnancy can make women tired so do offer', '8', \"Whenever anyone's having a baby, others love\", 'in your body is not', 'most women get through it, and usually, once the baby arrives, memories', 'is genuinely', 'be', 'Their lives are about', 'they might not', 'some longer than others to take to motherhood, but that is understandable', 'no wonder', 'their new role admirably'], ['and deeply', 'quagmire', 'be quite', 'Headphones', 'the same time', 'that doesn’t mean', 'being approached because', 'almost always', 'have missed', 'those blessed with an abundance of ego. It’s a defence', 'back to Dan', 'What to Do', 'in front', 'Have', 'hasn’t', 'to be taking', 'most', 'most', 'you understand that approaching a woman in this way isn’t', 'that you are a cool guy', 'excited\" and I’m not', 'any further action I take to extract myself from a situation', 'bullied me into one of the most', 'has used', 'I know it’s not', 'flattered by the compliment', 'some humor', 'Most likely laughing, smiling and enjoying', 'have something', 'hunched shoulders, darting eyes and rictus', 'I’ve been it, seen it and spoken', 'to be talked to but', 'me', '****, I DIDN’T FANCY YOU ANYWAY', 'any surprise', 'a woman who is wearing headphones. Sadly not one', 'inoffensive, generic dating guff', '2. Allowing', 'are a great', 'being determined to get', ', a woman usually won’t give', 'will he remain', 'is mentally and emotionally strong enough', 'most women will be turned off by his mental and emotional', 'to take', 'is more confident than her. A woman doesn’t want', 'being too assertive', 'million rape defence', 'jaw-drop factor:', 'be hunted and won', 'frustrated man-babies how to handle rejection with grace, because', 'whiny pissbabies ask, when am I allowed to approach', 'a good evening and toddle', 'you’re looking for a horde', 'soon from'], ['hundreds', 'some games capture', '5', 'butt when the situation', 'to be the first installment', 'we might see it: Ubisoft maintains that this game is in development', '4. Kingdom', 'you happen to fit into the target', 'some would say — filler. Never fear. A third installment', 'we might see it: Hopefully by 2017.', '. Final Fantasy XV', 'that’s currently called Final Fantasy XV began under the title Final Fantasy XIII', 'somewhat hard times. The 13th installment', 'a Big Important Game for the series’ 15th installment', 'we might see it: November 29', 'The Last Guardian', 'they’re both singular', 'a fresh look at the game at E3', 'we might see it: Sometime in 2016... hopefully', '1', 'no stretch to say that the original Half-Life was probably', 'that the last installment', 'in development'], ['+ READ', 'did give Entertainment', 'we know so far.', 'your friends the correct walkie talkies to discuss the finer points of Steve', 'Ryder', 'didn’t endure', 'Terminator 2. I guess a lot of this is James', 'Stranger', 'infested Hawkins won’t', 'curiosity door locked. They assure us the show will answer', 'any longer, it gets unwieldy'], ['in his hand. Sitting on a leather couch in Park', 'his', '10 years to make this happen,', 'spoilers throughout', 'did you originally come across', 'to actually make a', 'had written a shitty screenplay', 'had put all that time into it', 'going to write it anyway', 'much', 'few hours and crank it around a little bit and I wouldn’t', 'have', 're like I gotta get out of here', 'live in L', 'have a place I go surfing in Long', 'Isn’t', 'all', 'What made you want to make this', 'whether that makes me', 'would ever get without paying for it. So even though', 'disappointment she feels. He’s not', 'Did you consider acting in the', 'were like, \"good idea.\" [', 've directed a', 'on one side of the', 'stratosphere, but', 'Was Here', 'there are all kinds of reasons –', 'Did you just ask Christina Hendricks at', 'Shelburne. He called and said, \"I love', 'hope to get Phil. She was thrilled. I sent it to Richard Jenkins', 'are below in the street looking up at', 'condoned this guy being', 'that making this', 'well. I can’t play everything. I’m not', 'are sophisticated degrees of performing. There’s actor A, B, C', 'That’s also a testament', 'I should be so'], ['Gailey serves', 'She tweeted her story, which should be', 'Gather round, Twitter, and I', \"I shouldn't have dated him. You know the type. Just\", 'One', 'were at a family', 'Did', 'fiddle with it. \"Put that down, you don\\'t', 'do you imagine he did', 'in his hand to eye level, looked right at me', 'was trying', 'have probably', 'the uninitiated, is', 'gnarled-up feet.', 'lot', 'frequently, it can get *pretty much packed', 'level, looked at', 'shavings ERUPTED from within the Ped Egg like an explosion of flesh confetti', 'whisk', 'peeing myself and the only word I managed', 'in your mouth. And nose. And eyes. ~fin~', 'it.', 'BUNION DUST GOOD PEOPLE WILL BE REWARDED', 'that somehow, bonus footage of this wonderful moment is included', 'yZnaWrHI1o', \"that's not\", 'petty', 'scrolling for next'], ['Good-Bye: Famed Carnegie', 'had been hard at work in 2016 crafting new laws to take', 'pitchforks or spears. Spearfishing has always', 'do not like', 'normally only from a distributor. For wines and spirits, Pennsylvanians'], ['are formed on the lower back of women. However, some men', 'They are located in a', 'good', 'them with exercises. However, eliminating', 'them for the looks but to be', 'http', 'spinalmedical.co.uk/back_pain_causes.php'], ['you know, in case', 'pointing any fingers here', 'Davidowitz', 'your goals. So we decided', 'that promise', 'They... probably won\\'t work. \"You can only maximize', 'There’s no actual', '\"Here’s the thing,\" says Fisch', 'would be less,\" says Fisch', 'where to start, check', 'your pubic hair', 'extender you can buy', 'at maximum capacity', 'you can’t get it bigger than', 'they’re not', 'there are some pills you can take', 'most common. While they won’t necessarily', 'your vascular health or l', 's worth', 'you really shouldn’t worry so much about your size anyway', 'fall within an inch of that, says Fisch', 'possibly be unrelated entirely', 's have an honest conversation', '100', 'OK', \"tweaks to have the biggest and hardest penis that's physically possible for\"], ['Woolley', 'those tempted to play the game while driving, it’s proven extremely', 'http://kotaku.com/pokemon', 'there are some things that can be done to mitigate', 'Don’t', 'me say', 'there’s at least', 'Sponsored', 'Poliwag in sight. Park somewhere where you’ll stay', 'you’re then focusing', 'happy Pokémon', 'going', 'if you have', 'my next move', 'Scope Out Your Next Pokéstop', 'You can tap on further away gyms and Pokéstops', 'sure to follow', 'Silent And Hidden', 'anyone', 'well-suited', 'http://kotaku.com/pokemon', 'hidden while charging, as illustrated in a Porsche 918', 'you really have no self', 'don’t want', 'many landmarks you’ll find as Pokéstops', '4: Get Out And Walk Around Anyway', 'always', 'was one step ahead of that idea. After my roughly 48-kilometer drive', '20 kph', 'puttering around at speeds slower than 20 kph', 'worth', 'you’re playing around cars, make sure they’re going', 'you to do: get', 'my car anyway', 'silent phone on a charger'], ['most cherished moments, exemplifying', \"wouldn't\", 'THE', 'most sporting events, no piece of music is so deeply associated with a specific', 'MYSTERIOUS ORIGINS', 'dates back to the days of President William Howard', 'inventing \"the stretch\" (albeit', 'in April of 1910. (Photo by Mark Rucker', 'CAMARADERIE', 'you prefer, the seventh inning stretch remains', 'appreciated', 'tie to our history.\" (AP', 'TRADITION', 'tie to our history,\" Tony', 'THE', 'division into turn-based innings rather', 'York Yankees outfielder and future', 'may be', 'Relive The Longest Game In Baseball History', 'schultz@huffingtonpost'], ['’t quite', 'often in the strangest', 'many', 'family – and they’re trying to teach', 'family', 'unending stare can be', 'most creatures, cats don’t like', 'they carry it, the more content', 'their kittens', 'butting, cats', 'your cat', '10', 'high'], ['mogul Kathy Ireland. (Photo courtesy of Kathy', 'you have a net worth', 'Most interesting to us here at Women@Forbes', 'we decided to take a look at how the other half   actually, the top', 'In The Forbes', 's horse farm in California. (Photo courtesy of Sage', 'worth', 'homebody. It makes sense: Earlier this year Winfrey bought a $', 'YAMIL LAGE/AFP', 'worth', \"few. And that's not\", 'no wonder', 'Streisand: net worth', 'Streisand, who ranks number 19 on the Forbes', 'Ireland rents out in Palm Springs. (Photo courtesy of Kathy', 'Ireland: net worth', 'staggeringly beautiful vacation villas: Greece', 'The Top', 'wildly wealthy and definitely know how to travel in style', '(Photo courtesy of Inn', 'worth', 'that really rake', 'Montage Beverly', 'worth', 'Sheimdlin) has another career', '(Photo courtesy of Kenneth', 'worth', 'Spreckels Mansion, an opulent 55-room Beaux Arts manse', 'KCT', 'worth $255', 'Hadid, Karlie Kloss', 'St. Bart', 'Degeneres: net worth', 'jetting off to the dreamy Tahitian', 'hideaways', 'worth', 'hideaways', 'Sardinian skyline', 'worth', 'have also been to Hawaii and France', 'sale. (Photo courtesy of MICHEL GANGNE/AFP', 'Jolie: net worth', 'a cool $60'], ['effusive', 'in the Army, including three combat', 'I must visit Louisville', 'awesome,\" Johnson told me. \"This is', 'community of his dreams were it not', 'more than 100,000 soldiers leaving active', 'a new life as civilians. The greater Louisville, Kentucky, area where Fort', 'Kentucky', 'was no coordinated effort to connect the soon-to-be civilians in Fort', 'regional chambers of commerce launched Where', 'enthusiastic backing of the U.S. Army', 'navigating 10,000 veterans', 'Filling', 'processed at Fort', 'Herd said, helping soldiers', 'often on premises at training sessions in Fort Knox to assess soldiers', 'placement program. It just gives', 'disabilities to adult', 'them not just to a job, but to a community. Retired Col', 'Herd said there is no veterans', 'Herd said. \"The preparation', 'skilled workers that they say would otherwise be lacking', 'we’ve gotten past', 'no small part due', '10 percent in October 2009 to 5 percent today', 'Herd is director of the Army', 'boast', 'Yum! Brands, parent company of KFC, Pizza Hut and Taco', 'mid- and high', 'high school to get into the Army', 'often translate into civilian occupations -- everything from truck driving to supply', 'are virtually guaranteed to develop discipline', 'intangible qualities that make people reliable employees and innovators', 'Herd said. \"So we take those people and we train them and discipline', 'they stay out of trouble. Retired Col', 'Visit To An Army', 'being deployed to war', 'crucible that turns young high', 'their worst day in the service happen at Fort', 'they could make it through Fort', 'every', 'Marans Eileen Pickett, an economic consultant, co', '\"Army', 'one would think veterans', 'non-veteran peers', 'we are using annual data here for greatest', 'stress disorder and traumatic brain injury among returning Iraq and Afghanistan veterans', 'hard to make professional', 'Herd believes that departing soldiers', 'hard part comes in translating those skills from Army', 'human resources executive', 'ability to assess a vision and execute', 'less likely to be unemployed than Army', 'Fred Johnson volunteers with Healing and the Arts to help younger veterans', 'Community Change.', 'him with a sense of purpose like the kind he enjoyed in the Army', 'did not think he would have the luxury of finding a job that fit', 'Where Opportunity Knox', 'underprivileged schools.', 'certain', 'community building in the underserved west side of Louisville.', 'You can actually see the community change. Fred Johnson, Army veteran', 'When we attacked that city it was like a wasteland', 'in him a desire to be a part of something', 'diverse. I fit in as well there as at', 'stress disorder from combat', 'more CEOs', 'him one', 'initiative called Arts and Healing. The group uses art to help veterans', 'them, ‘Follow your heart, not', 'well for a civilian career', 'lot'], ['Thiruvananthapuram', '30', 'Thiruvananthapuram has a rating of 19.83', 'on the list are in the vast South Asian nation. Since', 'Banerjee', 'other', '20', '459. Nagpur', 'Hamilton, Bermuda, with an index of 141', 'nearly 500 cities around the world. Red'], ['enough', 'Weise/Getty', \"construction materials if you're building a home. You need to be\", 'still 50', '100', 'some extra cash by offering discounts', 'shoestring. Even if you decide to set up shop in the capital', \"My Second Home Program. If you're 50\"], ['were buzzing with discussions about the highly anticipated \"Beauty and the Beast\" remake', 'others thoroughly examined each', 'did the remake compare', 'Well, that’s still', 'not simply as a copycat', 'at nine ways the \"Beauty and the Beast\" remake', 'contains spoilers', 'more than', 'buried deep in a book -- and she’s not', 'She held this impromptu lesson', 'Kline', 'disheveled', 'disease as well. So he', 'pompous and entitled -- but he wasn’t always', 'him from his dad', 'were new to moviegoers, \"Beauty and the Beast\" composer Alan', 'they hadn’t been used', 'was too', 'highly educated, boasting about his expensive education while quoting Shakespeare', 'bored with the books and agrees', 'he', 'had any siblings', 'has taken his daughter, Belle, captive. So he and LeFou', 'in marriage. When Maurice', 'uncomfortable with the idea of leaving Maurice for dead, pleads', 'Gad’s character, LeFou', 'he wants. It’s somebody', 'soon switches to partner with one of Gaston’s henchmen, who', 'there’s no set deadline', 'knife', 'enchantress, who'], ['snarky quotes by anonymous \"insiders', 'Hardly Wait.\" But his', 'Fiona, with ex-wife Jennie Garth -- at GQ', 'When’s the last time', 'don’t remember', 'guiltiest pleasure', 'been very', 'could commit', 'Jaywalking.', 'in', 'I', 'okay to recline', 'if he reclined his seat than', 'overrated right', 'what', 'are you a twerker', 'I', 'time', 'You’re stumping me and I feel like I’m losing', 'most', 'always'], ['some jobs create more anxiety than others. Last week my colleague Karsten', 'survey CareerCast relies largely on data from the U', 'their median', 'unimportant. Some, such as audiologist and tenured professor', 'many interesting reader', 'the least stressful jobs. Photo credit', 'that lasts between one and four years. Median', \"if they're following\", 'eighth, with median income of $78,630. Using'], ['most', 'enough', 'empathy, selfishness', 'easily actionable) recent PsyBlog post', 'Clergyperson Chef Civil servant', 'Some of these are more surprising than others', 'most are intensely focused on empathizing with or caring for others', 'stylist Charity worker Teacher'], ['that are high in calories along with a lack', 'many of us, is getting the balance', 'metabolism is not always', 'there really', 'there are some foods that may help manage weight by boosting', 'the muscles in the digestive tract', 'certain', 'Thermogenesis kicks in after every meal and the digestive process continue', 'in the diet as a whole', 'it is important to remember', 'in mind', 'CHILI PEPPERS', 'chilli peppers', 'in the diet', 'chilli flakes or cayenne powder', '2. WHOLE', 'carbohydrates, such as brown rice', 'The extra effort', 'high portions of vegetables, and in particular the leafy greens such as spinach', 'thermic', 'a maximum of two are fruits. Choose fruits with high fibre content', 'BLACK', 'thermic', 'your meal', '4', 'in your food can speed up', '-fries, curries', 'grated from frozen or stored', '5', 'you enjoy the taste and include in marinades', '6. MUSTARD', 'in particular capsaicin', 'a casserole', '7', 'micronutrients', 'a healthy balanced', '8', 'in protein has a bigger thermic', 'you eat a chicken breast containing 300 calories, around 30', 'in part also due to its positive effect on post', 'quinoa, beans, brown rice'], ['After Tawny', 'been rough since her partner left — her vehicle was in such bad shape', 'desperately tried to help, Tawny', 'on its way and that his wife', 'she could set up a payment plan', 'more so than I care to explain, and without knowing us or our situation', 'she was falling apart. And while she knows that she can never repay'], ['are more common than the idea of collecting as an investment', \"candlesticks or a copy of the Declaration of Independence, there's always\", 'what could be', 'pogs to marbles to Cabbage', 'only really made sense in a specific time and a particular', 'ten collections that are worth', '10', 'education', 'not', 'That particular', 'enough', 'most of those Coke-stamped products are now just inexpensive curiosities', '9', 'collectors slept under Uncle', 'Not so much', 'mid- and early-century definitely', 'more than knick', 'that people think should,\" she said. \"is one', '99', '8', 'what wiped out collectors of Roseville', 'every Roseville', 'all that, by taking', 'was rare. With the internet, I could connect to every', 'some hard bargains. When shoppers can go home and Google up', '7', \"low by the internet, for a period of time in the '80s\", 'was value', 'slow collapse began in the early 2000s, culminating in a bankruptcy filing', 'scarcity\" as Dixey', '6', 'meticulously sorted rows of tchotchkes', 'enough', 'Endless special', 'few retain', '5', 'There must be some good reason why otherwise sane people shell out sometimes millions', 'masse. Hummel represented the end of the war', 'far', 'all based on comic book heroes is not', 'paperbacks of their youth, the reality is far more mundane. Aside', '4', 'mid-century, the idea of memorializing shared moments on dinnerware', 'still', 'QVC', 'gatekeeper for any of these products, there was never any', 'most Norman Rockwell ones going for $5 to $15 apiece', '. Baseball Cards', 'them all, Magic the Gathering, can still command', 'frequently disappoint', 'their youth, stacked up pieces of cardboard tucked away and sat', 'almost anyone, and prices reflected that. Today', 'were selling for hundreds', 'few bucks', '2.', 'furor,\" Dixey', 'had a front', 'several', 'Stern wrote', \"wasn't\", 'to be worth', 'the year... Today, the Britannia Beanie Baby sells for $', 'of the Princess', 'Lunch', \"them, these products just aren't\", 'were indeed rare, and they were bringing lots', 'glut', 'mismatch', 'lot', 'bursting'], ['a crop', 'of the most dangerous reality shows in TV history', 'Wiggins - who announced his retirement from cycling last weekend', 'fellow gold medallists Jade Jones MBE (Taekwondo) and Kadeena', 'Former rugby', 'array', 'Caprice, model and TV presenter', 'Gibson, winner', 'Hobley all being', 'returns to Channel'], ['collection offered in cup sizes ranging from D to J', 'I wear the pieces, which is important', \"Panache's new collection below. Are these nifty knickers\"], ['Farah Dhukai', 'Most', 'has found that it can help prevent dental disease. And this D'], ['mulitplayer lag is a huge', 'chalked it up to all other players being located halfway across the world in Japan', 'the world is amazing. But Smash is serious business. Despite', '(Smash', 'Super', 'our testing using', 'was a', '(Smash', 'sure they register, you can complete', '(Smash', 'SSB4', 'some reason', \"couldn't be said\", 't help the situation', 'much', '(Smash', 'Placebos', 'enough to get used', 'had lag because of my #', 'in the charger', 'heavily on location so I really don’t know what to say', 'not', '(Wordpress', 'The Part Where I Complain', 'Not to mention OG 3DS owners', 'that you could ever seriously play Smash on a smartphone', 'may be likely to forgive', 'Are you experiencing lag in your online battles'], ['You like the best of things but', 'you won’t just', 'you’re partial to fancy hipster foods, like expensive artisanal', 'you’ll happily skimp', 'all about balance, after all', 'you like to drink and won’t order anything', '5', 'it comes to your appearance, you generally', 'few hours to get ready.', 'You always', 'tend to just', 'ive worn the same shirt everyday for a week [packing for vacation', '10', 'you’re in a situation', 'are pretty high, people expect the best from you at all times', '13. Which can be an exhausting pressure because you’re actually quite', 'almost exclusively high', '15. But you can’t be', 'very', 'Most', 'strop', 'they don’t want to take', ', but', 'medium'], ['are about', 'are about', 'some steam built up at work or while studying. The holy grail though', \"They're easy to scoff\", 'you really have to commit', 'BOOM –', 'maelstrom of events encouraging people to converge', 'be found but', 'to be', 'in the Mountains –', 'shacks and art installations out wood sustainably', 'throws', 'Black', \"You already know the main details, so here's an anecdote\", 'her camp.\"AfrikaBurn', 'Rothbury, Michigan', 'hard to think of a festival more picturesque than this one', 'tall trees being utilised', 'Tankwa Karoo', 'so much a', 'decommodification, creativity, self-reliance and radical self', 's theme is simply', 'Envision - Costa', 'enough', 'Envision, which is', 'Nowhere –', 'we come to the appropriately named Nowhere.', \"intense it's website comes with not only\"], ['dashed for people who become millionaires before they can even walk, but Mary', 'bizarre lives since leaving the TGIF lineup. Though', 'on bad', 'beaucoup bucks when the popular sitcom ended. Their net worth', 'unintentionally laughable direct-to-video movies — 45', 'In spite', 'The Mary', 'masseuse', 'masseuse finally determined she should reach out to the', 'had anything to hide. \"Mary', 'stonewall tactic', 'opioid crisis', 'handbag', 'high fashion. According to Entertainment', 'ghastly accessory celebrating drug culture seems even more offensive', '-Kate', 'most of their adult', 'best approximation of due', 'unethical plastic surgeons who are willing', 'Paltrow', 'some Christmas gift ideas in 2014. Perhaps unsurprisingly', 'any convenience store for around', 'exorbitant', 'remains one', 'too', 'I was 17', 'snub a', 'no', \"taking time before diving into the acting world isn't the only\", \"well. Baby sister's resume\", 'no', 'would it kill you to be a little more like your sister', 'Kool', 'There are few', 'bizarre, especially since', 'were only 50, \"were required', 'They are', 'that only takes calls from Candace', \"There's definitely\", 'snobs', 'In a profile in The New York Times', 'tastefully appointed manse', 'we can do $5', 'Did they build a billion', 'not', 'whopping $530'], ['bound', 'some of these needs to share', 'Klefki', 'There are a couple more Pokemon like this, where it seems as though', 'Rotom', 'yes, Pokemon', 'anyone else realised this Pokemon', 'keeps', 'Luvdisk', 'hadn’t', 'laughable. The lost potential of this Pokemon', 'Unknown (Unown', 'little functions apart from the ability of flight and group', 'feeble attempt', 'Vanilluxe', 'cone! The designers thought this Ice Pokemon', 'ide', 'Jynx', 'terrifying large-bosomed-womanhood made for mankind. Jynx', 'Cofagrigus', 'bit silly. In its description on Bulbapedia, it says the Pokemon', 'Voltorb', 'laziest Pokemon', 'Dedenne', 'much-loved logo and everyone’s favourite, Pikachu', 'Druddigon', 'poorly drawn dragon Pokemon', 'Exeggutor', 've never heard of coconuts hatching from eggs but in the Pokemon', 'Garbodor', 'enough', 'Japanese', 'hasn’t been released yet'], ['there’s no denying that Elizabeth Taylor was a', 'quite a bit about relationships before she died at age', 'fiercest old Hollywood dame', 'wasn’t nearly', 'waxed poetic about his wife in his private', 'impossibilities and my drunkenness, she is an ache', 'we could get used to someone', 'awkward between Elizabeth Taylor and the late Debbie', 'going to carry a grudge', 'pave diamond-heart necklace after one', 'afraid to grow up,\" Dame', 'neighbors would be spared if one of their infamous lovers’ quarrels', 'I’ve always', 'each other', 'doesn’t work out? We’ve always'], ['Her inspirational journey is encouraging others', 'pageant contestant has taken to Instagram to share', 'most common skincare problems that people experience but that doesn’t detract', 'being bullied for her severe skin condition and despite', 'some seriously', 'be ashamed of with a litter of make-up free selfies', \"didn't sit at home comparing myself to others\", 'ॐ (@asprinkleofhealthandbeauty', 'most recent posts', 'to be the main culprits', 'good always comes out of something', 'ॐ (@asprinkleofhealthandbeauty', 'breakouts!\" she writes', 'High fat vegan plant based diet', 'acnetreatment #loveyourself', 'ॐ (@asprinkleofhealthandbeauty', 'in the Miss']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_spoilers = []\n",
        "final_spoilers = [' '.join(i) for i in spoilers]\n",
        "final_spoilers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC5BOh7W2pVB",
        "outputId": "99879d5c-79bd-450d-aad1-13b61f2e2712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Segall Maricopa sheriff of Arizona’s Maricopa were had unusually harsh words for Arpaio inequitable application of discipline had encouraged had violated the order \"out of spite had violated the order unknowingly contempt on two counts, and retired Chief Brian Sands and Lt evidentiary hearing, Sheriff Arpaio and Chief Deputy Sheridan made multiple intentional misstatements wither investigator to look into comments Snow’s wife purportedly made in a restaurant impartial and should recuse disobeyed orders to gather evidence and continued thousands of pieces of evidence from the plaintiffs and deleted the sheriff to resign be entrusted the original case against Arpaio, demanded investigations that root out and punish misconduct was one',\n",
              " \"less, to one singular staple Iggy Pop, Johnny CBGB's legacy are you up 'm just here will start [in Are you more of a theater guy was just, yeah, I’m enjoying Were you familiar with the legacy very much was amazing. They just had so much Did you grow up listening to the music depicted Blondie Blondie Did you dress was a new experience did you come to learn lot Grint: Yeah, there wasn’t really a whole was on set the whole was such a nice guy Did he give lot of that. And he was such a nice guy Was this Grint: Were you comfortable Weirdly, yeah. It didn’t really feel that big a deal that you'd be intimidated to have I think every was quite a hard one. It’s quite did you think of the band you were portraying I’ve always d ever pursue I’ve tried to leverage were your thoughts going into a character who was much some get Had you seen each great I don’t think I ever really saw him outside of that wig most I love her, she’s great It's October. What's your favorite Halloween costume in it, and you’d get had a good costume course a Play-Doh logo. With a yellow hat a favorite Halloween I don’t even all just kind of elderly in limited release now\",\n",
              " 'in ultra-sexy skivvies Rossellini of like a superhero suit Wiedemann hosts an online cooking series for Vogue my core. My diet stayed pretty much the same, except I cut be \"sexier and curvier we don\\'t plan',\n",
              " 'mid-\\'90s. Clark I really missed it,\" Clark took up writing. Since leaving the courtroom, Clark Wow, you\\'re not did change me,\" Clark 100',\n",
              " 'selling her Beverly well worth too big for',\n",
              " 'Instagram good deal straits when you realise we live raking in seven-figure salaries every Hathaway – £3 fanatic earns a small fortune most of her selfies Hathaway (@paigehathaway Hathaway (@paigehathaway Zales – £3 hair removal. TeamNoFuzz with alarming regularity. Zales (@chantelzales Zales (@chantelzales Cheri – hell We just hope AnaCherí (@anacheri anacheri) on Jul 25, 2016 at 2:42pm PDT Ratchford – £2 of it rubbed could definitely i l i l Alende – £2 doppleganger gets all back, she’s really just Alende (@claudiaalende Alende (@claudiaalende Somers – £2 waist training wraps that look a little like tofu bacon Somers (@lacikaysomers Somers (@lacikaysomers Amanda Lee – £1 protein shakes and hang have amandaeliselee) on Aug 29, 2016 at 5:22pm PDT amandaeliselee) on Aug 19, 2015 at 1:42pm PDT Falconi – £1 legitimate nutritionist would avoid You know, for the health of their clients. Falconi (@bellafalconi Falconi (@bellafalconi fillers to liposuction and private gym membership fulfilling prophecy GIPHY judgement curled the bags maybe their arm gains would match',\n",
              " \"most have in your home often the filthiest part of a kitchen YOUR OWN CLEANER Hellewell wonders to help remove react paste onto the area you need to treat and leave 30 was the last time you removed the shelves from your oven?' asks Rik you keep soak. Make sure you read the instructions on the cleaning product and wear shelving from the resealable bag. Rinse TOOTHBRUSH toothbrush is an essential you use an electric toothbrush 4. USE ideal soak in oven cleaner and warm water, then scrape 5 may sound strange, but you can remove In fact, this technique will make clean-ups in the future areas with all-purpose oven cleaner to ensure 6 all cooked a wonderful meal pungent few drops in 7. USE hob can help remove built-up grease. Simply apply hob clean, sprinkle 8. POLISH WITH CREAM OF TARTAR odd cleaning product to use on your oven, but 'Simply apply with a thin cloth, leave 9. REMOVE STUCK ON FOOD WITH DISHWASHER pans in a dishwasher 'Take a dishwasher 10 very quick and easy way to battle you can; if not, leave on food remains, cover with your homemade cleaning solution\",\n",
              " 'in this world that’s worth the BuzzFeed maybes.\" – Poussay good old days before you’ve actually left them.\" – Andy They are a reminder that our lives will get better if we just hold Khatun you want that, too?\" – undeniable.\" – how tightly you hold on, it\\'s already gone.\" – being compatible, or novels about shared don’t necessarily spoil indifference.\" – Bree Van de Kamp, Desperate they move on.\" – too much of a coward for that, then burn.\" – 13. You don’t deserve still 16. you’re supposed to.\" – few.\" – Debbie Novotny 19 t just run out of answers. You run out of hope.\" – well, I think you deserve 22 the world will not. Wear it like armour and it can never be used all you will ever see.\" – 25 would have stopped.\" – did love you because it makes me think that I might be capable of something 28 29 to be featured in similar BuzzFeed posts',\n",
              " 'be sinister oracle with the power the year 2000 might be in store Some alt-right guy the episode There will be a referendum Much Greedy, corrupt energy firms will cause an environmental catastrophe dome appeared in The Simpsons in Elton John’s private I illegal to teach the episode \"The Monkey Suit also sarcasm the episode \"The Saved Lisa Jolie and Brad Pitt Whopper\" , it’s revealed that the celeb trainer Lyle several actual clowns will stand in elections around the world. And win the episode Cumberbatch will be cast as David Cameron Many-Splintered 10 the episode Hawking will learn They Saved Lisa 12. To cut costs, industry workers will be replaced the episode was won the episode 14. White that’s already happening. From the episode \"Lisa there will be a female president. The Simpsons said it will happen',\n",
              " 'least a couple of his draft classmates are still Nowitzki, 38, hopes - unless you count the No being out of the league for six years, Traylor died of a LaFrentz, No. 4 Antawn Half Man, Half Amazing,\" Carter redefined his Nowitzki, the No. 9 pick despite most one Nowitzki greats separately sat down with ESPN recently for a three-way Q d love division to the NBA. That was a huge was literally was incredible Nowitzki, on his reaction to being drafted by the Mavs Had a press conference. Never had a suit Strick [Erick Strickland were a great team right [then], not really If they don\\'t take I was going was just weird. I thought I\\'d be in the top five me to be Olowokandi Olowokandi well come work out.\\' That\\'s what was introduced to the business of basketball pretty much in the first five being traded from Golden State was just perplexed was just Antawn at was already walking up to the stage. It blindsides me, pretty much each Nowitzki always was fun to watch during his prime athleticism and great shooting touch. Usually you see one without the other he was one transcendent player loves to compete. And he\\'s selfless me in hell Nowitzki was a great flat McDonald you just hope many great battles was just sitting on my butt in my 20s mid-aged guy. Couple of young guys, but still hopefully I can [stay camaraderie that I\\'m going lot of bus rides, a lot of pregame speeches, a lot I\\'m enjoying There\\'s nothing were just kind of like, \\'Where do I go from I go?\\' Then just spending I\\'m not have been doing it all these years but can see yourself [coaching full me, because I love Nowitzki: [Heavy sigh.] That sounds like a lot tough. It\\'s not going',\n",
              " 'there are easy ways to treat some small afflictions -yourself remedies and get a quick fix for everything from earaches Mouthwash for Black tea for cider vinegar for often used as an energy booster 5 peroxide for 7. Honey for cuts and small wounds 8 9 10 11 suffocate the wart 13 they’re so easy. I’m going to remember',\n",
              " 'high-pressured jobs with starting families and maintaining there was a simple three-minute solution anyone can master FEMAIL all you need to do in through two straws are going to hit in and out through the nose as per shoulders, eyes, mouth',\n",
              " 'ex-girlfriend of former basketball Alvin Japhet Investigation (NBI) for Not only on the offense has now committed in an entrapment mug shot of the suspect. (photo credit: gmanetwork According to GMA only lasted for a year after he hubad sa hallway ng strangles me, he tries to crush Almario has also threatened her parents common friends at him. (photo credit: gmanetwork way would do been able to speak up, the suspect remained CCD) chief Ronald Aguto Jr. (photo credit CCD them.-Kami',\n",
              " 'Did you know theres actually a right way to shower? Get most you know that some of the most common shower habits might not are doing 1 already in the shower. However, despite irritation—it could even burst Not there’s no real reason to actually bend down and give you’re not excuse Not that can be terrible you’re out, or create 4. Using a Soap Dish going have reasons 5 be doing a number their soap as the first culprit 6 Some people may not even high concentration of minerals like magnesium and calcium, which can end unable to add a water softener to your shower, try incorporating 7 Most people wouldn’t even stress you can tolerate regularly taking 8. Using most of us, old razors aren’t something is shaving off your unwanted hairs doesn’t mean 9 plenty of nooks you don’t 10 good idea, but doing so every day could actually be causing damage worth',\n",
              " 'most palliative care for physicians, people tend them comfortable, Campbell tend to lose their abilities for complex or executive coherence Palliative Medicine. Seventy',\n",
              " 'my pictures posted on Match.com or another [website],\"  says York Post phony accounts filed a $1.5 billion class-action suit Yonkers, N.Y Avalos said had to borrow preventable with the right software, ABC News reports. The Post filled misled',\n",
              " '\\'s bizarre road baffling tales Jacoba Tromp and their adult children Ella, Riana with paperwork everywhere As they drove towards NSW One day later he left the family trip at Bathurst, describing his parents Goulburn, where Riana was following had made their way back Their mother an end when Mark was found on a street near Wangaratta hard to explain\" and referred to the situation At the time the world, remains a mystery, but theories have included drugs, financial were found dead in far west New South Wales being good feed were sightings of between 5-50 dead kangaroos at a Former NSW All the work we\\'ve done says it\\'s not s possible it\\'s an infectious When a magnitude 7.8 earthquake struck they witnessed the sky light up said it occurred at were] of colours mainly thousands gradients that \"accumulate High were at a loss a top hospital in the capital also suffers , those suffered hijacker Dan \"DB had a bomb in his briefcase -coloured sticks inside his case parachutes and $ had landed in Seattle, he several crew members still on board, he ordered the plane to fly to Mexico somewhere was heard from longer actively',\n",
              " \"Herculean task will risk being sent back to the feds wasn't in any position cattle ranchers via Wikimedia Creative Mendoor Smith, 43-Year-Old from Served Custody in 2013 halfway house I was placed in. It wasn't really 10 AM, the cow had died. All that work was for nothing coworkers that knew about my [criminal] situation Hibdon, 55 10 Years for Custody halfway house to save up and buy a $500 K2 subcontracting myself out to do maintenance on rental telemarketing call center via -Year a Custody in 2009 wasn't were an outsider. There was a lot of favoritism had something better lined up. It served\",\n",
              " 'high school... it was one Lapeer High School’s class of 2016 and he would inevitably drift apart but he makes a promise',\n",
              " 'a serious impractical,\" Clark that great few crucial bulky. Their epinephrine solution isn’t particularly Mylan, which owns the EpiPen brand (though Mylan , not displace s why Mylan injector (to protect soldiers Mylan has been Mylan in that moment,\" said Matthew Mylan It would not There’s no injector for the past in a pants pocket without getting few years away from bringing Mylan Mylan injector shaped like a bulky credit injector Mylan injector by far,\" MannKind CEO Matthew Pfeffer exceedingly tough to get stymie an epinephrine inhaler, especially since 4 lot was worth high right now that Baum figures it is worth We’re just loud enough allergy, is a consultant though irritating to me, but not to the point Mylan Mylan’s motto',\n",
              " 'Gologursky Gwyneth Paltrow Her like to do a cleanse once a year. But it\\'s not Her Daughter to be with her. We went out to lunch Unplugging my phone away and I really listen, that is such money in the bank gwynethpaltrow On Her my life, and food is a big part of it. I love On on a shelf for years and you can open out of a bag Cheat them growing up in a hippie vacuum,\" she once told Redbook Being mindfulness. If you just parent gwynethpaltrow Taking at least in Balance be modern and easy on ourselves as well,\" she told InStyle On Her I get through Is Obese couples take longer to conceive suggests Are SERIOUSLY Stressed, Says 7 Valentine in Hairstylist Going Major Black Remini Her Mesmerizing Stamina SNL’ in the Midst of a Ratings Renaissance With Britney Spears Spends $80G Nyong the 2017 SAG Issues to Pose With Mom Hair , Miss Have Missed More Than GNC Ad Booted From Hair Looks Perfect for Valentine 5 Selleck Black Giambattista Valli Serves Whimsical Beauty Looks From the Dior Hunch Helped Crack a Jogger’s 6-Month-Old Slaying One in Your Shopping Cart ’ Star Richard Hatch Dead at 71 5 Times',\n",
              " \"it’s ironic were legitimately -watch Unbreakable Kimmy an HGTV who calls someone it's probably willing to endure the evening serums, etc. Make sure to give that pinot grigio and pinot have an opinion on which you prefer -unit laundry while looking at apartments Who has time to waste kiosks at places like Target and Best Buy like a total pro being intimidating Not only do you have friends when a new checker doesn’t recognize you and asks for your ID have a preferred You spend you used -create some of the dishes You mix up Kendall and Kylie they're The last crazy concert you went to was...an opera longer an option that you actually care 20 still felt guilty and even managed laughing matter When someone You know the difference between a traditional and Roth IRA t just something\",\n",
              " 'still work to do, although great still work to do, although great you will see just how many people belong there any names on this list that really surprised you? Feel free to share 15 Kristen Stewart Cargile have only been dating since July of 2016, but Stewart has expressed 14 most influential gay news magazines. Plaza did not 13 100% straight to 100 12 Colton all just enjoy life & have no regrets 11 Dysmorphia 10 often perform hilarious skits 9 Ryan enough 8 By the end of the music video, Owen has found a guy that suits 7 Gloria had a lesbian relationship with one of her classmates. It was a piece Warsame number of mosques in Australia that will not',\n",
              " \"isn't be a champion for young women in her situation had major great In fact, she's even joining There are so have collecting been through, she can't quite believe her current life situation pageant would want someone like me. It proves you don't need\",\n",
              " 'the weekend. Then, for good measure Feldman by—what else?—tweeting was beautiful; just everything forty minutes later, she dropped THIS bombshell all the cynics out there, Guthrie did YOU do',\n",
              " 'a while, but the morphine and lack I have a) your attention, and b at least another on her right side isn’t the no-biggie had just left many plans instantly went poof my mother. No writers’ residencies at those wonderful schools in India wonder in the present did it in one day had never met. I went to college out east were only 24 the end of dinner a year later eHarmony, but I’m going -pepper in no particular order because everything feels important sharp dresser. Our young adult sons, Justin and Miles, often borrow could speak, it would add that Jason is uncannily should also add was working on my first memoir, I kept you can use would agree — he was indeed a captivating an absolutely most days from 9 to 5 affinity always He knows I love is you know enough Did I mention that he is incredibly handsome? I’m going to miss too most recent memoir (written was totally serious about this and encouraged was based on an essay in the book where I mention was my second tattoo; the first is a small, lowercase \"j few days left I am wrapping this up on Valentine’s Day, and the most genuine you two the fresh start you deserve all',\n",
              " 'of his friends planned a trip to Majorca having to look at one some Joe He wrote It’s our friend Nathan’s 30th 15 namesakes, but only 15 Joe 99MQXdZVyw legitimacy of the offer at He wrote legit, I decided to take the plunge as my legendary boss all want to apologise to my mum',\n",
              " 'of the most interesting and powerful photo stories from across -Seen Photos Behind the Scenes at the Women’s March\" — in terms of scale, coverage and inclusivity. Kisha Bubacz, senior Honest Photos of Motherhood Challenge They don’t hold BuzzFeed The World\" — BuzzFeed intercommunication in the digital age BuzzFeed 4. \"A be K That Will Help You Understand the Refugee Experience\" — BuzzFeed all the more relevant as a nation of immigrants begins to grapple K Are Guaranteed my thumb on it, the collection constitutes a great G Nairobi’s Korogocho Slum\" — Al Jazeera most —A.M 8 misconceptions and showing that women also belong —A.M of the Most Powerful Photos of this',\n",
              " 'common will.\" The message was always conscious,\" Rodriguez says. \"That’s the one each morning, they did a series of jumping jacks Tsai were great in the country. And Gina Rodriguez won a Best Actress Golden Globe We lived the idea of the American Dream,\" Gina says Family Right: Courtesy of the Rodriguez Family Srinivasans thousands well. And we defined success by leadership none of these siblings grew up rich, they were privileged in many most said they grew up with much Indians from Kansas Immigrant Drive Saroja Srinivasan, a Hindu who is vegetarian, was mastering Saroja recalls. That meant cooking hot dogs and pizza as well as dosas Srinivasan household Srinija, the youngest. \"Put things away. Pay attention permissiveness that is way better than an allowance,\" says Srinivasan Family Srinivasan Family was more important Srinija is an entrepreneur who addition to Puerto Rico and India -selling author and New York Times Gay Family Hegger Good grades in school, that was not something Being from Haiti in particular Parent-Teachers Srinivasans in Kansas genetics company 23andMe paper airplanes during presentations lot of strong academics, I think one of the skills we have is not Wojcicki Wojcicki game.\" She did arts and crafts projects with her toddler among the most important Not supplementary lessons well-known actor, with major Dungey Family Left and Right: Courtesy of the Dungey Family Srinivasans, having a parent Activism most vice provost at the University of Pennsylvania dinner was a test of current events.\" (The brothers also have Tsai will change necessarily housing complexes, and never Emanuel Family Left: Courtesy of the Emanuel Family construction site. Now adults had his own moral ControlLed street fight against 12 other guys on our corner.\" That exposure also created motivation. \"Seeing tragedy always Tsai multimillionaire violence than most Few recalled major rifts between their parents. But many of these siblings Mealtime debates could get so Family Behar—Sipa Press/AP basket. Susan and Janet weren’t home. Esther Wojcicki had to withstand motivate achievement, says New York University psychologist Ben LESSONS t motivated by a constant gallbladder out, and I don’t want Antonoff Family Left: Courtesy of the Antonoff Family violence. Rahm Emanuel nearly died as a teenager when a deep cut going to not didn’t insist they finish college, and she took Jack had a kid range childhood many of the other siblings loathed so much Mao and ultimately became professors at Ohio University, didn’t Family Right: Courtesy of the Lin Family most of their time outside, or writing poems, or throwing Few of the siblings she allowed us to play and develop our own ideas,\" says Wojcicki often left to babysit 4-year-old Janet less empowered they feel,\" she says commonalities of our nine families combined to create drive will are five',\n",
              " 'By Division I football for Missouri State University, Andrew was an honors more timely by the recent heroin-related death of Glee star Cory Monteith much more powerful than before (purity can be as high as 90 in routine wisdom —legally and on the black was finally starting to get a handle on his addiction. Like Cory Monteith some of the best high schools in the area. Public, private was like I was leading had to give something to him,\" she admits When a friend length to get sober. I had to change every much been',\n",
              " 'eared giant, among them—and their triumphs over bullying adults evocative stories. In May, the Oxford University Press also published a Roald sizzle-pan\" to refer to a frying pan in Dahlisms added to the OED, and the revised phrases, with notes New entries loathsome adult characters, and gruesome or black humour in chocolate bars that granted access to Willy over a century older, having been used adaption of the book, starring Gene Wilder. Gupta called the phrase Scrumdiddlyumptious excellent scrumdiddlyumptious and some is uckyslush had the world to themselves.\" We can thank Shakespeare',\n",
              " 'have been up hope longer meeting monetization we announced Promoted User Posts be met lot great Happy to chat about this stuff, or anything',\n",
              " \"Temple University students, alumni, faculty and staff gathered at the Liacouras ,303 being made and sent to charitable organizations in the Dallas/Fort Worth Temple shattered that record, according to the university's Twitter account Fifteen food banks and shelters across the Philly Congrats, Temple. And once again, as a thank\",\n",
              " 'are home sick from school a feud between him and President Trump, who remains more than on the unresponsive child when the mother are a top the proposal to deter had communications during the campaign may have had with Russia during the 2016 campaign have polycystic ovarian syndrome, and Dr. Jennifer Ashton explains The Force Awakens\" star, Daisy Ridley, revealed a powerful message that she has been suffering from endometriosis since she was 15 View \\'Star Wars\\' Actress Daisy Ridley Fires \\'Star Wars Endometriosis occurs when the normal uterine lining grows outside the uterus in women of child bearing age have polycycstic ovaries in tatters have polycystic ovarian that with the help of dermatologists and diet changes, like cutting allergy testing; keep over 200,000 likes and countless comments of outpouring',\n",
              " 'a better parent on your kids have no the more you look like your kids do every your kid is embarrassing you in public happy Your kids walk around explaining things so you don’t have they also a disturbing level you get it you are one calm, cool badass mom 11. This image perfectly sums It doesn’t matter it’s like liquid confidence for motherhood there is to handle in your household much more pleasant mom when someone asks how you mom so good, your answer is always',\n",
              " \"you need 100 haven't done since 1995. The S&P the summer of 1975. However, real wage growth slowed to 0 Wilders's far-right party expected to perform Intermediate crude oil trades up 1.7% at $48 most of its shares after Jack Walgreens plans to sell more assets to win approval for its takeover S&P light. Oracle Housing Market Index is due\",\n",
              " \"Good Morning a bit re not , should be , should be to be View are generally good for a year. Aerosol spray products can last much is stored improperly — for example, in a place that is too they will have an exact expiration It's hard to keep Franzino's tips to save money on beauty products include swapping you may end up having to throw\",\n",
              " 'on your big day distasteful to some may be perfectly normal to others cringe-worthy dance routines, cheesy unquestionably tacky and definitely not horde you seen that video doing the rounds on Facebook where a guy tackiest things you can do at someone livid. Like no. This is my inconsiderate,\" and quite simply, \"F peeve guests have at weddings are vulgar Miserable marriage jokes are never toppers that show the bride dragging the groom and ring-bearer there under their own free will. S***\\'s not most common gripe among guests though had homes was fine, there were some circumstances the bride & groom very aren\\'t invited, but asks for a gift? GTF outta here they had her husband there was a cash screeching',\n",
              " \"could have been possible if the ruler had sex about once a was the first great sultan of the Moroccan Alaouite most of them from enemy chiefs at one of his wives or concubines may actually have had 1,171 children from four wives infertility often afflicts To solve this question, scientists developed were as conservative as possible with our calculations, and Moulay could still were at fertilizing women's eggs as he ,171 children in 32 years. Moreover, the sultan did not need a were all quite different from each other Oberzaucher\",\n",
              " 'ones who deserve Lakisha Lakisha My oldest daughter Kiona Kiona Along with her work as a healer, Dr. Jenkins strives other people do and you’re more in a position going to challenge you all the time K due much anything related to the operations of cannabis businesses regulated by the state I’ve always lot of opportunities to blaze the trail, so to speak, no pun Lyman, California State non-profit organization Drug Policy Alliance, \"the leading We always didn’t pass were a vital lot been men’s faces at the forefront and yet 4 diversity summit many community leaders of color to come in and share in far from over. \"I’m I’m gonna that literally credit 5 FECO lab grade, U.S. made, naturally extracted beta longer feeling stuck without options to address their reproductive concerns. \"Women have always',\n",
              " 'Abraj Kudai would make the hotel helipads and a full Handasah , the $ over 2 kilometers from the Masjid al-Ḥaram Abraj Kudai 10,000 hotel rooms, according to DesignMENA',\n",
              " \"moderate the first presidential debate Monday. (Photo by Jose have advised are five registered Republican into attack of indicative Conspiratorial a very lobbing questions at Republican Donald Trump and Democrat Hillary bias against him will be tough black been 24 years since a black I'm never going to pull a race card moderated one of Hillary a huge distinction. We're not not in almost a month. He was fairly active while in I've never done before a newscast. Beach volleyball. Tonight xJ5MoYGtPZ — Lester Holt (@LesterHoltNBC several days or even a week between tweets. His relative disinterest moderated a Democratic that night with Andrea Mitchell willingness fomented a war in Ukraine, provided has me he plans to do California State was planning to drop out of California State okay. Since dropping out, Holt has received\",\n",
              " 'you have or where it is, you’re going you don’t have to go broke just keeping You also miss well-served outgrow inFlow hiccups inFlow, Carta should offer invoice and receipt generation tools, geared can be managed be free for you’ll probably want to take advantage of at great open source answer for Almyta Control System. It’s a free package all free options, you’ll be supplying thoughts most small business inventory requirements, with many offering flexibility to move up us know in',\n",
              " 'lot Kis your time, he shares the ultimate many projects at least 10 per enough to be prepared to invest 10 per cent of your net worth can be run by a monkey, because one day it probably Multi-millionaire Sophia Amoruso, founder of Nasty Gal, says the more time you spend has to be vacations are not their time. Indeed, as Kim skilled in a certain',\n",
              " ', so, Oxford University is older than in time to the invention of Snapchat than more than 2,000 years ago in 30 are still was older to the Tyrannosaurus rex Not only did they not exist at the same time, but the T closer to the signing of the US Constitution than to today Martinuzzi, the oldest living person today at age the United States has two grandchildren who are alive today had a son, Lyon Tyler, at age 6 most 7 almost 50 years before Isaac Newton published his Principia only 66 There’s so much Americans were still alive when the Great Pyramid at Giza , which wasn’t until about 1560 10. When the first Star Wars movie came out, France was still executing Hamida Djandoubi were still Just two years later, Scottish inventor Alexander Bain Ottoman Empire all 13 that’s the year Betty White was born Uncle Phil , but Will Smith is now 48 years old. James Avery was 45 15 way after the end of the ’70s, but that gap is exactly Eiffel Eiffel Tower was inaugurated for the 1889 World’s Fair Jr in very different times, Anne Frank, Barbara Some of the world’s whales that are alive today may be whales out there who are nearly 50 didn’t even heartbreakingly demoted in 2006. Because the fall of the Berlin Wall than to today only 12 years before 9 21 If you compressed the entire 22 and medicine, the current human population living on Earth right now is about 6 in the past, not the present it takes about 50',\n",
              " \"happiest day of their life and the best sorely regret saying Plenty are sexual, with one woman admitting she misses his wife is simply 'taking their spouse I'm\",\n",
              " 'some of these items, but you won’t find any deep discounts School Supplies high profit margins — like binders, graph paper and computer memory you have to spend so much time waiting to see the attractions. Dave in mind that popular stores like Sears and Home Depot you need to purchase a new TV before the prime season, DealNews unveils their upcoming models in September or October, reported DealNews more than a few years old, even if they are deeply discounted',\n",
              " 'for a forever home ever undesirable to families looking to adopt. He also has for a home for Jingee since may, sending resident, was worth Hayley went to see Jingee with her few more nights she decided to go She definitely was potty trained! Apparently somewhere was taught to be could learn',\n",
              " 'Other you love at a skill that you can share with others on cooking for $30 lot fucking mug for $22 attention mask for $24.30 you love about yourself and show it off like every the tank for $39 on coffee table books that actually interest this illustrated book for $15 on the right for $17 Declutter! You automatically look 10 times five-pack cable organizer for $30 revamp your creative space with a structurally intriguing desk organizer for $38 not have to please Not Giving a Fuck you’ve nailed 8. Don’t hide 10 and the second shirt for $ on every five-year journal for $15 and the desk organizers for $40 10. Buy a few distinct has with this galaxy cover for $20 11. Smile (only when you want to) with the greatest whitening powder for $19 12 the second for $15, and the third for $35 13. Experiment with your appearance: If life’s not some semipermanent hair not the coat for $150 15. Instead of fearing your lack of creativity the first book for $9.60 16. Be a goals pad for $ of course the second pair for $',\n",
              " 'We’ll see the UK triggering Article 50, Trump take over the White to be a bigger year for some than others 1 Amy 3 4 5 7. Lauren 8 9 10 11 Hayley 13. Megan 14 15. Katie 17. 18. 19. 20 the UK',\n",
              " 'you need in two years. The S&P widely expected to leave 44.61 billion sharply lower. Data released by the Japanese government showed the economy grew at gun\" evidence allegedly shows major AMF, France\\'s markets regulator, told the BBC Lululemon expects to earn $0.96 copycat. China\\'s highest Broadcom and Restoration 10-year yield is up 3 basis points at 2.37',\n",
              " 'Mizrahi a 28 attempt handsome, charismatic and funny which, while admittedly Insider raging bag of dick tips you’d expect laughing candid shot, and finally the dog owner I quote good thing, my sleeves always fall down and I don’t even',\n",
              " 'some ideas, as do companies that have been trying to combat Everyone When employers transparency raises wages, in part by lending disclosing pay information is often required. Alexandre Mas spurred most Benioff, the C Not much 51 do not bargain lose as much as $750,000 difficult’ or ‘spoiled compensation are aware of the disparity Pao did onus on the company to pay fairly instead of on candidates to negotiate fair Don’t that is already low, one worth Cobert, explained that the practice particularly discrimination,\" Ms. Babcock Easier for Mothers few years later when women start having Sometimes their pay lags because they take that help keep reapply for her job, that’s not More Flexible Workplaces many tech jobs and when people can easily substitute it easier for different pharmacists to serve the Law most must be paid the same for similar jobs, not grants for negotiation training and make class',\n",
              " \"he loads and unloads , and he had to walk to work and back -has been working since he was 14 to pay was too had a driving license, but couldn't afford -workers clubbed together and bought one for was presented the car, his colleague said he wanted Taylor to know everyone appreciated the Mail: overwhelmed I'm not really\",\n",
              " \"most lack insanely talented salespeople, and they'll still Intelligent must be prepared intelligence comes in multitude contextual intelligence is relatively new. Sales managers and executives productivity. most likely hired your reps on the basis of their sales acumen potential ROI intelligence is worth key confused than intelligence is critical\",\n",
              " 'did not of America’s top IUD tough little lady! A post Tough little lady\" Abigail Ann Brown was born March 4, and Brown in her parents’ basement apartment in Warrenton quest to continue training for the Olympic Trials will never compare to the continuous quest hashtag #Mommyintraining — \"double meaning intended newmom #babygirl',\n",
              " 'Hogwarts. J interrogated and imprisoned for in the Kings hoof. It has not been re 4/33 Krum Death Eaters Dark Marks eventually faded to look like a Quibbler is back to publishing articles about the lunatic fringe and is appreciated did come to understand and appreciate . He never married, although he had a relationship with a giantess 10/33 Hogwarts, the school for witchcraft and wizardry is led Kingsley Shacklebolt became the Minister of Magic after the Second Wizarding War to be be concentrated elsewhere and hes not going the war Hogwarts to complete their seventh year. Harry, Ron and Neville number of years, Neville Hogwarts since an academic career Weasleys Wizard Wheezes prior to officially becoming an auror was over, Hermiones first act was to find her parents in Australia Dementors as guardians. The number of Dementors has been greatly Hermione tells Scrimgeour that she is not Hermione they are like badges of honor. Neville',\n",
              " 'GIF most common stress scenarios , but Gizmodo most shocking revelations, uncovered after an exhaustive Hydraulic GIF By removing the headphone jack we certainly hope Hammers GIF Sure, the average iPhone user probably plenty of reasons to \"beware Sponsored Grinders GIF high shine \"may show fine micro-abrasions high shine \"may show fine micro-abrasions Men GIF Is the iPhone 7 half with a little help from his furniture? Nyet Axes GIF Fire GIF headphone jack',\n",
              " \"deceive you. concerned someone there is 'no all those claims of agitation like fidgeting,' she liar can easily deliver not inventing the lie and the performance do you ask that?’ rather than a direct and open response we’re trying to hide something often accessing recalled memory in most can often be gesticulating too much in a bid many assume less is more and almost often suffer a strong desire to hide their face from their audience are aimed often use skew liars often struggle to keep often Whodunnit? and says condone lying, this is the perfect the transcript Visualisation is the nearest you’ll get shoulders, arms and hands. Keep in your audience you’re not be better than over-sharing in terms of your body language giveaways I the best lover For more information visit www.whodunnit.org.uk\",\n",
              " 'in his would never support him 35) Roseanne ’s up with that?\" Roseanne is just one \"Start 34 was self endorse him 33 realness of an all American, outdoor-sy family with an importance We both have wives 32) Wayne Well no one, anywhere, ever accused me of not 31) Chris Christie – Former Opponent to Trump for this Republican in an epic Kiyosaki endorse Donald 29 several times saying, \"Donald correctness is a public Heisman Trophy Winner we going to get back to what’s best for Stallworth Stallworth went in to bat for Trump at a black Coulter – Conservative author and television personality Coulter has been a huge Ferrigno – Former our country and keeping 24) Mike s gotta and former he’d make a great president. Because he’s not a politician 22) Fran Drescher – Actress and cancer lot of things that other people don’t really have the guts and celebrity apprentice the country needs and Trump ... he’s a guy 20 endorsing Trump concluding \"I am a huge Donald Kirstie in an interview California Rep endorse Trump, who he Former suited Super Super laughingly replied, \"This is really important Hogan – Former WWE professional I want to be Trump 14) Gene ungentlemanly\" at times Busey I know him professionally. He’s a great guy 12) Robert Davi In an article published on Breitbart and authored deceiver who feeds us sugarcoated poison at bedtime former great friend for many years. We don’t need 10) Dana White – President of Ultimate me say a negative thing about Donald Bilzerian the people who remain unfiltered @realDonaldTrump Icahn – Billionaire entrepreneur no-brainer. You can’t keep Former I shocked my staff today 6) Mike Hufington and Western I just think he’s the only one who’s going Sheriff on the front lines of the illegal immigration war He produces results and is ready to get tough in order ) Wayne would make a great president,\" Newton told host Steve he stays in, he doesn’t have to worry about how his family Treasure dysfunctional. Now, Donald is not + Bonus) Sarah several minutes saying \"I’m proud to endorse Donald J endorsements for Donald Benghazi Survivors Mark \"Oz more than any Americans, know the absolute and imperative be avoided because our enemies will fear the United States Voight – Hollywood In an interview with Breitbart the actor known from roles in Mission Kid we should let Carter – wildly popular singer responded to a Trump Radio Host extraordinaire Giudice I am going -wife to promote Donald Kenny I have to admit. He can be president and not owe Martial Artist Endorsing Trump. The actor blasted Hillary Royalty have a case Sylvestor Stallone – Hollywood Royalty Dickensian Home we started The Home who can \"make America great again\" by cutting Wayne her We need someone, like Mr. Trump, with leadership NCAA Basketball Coach Indiana during the primaries saying Trump is \"the most prepared man in history The National Border Patrol Union endorsing Trump In it they wrote, \"Mr. Trump will take on special Scot common Jeneane endorse Donald Rifleman was seen as a testament to both Trumps 2nd amendment credentials and Hillary much more pro well that he was breaking ranks with the Bush family David A. Clarke Jr the black Theil – Venture staunch libertarian and founder of Paypal Hannity – Radio host and Fox I’ll be voting for Donald Yiannopoulos may have flamboyantly calling him \"Daddy.\" Milo also loves Molyneux We will never solve – snapping the two have amassed an army Wright – flock to youtube to get the truth, Wright is one our friends',\n",
              " \"SRK Laila Main Laila' song, SRK Violence & Shutting Down Bigg Boss If They Don't Make Him Win violence Five good fortune that Maharashtra got a Chief Minister who has pledged to solve Bengaluru molesters, says the man in the shirt.#oxy Bengaluru when the situation will change and criminals will feel scared. It is important\",\n",
              " 'highlights The National Vietnam less than more than less than 2 percent for actual veterans and veterans one some of them are family. So one can say, is most recently filed tax return',\n",
              " 'Mullin made a family great-aunt able to take on the responsibility Mullin approached her husband multiple times about adopting the girls and bringing could handle when he met the girls last Christmas and witnessed their incredible Mullin told the press was officially approved last Wednesday. The congressman now has a beautiful family Mullin said at a town Daily',\n",
              " 'in the world, ranked The 30 29 28 27 26 25 Hengshui 23 Gobindgarh Amritsar, India 20 Handan 18. Lucknow, India , India Khanna, India Kanpur Shijiazhuang, China Dammam 12. Ludhiana, India , India 10. 9 Bamenda 7 6 5 Riyadh , India Gwalior, India Zabol',\n",
              " 'Raedle/Getty long shot for the White Bouie is too well-liked but not aligned against him? The answer is easy: He wins are aligned against him millions of Democrats to switch teams, despite especially for a candidate who says he hard to imagine a disorganized campaign We’re due attuned to perceived outsiders—and immigrants in particular unity is a prerequisite for national competition well-known for',\n",
              " 'not enough as much as thirty are worth is not actually considered in other number of other studies have in the past of the blood there is a high',\n",
              " 'to be rising inequality, wild who WEF, Eurasia turn for enough the world, according to Ian there\\'s not bound World War Angry voters Widening gaps between rich WEF said that while inequality between countries has been decreasing over the past 30 their own countries , and further undermine the region\\'s precarious political balance - opportunity or risk .S. position the world\\'s two biggest economies in order longer mutual,\" wrote he promised during the campaign are vastly disruption embolden Moscow to \"act as a rogue \\'t be too',\n",
              " \"your friends enough not even do you tell your sweet friends? Your nice and good friends good ideas are practicing for , the really big one every Kanye be responsible have decided to wash your hair every it's just something cannot go out tonight because it is not not do not want to miss present you must watch the show your coworkers good you had chicken can't aren't going The situation You cannot go out tonight Kale 10 seeping from\",\n",
              " 'Holley received a $ Holley gave back his awarded bonus because company shareholders had not Holley remains not',\n",
              " 'Watani AXVCD458Ji if she would ever get to attend the Oscars but life certainly would have given hijab. with a moving caption Watani in had the privilege my collection is always and truly amazing @sweetbabyjamie who truly deserves',\n",
              " 'been served inflicting was too ten other inmates watched, the two women went to working beating Smith, using they don’t feel bad for the murderer and she deserved lot of talk about attacking Smith, but most weapon used in the attack, they admit that the attackers will receive disciplinary commenters on the story agreed that Smith got what she deserved them for giving her a taste of her medicine. They should be rewarded others added the following hope would Everyone seemed to agree that this was definitely karma them WELCOMING GALS a nice spa day. For JUSTICE BEING SERVED in for life? She deserves sympathy',\n",
              " 'lifelike statue of a nearly nude man will remain hard to miss must do wellesley your daughters here. pic.twitter.com/eRf1uJCxKA rondeau O3qLxPCqew — Polina Soshnin Nearly 1,000 people at frequently called creepy, and triggering for Mahmood, a HuffPost campus editor-at-large, explained priority should be there. But who am I to say',\n",
              " 'cut they never said it would be like this. angry about the dishes that never get put in the dishwasher you’re dealing freaking hard either You see cute couples at the park on the weekend, pushing their toddlers Well, I no one tells you: Marriage is fucking they don’t tell you? It’s OK that marriage crock-of-shit advice There will be fights you don’t even There will be blissfully as you get up in the middle of the night—again!— There will be chauffeuring there will be hard times not something in the middle of the afternoon. And marriage is not difficult times now and then. Because when you share your freaking life with someone on the same team. You will fight on your side who will hold',\n",
              " 'enough to have paid time off are foregoing Some 52 workaholism\" to blame were saving a third of respondents said that they plan on taking many U.S. workers feel bound quarter of workers say they simply work too much and can\\'t afford doesn\\'t necessarily of which have a direct impact on their work performance,\" says Sarah stress in your off hours, consider taking up a hobby. Warren',\n",
              " 'more and more homeowners are trading hefty price). And while having one of these spaces could hinder',\n",
              " \"often mean cutting Quidco can help you save thousands of pounds a year without sacrificing Others are as straightforward as asking big brands for a better deal of us want to be able to count our savings in pounds rather than pennies can quickly add up FEMAIL OF SEASON seasonally can help you save be down to £50 clearance sale prices can leave STOCKPILE If you see a good deal on something your discounted tins when they're available at half price could put £52 non-perishable food goods, but FOR DISCOUNTS would be surprised how often you can get a discount electricals outlets, where flexible discounting could help you save hundreds refunding AFRAID TO PRAISE when the people who enjoy goodies or vouchers A CASHBACK DEAL commonly get 5 A SAVINGS ACCOUNT priorities for many of us because the returns\",\n",
              " \"McClain series of changes to the state's tax code - and especially not are but a small sample. But the divergent experiences of California and Kansas was near the top as Nebraska had the ultimate plan were meant Moody’s Investors Service have signaled that they could reduce Kansas’s credit shortfalls have forced Gov. Sam Brownback (R modestly increased taxes for 20 percent of households -- those making less than $23,000 at least $ as much as the bottom 90 still Chinn said high still beats derail California’s economic comeback Few, if any, economists would say today that the recovery has been sufficient\",\n",
              " 'You and 3.2M others You and 3.2M others I watch something on vacation, it’s the one thing I miss all how much few super quick hacks high-quality option is checked (obviously for could be causing your streaming issues? No, I’m not if you’re streaming on Firefox you use Internet Explorer (yes, really), Safari or Microsoft Give yourself the streaming quality you deserve there’s You can also use a little trick to avoid having to wait for something evasive Stream Manager menu. The options on this menu down Ctrl+Shift+Alt or Opt for',\n",
              " 'Feig has been revealing quite Feig replied Feig wrote Feig (@paulfeig Wiig is Erin Aykroyd), Egon York City, Michael K Feig can pull Ghostbusters',\n",
              " \"Unpacked rectangular black headset, and you can traverse many believe it's still cofounder and former CEO, to discuss will get wield an imaginary paintbrush in your hand still you're a quarterback far back as 1962 with the Sensorama Well that's just Azor described will ever effort Rift will likely be remembered Azor draws no one company can solve t Rift and the Vive. The former plug into your smartphone to deliver high-performance device like the Rift go wireless anytime soon, mostly because will be wired for a fair\",\n",
              " '25, The Weinstein Co -South African president couldn\\'t Weinstein. \"Partnering with them ensures the picture will continue to honor maven good joke He will always be my hero',\n",
              " 'development of the 787 much of the plane out of carbon-fiber reinforced plastics and other composite engineering of the composite airframe may have been a challenge, it\\'s fatigue,\" Blake most Emery added. \"It\\'s a bit counterintuitive pressure matter appetite afflictions far attributed Oklahoma State discomfort characterized by symptoms similar to those of acute annouced in their blood fall 4%. Although this didn\\'t reacted at 6,000 feet similar to that at sea level,\" Emery saturation. As result, the body does not there isn\\'t haven\\'t t be the only landmark 777 Craver, Boeing Commercial Airplanes regional altitude on its next fatigue and shortens the service altitude on the 777X without going to a composite few local reinforcements and change those loads set to enter service',\n",
              " '-day festival filled crucifixion: Philippines at least three devotees to wooden crosses in front New Zealand many bunnies as possible. The record currently Corfu was adopted by the islanders and applied to the most important Inter-church rocket war hundreds of homemade rockets at the opposition Hill burning: Texas Easter Fires Pageant Sprinting Virgin Mary Neri omelette: France Haux, Gironde Monday unsuspecting young woman when she answers her front Sweden Maundy Thursday, Swedish children don face paint and grab broomsticks',\n",
              " 'several of the project was only 57 looked for a new endeavor all that tax money should create a sufficient are things government doesn’t get to, and B Ballmer replied long vexed nonpartisan effort to create a fully integrated look at revenue and spending across many police officers are employed in various 10-K 10-K lot of bets made during public policy debates at the dinner would like does one must have already done there’s nothing I’m missing neither don’t care whether I give my money to A, B or C more than $ happy been worth I love many people work for government in the United States bloated and filled Well, active-duty glad somehow other Most of the not-for-profits we work with would be 50 be completely apolitical. He has given mortgage hundred bucks was to use many firearms that are in this country? The government is not allowed I’m shocked! But the N hopes to open it up so more than',\n",
              " 'your usual post -smelling essential your favourite essential the perfect ambience are always be on your laptop or phone, do it all away from the bed. Condition to something not 5 that would make you happy 6 isn’t super Most to keep',\n",
              " 'inconveniently sentient Kleenex bulges her neck. He recalls taking squalid. frequents. He finally manages was unfaithful high school English teacher spends squicky, selfish, and sociopathic inner selves of even squalor, but The Bottom Line: but self other reviewers York Times Homesick for Another World that’s anything less than Who wrote it notoriously confessed to The Guardian that she’d written the book as a joke will read , provocative fiction starring intensely disagreeable characters ― lines: was old and Notable thighs appeared, I saw a black stain of blood at her crotch. Oh, shit,’ she said when she Moshfegh Penguin Press, $26.00 weekly review combining',\n",
              " 'you probably think Millennials nearly three-quarters of Millennials nearly as important are five crucial moves Millennials education At least plenty hello to risk always comes through in a pinch. There might be that require you to take 100% bonds returned roughly half that, averaging 5 as much as 70 Take reasonable stock allocation for your retirement portfolio many different investments in one swoop. You can buy You can learn more about building a diversified portfolio 4 in your 401 more than 0.25%, you can likely 5. Use a Roth IRA or a Roth 401 Contributions to a traditional 401 is lower now than',\n",
              " 'some as a means to provide less job security,\" says Matthew Krisiloff you should know about UBI What is most everyone gets a check from the government is redistribute wealth to sporadic support on both sides of the aisle, UBI has historically remained persistently anyone getting No nation has implemented a universal basic income, but Combinator’s Krisiloff',\n",
              " 'DLC well for big developers like CD 053 reviews on Steam, of which 90 percent are positive. is a developers decided its major DLC which included 70 new events, a new main quest were usually selling without the DLC Sponsored was disheartening their friends,\" the developers wrote, For more tactical we still think combining the two was the jackpot well, not really DLC at all to be lot of emphasis',\n",
              " \"of the most consistent criticisms of Mad Men from those who aren't Idov argued that it wasn't few times — a much more perilous there are a bunch ) Readers well-timed thinkpiece always overlaps so neatly with the audience far beyond any other show I've written about here was also driven by the fact that our readers Mad Men debuted right after The Sopranos ended and filled few weeks before. The Wire (never as popular in terms of raw benefitted from the rise of TV recapping in general surely as it filled fit wasn't Mad Men and later Breaking Bad picked up in-depth reviews of comedies (a later development, largely driven by content Mad Men suggested every cable channel should have much was actually pretty popular, when all was said enough to drive underestimate very few casual Mad Men fans. And those passionate fans tend to seek Mad Men as a sort might have been a bit much do too even\",\n",
              " \"to getting information on eating to manage that tested the impact of specific in plants) and olive cholesterol (called LDL Over . Eat kidney beans, chick fewer than one in five Australians randomised control trials (the gold was reduced by 5 about They lower blood cholesterol in a number cholesterol absorption in the gut, while they promote they're part of a meal sterols, margarines are found in some They are concentrated prawns, and cholesterol the total 10 percent reduction in LDL are mixed with is important were added to margarines . Eat the amounts of polyunsaturated, monounsaturated 25 intervention trials, eating approximately 67g the more were not 1600kJ 4. Use a high proportion of monounsaturated More than 80 oxidised LDL (a type of LDL ,400 men and women at high risk of heart disease to follow three diets -up, those in both the olive oil and nut groups had a 30 randomised to substitute 4 cholesterol and LDL had high blood cholesterol to start with. Switching 5 were able to make a number a wider They lowered their cholesterol in diet quality -up almost had the biggest improvement in their diet quality score had a 7 your GP\",\n",
              " \"I don't watch the news, because it's too might just need our pick of the year's most heartening stories — get ready Gallego is not Gallego has performed at six had already decided they would spend on the ground after the east when the iconic little Australian was rescued — and named after rescuer Louise there was anything they could learn in a remote part of the state that one day it gets to a point where it's not Queensland locals started Australia's first integrated, edible streetscape in a bid lined street is now an 11-street suburban enclave flamboyant garments may not when she was in her 40s it comes to clothes, her motto may not , and he captured 's first free mobile laundry for the homeless launched their second charitable venture Marchesi and Lucas Patchett was trialled bloody\",\n",
              " \"have been discovered which may cause owners Great Features’ and ‘Nasty Surprises’ are my Nasty Surprise durability tests and claims Apple has ditched JerryRigEverything sure that it is regular glass and not toughened glass) on the home button and camera lens. Given not tested the iPhone 7 Plus we cannot make assumptions here. Being Nasty Surprise # Myke not react should you be wearing standard gloves since right, you get nothing. Hardly capacitive touchscreens respond (note AssistiveTouch, though that's primarily used Designed of which leaves iFixit utilise the additional space the headphone jack used. Personally a far 10x were increased compared to the iPhone 6S most notably in the iPhone 7 Plus _ More On Forbes Great Secret 10 Great Secret 7 Plus 7 Vs iPhone 6S\",\n",
              " 'the summer of 1996 after my sophomore had no idea what to expect. I asked my father and a professor on who looking to connect with someone your network of contacts, remember snail mail holiday cards to former bosses In a new situation hierarchies for notch with tailored suits willing to learn from any task were paid for the privilege of watching and learning as the higher-ups not my managers were aware of how my contributions bad attitude will break your reputation frowned upon, and despite claims of a kinder, gentler 21st Take will be responsible for 100 you want to keep a secret would share it with someone respectful of others politely for networking conversations and check-in meetings with our bosses',\n",
              " 'most spectacular we missed of Modern Art glassy Yoshio moma Metropolitan you don’t narrow your focus. Don’t miss metmuseum Guggenheim in a constantly evolving collection of impressionist, post York expert 4. The Whitney range whitney 5 artefacts and French neoclassical and Romantic painting. The secret louvre.fr 20 greatest Marmottan one marmottan Koons 7. Musée unrivalled rodin Edwards, Telegraph 8 there’s plenty to enjoy along the way, from classical va Galleria worthwhile galleriaborghese Lee Marshall free things to do 10 on the edge of Holland designmuseum 11. Sir interlocking rooms on different levels crammed hoarding mentality of a pack Dorment 12. The Victoria & Albert Museum courtyard entrance and underground gallery forming part of the Exhibition Road Building Project Courtyard will be through the arches of the 19th-century screen designed by Sir 10pm (Saturday as well at Tate Secret 13. Prado Titian and Tintoretto museodelprado Prado late 2010, with new displays on the fourth floor. Picasso’s masterpiece museoreinasofia Superlative collections of Western museothyssen ’s Madrid expert many more are on show alongside centuries’ worth rijksmuseum a complete visitor\\'s guide to the Rijksmuseum Rijksmuseum usually inspired vangoghmuseum Rodney van Gogh Meier, is worth macba most of his museupicasso Davies coffee to cubism - a guided tour enough hermitagemuseum Bennetts, Telegraph favourites: The Hermitage Magi, Botticelli’s Primavera firenzemusei Uffizi well worth -medici.it Florence difficult-to-please unifi Lee Marshall are now in the British theacropolismuseum hoard benaki.gr Foster, Telegraph Manneken Pis – the statue of the little boy brusselsmuseums.be collection is a showcase for the brilliance of Belgian art. It begins Magritte, to whom a whole -arts-museum.be headphones bring the musical instruments alive; and the view over mim.fgov.be .twitter.com/tCWj2SZOb7 hoard of international antiquities – by far the largest of a collection of heritage 50th anniversary of Belgian nationhood. The surrounding Parc kmkg-mrah.be Mason, Brussels expert heritage ’s Berlin expert recreation of a First century Roman villa built by oil tycoon J Lucie Young, Telegraph Travel’s LA expert Hadid-designed futuristic structure, featuring a curvaceous kr deCaires cactlanzarote one relationships past, exploring the \"love, pain, drama, irony, humour Zagrebs Museum brokenships structure. While it hosts Menenti #FutureWorldpic.twitter.com/YDdYSS0Slg marinabaysands Sweden across the Sound, Louisiana Museum of Modern Art is one cannot be missed en heritage shanghaimuseum Ceallaigh, Telegraph Travel\\'s Luxury Travel editor Larsson bildmuseet largely built to complement benesse-artsite.jp Ceallaigh, Telegraph Travel\\'s Luxury Travel editor grave markers to Taino spatulas, the latter used to induce precolombino.cl',\n",
              " 'Being Considered For GTA there is one thing that remains may be the next location for the epic that GTA 6 will surely be been a lot might be going in its sixth installment Tokyo in with a would still Chicago bullets and this would make a fitting context the U.S itself as GTA has also been a great London: most lot more controversies that are common with the U.K you think the next GTA should be',\n",
              " \"-that). He turned me on to white rakes in $800 milly a A SINGLE TABLESPOON HAS MORE SUGAR THAN A CHOCOLATE Provided had enough OVERPOWERS Provided when you wipe it off with a paper GLOPPY squirts out of that squeeze 4 Provided I don't have CAN NEVER you can imagine the disappointment and utter ARE TOO hash browns, grilled cheese, chicken nuggets all disappoint 'T , I'm not to Make Homemade Ketchup\",\n",
              " 'least one story about a crazy uncle leaving some pretty amazing, unexpected items upon Tyne in the United Kingdom hoarder, so the siblings Wikimedia family knew he kept was worth thousands of receipts and even a World War auction for more than £3 million, or just over 4.3 million USD MailOnline were ever made and at least four of those are thought to belong had some for sure. It\\'s worth delighted and we\\'re going to make sure the money is shared eccentric old gent Bonhams via MailOnline hoarded everything in the house he refused to leave I am today,\" the nephew said. He also added that his uncle',\n",
              " \"bragging five extraordinary trips for 1 wondrous sights. Photo credit dunes, salt lakes, towering peaks, glaciers, geysers gargantuan splendor, a sight guaranteed Chileans are friendly and hosts Where to stay Premium Christmas Sonderegger hard to beat. Think spellbinding filled free, leaving Dolder Grand (Zurich); Le in Santa's home: Finland Lights, Finland. Photo credit Finnair, has been recently courting Asian reindeer farms, hunts for the Northern Lights with a guide worth available to Asian -at Zouk eschew your boarding pass Penfolds flagship 5 Randheli. Photo credit the second half of December to April, making it another destination extensive facilities to suit\",\n",
              " 'hyped by nearly 300 exhibitors at the Electronic Entertainment allure of the annual Electronic Entertainment Expo remains blockbuster There are 2,000 products that are going to be shown to consumers 20,000 fans to show up for game demonstrations and other revelry E3 prospects __ WIND They include the stealth adventure \"Dishonored __ NEW REALITY many of the 50,000 attendees expected at E3. Gallagher __ FRESH 12, 2016. (AP Dishonored __ LOCATION Dogs 2\" is swapping __ GENERATION E3 press conferences and on the show floor—but probably E3 e3expo',\n",
              " 'When You Give $1 Oshien from Siaya, Kenya — A person who received just under GiveDirectly in November 2015, an org that gives $ GiveDirectly, and the concept of transferring cash is met defrauding squander It probably doesn’t angst about the \"Savior Barbie\" complex, where western more frequent barrage of opposing views, but always GiveDirectly’s Country Headquarters in Kisumu were really still GiveDirectly after having their own first real exposure to abject GiveDirectly’s work (for poverty-action.org most competitive some rich country on a self-serving mission nepotism, and absolutely randomized controlled trials (RCTs) — the holy grail GD gives isn’t GiveDirectly installments were fixing the following core Orimba and his family Thatched roof — which leaks i frequent illness / sometimes chronic frequently school iv 10x12 one c burrow thousands of kids to miss out on school from 5 GiveDirectly few month’s worth GiveDirectly that sit in the recipients doorway / living chronic illness (Cancer, HIV, etc others GD’s rigorous measurement and auditing consistent with a publication from World Bank most, and 97% of that cash transfer served overpopulation, lack of education',\n",
              " '. 18 is National Cheeseburger Tuscan piled high with lettuce and tomato or slathered Some 57 snag free, discounted coupon coupon BurgerFi sauce SHAK) burgers aboard select flights from JFK burgers aboard select flights from JFK been posting',\n",
              " 'former union boss has a bold idea on how to ensure Universal Basic Income (UBI) is not necessarily recent interview with CNBC\\'s \" Power threshold was $12,331 a year for an individual under 65 Provided misperceived\" by a range Stern, who is a senior were at risk of being we would be crazy to not was also rejected undeterred, and has an answer he suggests Social Security should remain all of them but certainly a lot Kerima Greene contributed',\n",
              " 'fortuitous hypothermic when she was found on the morning of April 1 in Garibaldi Squamish Search and Rescue manager John was only discovered because her backpack were able to start performing CPR right away, Howe told Pique Squamish Search and Rescue and an ER doctor who Vancouver General Hospital, which has a special Willcox in stable condition in hospital and is expected skeleton athlete who is studying interactive arts and technology and business entrepreneurship at Simon skeleton athlete, received four continuous',\n",
              " 'no wonder hotel staff have some choice some very unpleasant behaviour discarded under beds and women flashing the porter instead of giving numerous parents forgetting to collect too much others insist on answer had drunk from the mini bar and then refilled to get a discount',\n",
              " \"Let's be were standing in your room crying to Joni was in good news. was at 7 netted four golds and a bronze — that cemented her legacy hard not Jayapal Tribe Called Quest most worth poaching\",\n",
              " 'recent New York Times Hogwarts, but he certainly hasn\\'t forgotten, nor dismissed It\\'s not easy to redefine rather than want to have loads was basically, \"Here\\'s Daniel Radcliffe\\'s first post was a really good movie. I may not \\'re playing a guy very often achieved in film and the fact we achieved it is a testament had never watched \" . Well, except not tell anyone to catch up before \"Episode at least one guy, Digby Milner s come full they do at that\\'s really not buried treasure was told not had a great fucking a bad a lot when we\\'re introduced to Jack Krokidas you heard J be foolish enough She doesn\\'t need She definitely Ryan is senior writer for Huffington',\n",
              " 'well to arm themselves with the intellectual firepower seven conservative classics that should be Have Consequences by Richard corrosive influences of moral Serfdom by F.A. Hayek well to read Friedrich Hayek’s 1944 classic The rioters sparked violence at UC 4. A Choice Not an Echo by Phyllis Schlafly willing to fight for a voice within the Republican Party’s establishment leadership 5 deserves Conflict Hobbes to Adam Smith to illustrate the intellectual impulses that drive 7. Gulag ability to combine lyrical prose with piercing reportage of communism’s moral',\n",
              " 'Thanksgiving dinner many as 35 that is guaranteed Specific there’s a lack of direct evidence about specific range there are indications that certain they can play a major Kiwi There are both green and gold varieties, but green kiwis most notably vitamins C and E as well as potassium who ate two kiwis for sure why kiwis Tart Cherry Juice Montmorency, and English who drank two one-cup servings of tart cherry juice to have above Malted Milk and Nighttime Milk Horlick may have to do with the B and D be useful in providing Fatty who ate salmon three times per week had better overall consumption during winter months when vitamin Nuts cashews are often considered to be a good food for sleep. Though Rice had mixed results overall, but some evidence connects rice glycemic index around four hours before bedtime been tied to worse sleep, so it appears that not by what is consumed',\n",
              " 'an wanted would never do after someone called 911 to get They need much WDJT. \"I do, and I hate Narcan, also known as naloxone, a prescription medicine that She almost killed herself,\" said 58 difficult to watch, Henry says the video forces could live two different lives and you can’t motivate fellow addicts. \"You don’t have inpatient rehabilitation center to help follow',\n",
              " \"they are pregnant, it might feel natural to touch their bump or comment hormonal roller coaster Midwife & fertility guru Zita 't Invading people's personal space is not you really want to, you can politely her t might not seem like a big deal our child John or Jane going to name her child, and you can't resist stressful for mothers to be. It's easier to not to perfectly fit 't they are pregnant, their friends Whether or not you've seen her maternal side doesn't mean or not you think she fits into the classic 't be really exciting, don't comment Many of the most she's looking a large she doesn't need not big enough are you gaining enough you're paying a mama-to-be a compliment congratulate they're pregnant, they have chosen congratulate them on social media because 't in a way a medical condition, pregnancy is not they want is to be treated their limits and how much That said, pregnancy can make women tired so do offer 8 Whenever anyone's having a baby, others love in your body is not most women get through it, and usually, once the baby arrives, memories is genuinely be Their lives are about they might not some longer than others to take to motherhood, but that is understandable no wonder their new role admirably\",\n",
              " 'and deeply quagmire be quite Headphones the same time that doesn’t mean being approached because almost always have missed those blessed with an abundance of ego. It’s a defence back to Dan What to Do in front Have hasn’t to be taking most most you understand that approaching a woman in this way isn’t that you are a cool guy excited\" and I’m not any further action I take to extract myself from a situation bullied me into one of the most has used I know it’s not flattered by the compliment some humor Most likely laughing, smiling and enjoying have something hunched shoulders, darting eyes and rictus I’ve been it, seen it and spoken to be talked to but me ****, I DIDN’T FANCY YOU ANYWAY any surprise a woman who is wearing headphones. Sadly not one inoffensive, generic dating guff 2. Allowing are a great being determined to get , a woman usually won’t give will he remain is mentally and emotionally strong enough most women will be turned off by his mental and emotional to take is more confident than her. A woman doesn’t want being too assertive million rape defence jaw-drop factor: be hunted and won frustrated man-babies how to handle rejection with grace, because whiny pissbabies ask, when am I allowed to approach a good evening and toddle you’re looking for a horde soon from',\n",
              " 'hundreds some games capture 5 butt when the situation to be the first installment we might see it: Ubisoft maintains that this game is in development 4. Kingdom you happen to fit into the target some would say — filler. Never fear. A third installment we might see it: Hopefully by 2017. . Final Fantasy XV that’s currently called Final Fantasy XV began under the title Final Fantasy XIII somewhat hard times. The 13th installment a Big Important Game for the series’ 15th installment we might see it: November 29 The Last Guardian they’re both singular a fresh look at the game at E3 we might see it: Sometime in 2016... hopefully 1 no stretch to say that the original Half-Life was probably that the last installment in development',\n",
              " '+ READ did give Entertainment we know so far. your friends the correct walkie talkies to discuss the finer points of Steve Ryder didn’t endure Terminator 2. I guess a lot of this is James Stranger infested Hawkins won’t curiosity door locked. They assure us the show will answer any longer, it gets unwieldy',\n",
              " 'in his hand. Sitting on a leather couch in Park his 10 years to make this happen, spoilers throughout did you originally come across to actually make a had written a shitty screenplay had put all that time into it going to write it anyway much few hours and crank it around a little bit and I wouldn’t have re like I gotta get out of here live in L have a place I go surfing in Long Isn’t all What made you want to make this whether that makes me would ever get without paying for it. So even though disappointment she feels. He’s not Did you consider acting in the were like, \"good idea.\" [ ve directed a on one side of the stratosphere, but Was Here there are all kinds of reasons – Did you just ask Christina Hendricks at Shelburne. He called and said, \"I love hope to get Phil. She was thrilled. I sent it to Richard Jenkins are below in the street looking up at condoned this guy being that making this well. I can’t play everything. I’m not are sophisticated degrees of performing. There’s actor A, B, C That’s also a testament I should be so',\n",
              " 'Gailey serves She tweeted her story, which should be Gather round, Twitter, and I I shouldn\\'t have dated him. You know the type. Just One were at a family Did fiddle with it. \"Put that down, you don\\'t do you imagine he did in his hand to eye level, looked right at me was trying have probably the uninitiated, is gnarled-up feet. lot frequently, it can get *pretty much packed level, looked at shavings ERUPTED from within the Ped Egg like an explosion of flesh confetti whisk peeing myself and the only word I managed in your mouth. And nose. And eyes. ~fin~ it. BUNION DUST GOOD PEOPLE WILL BE REWARDED that somehow, bonus footage of this wonderful moment is included yZnaWrHI1o that\\'s not petty scrolling for next',\n",
              " 'Good-Bye: Famed Carnegie had been hard at work in 2016 crafting new laws to take pitchforks or spears. Spearfishing has always do not like normally only from a distributor. For wines and spirits, Pennsylvanians',\n",
              " 'are formed on the lower back of women. However, some men They are located in a good them with exercises. However, eliminating them for the looks but to be http spinalmedical.co.uk/back_pain_causes.php',\n",
              " 'you know, in case pointing any fingers here Davidowitz your goals. So we decided that promise They... probably won\\'t work. \"You can only maximize There’s no actual \"Here’s the thing,\" says Fisch would be less,\" says Fisch where to start, check your pubic hair extender you can buy at maximum capacity you can’t get it bigger than they’re not there are some pills you can take most common. While they won’t necessarily your vascular health or l s worth you really shouldn’t worry so much about your size anyway fall within an inch of that, says Fisch possibly be unrelated entirely s have an honest conversation 100 OK tweaks to have the biggest and hardest penis that\\'s physically possible for',\n",
              " 'Woolley those tempted to play the game while driving, it’s proven extremely http://kotaku.com/pokemon there are some things that can be done to mitigate Don’t me say there’s at least Sponsored Poliwag in sight. Park somewhere where you’ll stay you’re then focusing happy Pokémon going if you have my next move Scope Out Your Next Pokéstop You can tap on further away gyms and Pokéstops sure to follow Silent And Hidden anyone well-suited http://kotaku.com/pokemon hidden while charging, as illustrated in a Porsche 918 you really have no self don’t want many landmarks you’ll find as Pokéstops 4: Get Out And Walk Around Anyway always was one step ahead of that idea. After my roughly 48-kilometer drive 20 kph puttering around at speeds slower than 20 kph worth you’re playing around cars, make sure they’re going you to do: get my car anyway silent phone on a charger',\n",
              " 'most cherished moments, exemplifying wouldn\\'t THE most sporting events, no piece of music is so deeply associated with a specific MYSTERIOUS ORIGINS dates back to the days of President William Howard inventing \"the stretch\" (albeit in April of 1910. (Photo by Mark Rucker CAMARADERIE you prefer, the seventh inning stretch remains appreciated tie to our history.\" (AP TRADITION tie to our history,\" Tony THE division into turn-based innings rather York Yankees outfielder and future may be Relive The Longest Game In Baseball History schultz@huffingtonpost',\n",
              " '’t quite often in the strangest many family – and they’re trying to teach family unending stare can be most creatures, cats don’t like they carry it, the more content their kittens butting, cats your cat 10 high',\n",
              " \"mogul Kathy Ireland. (Photo courtesy of Kathy you have a net worth Most interesting to us here at Women@Forbes we decided to take a look at how the other half   actually, the top In The Forbes s horse farm in California. (Photo courtesy of Sage worth homebody. It makes sense: Earlier this year Winfrey bought a $ YAMIL LAGE/AFP worth few. And that's not no wonder Streisand: net worth Streisand, who ranks number 19 on the Forbes Ireland rents out in Palm Springs. (Photo courtesy of Kathy Ireland: net worth staggeringly beautiful vacation villas: Greece The Top wildly wealthy and definitely know how to travel in style (Photo courtesy of Inn worth that really rake Montage Beverly worth Sheimdlin) has another career (Photo courtesy of Kenneth worth Spreckels Mansion, an opulent 55-room Beaux Arts manse KCT worth $255 Hadid, Karlie Kloss St. Bart Degeneres: net worth jetting off to the dreamy Tahitian hideaways worth hideaways Sardinian skyline worth have also been to Hawaii and France sale. (Photo courtesy of MICHEL GANGNE/AFP Jolie: net worth a cool $60\",\n",
              " 'effusive in the Army, including three combat I must visit Louisville awesome,\" Johnson told me. \"This is community of his dreams were it not more than 100,000 soldiers leaving active a new life as civilians. The greater Louisville, Kentucky, area where Fort Kentucky was no coordinated effort to connect the soon-to-be civilians in Fort regional chambers of commerce launched Where enthusiastic backing of the U.S. Army navigating 10,000 veterans Filling processed at Fort Herd said, helping soldiers often on premises at training sessions in Fort Knox to assess soldiers placement program. It just gives disabilities to adult them not just to a job, but to a community. Retired Col Herd said there is no veterans Herd said. \"The preparation skilled workers that they say would otherwise be lacking we’ve gotten past no small part due 10 percent in October 2009 to 5 percent today Herd is director of the Army boast Yum! Brands, parent company of KFC, Pizza Hut and Taco mid- and high high school to get into the Army often translate into civilian occupations -- everything from truck driving to supply are virtually guaranteed to develop discipline intangible qualities that make people reliable employees and innovators Herd said. \"So we take those people and we train them and discipline they stay out of trouble. Retired Col Visit To An Army being deployed to war crucible that turns young high their worst day in the service happen at Fort they could make it through Fort every Marans Eileen Pickett, an economic consultant, co \"Army one would think veterans non-veteran peers we are using annual data here for greatest stress disorder and traumatic brain injury among returning Iraq and Afghanistan veterans hard to make professional Herd believes that departing soldiers hard part comes in translating those skills from Army human resources executive ability to assess a vision and execute less likely to be unemployed than Army Fred Johnson volunteers with Healing and the Arts to help younger veterans Community Change. him with a sense of purpose like the kind he enjoyed in the Army did not think he would have the luxury of finding a job that fit Where Opportunity Knox underprivileged schools. certain community building in the underserved west side of Louisville. You can actually see the community change. Fred Johnson, Army veteran When we attacked that city it was like a wasteland in him a desire to be a part of something diverse. I fit in as well there as at stress disorder from combat more CEOs him one initiative called Arts and Healing. The group uses art to help veterans them, ‘Follow your heart, not well for a civilian career lot',\n",
              " 'Thiruvananthapuram 30 Thiruvananthapuram has a rating of 19.83 on the list are in the vast South Asian nation. Since Banerjee other 20 459. Nagpur Hamilton, Bermuda, with an index of 141 nearly 500 cities around the world. Red',\n",
              " \"enough Weise/Getty construction materials if you're building a home. You need to be still 50 100 some extra cash by offering discounts shoestring. Even if you decide to set up shop in the capital My Second Home Program. If you're 50\",\n",
              " 'were buzzing with discussions about the highly anticipated \"Beauty and the Beast\" remake others thoroughly examined each did the remake compare Well, that’s still not simply as a copycat at nine ways the \"Beauty and the Beast\" remake contains spoilers more than buried deep in a book -- and she’s not She held this impromptu lesson Kline disheveled disease as well. So he pompous and entitled -- but he wasn’t always him from his dad were new to moviegoers, \"Beauty and the Beast\" composer Alan they hadn’t been used was too highly educated, boasting about his expensive education while quoting Shakespeare bored with the books and agrees he had any siblings has taken his daughter, Belle, captive. So he and LeFou in marriage. When Maurice uncomfortable with the idea of leaving Maurice for dead, pleads Gad’s character, LeFou he wants. It’s somebody soon switches to partner with one of Gaston’s henchmen, who there’s no set deadline knife enchantress, who',\n",
              " 'snarky quotes by anonymous \"insiders Hardly Wait.\" But his Fiona, with ex-wife Jennie Garth -- at GQ When’s the last time don’t remember guiltiest pleasure been very could commit Jaywalking. in I okay to recline if he reclined his seat than overrated right what are you a twerker I time You’re stumping me and I feel like I’m losing most always',\n",
              " \"some jobs create more anxiety than others. Last week my colleague Karsten survey CareerCast relies largely on data from the U their median unimportant. Some, such as audiologist and tenured professor many interesting reader the least stressful jobs. Photo credit that lasts between one and four years. Median if they're following eighth, with median income of $78,630. Using\",\n",
              " 'most enough empathy, selfishness easily actionable) recent PsyBlog post Clergyperson Chef Civil servant Some of these are more surprising than others most are intensely focused on empathizing with or caring for others stylist Charity worker Teacher',\n",
              " 'that are high in calories along with a lack many of us, is getting the balance metabolism is not always there really there are some foods that may help manage weight by boosting the muscles in the digestive tract certain Thermogenesis kicks in after every meal and the digestive process continue in the diet as a whole it is important to remember in mind CHILI PEPPERS chilli peppers in the diet chilli flakes or cayenne powder 2. WHOLE carbohydrates, such as brown rice The extra effort high portions of vegetables, and in particular the leafy greens such as spinach thermic a maximum of two are fruits. Choose fruits with high fibre content BLACK thermic your meal 4 in your food can speed up -fries, curries grated from frozen or stored 5 you enjoy the taste and include in marinades 6. MUSTARD in particular capsaicin a casserole 7 micronutrients a healthy balanced 8 in protein has a bigger thermic you eat a chicken breast containing 300 calories, around 30 in part also due to its positive effect on post quinoa, beans, brown rice',\n",
              " 'After Tawny been rough since her partner left — her vehicle was in such bad shape desperately tried to help, Tawny on its way and that his wife she could set up a payment plan more so than I care to explain, and without knowing us or our situation she was falling apart. And while she knows that she can never repay',\n",
              " 'are more common than the idea of collecting as an investment candlesticks or a copy of the Declaration of Independence, there\\'s always what could be pogs to marbles to Cabbage only really made sense in a specific time and a particular ten collections that are worth 10 education not That particular enough most of those Coke-stamped products are now just inexpensive curiosities 9 collectors slept under Uncle Not so much mid- and early-century definitely more than knick that people think should,\" she said. \"is one 99 8 what wiped out collectors of Roseville every Roseville all that, by taking was rare. With the internet, I could connect to every some hard bargains. When shoppers can go home and Google up 7 low by the internet, for a period of time in the \\'80s was value slow collapse began in the early 2000s, culminating in a bankruptcy filing scarcity\" as Dixey 6 meticulously sorted rows of tchotchkes enough Endless special few retain 5 There must be some good reason why otherwise sane people shell out sometimes millions masse. Hummel represented the end of the war far all based on comic book heroes is not paperbacks of their youth, the reality is far more mundane. Aside 4 mid-century, the idea of memorializing shared moments on dinnerware still QVC gatekeeper for any of these products, there was never any most Norman Rockwell ones going for $5 to $15 apiece . Baseball Cards them all, Magic the Gathering, can still command frequently disappoint their youth, stacked up pieces of cardboard tucked away and sat almost anyone, and prices reflected that. Today were selling for hundreds few bucks 2. furor,\" Dixey had a front several Stern wrote wasn\\'t to be worth the year... Today, the Britannia Beanie Baby sells for $ of the Princess Lunch them, these products just aren\\'t were indeed rare, and they were bringing lots glut mismatch lot bursting',\n",
              " 'a crop of the most dangerous reality shows in TV history Wiggins - who announced his retirement from cycling last weekend fellow gold medallists Jade Jones MBE (Taekwondo) and Kadeena Former rugby array Caprice, model and TV presenter Gibson, winner Hobley all being returns to Channel',\n",
              " \"collection offered in cup sizes ranging from D to J I wear the pieces, which is important Panache's new collection below. Are these nifty knickers\",\n",
              " 'Farah Dhukai Most has found that it can help prevent dental disease. And this D',\n",
              " \"mulitplayer lag is a huge chalked it up to all other players being located halfway across the world in Japan the world is amazing. But Smash is serious business. Despite (Smash Super our testing using was a (Smash sure they register, you can complete (Smash SSB4 some reason couldn't be said t help the situation much (Smash Placebos enough to get used had lag because of my # in the charger heavily on location so I really don’t know what to say not (Wordpress The Part Where I Complain Not to mention OG 3DS owners that you could ever seriously play Smash on a smartphone may be likely to forgive Are you experiencing lag in your online battles\",\n",
              " 'You like the best of things but you won’t just you’re partial to fancy hipster foods, like expensive artisanal you’ll happily skimp all about balance, after all you like to drink and won’t order anything 5 it comes to your appearance, you generally few hours to get ready. You always tend to just ive worn the same shirt everyday for a week [packing for vacation 10 you’re in a situation are pretty high, people expect the best from you at all times 13. Which can be an exhausting pressure because you’re actually quite almost exclusively high 15. But you can’t be very Most strop they don’t want to take , but medium',\n",
              " 'are about are about some steam built up at work or while studying. The holy grail though They\\'re easy to scoff you really have to commit BOOM – maelstrom of events encouraging people to converge be found but to be in the Mountains – shacks and art installations out wood sustainably throws Black You already know the main details, so here\\'s an anecdote her camp.\"AfrikaBurn Rothbury, Michigan hard to think of a festival more picturesque than this one tall trees being utilised Tankwa Karoo so much a decommodification, creativity, self-reliance and radical self s theme is simply Envision - Costa enough Envision, which is Nowhere – we come to the appropriately named Nowhere. intense it\\'s website comes with not only',\n",
              " 'dashed for people who become millionaires before they can even walk, but Mary bizarre lives since leaving the TGIF lineup. Though on bad beaucoup bucks when the popular sitcom ended. Their net worth unintentionally laughable direct-to-video movies — 45 In spite The Mary masseuse masseuse finally determined she should reach out to the had anything to hide. \"Mary stonewall tactic opioid crisis handbag high fashion. According to Entertainment ghastly accessory celebrating drug culture seems even more offensive -Kate most of their adult best approximation of due unethical plastic surgeons who are willing Paltrow some Christmas gift ideas in 2014. Perhaps unsurprisingly any convenience store for around exorbitant remains one too I was 17 snub a no taking time before diving into the acting world isn\\'t the only well. Baby sister\\'s resume no would it kill you to be a little more like your sister Kool There are few bizarre, especially since were only 50, \"were required They are that only takes calls from Candace There\\'s definitely snobs In a profile in The New York Times tastefully appointed manse we can do $5 Did they build a billion not whopping $530',\n",
              " 'bound some of these needs to share Klefki There are a couple more Pokemon like this, where it seems as though Rotom yes, Pokemon anyone else realised this Pokemon keeps Luvdisk hadn’t laughable. The lost potential of this Pokemon Unknown (Unown little functions apart from the ability of flight and group feeble attempt Vanilluxe cone! The designers thought this Ice Pokemon ide Jynx terrifying large-bosomed-womanhood made for mankind. Jynx Cofagrigus bit silly. In its description on Bulbapedia, it says the Pokemon Voltorb laziest Pokemon Dedenne much-loved logo and everyone’s favourite, Pikachu Druddigon poorly drawn dragon Pokemon Exeggutor ve never heard of coconuts hatching from eggs but in the Pokemon Garbodor enough Japanese hasn’t been released yet',\n",
              " 'there’s no denying that Elizabeth Taylor was a quite a bit about relationships before she died at age fiercest old Hollywood dame wasn’t nearly waxed poetic about his wife in his private impossibilities and my drunkenness, she is an ache we could get used to someone awkward between Elizabeth Taylor and the late Debbie going to carry a grudge pave diamond-heart necklace after one afraid to grow up,\" Dame neighbors would be spared if one of their infamous lovers’ quarrels I’ve always each other doesn’t work out? We’ve always',\n",
              " 'Her inspirational journey is encouraging others pageant contestant has taken to Instagram to share most common skincare problems that people experience but that doesn’t detract being bullied for her severe skin condition and despite some seriously be ashamed of with a litter of make-up free selfies didn\\'t sit at home comparing myself to others ॐ (@asprinkleofhealthandbeauty most recent posts to be the main culprits good always comes out of something ॐ (@asprinkleofhealthandbeauty breakouts!\" she writes High fat vegan plant based diet acnetreatment #loveyourself ॐ (@asprinkleofhealthandbeauty in the Miss']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_validation['generated_spoiler'] = final_spoilers"
      ],
      "metadata": {
        "id": "XeuQVbgrwMHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "# Define the tokenizer function\n",
        "tokenizer = TreebankWordTokenizer().tokenize\n",
        "\n",
        "# Tokenize the generated spoilers\n",
        "df_validation['tokenized_generated_spoiler'] = df_validation['generated_spoiler'].apply(tokenizer)\n",
        "df_validation['tokenized_spoiler'] = df_validation['spoiler'].apply(tokenizer)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T_KR7ZWTwMHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f74fca6-1da5-418e-f0b7-81ad8ecfe38d",
        "id": "aSetU8pxwMHK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.0.0+cu118)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.5.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.65.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->bert_score) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->bert_score) (16.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.14.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.13.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=3.0.0->bert_score) (2023.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Installing collected packages: bert_score\n",
            "Successfully installed bert_score-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bert_score import score\n",
        "\n",
        "total_precision, total_recall, total_f1, count = 0, 0, 0, 0\n",
        "\n",
        "for index, row in df_validation.iterrows():\n",
        "    if row['tags'] == \"multi\":\n",
        "        # Calculate the BERT score for each pair of sentences\n",
        "        scores = score([row['generated_spoiler']], [row['spoiler']], lang='en', verbose=False)\n",
        "\n",
        "        # Extract precision, recall, and F1 scores\n",
        "        precision, recall, f1 = scores\n",
        "\n",
        "        # Add to running total\n",
        "        total_precision += precision.mean()\n",
        "        total_recall += recall.mean()\n",
        "        total_f1 += f1.mean()\n",
        "        count += 1\n",
        "\n",
        "if count > 0:\n",
        "    # Calculate and print average scores\n",
        "    avg_precision = total_precision / count\n",
        "    avg_recall = total_recall / count\n",
        "    avg_f1 = total_f1 / count\n",
        "    print(f\"BERT precision score (average): {avg_precision:.4f}\")\n",
        "    print(f\"BERT recall score (average): {avg_recall:.4f}\")\n",
        "    print(f\"BERT F1 score (average): {avg_f1:.4f}\")\n",
        "else:\n",
        "    print(\"No rows with 'tags' equal to 'phrase' found in DataFrame\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "89eafe1a0aed49d08408eb01b2f41595",
            "e920630da58044e78ba230e9ded95660",
            "de6fae214f964797bcbbe758bd13d66b",
            "1ac1f04be6484cf984d097d92eb5b994",
            "7d764d23d82d4914a8552db49dce69fc",
            "ef18f14751634210bdce6a1ce7736865",
            "cbac79d2e18247e6bbc53ce598867f48",
            "368a103847724bde8198cca521dd047d",
            "72b0555bc9ee4cea8f982ab39755c67e",
            "4a3020f722fa42628ec46fb540b82b9d",
            "3f39e11daf9445918c997de5abdc32a2",
            "311e2f0501974eeda430362e446e9d60",
            "029e712d7e66432192a95a6263c230c3",
            "53062eab40484ce29069c32d1b2817ce",
            "5edebec614e1419da88989bf1296f906",
            "3fe019993b9c4862932fa5771a46dfbd",
            "9b42c2a4647f41839d18ffdc5e4f7e8d",
            "3512f1c6b6db4402955dd7c7150c2644",
            "873ae62fd5974c20aebb8d714b306476",
            "c850a7eb852c4c1099b3f27fa78bd516",
            "d685d46ed4cc41e3860bc73b0c96562a",
            "6be0bc77ec0e42fd8f97b3d5d9a72b42",
            "57b30d168e9c4f62ac9bfa73883903e7",
            "ab7adb8901bd4185ae534b3167c97830",
            "bf6ae60dd7724b099e5c5835c7d27b95",
            "cf03d795aea04050a3e5ba9516b23ae8",
            "145b30f0413748d68c234e69f0ec11ac",
            "36d4a2da1a724a3d8e5c14445a7d6e5c",
            "5ca07a58a689401c982829e0b44f1ee4",
            "4dc2fa0a0d66490aacab3c9f9ceb64e7",
            "e68e7e75059049b98bbe06d471bc3f40",
            "10be1dab9adf4d55a060924f8c2ec3f5",
            "a3ba08cf516248fbbcf1b880278c01a8",
            "3974c37f6ccd42fd9be810bec67fc6df",
            "80d61df1643946bca0b7f574fd196135",
            "d196a33ce7334c6f91ee71c70af0a8ef",
            "f4df8dff31894278ac92ce51276b23a8",
            "03fe43a2c1da44f6853e4a01e73d53f8",
            "c2fe0fe4e9114409b40a3a67007812c0",
            "feebaf844370461296ee9ed5aa7d5694",
            "97dd9564aa52478689a70b885e79f405",
            "9331e152cfcf49f69b3006c959fa7885",
            "4722439b9b05445bba229227fad75531",
            "e72a109f9ae740f0988c55731e954b56"
          ]
        },
        "outputId": "48490018-a640-44b0-9567-ef71d5699b15",
        "id": "rGkjBlxqwMHK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89eafe1a0aed49d08408eb01b2f41595"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "311e2f0501974eeda430362e446e9d60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57b30d168e9c4f62ac9bfa73883903e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3974c37f6ccd42fd9be810bec67fc6df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT precision score (average): 0.7946\n",
            "BERT recall score (average): 0.8352\n",
            "BERT F1 score (average): 0.8141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9cfb115-d4cd-4887-9fd4-67b4d011f34f",
        "id": "Xv4TPNLkwMHK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc6c34a-69af-4be8-acb0-6a8532a25802",
        "id": "mmiKh-eYwMHK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate import meteor_score\n",
        "\n",
        "meteor_scores = []\n",
        "\n",
        "for index, row in df_validation.iterrows():\n",
        "    if row['tags'] == \"multi\":\n",
        "        ref = row['spoiler']\n",
        "        hyp = row['generated_spoiler']\n",
        "\n",
        "        ref_tokens = nltk.word_tokenize(ref)\n",
        "        hyp_tokens = nltk.word_tokenize(hyp)\n",
        "\n",
        "        score = meteor_score.meteor_score([ref_tokens], hyp_tokens)\n",
        "        meteor_scores.append(score)\n",
        "\n",
        "average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
        "print(f\"Average METEOR score: {average_meteor_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3447d6-dfcc-4c03-de64-5f63d5a36cfe",
        "id": "eziDMY82wMHK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average METEOR score: 0.22928763380649475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "bleu_scores = []\n",
        "\n",
        "for index, row in df_validation.iterrows():\n",
        "    if row['tags'] == \"multi\":\n",
        "        true_spoiler = row['tokenized_spoiler']\n",
        "        myoutput = row['tokenized_generated_spoiler']\n",
        "        bleu_score = nltk.translate.bleu_score.sentence_bleu([true_spoiler], myoutput)\n",
        "        bleu_scores.append(bleu_score)\n",
        "\n",
        "average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "print(f\"Average BLEU score for multi: {average_bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REV2DDG0Qf-o",
        "outputId": "9b2e13bf-587a-4df2-9cde-6f4cf0e67f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU score for multi: 0.04048916814793454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_validation[['spoiler','generated_spoiler']])"
      ],
      "metadata": {
        "id": "KfNgT2tTwMHK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}